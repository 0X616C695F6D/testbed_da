<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>compute_matlab_samples</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        const { svg } = await mermaid.render(id, raw, el);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=82c77d20">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">funcs</span>
<span class="kn">import</span> <span class="nn">jan</span>
<span class="kn">import</span> <span class="nn">coral</span>
<span class="kn">import</span> <span class="nn">star</span>
<span class="kn">import</span> <span class="nn">mcd</span>
<span class="kn">import</span> <span class="nn">dann</span>
<span class="kn">import</span> <span class="nn">base</span>
<span class="kn">import</span> <span class="nn">plots</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=0d5022b5-1350-4b3b-8bcc-c653e90518d2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Load testbed data</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="s2">"/home/ash/ic3/testbed_da/data"</span>

<span class="c1"># Classes</span>
<span class="n">class_subset</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"bpsk"</span><span class="p">,</span> <span class="s2">"qpsk"</span><span class="p">,</span> <span class="s2">"4qam"</span><span class="p">,</span> <span class="s2">"16qam"</span><span class="p">,</span> <span class="s2">"apsk"</span><span class="p">]</span>

<span class="c1"># Split source, target</span>
<span class="c1"># try selecting some of the mods, not all</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span> <span class="o">+</span> <span class="s2">"/SNR_X.npy"</span><span class="p">)</span> <span class="c1"># tmpSNR_ does not include 4qam. SNR_ does.</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span> <span class="o">+</span> <span class="s2">"/SNR_Y.npy"</span><span class="p">)</span>

<span class="n">doppler_offset_source</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">doppler_offset_target</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">base_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dann_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">star_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mcd_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">coral_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">jan_acc</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">):</span>    
    <span class="n">source_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">doppler_offset_source</span><span class="p">)</span>
    <span class="n">target_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">doppler_offset_target</span><span class="p">)</span>
    
    <span class="n">X_s</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">source_mask</span><span class="p">]</span>
    <span class="n">Y_s</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">source_mask</span><span class="p">]</span>
    <span class="n">Y_s</span> <span class="o">=</span> <span class="n">Y_s</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">X_t</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">target_mask</span><span class="p">]</span>
    <span class="n">Y_t</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">target_mask</span><span class="p">]</span>
    <span class="n">Y_t</span> <span class="o">=</span> <span class="n">Y_t</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>

    
    <span class="c1"># Dataloaders</span>
    <span class="n">S_train_loader</span><span class="p">,</span> <span class="n">S_val_loader</span> <span class="o">=</span> <span class="n">funcs</span><span class="o">.</span><span class="n">create_loader</span><span class="p">(</span><span class="n">X_s</span><span class="p">,</span> <span class="n">Y_s</span><span class="p">,</span> <span class="n">permute</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">T_train_loader</span><span class="p">,</span> <span class="n">T_val_loader</span> <span class="o">=</span> <span class="n">funcs</span><span class="o">.</span><span class="n">create_loader</span><span class="p">(</span><span class="n">X_t</span><span class="p">,</span> <span class="n">Y_t</span><span class="p">,</span> <span class="n">permute</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">t_base</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">Base</span><span class="p">(</span><span class="n">model_cls</span><span class="o">=</span><span class="n">base</span><span class="o">.</span><span class="n">CLDNN</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">S_train_loader</span><span class="o">=</span><span class="n">S_train_loader</span><span class="p">,</span> 
                    <span class="n">S_val_loader</span><span class="o">=</span><span class="n">S_val_loader</span><span class="p">,</span> <span class="n">T_val_loader</span><span class="o">=</span><span class="n">T_val_loader</span><span class="p">,</span> <span class="n">class_subset</span><span class="o">=</span><span class="n">class_subset</span><span class="p">,</span> 
                    <span class="n">n_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_subset</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_runs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="n">base_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t_base</span><span class="p">)</span>
    
    <span class="n">_</span><span class="p">,</span> <span class="n">t_dan</span> <span class="o">=</span> <span class="n">dann</span><span class="o">.</span><span class="n">DAN</span><span class="p">(</span><span class="n">dann</span><span class="o">.</span><span class="n">DANN</span><span class="p">,</span> <span class="n">FA</span><span class="o">=</span><span class="n">dann</span><span class="o">.</span><span class="n">CLDNN_FA</span><span class="p">,</span> <span class="n">LP</span><span class="o">=</span><span class="n">dann</span><span class="o">.</span><span class="n">CLDNN_LP</span><span class="p">,</span> <span class="n">DC</span><span class="o">=</span><span class="n">dann</span><span class="o">.</span><span class="n">CLDNN_DC</span><span class="p">,</span>
                      <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">S_train_loader</span><span class="o">=</span><span class="n">S_train_loader</span><span class="p">,</span> <span class="n">S_val_loader</span><span class="o">=</span><span class="n">S_val_loader</span><span class="p">,</span>
                      <span class="n">T_train_loader</span><span class="o">=</span><span class="n">T_train_loader</span><span class="p">,</span> <span class="n">T_val_loader</span><span class="o">=</span><span class="n">T_val_loader</span><span class="p">,</span>
                      <span class="n">class_subset</span><span class="o">=</span><span class="n">class_subset</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_subset</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                      <span class="n">n_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">n_runs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="n">dann_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t_dan</span><span class="p">)</span>
    
    <span class="n">_</span><span class="p">,</span> <span class="n">t_star</span> <span class="o">=</span> <span class="n">star</span><span class="o">.</span><span class="n">Star</span><span class="p">(</span><span class="n">G</span><span class="o">=</span><span class="n">star</span><span class="o">.</span><span class="n">CLDNN_G</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">star</span><span class="o">.</span><span class="n">CLDNN_C</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">S_train_loader</span><span class="o">=</span><span class="n">S_train_loader</span><span class="p">,</span> <span class="n">S_val_loader</span><span class="o">=</span><span class="n">S_val_loader</span><span class="p">,</span>  
               <span class="n">T_train_loader</span><span class="o">=</span><span class="n">T_train_loader</span><span class="p">,</span> <span class="n">T_val_loader</span><span class="o">=</span><span class="n">T_val_loader</span><span class="p">,</span> <span class="n">class_subset</span><span class="o">=</span><span class="n">class_subset</span><span class="p">,</span>
               <span class="n">n_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_subset</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_runs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="n">star_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t_star</span><span class="p">)</span>
    
    <span class="n">_</span><span class="p">,</span> <span class="n">t_mcd</span> <span class="o">=</span> <span class="n">mcd</span><span class="o">.</span><span class="n">Mcd</span><span class="p">(</span><span class="n">G</span><span class="o">=</span><span class="n">mcd</span><span class="o">.</span><span class="n">CLDNN_G</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">mcd</span><span class="o">.</span><span class="n">CLDNN_C</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">S_train_loader</span><span class="o">=</span><span class="n">S_train_loader</span><span class="p">,</span> <span class="n">S_val_loader</span><span class="o">=</span><span class="n">S_val_loader</span><span class="p">,</span>  
               <span class="n">T_train_loader</span><span class="o">=</span><span class="n">T_train_loader</span><span class="p">,</span> <span class="n">T_val_loader</span><span class="o">=</span><span class="n">T_val_loader</span><span class="p">,</span> <span class="n">class_subset</span><span class="o">=</span><span class="n">class_subset</span><span class="p">,</span>
               <span class="n">n_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_subset</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_runs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="n">mcd_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t_mcd</span><span class="p">)</span>
    
    <span class="n">_</span><span class="p">,</span> <span class="n">t_coral</span> <span class="o">=</span> <span class="n">coral</span><span class="o">.</span><span class="n">Coral</span><span class="p">(</span><span class="n">G</span><span class="o">=</span><span class="n">coral</span><span class="o">.</span><span class="n">CLDNN_G</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">coral</span><span class="o">.</span><span class="n">CLDNN_C</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">S_train_loader</span><span class="o">=</span><span class="n">S_train_loader</span><span class="p">,</span>
                           <span class="n">S_val_loader</span><span class="o">=</span><span class="n">S_val_loader</span><span class="p">,</span> <span class="n">T_train_loader</span><span class="o">=</span><span class="n">T_train_loader</span><span class="p">,</span> <span class="n">T_val_loader</span><span class="o">=</span><span class="n">T_val_loader</span><span class="p">,</span>
                           <span class="n">class_subset</span><span class="o">=</span><span class="n">class_subset</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_subset</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_runs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                           <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lambda_coral</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="n">coral_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t_coral</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">t_jan</span> <span class="o">=</span> <span class="n">jan</span><span class="o">.</span><span class="n">Jan</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_subset</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">S_train_loader</span><span class="o">=</span><span class="n">S_train_loader</span><span class="p">,</span>
                     <span class="n">T_train_loader</span><span class="o">=</span><span class="n">T_train_loader</span><span class="p">,</span> <span class="n">S_val_loader</span><span class="o">=</span><span class="n">S_val_loader</span><span class="p">,</span> <span class="n">T_val_loader</span><span class="o">=</span><span class="n">T_val_loader</span><span class="p">,</span>
                     <span class="n">n_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">lambda_jmmd</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_runs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="n">jan_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t_jan</span><span class="p">)</span>
    
    <span class="n">doppler_offset_target</span> <span class="o">+=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
Run 1/10
Epoch 1/50, Train Loss: 1.4118, Train Acc: 0.3700, Val Loss: 0.9550, Val Acc: 0.4055
Epoch 2/50, Train Loss: 0.7938, Train Acc: 0.5429, Val Loss: 0.4011, Val Acc: 0.8030
Epoch 3/50, Train Loss: 0.6790, Train Acc: 0.6645, Val Loss: 1.4440, Val Acc: 0.4197
Epoch 4/50, Train Loss: 0.7248, Train Acc: 0.7672, Val Loss: 0.1255, Val Acc: 0.9983
Epoch 5/50, Train Loss: 0.3259, Train Acc: 0.8521, Val Loss: 0.0041, Val Acc: 0.9993
Epoch 6/50, Train Loss: 0.3953, Train Acc: 0.9131, Val Loss: 3.6859, Val Acc: 0.5879
Epoch 7/50, Train Loss: 0.3824, Train Acc: 0.9117, Val Loss: 0.0754, Val Acc: 0.9944
Epoch 8/50, Train Loss: 0.7474, Train Acc: 0.8792, Val Loss: 0.1511, Val Acc: 0.9902
Epoch 9/50, Train Loss: 0.7848, Train Acc: 0.7921, Val Loss: 0.2853, Val Acc: 0.7979
Epoch 10/50, Train Loss: 0.2486, Train Acc: 0.9544, Val Loss: 0.0025, Val Acc: 0.9993
Epoch 11/50, Train Loss: 0.0071, Train Acc: 0.9991, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0054, Train Acc: 0.9995, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0052, Train Acc: 0.9995, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0045, Train Acc: 0.9993, Val Loss: 0.0019, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0047, Train Acc: 0.9995, Val Loss: 0.0018, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0045, Train Acc: 0.9994, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0042, Train Acc: 0.9994, Val Loss: 0.0011, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0042, Train Acc: 0.9996, Val Loss: 0.0019, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0045, Train Acc: 0.9992, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0036, Train Acc: 0.9997, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0036, Train Acc: 0.9996, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0032, Train Acc: 0.9997, Val Loss: 0.0011, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0037, Train Acc: 0.9996, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0034, Train Acc: 0.9997, Val Loss: 0.0012, Val Acc: 0.9998
Epoch 26/50, Train Loss: 0.0034, Train Acc: 0.9997, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 27/50, Train Loss: 0.0036, Train Acc: 0.9997, Val Loss: 0.0012, Val Acc: 0.9998
Epoch 28/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0016, Val Acc: 0.9998
Early stopping!

Run 2/10
Epoch 1/50, Train Loss: 1.4434, Train Acc: 0.4221, Val Loss: 0.6489, Val Acc: 0.5520
Epoch 2/50, Train Loss: 0.9772, Train Acc: 0.6671, Val Loss: 2.1462, Val Acc: 0.4119
Epoch 3/50, Train Loss: 0.7633, Train Acc: 0.5820, Val Loss: 0.6992, Val Acc: 0.5574
Epoch 4/50, Train Loss: 0.4948, Train Acc: 0.7288, Val Loss: 0.5715, Val Acc: 0.5813
Epoch 5/50, Train Loss: 0.7518, Train Acc: 0.7588, Val Loss: 0.1261, Val Acc: 0.9954
Epoch 6/50, Train Loss: 0.7205, Train Acc: 0.8640, Val Loss: 0.4029, Val Acc: 0.7942
Epoch 7/50, Train Loss: 0.7302, Train Acc: 0.7965, Val Loss: 0.0818, Val Acc: 0.9985
Epoch 8/50, Train Loss: 0.2505, Train Acc: 0.8853, Val Loss: 0.1452, Val Acc: 0.8074
Epoch 9/50, Train Loss: 0.2685, Train Acc: 0.9056, Val Loss: 0.1218, Val Acc: 0.9307
Epoch 10/50, Train Loss: 0.2119, Train Acc: 0.9153, Val Loss: 0.8269, Val Acc: 0.7913
Epoch 11/50, Train Loss: 0.0200, Train Acc: 0.9956, Val Loss: 0.0028, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0054, Train Acc: 0.9993, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0045, Train Acc: 0.9995, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0033, Train Acc: 0.9995, Val Loss: 0.0020, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0028, Train Acc: 0.9995, Val Loss: 0.0019, Val Acc: 0.9993
Early stopping!

Run 3/10
Epoch 1/50, Train Loss: 1.3957, Train Acc: 0.3465, Val Loss: 0.6547, Val Acc: 0.6484
Epoch 2/50, Train Loss: 0.8652, Train Acc: 0.6503, Val Loss: 0.3121, Val Acc: 0.8071
Epoch 3/50, Train Loss: 0.6089, Train Acc: 0.7659, Val Loss: 0.2503, Val Acc: 0.8010
Epoch 4/50, Train Loss: 0.7578, Train Acc: 0.7499, Val Loss: 0.1534, Val Acc: 0.9995
Epoch 5/50, Train Loss: 0.3671, Train Acc: 0.8075, Val Loss: 0.3309, Val Acc: 0.8030
Epoch 6/50, Train Loss: 0.2867, Train Acc: 0.8636, Val Loss: 0.2706, Val Acc: 0.7998
Epoch 7/50, Train Loss: 0.2709, Train Acc: 0.9086, Val Loss: 0.3556, Val Acc: 0.8093
Epoch 8/50, Train Loss: 0.2516, Train Acc: 0.9095, Val Loss: 0.1275, Val Acc: 0.9980
Epoch 9/50, Train Loss: 0.2096, Train Acc: 0.9163, Val Loss: 0.9564, Val Acc: 0.8035
Epoch 10/50, Train Loss: 0.3538, Train Acc: 0.9103, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 11/50, Train Loss: 0.0055, Train Acc: 0.9992, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0050, Train Acc: 0.9993, Val Loss: 0.0011, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0045, Train Acc: 0.9993, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0037, Train Acc: 0.9995, Val Loss: 0.0012, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0034, Train Acc: 0.9995, Val Loss: 0.0006, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0045, Train Acc: 0.9995, Val Loss: 0.0005, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0005, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0041, Train Acc: 0.9991, Val Loss: 0.0042, Val Acc: 0.9990
Epoch 19/50, Train Loss: 0.0042, Train Acc: 0.9995, Val Loss: 0.0060, Val Acc: 0.9983
Epoch 20/50, Train Loss: 0.0037, Train Acc: 0.9995, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0028, Train Acc: 0.9997, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0028, Train Acc: 0.9997, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 23/50, Train Loss: 0.0028, Train Acc: 0.9998, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 24/50, Train Loss: 0.0032, Train Acc: 0.9996, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 25/50, Train Loss: 0.0030, Train Acc: 0.9997, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 26/50, Train Loss: 0.0030, Train Acc: 0.9998, Val Loss: 0.0000, Val Acc: 1.0000
Epoch 27/50, Train Loss: 0.0028, Train Acc: 0.9998, Val Loss: 0.0000, Val Acc: 1.0000
Epoch 28/50, Train Loss: 0.0027, Train Acc: 0.9998, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 29/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0000, Val Acc: 1.0000
Epoch 30/50, Train Loss: 0.0027, Train Acc: 0.9997, Val Loss: 0.0002, Val Acc: 1.0000
Epoch 31/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 32/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0000, Val Acc: 1.0000
Epoch 33/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0000, Val Acc: 1.0000
Epoch 34/50, Train Loss: 0.0025, Train Acc: 0.9998, Val Loss: 0.0000, Val Acc: 1.0000
Early stopping!

Run 4/10
Epoch 1/50, Train Loss: 1.4104, Train Acc: 0.3425, Val Loss: 2.1538, Val Acc: 0.2119
Epoch 2/50, Train Loss: 0.6977, Train Acc: 0.6962, Val Loss: 0.2474, Val Acc: 0.9412
Epoch 3/50, Train Loss: 0.3990, Train Acc: 0.8031, Val Loss: 0.2950, Val Acc: 0.8071
Epoch 4/50, Train Loss: 0.7035, Train Acc: 0.7443, Val Loss: 1.4740, Val Acc: 0.6069
Epoch 5/50, Train Loss: 0.4679, Train Acc: 0.8142, Val Loss: 0.1170, Val Acc: 0.9998
Epoch 6/50, Train Loss: 0.2301, Train Acc: 0.8535, Val Loss: 0.2236, Val Acc: 0.8064
Epoch 7/50, Train Loss: 0.2127, Train Acc: 0.8666, Val Loss: 0.4343, Val Acc: 0.8049
Epoch 8/50, Train Loss: 0.2095, Train Acc: 0.8774, Val Loss: 0.1601, Val Acc: 0.8071
Epoch 9/50, Train Loss: 0.2054, Train Acc: 0.9016, Val Loss: 0.2263, Val Acc: 0.8398
Epoch 10/50, Train Loss: 0.4305, Train Acc: 0.8903, Val Loss: 0.0049, Val Acc: 0.9998
Epoch 11/50, Train Loss: 0.0056, Train Acc: 0.9993, Val Loss: 0.0018, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0020, Val Acc: 0.9993
Epoch 13/50, Train Loss: 0.0030, Train Acc: 0.9995, Val Loss: 0.0021, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0023, Val Acc: 0.9993
Epoch 16/50, Train Loss: 0.0024, Train Acc: 0.9995, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0018, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0025, Train Acc: 0.9995, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0019, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0012, Val Acc: 0.9995
Epoch 21/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9998
Early stopping!

Run 5/10
Epoch 1/50, Train Loss: 1.2490, Train Acc: 0.4479, Val Loss: 0.4409, Val Acc: 0.7900
Epoch 2/50, Train Loss: 0.8439, Train Acc: 0.5964, Val Loss: 0.9139, Val Acc: 0.4495
Epoch 3/50, Train Loss: 0.6042, Train Acc: 0.6508, Val Loss: 0.6713, Val Acc: 0.5583
Epoch 4/50, Train Loss: 0.5280, Train Acc: 0.8069, Val Loss: 0.0153, Val Acc: 0.9998
Epoch 5/50, Train Loss: 0.4444, Train Acc: 0.9011, Val Loss: 0.7597, Val Acc: 0.7344
Epoch 6/50, Train Loss: 0.9183, Train Acc: 0.7887, Val Loss: 0.8701, Val Acc: 0.7986
Epoch 7/50, Train Loss: 0.5654, Train Acc: 0.8392, Val Loss: 0.7894, Val Acc: 0.7861
Epoch 8/50, Train Loss: 0.2866, Train Acc: 0.9191, Val Loss: 0.0024, Val Acc: 0.9995
Epoch 9/50, Train Loss: 0.2973, Train Acc: 0.9405, Val Loss: 0.0022, Val Acc: 0.9995
Epoch 10/50, Train Loss: 0.5807, Train Acc: 0.8778, Val Loss: 0.0638, Val Acc: 0.9995
Epoch 11/50, Train Loss: 0.0145, Train Acc: 0.9993, Val Loss: 0.0016, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0027, Train Acc: 0.9997, Val Loss: 0.0009, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0030, Train Acc: 0.9998, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0023, Train Acc: 0.9997, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0386, Train Acc: 0.9929, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0011, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0024, Train Acc: 0.9998, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0008, Val Acc: 0.9995
Epoch 21/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 22/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 23/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0002, Val Acc: 1.0000
Epoch 25/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 26/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 27/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 28/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 29/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 30/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0004, Val Acc: 0.9998
Early stopping!

Run 6/10
Epoch 1/50, Train Loss: 1.4472, Train Acc: 0.3946, Val Loss: 2.4091, Val Acc: 0.2119
Epoch 2/50, Train Loss: 0.9228, Train Acc: 0.6068, Val Loss: 0.5428, Val Acc: 0.5732
Epoch 3/50, Train Loss: 0.4665, Train Acc: 0.7239, Val Loss: 0.6293, Val Acc: 0.5811
Epoch 4/50, Train Loss: 0.7868, Train Acc: 0.7577, Val Loss: 0.8153, Val Acc: 0.6143
Epoch 5/50, Train Loss: 0.8061, Train Acc: 0.7307, Val Loss: 0.1495, Val Acc: 0.9265
Epoch 6/50, Train Loss: 0.3022, Train Acc: 0.8167, Val Loss: 0.2221, Val Acc: 0.8069
Epoch 7/50, Train Loss: 0.2441, Train Acc: 0.8496, Val Loss: 0.2746, Val Acc: 0.8005
Epoch 8/50, Train Loss: 0.5753, Train Acc: 0.8384, Val Loss: 0.2205, Val Acc: 0.8291
Epoch 9/50, Train Loss: 0.3989, Train Acc: 0.8727, Val Loss: 0.1281, Val Acc: 0.9312
Epoch 10/50, Train Loss: 0.1788, Train Acc: 0.9033, Val Loss: 0.5380, Val Acc: 0.7961
Epoch 11/50, Train Loss: 0.0221, Train Acc: 0.9915, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0040, Train Acc: 0.9993, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0044, Train Acc: 0.9995, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0043, Train Acc: 0.9995, Val Loss: 0.0017, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0047, Train Acc: 0.9995, Val Loss: 0.0035, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0116, Train Acc: 0.9960, Val Loss: 0.0019, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0045, Train Acc: 0.9991, Val Loss: 0.0032, Val Acc: 0.9993
Epoch 18/50, Train Loss: 0.0050, Train Acc: 0.9994, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0033, Train Acc: 0.9996, Val Loss: 0.0012, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0040, Train Acc: 0.9996, Val Loss: 0.0009, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0027, Train Acc: 0.9997, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0024, Train Acc: 0.9998, Val Loss: 0.0014, Val Acc: 0.9998
Early stopping!

Run 7/10
Epoch 1/50, Train Loss: 1.3571, Train Acc: 0.4210, Val Loss: 0.5212, Val Acc: 0.6792
Epoch 2/50, Train Loss: 0.9579, Train Acc: 0.6367, Val Loss: 0.4805, Val Acc: 0.6663
Epoch 3/50, Train Loss: 0.6115, Train Acc: 0.7563, Val Loss: 0.1168, Val Acc: 0.9958
Epoch 4/50, Train Loss: 0.8558, Train Acc: 0.8400, Val Loss: 1.3186, Val Acc: 0.7583
Epoch 5/50, Train Loss: 0.7792, Train Acc: 0.7369, Val Loss: 0.0704, Val Acc: 0.9951
Epoch 6/50, Train Loss: 0.6608, Train Acc: 0.7984, Val Loss: 0.2488, Val Acc: 0.7908
Epoch 7/50, Train Loss: 0.1063, Train Acc: 0.9651, Val Loss: 0.0060, Val Acc: 0.9995
Epoch 8/50, Train Loss: 0.2830, Train Acc: 0.9366, Val Loss: 0.5686, Val Acc: 0.8079
Epoch 9/50, Train Loss: 0.3996, Train Acc: 0.8912, Val Loss: 0.0023, Val Acc: 0.9993
Epoch 10/50, Train Loss: 0.7849, Train Acc: 0.8591, Val Loss: 0.5990, Val Acc: 0.7603
Epoch 11/50, Train Loss: 0.0206, Train Acc: 0.9949, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0063, Train Acc: 0.9994, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0066, Train Acc: 0.9985, Val Loss: 0.0005, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0031, Train Acc: 0.9995, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0023, Train Acc: 0.9997, Val Loss: 0.0005, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0003, Val Acc: 1.0000
Epoch 19/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0022, Train Acc: 0.9995, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0002, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 24/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 26/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0002, Val Acc: 0.9998
Epoch 27/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0002, Val Acc: 0.9998
Epoch 28/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0002, Val Acc: 0.9998
Early stopping!

Run 8/10
Epoch 1/50, Train Loss: 1.5023, Train Acc: 0.3890, Val Loss: 0.6072, Val Acc: 0.6133
Epoch 2/50, Train Loss: 0.9182, Train Acc: 0.6875, Val Loss: 1.7212, Val Acc: 0.4060
Epoch 3/50, Train Loss: 0.5560, Train Acc: 0.7522, Val Loss: 1.3400, Val Acc: 0.4209
Epoch 4/50, Train Loss: 1.0845, Train Acc: 0.5896, Val Loss: 1.8461, Val Acc: 0.4683
Epoch 5/50, Train Loss: 0.5879, Train Acc: 0.7617, Val Loss: 0.2510, Val Acc: 0.9312
Epoch 6/50, Train Loss: 0.5134, Train Acc: 0.8575, Val Loss: 0.1096, Val Acc: 0.9973
Epoch 7/50, Train Loss: 0.3841, Train Acc: 0.8950, Val Loss: 0.2521, Val Acc: 0.8074
Epoch 8/50, Train Loss: 0.7273, Train Acc: 0.8962, Val Loss: 0.1807, Val Acc: 0.8064
Epoch 9/50, Train Loss: 0.5327, Train Acc: 0.8364, Val Loss: 0.0175, Val Acc: 0.9961
Epoch 10/50, Train Loss: 0.5880, Train Acc: 0.8777, Val Loss: 0.0469, Val Acc: 0.9990
Epoch 11/50, Train Loss: 0.0092, Train Acc: 0.9990, Val Loss: 0.0011, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0063, Train Acc: 0.9992, Val Loss: 0.0012, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0046, Train Acc: 0.9992, Val Loss: 0.0020, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0044, Train Acc: 0.9993, Val Loss: 0.0009, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0040, Train Acc: 0.9993, Val Loss: 0.0009, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0047, Train Acc: 0.9993, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0048, Train Acc: 0.9992, Val Loss: 0.0012, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0038, Train Acc: 0.9996, Val Loss: 0.0012, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0039, Train Acc: 0.9995, Val Loss: 0.0010, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0032, Train Acc: 0.9996, Val Loss: 0.0010, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0031, Train Acc: 0.9996, Val Loss: 0.0007, Val Acc: 0.9995
Epoch 23/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0010, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0030, Train Acc: 0.9995, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0007, Val Acc: 0.9995
Epoch 26/50, Train Loss: 0.0030, Train Acc: 0.9996, Val Loss: 0.0007, Val Acc: 0.9995
Epoch 27/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0008, Val Acc: 0.9998
Early stopping!

Run 9/10
Epoch 1/50, Train Loss: 1.7144, Train Acc: 0.4027, Val Loss: 0.3602, Val Acc: 0.7917
Epoch 2/50, Train Loss: 1.4883, Train Acc: 0.6306, Val Loss: 0.5887, Val Acc: 0.6045
Epoch 3/50, Train Loss: 0.7542, Train Acc: 0.7292, Val Loss: 1.8019, Val Acc: 0.4663
Epoch 4/50, Train Loss: 0.8890, Train Acc: 0.7284, Val Loss: 0.1434, Val Acc: 0.9978
Epoch 5/50, Train Loss: 0.7557, Train Acc: 0.7231, Val Loss: 0.3294, Val Acc: 0.7937
Epoch 6/50, Train Loss: 0.4654, Train Acc: 0.8433, Val Loss: 0.0080, Val Acc: 0.9990
Epoch 7/50, Train Loss: 1.2527, Train Acc: 0.7798, Val Loss: 0.2203, Val Acc: 0.9785
Epoch 8/50, Train Loss: 0.5693, Train Acc: 0.8242, Val Loss: 0.1785, Val Acc: 0.8879
Epoch 9/50, Train Loss: 0.3828, Train Acc: 0.9426, Val Loss: 0.0059, Val Acc: 0.9988
Epoch 10/50, Train Loss: 0.8590, Train Acc: 0.8028, Val Loss: 0.1156, Val Acc: 0.9980
Epoch 11/50, Train Loss: 0.0219, Train Acc: 0.9988, Val Loss: 0.0041, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0060, Train Acc: 0.9991, Val Loss: 0.0023, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0038, Train Acc: 0.9993, Val Loss: 0.0021, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0041, Train Acc: 0.9993, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0041, Train Acc: 0.9993, Val Loss: 0.0019, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0025, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0037, Train Acc: 0.9995, Val Loss: 0.0021, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0099, Train Acc: 0.9976, Val Loss: 0.0037, Val Acc: 0.9993
Epoch 19/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0017, Val Acc: 0.9998
Early stopping!

Run 10/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.3816, Train Acc: 0.3652, Val Loss: 1.9513, Val Acc: 0.4119
Epoch 2/50, Train Loss: 0.9730, Train Acc: 0.5665, Val Loss: 0.9555, Val Acc: 0.4121
Epoch 3/50, Train Loss: 0.6160, Train Acc: 0.7113, Val Loss: 1.3131, Val Acc: 0.6287
Epoch 4/50, Train Loss: 0.6198, Train Acc: 0.8009, Val Loss: 0.7474, Val Acc: 0.8049
Epoch 5/50, Train Loss: 0.6399, Train Acc: 0.8246, Val Loss: 0.1652, Val Acc: 0.8752
Epoch 6/50, Train Loss: 0.6622, Train Acc: 0.8735, Val Loss: 0.0070, Val Acc: 0.9995
Epoch 7/50, Train Loss: 0.4134, Train Acc: 0.9230, Val Loss: 0.6566, Val Acc: 0.7988
Epoch 8/50, Train Loss: 0.5161, Train Acc: 0.8912, Val Loss: 0.2428, Val Acc: 0.8328
Epoch 9/50, Train Loss: 0.4873, Train Acc: 0.9155, Val Loss: 0.0037, Val Acc: 0.9995
Epoch 10/50, Train Loss: 0.4291, Train Acc: 0.9146, Val Loss: 0.4737, Val Acc: 0.8069
Epoch 11/50, Train Loss: 0.0174, Train Acc: 0.9943, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0075, Train Acc: 0.9995, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0069, Train Acc: 0.9994, Val Loss: 0.0010, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0065, Train Acc: 0.9995, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0062, Train Acc: 0.9995, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0055, Train Acc: 0.9995, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0054, Train Acc: 0.9996, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0049, Train Acc: 0.9995, Val Loss: 0.0009, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0043, Train Acc: 0.9996, Val Loss: 0.0007, Val Acc: 0.9998
Early stopping!

Source performance: 99.97 99.97 99.97 99.97
Target performance: 43.90 39.52 42.65 35.31

bpsk: 95.84
qpsk: 17.61
4qam: 0.01
16qam: 99.80
apsk: 0.00
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1560, Domain Loss: 1.4525, Class Loss: 1.7035
Epoch 2/25, Loss: 3.0240, Domain Loss: 1.3881, Class Loss: 1.6359
Epoch 3/25, Loss: 2.9242, Domain Loss: 1.3799, Class Loss: 1.5443
Epoch 4/25, Loss: 2.5161, Domain Loss: 1.4212, Class Loss: 1.0950
Epoch 5/25, Loss: 2.2291, Domain Loss: 1.3144, Class Loss: 0.9148
Epoch 6/25, Loss: 2.0102, Domain Loss: 1.2206, Class Loss: 0.7896
Epoch 7/25, Loss: 1.5417, Domain Loss: 1.1802, Class Loss: 0.3615
Epoch 8/25, Loss: 1.7633, Domain Loss: 1.1866, Class Loss: 0.5767
Epoch 9/25, Loss: 1.4220, Domain Loss: 1.1640, Class Loss: 0.2580
Epoch 10/25, Loss: 1.3037, Domain Loss: 1.1604, Class Loss: 0.1433
Epoch 11/25, Loss: 2.0192, Domain Loss: 1.2048, Class Loss: 0.8144
Epoch 12/25, Loss: 1.5739, Domain Loss: 1.2035, Class Loss: 0.3704
Epoch 13/25, Loss: 1.3146, Domain Loss: 1.1774, Class Loss: 0.1372
Epoch 14/25, Loss: 2.2001, Domain Loss: 1.2076, Class Loss: 0.9925
Epoch 15/25, Loss: 1.5747, Domain Loss: 1.1995, Class Loss: 0.3752
Epoch 16/25, Loss: 1.4555, Domain Loss: 1.1883, Class Loss: 0.2672
Epoch 17/25, Loss: 1.3834, Domain Loss: 1.1738, Class Loss: 0.2096
Epoch 18/25, Loss: 1.2938, Domain Loss: 1.1680, Class Loss: 0.1258
Epoch 19/25, Loss: 1.2194, Domain Loss: 1.1608, Class Loss: 0.0586
Epoch 20/25, Loss: 1.3558, Domain Loss: 1.1667, Class Loss: 0.1891
Epoch 21/25, Loss: 1.2241, Domain Loss: 1.1614, Class Loss: 0.0627
Epoch 22/25, Loss: 1.2503, Domain Loss: 1.2150, Class Loss: 0.0353
Epoch 23/25, Loss: 1.8821, Domain Loss: 1.3105, Class Loss: 0.5716
Epoch 24/25, Loss: 1.4128, Domain Loss: 1.2979, Class Loss: 0.1149
Epoch 25/25, Loss: 1.4901, Domain Loss: 1.4135, Class Loss: 0.0766
45.95


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1405, Domain Loss: 1.4265, Class Loss: 1.7140
Epoch 2/25, Loss: 3.2106, Domain Loss: 1.6524, Class Loss: 1.5582
Epoch 3/25, Loss: 3.3275, Domain Loss: 1.7296, Class Loss: 1.5979
Epoch 4/25, Loss: 2.3118, Domain Loss: 1.3768, Class Loss: 0.9350
Epoch 5/25, Loss: 2.2638, Domain Loss: 1.3797, Class Loss: 0.8841
Epoch 6/25, Loss: 1.7194, Domain Loss: 1.3248, Class Loss: 0.3946
Epoch 7/25, Loss: 2.0321, Domain Loss: 1.2825, Class Loss: 0.7496
Epoch 8/25, Loss: 1.5728, Domain Loss: 1.2371, Class Loss: 0.3357
Epoch 9/25, Loss: 1.3500, Domain Loss: 1.1729, Class Loss: 0.1771
Epoch 10/25, Loss: 1.3622, Domain Loss: 1.1715, Class Loss: 0.1907
Epoch 11/25, Loss: 1.8682, Domain Loss: 1.1721, Class Loss: 0.6961
Epoch 12/25, Loss: 1.5135, Domain Loss: 1.1724, Class Loss: 0.3411
Epoch 13/25, Loss: 1.3464, Domain Loss: 1.1699, Class Loss: 0.1765
Epoch 14/25, Loss: 1.3542, Domain Loss: 1.1728, Class Loss: 0.1814
Epoch 15/25, Loss: 1.4637, Domain Loss: 1.1640, Class Loss: 0.2998
Epoch 16/25, Loss: 1.2758, Domain Loss: 1.1772, Class Loss: 0.0986
Epoch 17/25, Loss: 1.1943, Domain Loss: 1.1740, Class Loss: 0.0203
Epoch 18/25, Loss: 3.5341, Domain Loss: 1.3068, Class Loss: 2.2273
Epoch 19/25, Loss: 1.5188, Domain Loss: 1.2172, Class Loss: 0.3015
Epoch 20/25, Loss: 1.4052, Domain Loss: 1.1995, Class Loss: 0.2057
Epoch 21/25, Loss: 1.3221, Domain Loss: 1.1745, Class Loss: 0.1477
Epoch 22/25, Loss: 1.2894, Domain Loss: 1.1735, Class Loss: 0.1160
Epoch 23/25, Loss: 1.2334, Domain Loss: 1.1694, Class Loss: 0.0640
Epoch 24/25, Loss: 1.1781, Domain Loss: 1.1640, Class Loss: 0.0142
Epoch 25/25, Loss: 1.1889, Domain Loss: 1.1713, Class Loss: 0.0176
46.83


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1535, Domain Loss: 1.4279, Class Loss: 1.7256
Epoch 2/25, Loss: 3.0206, Domain Loss: 1.3866, Class Loss: 1.6340
Epoch 3/25, Loss: 2.9890, Domain Loss: 1.4098, Class Loss: 1.5792
Epoch 4/25, Loss: 2.9264, Domain Loss: 1.4755, Class Loss: 1.4510
Epoch 5/25, Loss: 2.3338, Domain Loss: 1.3767, Class Loss: 0.9570
Epoch 6/25, Loss: 2.4343, Domain Loss: 1.3514, Class Loss: 1.0829
Epoch 7/25, Loss: 2.0146, Domain Loss: 1.3397, Class Loss: 0.6749
Epoch 8/25, Loss: 1.8266, Domain Loss: 1.2633, Class Loss: 0.5632
Epoch 9/25, Loss: 1.4944, Domain Loss: 1.1832, Class Loss: 0.3112
Epoch 10/25, Loss: 1.4955, Domain Loss: 1.1744, Class Loss: 0.3211
Epoch 11/25, Loss: 1.4307, Domain Loss: 1.1653, Class Loss: 0.2654
Epoch 12/25, Loss: 1.3327, Domain Loss: 1.1634, Class Loss: 0.1693
Epoch 13/25, Loss: 1.4771, Domain Loss: 1.1678, Class Loss: 0.3092
Epoch 14/25, Loss: 1.2871, Domain Loss: 1.1510, Class Loss: 0.1360
Epoch 15/25, Loss: 1.3769, Domain Loss: 1.1711, Class Loss: 0.2058
Epoch 16/25, Loss: 1.3015, Domain Loss: 1.1630, Class Loss: 0.1385
Epoch 17/25, Loss: 1.6744, Domain Loss: 1.2045, Class Loss: 0.4699
Epoch 18/25, Loss: 1.4769, Domain Loss: 1.2294, Class Loss: 0.2475
Epoch 19/25, Loss: 1.2956, Domain Loss: 1.1794, Class Loss: 0.1162
Epoch 20/25, Loss: 1.3050, Domain Loss: 1.1781, Class Loss: 0.1269
Epoch 21/25, Loss: 1.4660, Domain Loss: 1.1883, Class Loss: 0.2777
Epoch 22/25, Loss: 1.2539, Domain Loss: 1.1540, Class Loss: 0.0998
Epoch 23/25, Loss: 1.1725, Domain Loss: 1.1399, Class Loss: 0.0326
Epoch 24/25, Loss: 1.3803, Domain Loss: 1.1362, Class Loss: 0.2440
Epoch 25/25, Loss: 1.3936, Domain Loss: 1.1545, Class Loss: 0.2391
46.92


Epoch 1/25, Loss: 3.1693, Domain Loss: 1.4243, Class Loss: 1.7450
Epoch 2/25, Loss: 3.0143, Domain Loss: 1.3849, Class Loss: 1.6294
Epoch 3/25, Loss: 2.9310, Domain Loss: 1.4279, Class Loss: 1.5031
Epoch 4/25, Loss: 2.9102, Domain Loss: 1.4006, Class Loss: 1.5096
Epoch 5/25, Loss: 2.5138, Domain Loss: 1.3546, Class Loss: 1.1592
Epoch 6/25, Loss: 2.0641, Domain Loss: 1.3476, Class Loss: 0.7164
Epoch 7/25, Loss: 1.6755, Domain Loss: 1.2841, Class Loss: 0.3914
Epoch 8/25, Loss: 1.7223, Domain Loss: 1.1748, Class Loss: 0.5475
Epoch 9/25, Loss: 1.4016, Domain Loss: 1.1622, Class Loss: 0.2394
Epoch 10/25, Loss: 1.4848, Domain Loss: 1.1602, Class Loss: 0.3246
Epoch 11/25, Loss: 1.3650, Domain Loss: 1.1560, Class Loss: 0.2090
Epoch 12/25, Loss: 1.3499, Domain Loss: 1.1618, Class Loss: 0.1881
Epoch 13/25, Loss: 1.3278, Domain Loss: 1.1602, Class Loss: 0.1676
Epoch 14/25, Loss: 1.3312, Domain Loss: 1.1593, Class Loss: 0.1720
Epoch 15/25, Loss: 1.5594, Domain Loss: 1.1591, Class Loss: 0.4003
Epoch 16/25, Loss: 1.2746, Domain Loss: 1.1621, Class Loss: 0.1125
Epoch 17/25, Loss: 1.4647, Domain Loss: 1.1604, Class Loss: 0.3043
Epoch 18/25, Loss: 1.2782, Domain Loss: 1.1520, Class Loss: 0.1263
Epoch 19/25, Loss: 1.2157, Domain Loss: 1.1628, Class Loss: 0.0529
Epoch 20/25, Loss: 1.1790, Domain Loss: 1.1537, Class Loss: 0.0253
Epoch 21/25, Loss: 1.1691, Domain Loss: 1.1573, Class Loss: 0.0118
Epoch 22/25, Loss: 1.2024, Domain Loss: 1.1513, Class Loss: 0.0511
Epoch 23/25, Loss: 1.4667, Domain Loss: 1.1613, Class Loss: 0.3054
Epoch 24/25, Loss: 1.2458, Domain Loss: 1.1583, Class Loss: 0.0875
Epoch 25/25, Loss: 1.1850, Domain Loss: 1.1579, Class Loss: 0.0271
55.22


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1303, Domain Loss: 1.4212, Class Loss: 1.7091
Epoch 2/25, Loss: 2.9968, Domain Loss: 1.3885, Class Loss: 1.6083
Epoch 3/25, Loss: 2.4152, Domain Loss: 1.3102, Class Loss: 1.1051
Epoch 4/25, Loss: 2.1878, Domain Loss: 1.2691, Class Loss: 0.9187
Epoch 5/25, Loss: 1.8837, Domain Loss: 1.2501, Class Loss: 0.6336
Epoch 6/25, Loss: 1.5729, Domain Loss: 1.2314, Class Loss: 0.3415
Epoch 7/25, Loss: 2.5913, Domain Loss: 1.2934, Class Loss: 1.2979
Epoch 8/25, Loss: 1.7875, Domain Loss: 1.2375, Class Loss: 0.5500
Epoch 9/25, Loss: 1.5160, Domain Loss: 1.2335, Class Loss: 0.2825
Epoch 10/25, Loss: 1.5010, Domain Loss: 1.1752, Class Loss: 0.3258
Epoch 11/25, Loss: 1.3261, Domain Loss: 1.1519, Class Loss: 0.1742
Epoch 12/25, Loss: 1.2495, Domain Loss: 1.1308, Class Loss: 0.1187
Epoch 13/25, Loss: 2.2177, Domain Loss: 1.1797, Class Loss: 1.0380
Epoch 14/25, Loss: 1.4183, Domain Loss: 1.1470, Class Loss: 0.2713
Epoch 15/25, Loss: 1.3263, Domain Loss: 1.1376, Class Loss: 0.1887
Epoch 16/25, Loss: 1.2473, Domain Loss: 1.1414, Class Loss: 0.1059
Epoch 17/25, Loss: 1.5046, Domain Loss: 1.1324, Class Loss: 0.3722
Epoch 18/25, Loss: 1.6679, Domain Loss: 1.1616, Class Loss: 0.5064
Epoch 19/25, Loss: 1.2950, Domain Loss: 1.1404, Class Loss: 0.1546
Epoch 20/25, Loss: 1.1800, Domain Loss: 1.1350, Class Loss: 0.0449
Epoch 21/25, Loss: 1.1628, Domain Loss: 1.1390, Class Loss: 0.0238
Epoch 22/25, Loss: 1.1513, Domain Loss: 1.1401, Class Loss: 0.0113
Epoch 23/25, Loss: 1.1486, Domain Loss: 1.1424, Class Loss: 0.0062
Epoch 24/25, Loss: 1.1393, Domain Loss: 1.1330, Class Loss: 0.0064
Epoch 25/25, Loss: 1.1405, Domain Loss: 1.1386, Class Loss: 0.0020
55.93


Epoch 1/25, Loss: 3.1388, Domain Loss: 1.4374, Class Loss: 1.7015
Epoch 2/25, Loss: 2.6989, Domain Loss: 1.3772, Class Loss: 1.3217
Epoch 3/25, Loss: 2.4768, Domain Loss: 1.3073, Class Loss: 1.1696
Epoch 4/25, Loss: 2.1325, Domain Loss: 1.2608, Class Loss: 0.8717
Epoch 5/25, Loss: 2.7028, Domain Loss: 1.3911, Class Loss: 1.3117
Epoch 6/25, Loss: 1.9978, Domain Loss: 1.2810, Class Loss: 0.7167
Epoch 7/25, Loss: 2.1916, Domain Loss: 1.2329, Class Loss: 0.9587
Epoch 8/25, Loss: 1.5011, Domain Loss: 1.1606, Class Loss: 0.3405
Epoch 9/25, Loss: 1.4182, Domain Loss: 1.1508, Class Loss: 0.2674
Epoch 10/25, Loss: 1.6991, Domain Loss: 1.1647, Class Loss: 0.5345
Epoch 11/25, Loss: 1.4148, Domain Loss: 1.1713, Class Loss: 0.2435
Epoch 12/25, Loss: 1.3452, Domain Loss: 1.1490, Class Loss: 0.1963
Epoch 13/25, Loss: 1.3667, Domain Loss: 1.1622, Class Loss: 0.2045
Epoch 14/25, Loss: 1.7488, Domain Loss: 1.1618, Class Loss: 0.5870
Epoch 15/25, Loss: 1.7736, Domain Loss: 1.1619, Class Loss: 0.6118
Epoch 16/25, Loss: 1.3770, Domain Loss: 1.1349, Class Loss: 0.2421
Epoch 17/25, Loss: 1.2556, Domain Loss: 1.1335, Class Loss: 0.1221
Epoch 18/25, Loss: 1.2252, Domain Loss: 1.1427, Class Loss: 0.0825
Epoch 19/25, Loss: 1.1682, Domain Loss: 1.1463, Class Loss: 0.0218
Epoch 20/25, Loss: 2.6546, Domain Loss: 1.2254, Class Loss: 1.4292
Epoch 21/25, Loss: 1.5398, Domain Loss: 1.1704, Class Loss: 0.3694
Epoch 22/25, Loss: 1.3246, Domain Loss: 1.1381, Class Loss: 0.1865
Epoch 23/25, Loss: 1.2101, Domain Loss: 1.1234, Class Loss: 0.0867
Epoch 24/25, Loss: 1.4524, Domain Loss: 1.1419, Class Loss: 0.3105
Epoch 25/25, Loss: 1.3080, Domain Loss: 1.1555, Class Loss: 0.1525
45.75


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1220, Domain Loss: 1.4189, Class Loss: 1.7030
Epoch 2/25, Loss: 2.7645, Domain Loss: 1.3669, Class Loss: 1.3975
Epoch 3/25, Loss: 2.3122, Domain Loss: 1.2807, Class Loss: 1.0315
Epoch 4/25, Loss: 2.6055, Domain Loss: 1.4383, Class Loss: 1.1672
Epoch 5/25, Loss: 2.1384, Domain Loss: 1.2930, Class Loss: 0.8454
Epoch 6/25, Loss: 1.7227, Domain Loss: 1.1898, Class Loss: 0.5329
Epoch 7/25, Loss: 2.3934, Domain Loss: 1.2147, Class Loss: 1.1786
Epoch 8/25, Loss: 1.9435, Domain Loss: 1.2006, Class Loss: 0.7429
Epoch 9/25, Loss: 1.5110, Domain Loss: 1.1646, Class Loss: 0.3464
Epoch 10/25, Loss: 1.4572, Domain Loss: 1.1611, Class Loss: 0.2961
Epoch 11/25, Loss: 1.4799, Domain Loss: 1.1633, Class Loss: 0.3166
Epoch 12/25, Loss: 1.4221, Domain Loss: 1.1585, Class Loss: 0.2636
Epoch 13/25, Loss: 1.3767, Domain Loss: 1.1511, Class Loss: 0.2256
Epoch 14/25, Loss: 1.2252, Domain Loss: 1.1356, Class Loss: 0.0897
Epoch 15/25, Loss: 3.0496, Domain Loss: 1.2341, Class Loss: 1.8156
Epoch 16/25, Loss: 1.5850, Domain Loss: 1.1756, Class Loss: 0.4094
Epoch 17/25, Loss: 1.3360, Domain Loss: 1.1524, Class Loss: 0.1836
Epoch 18/25, Loss: 1.3039, Domain Loss: 1.1640, Class Loss: 0.1399
Epoch 19/25, Loss: 1.3910, Domain Loss: 1.1629, Class Loss: 0.2281
Epoch 20/25, Loss: 1.3151, Domain Loss: 1.1606, Class Loss: 0.1544
Epoch 21/25, Loss: 1.2775, Domain Loss: 1.1646, Class Loss: 0.1129
Epoch 22/25, Loss: 1.3557, Domain Loss: 1.1588, Class Loss: 0.1970
Epoch 23/25, Loss: 1.2062, Domain Loss: 1.1635, Class Loss: 0.0427
Epoch 24/25, Loss: 1.2419, Domain Loss: 1.1647, Class Loss: 0.0772
Epoch 25/25, Loss: 1.2643, Domain Loss: 1.1664, Class Loss: 0.0979
48.14


Epoch 1/25, Loss: 3.1560, Domain Loss: 1.4508, Class Loss: 1.7052
Epoch 2/25, Loss: 2.9821, Domain Loss: 1.3846, Class Loss: 1.5976
Epoch 3/25, Loss: 2.4472, Domain Loss: 1.3121, Class Loss: 1.1351
Epoch 4/25, Loss: 2.8547, Domain Loss: 1.3620, Class Loss: 1.4926
Epoch 5/25, Loss: 2.1763, Domain Loss: 1.3537, Class Loss: 0.8226
Epoch 6/25, Loss: 3.1335, Domain Loss: 1.3345, Class Loss: 1.7990
Epoch 7/25, Loss: 2.1390, Domain Loss: 1.2759, Class Loss: 0.8631
Epoch 8/25, Loss: 1.5349, Domain Loss: 1.1821, Class Loss: 0.3529
Epoch 9/25, Loss: 1.8979, Domain Loss: 1.1810, Class Loss: 0.7169
Epoch 10/25, Loss: 1.5070, Domain Loss: 1.1780, Class Loss: 0.3290
Epoch 11/25, Loss: 1.3894, Domain Loss: 1.1775, Class Loss: 0.2119
Epoch 12/25, Loss: 1.3637, Domain Loss: 1.1681, Class Loss: 0.1957
Epoch 13/25, Loss: 1.4131, Domain Loss: 1.1637, Class Loss: 0.2494
Epoch 14/25, Loss: 1.3305, Domain Loss: 1.1558, Class Loss: 0.1747
Epoch 15/25, Loss: 1.2921, Domain Loss: 1.1692, Class Loss: 0.1229
Epoch 16/25, Loss: 1.4644, Domain Loss: 1.1680, Class Loss: 0.2964
Epoch 17/25, Loss: 1.2516, Domain Loss: 1.1633, Class Loss: 0.0884
Epoch 18/25, Loss: 1.2296, Domain Loss: 1.1618, Class Loss: 0.0677
Epoch 19/25, Loss: 1.4775, Domain Loss: 1.1522, Class Loss: 0.3253
Epoch 20/25, Loss: 1.2548, Domain Loss: 1.1455, Class Loss: 0.1093
Epoch 21/25, Loss: 1.1422, Domain Loss: 1.1208, Class Loss: 0.0215
Epoch 22/25, Loss: 1.4082, Domain Loss: 1.1551, Class Loss: 0.2532
Epoch 23/25, Loss: 1.2265, Domain Loss: 1.1295, Class Loss: 0.0971
Epoch 24/25, Loss: 1.1317, Domain Loss: 1.1080, Class Loss: 0.0236
Epoch 25/25, Loss: 2.2036, Domain Loss: 1.1812, Class Loss: 1.0224
60.28


Epoch 1/25, Loss: 3.1160, Domain Loss: 1.4157, Class Loss: 1.7003
Epoch 2/25, Loss: 2.6730, Domain Loss: 1.3487, Class Loss: 1.3244
Epoch 3/25, Loss: 2.4125, Domain Loss: 1.2875, Class Loss: 1.1250
Epoch 4/25, Loss: 2.0580, Domain Loss: 1.2391, Class Loss: 0.8189
Epoch 5/25, Loss: 1.9328, Domain Loss: 1.2449, Class Loss: 0.6879
Epoch 6/25, Loss: 17.8240, Domain Loss: 4.4957, Class Loss: 13.3282
Epoch 7/25, Loss: 3.8937, Domain Loss: 2.1467, Class Loss: 1.7469
Epoch 8/25, Loss: 3.0534, Domain Loss: 1.4366, Class Loss: 1.6168
Epoch 9/25, Loss: 3.0725, Domain Loss: 1.4553, Class Loss: 1.6172
Epoch 10/25, Loss: 3.0915, Domain Loss: 1.4818, Class Loss: 1.6098
Epoch 11/25, Loss: 3.1473, Domain Loss: 1.5423, Class Loss: 1.6050
Epoch 12/25, Loss: 6.6452, Domain Loss: 5.0435, Class Loss: 1.6017
Epoch 13/25, Loss: 3.4874, Domain Loss: 1.8769, Class Loss: 1.6105
Epoch 14/25, Loss: 3.6482, Domain Loss: 2.0420, Class Loss: 1.6062
Epoch 15/25, Loss: 3.4059, Domain Loss: 1.8381, Class Loss: 1.5678
Epoch 16/25, Loss: 4.1029, Domain Loss: 2.4180, Class Loss: 1.6849
Epoch 17/25, Loss: 4.1480, Domain Loss: 2.6107, Class Loss: 1.5373
Epoch 18/25, Loss: 4.2651, Domain Loss: 2.7607, Class Loss: 1.5044
Epoch 19/25, Loss: 4.6536, Domain Loss: 3.2773, Class Loss: 1.3763
Epoch 20/25, Loss: 3.8790, Domain Loss: 2.6872, Class Loss: 1.1918
Epoch 21/25, Loss: 2.7787, Domain Loss: 1.8965, Class Loss: 0.8823
Epoch 22/25, Loss: 4.1046, Domain Loss: 2.2935, Class Loss: 1.8111
Epoch 23/25, Loss: 3.9341, Domain Loss: 2.5648, Class Loss: 1.3694
Epoch 24/25, Loss: 3.6057, Domain Loss: 2.0187, Class Loss: 1.5870
Epoch 25/25, Loss: 3.0977, Domain Loss: 1.7694, Class Loss: 1.3283
20.21


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1245, Domain Loss: 1.4161, Class Loss: 1.7084
Epoch 2/25, Loss: 2.7204, Domain Loss: 1.3755, Class Loss: 1.3448
Epoch 3/25, Loss: 2.5634, Domain Loss: 1.3674, Class Loss: 1.1960
Epoch 4/25, Loss: 2.2705, Domain Loss: 1.2610, Class Loss: 1.0095
Epoch 5/25, Loss: 1.8387, Domain Loss: 1.2101, Class Loss: 0.6286
Epoch 6/25, Loss: 1.6144, Domain Loss: 1.1560, Class Loss: 0.4584
Epoch 7/25, Loss: 1.4204, Domain Loss: 1.1725, Class Loss: 0.2479
Epoch 8/25, Loss: 1.4118, Domain Loss: 1.1640, Class Loss: 0.2479
Epoch 9/25, Loss: 1.4031, Domain Loss: 1.1678, Class Loss: 0.2353
Epoch 10/25, Loss: 1.8791, Domain Loss: 1.1774, Class Loss: 0.7017
Epoch 11/25, Loss: 1.3981, Domain Loss: 1.1630, Class Loss: 0.2351
Epoch 12/25, Loss: 1.2656, Domain Loss: 1.1659, Class Loss: 0.0997
Epoch 13/25, Loss: 1.8785, Domain Loss: 1.1849, Class Loss: 0.6936
Epoch 14/25, Loss: 1.4411, Domain Loss: 1.1374, Class Loss: 0.3036
Epoch 15/25, Loss: 1.3143, Domain Loss: 1.1300, Class Loss: 0.1842
Epoch 16/25, Loss: 1.2284, Domain Loss: 1.1361, Class Loss: 0.0922
Epoch 17/25, Loss: 1.1733, Domain Loss: 1.1304, Class Loss: 0.0429
Epoch 18/25, Loss: 1.4488, Domain Loss: 1.1386, Class Loss: 0.3103
Epoch 19/25, Loss: 1.2463, Domain Loss: 1.1326, Class Loss: 0.1137
Epoch 20/25, Loss: 2.2063, Domain Loss: 1.2225, Class Loss: 0.9838
Epoch 21/25, Loss: 1.6313, Domain Loss: 1.1799, Class Loss: 0.4514
Epoch 22/25, Loss: 1.3580, Domain Loss: 1.1572, Class Loss: 0.2008
Epoch 23/25, Loss: 1.2509, Domain Loss: 1.1398, Class Loss: 0.1111
Epoch 24/25, Loss: 1.2419, Domain Loss: 1.1363, Class Loss: 0.1057
Epoch 25/25, Loss: 1.2621, Domain Loss: 1.1310, Class Loss: 0.1312
42.99


Source performance:
93.94 91.48 93.82 92.16 
Target performance:
46.82 40.83 45.89 38.38 

Per-class target performance: 84.34 45.23 0.01 99.87 0.00 
Run 1/10
Epoch [1/50], Class Loss: 3.7758, Discrepancy Loss: 0.0872
Epoch [2/50], Class Loss: 0.9582, Discrepancy Loss: 0.0957
Epoch [3/50], Class Loss: 0.5164, Discrepancy Loss: 0.1045
Epoch [4/50], Class Loss: 0.4471, Discrepancy Loss: 0.1017
Epoch [5/50], Class Loss: 0.3937, Discrepancy Loss: 0.1079
Epoch [6/50], Class Loss: 0.3681, Discrepancy Loss: 0.0990
Epoch [7/50], Class Loss: 0.3118, Discrepancy Loss: 0.1019
Epoch [8/50], Class Loss: 0.2546, Discrepancy Loss: 0.0974
Epoch [9/50], Class Loss: 0.2527, Discrepancy Loss: 0.1005
Epoch [10/50], Class Loss: 0.1919, Discrepancy Loss: 0.0967
Epoch [11/50], Class Loss: 0.1567, Discrepancy Loss: 0.0907
Epoch [12/50], Class Loss: 0.1104, Discrepancy Loss: 0.0867
Epoch [13/50], Class Loss: 0.1148, Discrepancy Loss: 0.0909
Epoch [14/50], Class Loss: 0.0536, Discrepancy Loss: 0.0868
Epoch [15/50], Class Loss: 0.0297, Discrepancy Loss: 0.1122
Epoch [16/50], Class Loss: 0.0354, Discrepancy Loss: 0.1257
Epoch [17/50], Class Loss: 0.0523, Discrepancy Loss: 0.1415
Epoch [18/50], Class Loss: 0.1011, Discrepancy Loss: 0.1161
Epoch [19/50], Class Loss: 0.0364, Discrepancy Loss: 0.1274
Epoch [20/50], Class Loss: 0.0451, Discrepancy Loss: 0.1381
Epoch [21/50], Class Loss: 0.0804, Discrepancy Loss: 0.0919
Epoch [22/50], Class Loss: 0.0521, Discrepancy Loss: 0.1070
Epoch [23/50], Class Loss: 0.0415, Discrepancy Loss: 0.1144
Epoch [24/50], Class Loss: 0.0263, Discrepancy Loss: 0.1226
Epoch [25/50], Class Loss: 0.0242, Discrepancy Loss: 0.1284
Epoch [26/50], Class Loss: 0.0242, Discrepancy Loss: 0.1379
Epoch [27/50], Class Loss: 0.0290, Discrepancy Loss: 0.1352
Epoch [28/50], Class Loss: 0.0402, Discrepancy Loss: 0.1252
Epoch [29/50], Class Loss: 0.0273, Discrepancy Loss: 0.1326
Epoch [30/50], Class Loss: 0.0310, Discrepancy Loss: 0.1392
Epoch [31/50], Class Loss: 0.0295, Discrepancy Loss: 0.1334
Epoch [32/50], Class Loss: 0.0319, Discrepancy Loss: 0.1392
Epoch [33/50], Class Loss: 0.0287, Discrepancy Loss: 0.1370
Epoch [34/50], Class Loss: 0.0367, Discrepancy Loss: 0.1401
Epoch [35/50], Class Loss: 0.0410, Discrepancy Loss: 0.1387
Epoch [36/50], Class Loss: 0.0279, Discrepancy Loss: 0.1401
Epoch [37/50], Class Loss: 0.0319, Discrepancy Loss: 0.1384
Epoch [38/50], Class Loss: 0.0320, Discrepancy Loss: 0.1368
Epoch [39/50], Class Loss: 0.0321, Discrepancy Loss: 0.1444
Epoch [40/50], Class Loss: 0.0347, Discrepancy Loss: 0.1404
Epoch [41/50], Class Loss: 0.0294, Discrepancy Loss: 0.1354
Epoch [42/50], Class Loss: 0.0360, Discrepancy Loss: 0.1436
Epoch [43/50], Class Loss: 0.0311, Discrepancy Loss: 0.1449
Epoch [44/50], Class Loss: 0.0357, Discrepancy Loss: 0.1399
Epoch [45/50], Class Loss: 0.0345, Discrepancy Loss: 0.1391
Epoch [46/50], Class Loss: 0.0358, Discrepancy Loss: 0.1379
Epoch [47/50], Class Loss: 0.0363, Discrepancy Loss: 0.1359
Epoch [48/50], Class Loss: 0.0364, Discrepancy Loss: 0.1371
Epoch [49/50], Class Loss: 0.0396, Discrepancy Loss: 0.1409
Epoch [50/50], Class Loss: 0.0331, Discrepancy Loss: 0.1340
Source Domain Performance - Accuracy: 99.34%, Precision: 99.38%, Recall: 99.34%, F1 Score: 99.35%
Target Domain Performance - Accuracy: 47.31%, Precision: 42.52%, Recall: 46.32%, F1 Score: 42.69%

Run 2/10
Epoch [1/50], Class Loss: 3.8020, Discrepancy Loss: 0.0760
Epoch [2/50], Class Loss: 0.6815, Discrepancy Loss: 0.0980
Epoch [3/50], Class Loss: 0.5213, Discrepancy Loss: 0.0956
Epoch [4/50], Class Loss: 0.4149, Discrepancy Loss: 0.0917
Epoch [5/50], Class Loss: 0.4353, Discrepancy Loss: 0.1037
Epoch [6/50], Class Loss: 0.4416, Discrepancy Loss: 0.0944
Epoch [7/50], Class Loss: 0.3381, Discrepancy Loss: 0.0991
Epoch [8/50], Class Loss: 0.2451, Discrepancy Loss: 0.0978
Epoch [9/50], Class Loss: 0.2080, Discrepancy Loss: 0.1010
Epoch [10/50], Class Loss: 0.1877, Discrepancy Loss: 0.1027
Epoch [11/50], Class Loss: 0.1044, Discrepancy Loss: 0.1241
Epoch [12/50], Class Loss: 0.0722, Discrepancy Loss: 0.1189
Epoch [13/50], Class Loss: 0.0553, Discrepancy Loss: 0.1339
Epoch [14/50], Class Loss: 0.0630, Discrepancy Loss: 0.1265
Epoch [15/50], Class Loss: 0.0545, Discrepancy Loss: 0.1209
Epoch [16/50], Class Loss: 0.0455, Discrepancy Loss: 0.1263
Epoch [17/50], Class Loss: 0.0460, Discrepancy Loss: 0.1288
Epoch [18/50], Class Loss: 0.0382, Discrepancy Loss: 0.1169
Epoch [19/50], Class Loss: 0.0576, Discrepancy Loss: 0.0963
Epoch [20/50], Class Loss: 0.0316, Discrepancy Loss: 0.1110
Epoch [21/50], Class Loss: 0.0305, Discrepancy Loss: 0.1232
Epoch [22/50], Class Loss: 0.0338, Discrepancy Loss: 0.1153
Epoch [23/50], Class Loss: 0.0351, Discrepancy Loss: 0.1077
Epoch [24/50], Class Loss: 0.0399, Discrepancy Loss: 0.1212
Epoch [25/50], Class Loss: 0.0442, Discrepancy Loss: 0.1227
Epoch [26/50], Class Loss: 0.0403, Discrepancy Loss: 0.1294
Epoch [27/50], Class Loss: 0.0547, Discrepancy Loss: 0.1329
Epoch [28/50], Class Loss: 0.0368, Discrepancy Loss: 0.1380
Epoch [29/50], Class Loss: 0.0308, Discrepancy Loss: 0.1412
Epoch [30/50], Class Loss: 0.0406, Discrepancy Loss: 0.1398
Epoch [31/50], Class Loss: 0.0440, Discrepancy Loss: 0.1333
Epoch [32/50], Class Loss: 0.0417, Discrepancy Loss: 0.1342
Epoch [33/50], Class Loss: 0.0335, Discrepancy Loss: 0.1388
Epoch [34/50], Class Loss: 0.0350, Discrepancy Loss: 0.1365
Epoch [35/50], Class Loss: 0.0300, Discrepancy Loss: 0.1363
Epoch [36/50], Class Loss: 0.0359, Discrepancy Loss: 0.1361
Epoch [37/50], Class Loss: 0.0372, Discrepancy Loss: 0.1425
Epoch [38/50], Class Loss: 0.0360, Discrepancy Loss: 0.1351
Epoch [39/50], Class Loss: 0.0303, Discrepancy Loss: 0.1370
Epoch [40/50], Class Loss: 0.0281, Discrepancy Loss: 0.1370
Epoch [41/50], Class Loss: 0.0308, Discrepancy Loss: 0.1338
Epoch [42/50], Class Loss: 0.0287, Discrepancy Loss: 0.1414
Epoch [43/50], Class Loss: 0.0377, Discrepancy Loss: 0.1393
Epoch [44/50], Class Loss: 0.0383, Discrepancy Loss: 0.1391
Epoch [45/50], Class Loss: 0.0313, Discrepancy Loss: 0.1369
Epoch [46/50], Class Loss: 0.0322, Discrepancy Loss: 0.1360
Epoch [47/50], Class Loss: 0.0345, Discrepancy Loss: 0.1368
Epoch [48/50], Class Loss: 0.0307, Discrepancy Loss: 0.1403
Epoch [49/50], Class Loss: 0.0311, Discrepancy Loss: 0.1344
Epoch [50/50], Class Loss: 0.0376, Discrepancy Loss: 0.1430
Source Domain Performance - Accuracy: 99.51%, Precision: 99.52%, Recall: 99.51%, F1 Score: 99.51%
Target Domain Performance - Accuracy: 42.33%, Precision: 33.74%, Recall: 41.09%, F1 Score: 35.75%

Run 3/10
Epoch [1/50], Class Loss: 3.8828, Discrepancy Loss: 0.0862
Epoch [2/50], Class Loss: 1.2201, Discrepancy Loss: 0.0982
Epoch [3/50], Class Loss: 0.6917, Discrepancy Loss: 0.0889
Epoch [4/50], Class Loss: 0.7715, Discrepancy Loss: 0.0928
Epoch [5/50], Class Loss: 0.5802, Discrepancy Loss: 0.0963
Epoch [6/50], Class Loss: 0.4086, Discrepancy Loss: 0.0955
Epoch [7/50], Class Loss: 0.3604, Discrepancy Loss: 0.0944
Epoch [8/50], Class Loss: 0.3650, Discrepancy Loss: 0.0857
Epoch [9/50], Class Loss: 0.2743, Discrepancy Loss: 0.0929
Epoch [10/50], Class Loss: 0.3632, Discrepancy Loss: 0.0946
Epoch [11/50], Class Loss: 0.2608, Discrepancy Loss: 0.0965
Epoch [12/50], Class Loss: 0.2276, Discrepancy Loss: 0.0984
Epoch [13/50], Class Loss: 0.2205, Discrepancy Loss: 0.1015
Epoch [14/50], Class Loss: 0.2051, Discrepancy Loss: 0.1067
Epoch [15/50], Class Loss: 0.1960, Discrepancy Loss: 0.1098
Epoch [16/50], Class Loss: 0.1873, Discrepancy Loss: 0.1030
Epoch [17/50], Class Loss: 0.1823, Discrepancy Loss: 0.1148
Epoch [18/50], Class Loss: 0.1453, Discrepancy Loss: 0.1210
Epoch [19/50], Class Loss: 0.1019, Discrepancy Loss: 0.1284
Epoch [20/50], Class Loss: 0.0520, Discrepancy Loss: 0.1217
Epoch [21/50], Class Loss: 0.0400, Discrepancy Loss: 0.1367
Epoch [22/50], Class Loss: 0.0260, Discrepancy Loss: 0.1420
Epoch [23/50], Class Loss: 0.0260, Discrepancy Loss: 0.1402
Epoch [24/50], Class Loss: 0.0270, Discrepancy Loss: 0.1378
Epoch [25/50], Class Loss: 0.0300, Discrepancy Loss: 0.1458
Epoch [26/50], Class Loss: 0.0293, Discrepancy Loss: 0.1516
Epoch [27/50], Class Loss: 0.0276, Discrepancy Loss: 0.1483
Epoch [28/50], Class Loss: 0.0297, Discrepancy Loss: 0.1515
Epoch [29/50], Class Loss: 0.0298, Discrepancy Loss: 0.1501
Epoch [30/50], Class Loss: 0.0308, Discrepancy Loss: 0.1543
Epoch [31/50], Class Loss: 0.0341, Discrepancy Loss: 0.1530
Epoch [32/50], Class Loss: 0.0352, Discrepancy Loss: 0.1582
Epoch [33/50], Class Loss: 0.0302, Discrepancy Loss: 0.1582
Epoch [34/50], Class Loss: 0.0325, Discrepancy Loss: 0.1535
Epoch [35/50], Class Loss: 0.0323, Discrepancy Loss: 0.1577
Epoch [36/50], Class Loss: 0.0342, Discrepancy Loss: 0.1577
Epoch [37/50], Class Loss: 0.0348, Discrepancy Loss: 0.1544
Epoch [38/50], Class Loss: 0.0333, Discrepancy Loss: 0.1529
Epoch [39/50], Class Loss: 0.0340, Discrepancy Loss: 0.1567
Epoch [40/50], Class Loss: 0.0491, Discrepancy Loss: 0.1468
Epoch [41/50], Class Loss: 0.0396, Discrepancy Loss: 0.1469
Epoch [42/50], Class Loss: 0.0426, Discrepancy Loss: 0.1490
Epoch [43/50], Class Loss: 0.0361, Discrepancy Loss: 0.1476
Epoch [44/50], Class Loss: 0.0393, Discrepancy Loss: 0.1518
Epoch [45/50], Class Loss: 0.0400, Discrepancy Loss: 0.1503
Epoch [46/50], Class Loss: 0.0407, Discrepancy Loss: 0.1507
Epoch [47/50], Class Loss: 0.0394, Discrepancy Loss: 0.1464
Epoch [48/50], Class Loss: 0.0381, Discrepancy Loss: 0.1473
Epoch [49/50], Class Loss: 0.0379, Discrepancy Loss: 0.1505
Epoch [50/50], Class Loss: 0.0376, Discrepancy Loss: 0.1507
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 56.76%, Precision: 51.15%, Recall: 56.02%, F1 Score: 50.92%

Run 4/10
Epoch [1/50], Class Loss: 4.3199, Discrepancy Loss: 0.0829
Epoch [2/50], Class Loss: 0.7640, Discrepancy Loss: 0.0983
Epoch [3/50], Class Loss: 0.5645, Discrepancy Loss: 0.0965
Epoch [4/50], Class Loss: 0.4338, Discrepancy Loss: 0.0987
Epoch [5/50], Class Loss: 0.3632, Discrepancy Loss: 0.1018
Epoch [6/50], Class Loss: 0.3484, Discrepancy Loss: 0.1048
Epoch [7/50], Class Loss: 0.5075, Discrepancy Loss: 0.0907
Epoch [8/50], Class Loss: 0.3581, Discrepancy Loss: 0.1030
Epoch [9/50], Class Loss: 0.2462, Discrepancy Loss: 0.0894
Epoch [10/50], Class Loss: 0.2177, Discrepancy Loss: 0.1060
Epoch [11/50], Class Loss: 0.1795, Discrepancy Loss: 0.0983
Epoch [12/50], Class Loss: 0.1049, Discrepancy Loss: 0.1099
Epoch [13/50], Class Loss: 0.0715, Discrepancy Loss: 0.1113
Epoch [14/50], Class Loss: 0.0629, Discrepancy Loss: 0.1177
Epoch [15/50], Class Loss: 0.0557, Discrepancy Loss: 0.1152
Epoch [16/50], Class Loss: 0.0347, Discrepancy Loss: 0.1251
Epoch [17/50], Class Loss: 0.0467, Discrepancy Loss: 0.1359
Epoch [18/50], Class Loss: 0.0593, Discrepancy Loss: 0.1250
Epoch [19/50], Class Loss: 0.0542, Discrepancy Loss: 0.1319
Epoch [20/50], Class Loss: 0.0902, Discrepancy Loss: 0.1159
Epoch [21/50], Class Loss: 0.0351, Discrepancy Loss: 0.1343
Epoch [22/50], Class Loss: 0.0290, Discrepancy Loss: 0.1324
Epoch [23/50], Class Loss: 0.0310, Discrepancy Loss: 0.1382
Epoch [24/50], Class Loss: 0.0255, Discrepancy Loss: 0.1362
Epoch [25/50], Class Loss: 0.0279, Discrepancy Loss: 0.1359
Epoch [26/50], Class Loss: 0.0348, Discrepancy Loss: 0.1370
Epoch [27/50], Class Loss: 0.0231, Discrepancy Loss: 0.1404
Epoch [28/50], Class Loss: 0.0233, Discrepancy Loss: 0.1434
Epoch [29/50], Class Loss: 0.0223, Discrepancy Loss: 0.1387
Epoch [30/50], Class Loss: 0.0267, Discrepancy Loss: 0.1381
Epoch [31/50], Class Loss: 0.0223, Discrepancy Loss: 0.1410
Epoch [32/50], Class Loss: 0.0224, Discrepancy Loss: 0.1501
Epoch [33/50], Class Loss: 0.0218, Discrepancy Loss: 0.1416
Epoch [34/50], Class Loss: 0.0223, Discrepancy Loss: 0.1456
Epoch [35/50], Class Loss: 0.0205, Discrepancy Loss: 0.1484
Epoch [36/50], Class Loss: 0.0213, Discrepancy Loss: 0.1497
Epoch [37/50], Class Loss: 0.0191, Discrepancy Loss: 0.1467
Epoch [38/50], Class Loss: 0.0219, Discrepancy Loss: 0.1491
Epoch [39/50], Class Loss: 0.0205, Discrepancy Loss: 0.1466
Epoch [40/50], Class Loss: 0.0251, Discrepancy Loss: 0.1454
Epoch [41/50], Class Loss: 0.0220, Discrepancy Loss: 0.1480
Epoch [42/50], Class Loss: 0.0219, Discrepancy Loss: 0.1487
Epoch [43/50], Class Loss: 0.0229, Discrepancy Loss: 0.1459
Epoch [44/50], Class Loss: 0.0229, Discrepancy Loss: 0.1507
Epoch [45/50], Class Loss: 0.0187, Discrepancy Loss: 0.1493
Epoch [46/50], Class Loss: 0.0196, Discrepancy Loss: 0.1506
Epoch [47/50], Class Loss: 0.0219, Discrepancy Loss: 0.1502
Epoch [48/50], Class Loss: 0.0183, Discrepancy Loss: 0.1525
Epoch [49/50], Class Loss: 0.0211, Discrepancy Loss: 0.1452
Epoch [50/50], Class Loss: 0.0200, Discrepancy Loss: 0.1449
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 41.36%, Precision: 31.57%, Recall: 39.99%, F1 Score: 32.17%

Run 5/10
Epoch [1/50], Class Loss: 4.7762, Discrepancy Loss: 0.0892
Epoch [2/50], Class Loss: 0.7800, Discrepancy Loss: 0.0940
Epoch [3/50], Class Loss: 0.6841, Discrepancy Loss: 0.1062
Epoch [4/50], Class Loss: 0.4916, Discrepancy Loss: 0.1152
Epoch [5/50], Class Loss: 0.3919, Discrepancy Loss: 0.1107
Epoch [6/50], Class Loss: 0.5886, Discrepancy Loss: 0.0981
Epoch [7/50], Class Loss: 0.4815, Discrepancy Loss: 0.0946
Epoch [8/50], Class Loss: 0.3641, Discrepancy Loss: 0.0977
Epoch [9/50], Class Loss: 0.3124, Discrepancy Loss: 0.0969
Epoch [10/50], Class Loss: 0.1994, Discrepancy Loss: 0.1019
Epoch [11/50], Class Loss: 0.1008, Discrepancy Loss: 0.1003
Epoch [12/50], Class Loss: 0.0772, Discrepancy Loss: 0.1080
Epoch [13/50], Class Loss: 0.0577, Discrepancy Loss: 0.1050
Epoch [14/50], Class Loss: 0.0559, Discrepancy Loss: 0.1117
Epoch [15/50], Class Loss: 0.0450, Discrepancy Loss: 0.1165
Epoch [16/50], Class Loss: 0.0540, Discrepancy Loss: 0.1074
Epoch [17/50], Class Loss: 0.0576, Discrepancy Loss: 0.1107
Epoch [18/50], Class Loss: 0.0691, Discrepancy Loss: 0.1043
Epoch [19/50], Class Loss: 0.0368, Discrepancy Loss: 0.1238
Epoch [20/50], Class Loss: 0.0837, Discrepancy Loss: 0.1267
Epoch [21/50], Class Loss: 0.0394, Discrepancy Loss: 0.1183
Epoch [22/50], Class Loss: 0.0475, Discrepancy Loss: 0.1173
Epoch [23/50], Class Loss: 0.0492, Discrepancy Loss: 0.1308
Epoch [24/50], Class Loss: 0.0602, Discrepancy Loss: 0.1422
Epoch [25/50], Class Loss: 0.0514, Discrepancy Loss: 0.1386
Epoch [26/50], Class Loss: 0.0553, Discrepancy Loss: 0.1369
Epoch [27/50], Class Loss: 0.0588, Discrepancy Loss: 0.1433
Epoch [28/50], Class Loss: 0.0504, Discrepancy Loss: 0.1436
Epoch [29/50], Class Loss: 0.0536, Discrepancy Loss: 0.1465
Epoch [30/50], Class Loss: 0.0553, Discrepancy Loss: 0.1481
Epoch [31/50], Class Loss: 0.0469, Discrepancy Loss: 0.1535
Epoch [32/50], Class Loss: 0.0524, Discrepancy Loss: 0.1490
Epoch [33/50], Class Loss: 0.0455, Discrepancy Loss: 0.1488
Epoch [34/50], Class Loss: 0.0479, Discrepancy Loss: 0.1510
Epoch [35/50], Class Loss: 0.0447, Discrepancy Loss: 0.1482
Epoch [36/50], Class Loss: 0.0441, Discrepancy Loss: 0.1487
Epoch [37/50], Class Loss: 0.0439, Discrepancy Loss: 0.1532
Epoch [38/50], Class Loss: 0.0396, Discrepancy Loss: 0.1518
Epoch [39/50], Class Loss: 0.0444, Discrepancy Loss: 0.1457
Epoch [40/50], Class Loss: 0.0463, Discrepancy Loss: 0.1546
Epoch [41/50], Class Loss: 0.0449, Discrepancy Loss: 0.1471
Epoch [42/50], Class Loss: 0.0454, Discrepancy Loss: 0.1516
Epoch [43/50], Class Loss: 0.0474, Discrepancy Loss: 0.1459
Epoch [44/50], Class Loss: 0.0460, Discrepancy Loss: 0.1546
Epoch [45/50], Class Loss: 0.0414, Discrepancy Loss: 0.1516
Epoch [46/50], Class Loss: 0.0441, Discrepancy Loss: 0.1507
Epoch [47/50], Class Loss: 0.0445, Discrepancy Loss: 0.1523
Epoch [48/50], Class Loss: 0.0470, Discrepancy Loss: 0.1499
Epoch [49/50], Class Loss: 0.0386, Discrepancy Loss: 0.1469
Epoch [50/50], Class Loss: 0.0432, Discrepancy Loss: 0.1518
Source Domain Performance - Accuracy: 99.66%, Precision: 99.67%, Recall: 99.65%, F1 Score: 99.66%
Target Domain Performance - Accuracy: 42.60%, Precision: 32.47%, Recall: 41.28%, F1 Score: 34.39%

Run 6/10
Epoch [1/50], Class Loss: 3.5736, Discrepancy Loss: 0.0862
Epoch [2/50], Class Loss: 1.2976, Discrepancy Loss: 0.0989
Epoch [3/50], Class Loss: 0.5919, Discrepancy Loss: 0.1009
Epoch [4/50], Class Loss: 0.3385, Discrepancy Loss: 0.0973
Epoch [5/50], Class Loss: 0.3193, Discrepancy Loss: 0.0887
Epoch [6/50], Class Loss: 0.3061, Discrepancy Loss: 0.0930
Epoch [7/50], Class Loss: 0.2447, Discrepancy Loss: 0.0851
Epoch [8/50], Class Loss: 0.4013, Discrepancy Loss: 0.0886
Epoch [9/50], Class Loss: 0.3563, Discrepancy Loss: 0.0860
Epoch [10/50], Class Loss: 0.3157, Discrepancy Loss: 0.0769
Epoch [11/50], Class Loss: 0.1026, Discrepancy Loss: 0.0859
Epoch [12/50], Class Loss: 0.0633, Discrepancy Loss: 0.0937
Epoch [13/50], Class Loss: 0.0507, Discrepancy Loss: 0.1018
Epoch [14/50], Class Loss: 0.0370, Discrepancy Loss: 0.1086
Epoch [15/50], Class Loss: 0.0456, Discrepancy Loss: 0.0941
Epoch [16/50], Class Loss: 0.0477, Discrepancy Loss: 0.0882
Epoch [17/50], Class Loss: 0.0609, Discrepancy Loss: 0.0993
Epoch [18/50], Class Loss: 0.0440, Discrepancy Loss: 0.1225
Epoch [19/50], Class Loss: 0.0390, Discrepancy Loss: 0.1163
Epoch [20/50], Class Loss: 0.0518, Discrepancy Loss: 0.1031
Epoch [21/50], Class Loss: 0.0390, Discrepancy Loss: 0.1143
Epoch [22/50], Class Loss: 0.0321, Discrepancy Loss: 0.1204
Epoch [23/50], Class Loss: 0.0355, Discrepancy Loss: 0.1300
Epoch [24/50], Class Loss: 0.0327, Discrepancy Loss: 0.1317
Epoch [25/50], Class Loss: 0.0242, Discrepancy Loss: 0.1349
Epoch [26/50], Class Loss: 0.0424, Discrepancy Loss: 0.1153
Epoch [27/50], Class Loss: 0.0466, Discrepancy Loss: 0.1167
Epoch [28/50], Class Loss: 0.0648, Discrepancy Loss: 0.1227
Epoch [29/50], Class Loss: 0.0864, Discrepancy Loss: 0.1127
Epoch [30/50], Class Loss: 0.0684, Discrepancy Loss: 0.1200
Epoch [31/50], Class Loss: 0.0652, Discrepancy Loss: 0.1147
Epoch [32/50], Class Loss: 0.0706, Discrepancy Loss: 0.1213
Epoch [33/50], Class Loss: 0.0616, Discrepancy Loss: 0.1177
Epoch [34/50], Class Loss: 0.0774, Discrepancy Loss: 0.1201
Epoch [35/50], Class Loss: 0.0711, Discrepancy Loss: 0.1206
Epoch [36/50], Class Loss: 0.0645, Discrepancy Loss: 0.1184
Epoch [37/50], Class Loss: 0.0683, Discrepancy Loss: 0.1201
Epoch [38/50], Class Loss: 0.0677, Discrepancy Loss: 0.1187
Epoch [39/50], Class Loss: 0.0634, Discrepancy Loss: 0.1200
Epoch [40/50], Class Loss: 0.0569, Discrepancy Loss: 0.1227
Epoch [41/50], Class Loss: 0.0653, Discrepancy Loss: 0.1203
Epoch [42/50], Class Loss: 0.0601, Discrepancy Loss: 0.1187
Epoch [43/50], Class Loss: 0.0707, Discrepancy Loss: 0.1235
Epoch [44/50], Class Loss: 0.0686, Discrepancy Loss: 0.1198
Epoch [45/50], Class Loss: 0.0589, Discrepancy Loss: 0.1202
Epoch [46/50], Class Loss: 0.0668, Discrepancy Loss: 0.1197
Epoch [47/50], Class Loss: 0.0626, Discrepancy Loss: 0.1190
Epoch [48/50], Class Loss: 0.0635, Discrepancy Loss: 0.1153
Epoch [49/50], Class Loss: 0.0581, Discrepancy Loss: 0.1204
Epoch [50/50], Class Loss: 0.0728, Discrepancy Loss: 0.1166
Source Domain Performance - Accuracy: 99.29%, Precision: 99.33%, Recall: 99.29%, F1 Score: 99.30%
Target Domain Performance - Accuracy: 43.65%, Precision: 36.36%, Recall: 42.47%, F1 Score: 37.95%

Run 7/10
Epoch [1/50], Class Loss: 6.1677, Discrepancy Loss: 0.0795
Epoch [2/50], Class Loss: 0.7436, Discrepancy Loss: 0.0971
Epoch [3/50], Class Loss: 0.4868, Discrepancy Loss: 0.0971
Epoch [4/50], Class Loss: 0.4638, Discrepancy Loss: 0.0955
Epoch [5/50], Class Loss: 0.5388, Discrepancy Loss: 0.0936
Epoch [6/50], Class Loss: 0.3820, Discrepancy Loss: 0.1053
Epoch [7/50], Class Loss: 0.2894, Discrepancy Loss: 0.1077
Epoch [8/50], Class Loss: 0.3453, Discrepancy Loss: 0.1013
Epoch [9/50], Class Loss: 0.2815, Discrepancy Loss: 0.1137
Epoch [10/50], Class Loss: 0.1754, Discrepancy Loss: 0.1043
Epoch [11/50], Class Loss: 0.0528, Discrepancy Loss: 0.1076
Epoch [12/50], Class Loss: 0.0365, Discrepancy Loss: 0.1199
Epoch [13/50], Class Loss: 0.0293, Discrepancy Loss: 0.1345
Epoch [14/50], Class Loss: 0.0306, Discrepancy Loss: 0.1358
Epoch [15/50], Class Loss: 0.0524, Discrepancy Loss: 0.1349
Epoch [16/50], Class Loss: 0.0373, Discrepancy Loss: 0.1288
Epoch [17/50], Class Loss: 0.0383, Discrepancy Loss: 0.1283
Epoch [18/50], Class Loss: 0.0335, Discrepancy Loss: 0.1236
Epoch [19/50], Class Loss: 0.0500, Discrepancy Loss: 0.1341
Epoch [20/50], Class Loss: 0.0587, Discrepancy Loss: 0.1452
Epoch [21/50], Class Loss: 0.0220, Discrepancy Loss: 0.1633
Epoch [22/50], Class Loss: 0.0218, Discrepancy Loss: 0.1612
Epoch [23/50], Class Loss: 0.0151, Discrepancy Loss: 0.1665
Epoch [24/50], Class Loss: 0.0176, Discrepancy Loss: 0.1628
Epoch [25/50], Class Loss: 0.0197, Discrepancy Loss: 0.1576
Epoch [26/50], Class Loss: 0.0274, Discrepancy Loss: 0.1488
Epoch [27/50], Class Loss: 0.0410, Discrepancy Loss: 0.1436
Epoch [28/50], Class Loss: 0.0429, Discrepancy Loss: 0.1400
Epoch [29/50], Class Loss: 0.0469, Discrepancy Loss: 0.1349
Epoch [30/50], Class Loss: 0.0420, Discrepancy Loss: 0.1427
Epoch [31/50], Class Loss: 0.0593, Discrepancy Loss: 0.1360
Epoch [32/50], Class Loss: 0.0538, Discrepancy Loss: 0.1371
Epoch [33/50], Class Loss: 0.0568, Discrepancy Loss: 0.1391
Epoch [34/50], Class Loss: 0.0595, Discrepancy Loss: 0.1402
Epoch [35/50], Class Loss: 0.0664, Discrepancy Loss: 0.1359
Epoch [36/50], Class Loss: 0.0551, Discrepancy Loss: 0.1356
Epoch [37/50], Class Loss: 0.0477, Discrepancy Loss: 0.1393
Epoch [38/50], Class Loss: 0.0715, Discrepancy Loss: 0.1365
Epoch [39/50], Class Loss: 0.0586, Discrepancy Loss: 0.1363
Epoch [40/50], Class Loss: 0.0670, Discrepancy Loss: 0.1342
Epoch [41/50], Class Loss: 0.0762, Discrepancy Loss: 0.1377
Epoch [42/50], Class Loss: 0.0801, Discrepancy Loss: 0.1436
Epoch [43/50], Class Loss: 0.0718, Discrepancy Loss: 0.1403
Epoch [44/50], Class Loss: 0.0719, Discrepancy Loss: 0.1388
Epoch [45/50], Class Loss: 0.0723, Discrepancy Loss: 0.1385
Epoch [46/50], Class Loss: 0.0660, Discrepancy Loss: 0.1378
Epoch [47/50], Class Loss: 0.0615, Discrepancy Loss: 0.1366
Epoch [48/50], Class Loss: 0.0656, Discrepancy Loss: 0.1366
Epoch [49/50], Class Loss: 0.0581, Discrepancy Loss: 0.1367
Epoch [50/50], Class Loss: 0.0708, Discrepancy Loss: 0.1373
Source Domain Performance - Accuracy: 99.24%, Precision: 99.29%, Recall: 99.24%, F1 Score: 99.26%
Target Domain Performance - Accuracy: 53.91%, Precision: 46.04%, Recall: 52.98%, F1 Score: 48.70%

Run 8/10
Epoch [1/50], Class Loss: 3.5433, Discrepancy Loss: 0.0835
Epoch [2/50], Class Loss: 0.7182, Discrepancy Loss: 0.0942
Epoch [3/50], Class Loss: 0.6506, Discrepancy Loss: 0.1029
Epoch [4/50], Class Loss: 0.4758, Discrepancy Loss: 0.1100
Epoch [5/50], Class Loss: 0.5177, Discrepancy Loss: 0.1155
Epoch [6/50], Class Loss: 0.5482, Discrepancy Loss: 0.1005
Epoch [7/50], Class Loss: 0.4828, Discrepancy Loss: 0.0906
Epoch [8/50], Class Loss: 0.3148, Discrepancy Loss: 0.1001
Epoch [9/50], Class Loss: 0.3072, Discrepancy Loss: 0.0984
Epoch [10/50], Class Loss: 0.1834, Discrepancy Loss: 0.0929
Epoch [11/50], Class Loss: 0.0625, Discrepancy Loss: 0.0929
Epoch [12/50], Class Loss: 0.0486, Discrepancy Loss: 0.1040
Epoch [13/50], Class Loss: 0.0545, Discrepancy Loss: 0.1119
Epoch [14/50], Class Loss: 0.0472, Discrepancy Loss: 0.1159
Epoch [15/50], Class Loss: 0.0345, Discrepancy Loss: 0.1005
Epoch [16/50], Class Loss: 0.0541, Discrepancy Loss: 0.0868
Epoch [17/50], Class Loss: 0.0446, Discrepancy Loss: 0.0946
Epoch [18/50], Class Loss: 0.0308, Discrepancy Loss: 0.0994
Epoch [19/50], Class Loss: 0.0669, Discrepancy Loss: 0.1100
Epoch [20/50], Class Loss: 0.0612, Discrepancy Loss: 0.1133
Epoch [21/50], Class Loss: 0.0893, Discrepancy Loss: 0.0937
Epoch [22/50], Class Loss: 0.1020, Discrepancy Loss: 0.1093
Epoch [23/50], Class Loss: 0.0886, Discrepancy Loss: 0.1182
Epoch [24/50], Class Loss: 0.0834, Discrepancy Loss: 0.1221
Epoch [25/50], Class Loss: 0.0921, Discrepancy Loss: 0.1382
Epoch [26/50], Class Loss: 0.0883, Discrepancy Loss: 0.1309
Epoch [27/50], Class Loss: 0.0922, Discrepancy Loss: 0.1362
Epoch [28/50], Class Loss: 0.0808, Discrepancy Loss: 0.1408
Epoch [29/50], Class Loss: 0.0770, Discrepancy Loss: 0.1438
Epoch [30/50], Class Loss: 0.0836, Discrepancy Loss: 0.1465
Epoch [31/50], Class Loss: 0.0691, Discrepancy Loss: 0.1454
Epoch [32/50], Class Loss: 0.0766, Discrepancy Loss: 0.1499
Epoch [33/50], Class Loss: 0.0740, Discrepancy Loss: 0.1494
Epoch [34/50], Class Loss: 0.0753, Discrepancy Loss: 0.1567
Epoch [35/50], Class Loss: 0.0797, Discrepancy Loss: 0.1537
Epoch [36/50], Class Loss: 0.0749, Discrepancy Loss: 0.1546
Epoch [37/50], Class Loss: 0.0789, Discrepancy Loss: 0.1591
Epoch [38/50], Class Loss: 0.0663, Discrepancy Loss: 0.1514
Epoch [39/50], Class Loss: 0.0651, Discrepancy Loss: 0.1543
Epoch [40/50], Class Loss: 0.0726, Discrepancy Loss: 0.1509
Epoch [41/50], Class Loss: 0.0733, Discrepancy Loss: 0.1556
Epoch [42/50], Class Loss: 0.0802, Discrepancy Loss: 0.1569
Epoch [43/50], Class Loss: 0.0758, Discrepancy Loss: 0.1541
Epoch [44/50], Class Loss: 0.0699, Discrepancy Loss: 0.1583
Epoch [45/50], Class Loss: 0.0649, Discrepancy Loss: 0.1614
Epoch [46/50], Class Loss: 0.0693, Discrepancy Loss: 0.1553
Epoch [47/50], Class Loss: 0.0723, Discrepancy Loss: 0.1520
Epoch [48/50], Class Loss: 0.0704, Discrepancy Loss: 0.1574
Epoch [49/50], Class Loss: 0.0707, Discrepancy Loss: 0.1556
Epoch [50/50], Class Loss: 0.0688, Discrepancy Loss: 0.1591
Source Domain Performance - Accuracy: 99.49%, Precision: 99.50%, Recall: 99.48%, F1 Score: 99.49%
Target Domain Performance - Accuracy: 32.69%, Precision: 31.29%, Recall: 31.80%, F1 Score: 28.99%

Run 9/10
Epoch [1/50], Class Loss: 4.1742, Discrepancy Loss: 0.0843
Epoch [2/50], Class Loss: 0.9612, Discrepancy Loss: 0.0976
Epoch [3/50], Class Loss: 0.5482, Discrepancy Loss: 0.1086
Epoch [4/50], Class Loss: 0.4082, Discrepancy Loss: 0.0982
Epoch [5/50], Class Loss: 0.8496, Discrepancy Loss: 0.0943
Epoch [6/50], Class Loss: 0.4956, Discrepancy Loss: 0.1053
Epoch [7/50], Class Loss: 0.2452, Discrepancy Loss: 0.0977
Epoch [8/50], Class Loss: 0.1530, Discrepancy Loss: 0.0948
Epoch [9/50], Class Loss: 0.1768, Discrepancy Loss: 0.0961
Epoch [10/50], Class Loss: 0.2045, Discrepancy Loss: 0.1106
Epoch [11/50], Class Loss: 0.0954, Discrepancy Loss: 0.0849
Epoch [12/50], Class Loss: 0.0572, Discrepancy Loss: 0.0876
Epoch [13/50], Class Loss: 0.0660, Discrepancy Loss: 0.1086
Epoch [14/50], Class Loss: 0.0401, Discrepancy Loss: 0.1129
Epoch [15/50], Class Loss: 0.0349, Discrepancy Loss: 0.1125
Epoch [16/50], Class Loss: 0.0479, Discrepancy Loss: 0.1185
Epoch [17/50], Class Loss: 0.0366, Discrepancy Loss: 0.1204
Epoch [18/50], Class Loss: 0.0358, Discrepancy Loss: 0.1030
Epoch [19/50], Class Loss: 0.0682, Discrepancy Loss: 0.1134
Epoch [20/50], Class Loss: 0.0339, Discrepancy Loss: 0.1326
Epoch [21/50], Class Loss: 0.0229, Discrepancy Loss: 0.1474
Epoch [22/50], Class Loss: 0.0272, Discrepancy Loss: 0.1469
Epoch [23/50], Class Loss: 0.0244, Discrepancy Loss: 0.1489
Epoch [24/50], Class Loss: 0.0252, Discrepancy Loss: 0.1482
Epoch [25/50], Class Loss: 0.0317, Discrepancy Loss: 0.1404
Epoch [26/50], Class Loss: 0.0258, Discrepancy Loss: 0.1509
Epoch [27/50], Class Loss: 0.0241, Discrepancy Loss: 0.1514
Epoch [28/50], Class Loss: 0.0287, Discrepancy Loss: 0.1536
Epoch [29/50], Class Loss: 0.0266, Discrepancy Loss: 0.1452
Epoch [30/50], Class Loss: 0.0270, Discrepancy Loss: 0.1509
Epoch [31/50], Class Loss: 0.0303, Discrepancy Loss: 0.1507
Epoch [32/50], Class Loss: 0.0284, Discrepancy Loss: 0.1559
Epoch [33/50], Class Loss: 0.0221, Discrepancy Loss: 0.1512
Epoch [34/50], Class Loss: 0.0248, Discrepancy Loss: 0.1534
Epoch [35/50], Class Loss: 0.0249, Discrepancy Loss: 0.1533
Epoch [36/50], Class Loss: 0.0293, Discrepancy Loss: 0.1470
Epoch [37/50], Class Loss: 0.0248, Discrepancy Loss: 0.1526
Epoch [38/50], Class Loss: 0.0259, Discrepancy Loss: 0.1500
Epoch [39/50], Class Loss: 0.0251, Discrepancy Loss: 0.1536
Epoch [40/50], Class Loss: 0.0222, Discrepancy Loss: 0.1554
Epoch [41/50], Class Loss: 0.0195, Discrepancy Loss: 0.1502
Epoch [42/50], Class Loss: 0.0247, Discrepancy Loss: 0.1500
Epoch [43/50], Class Loss: 0.0244, Discrepancy Loss: 0.1552
Epoch [44/50], Class Loss: 0.0199, Discrepancy Loss: 0.1547
Epoch [45/50], Class Loss: 0.0236, Discrepancy Loss: 0.1553
Epoch [46/50], Class Loss: 0.0242, Discrepancy Loss: 0.1552
Epoch [47/50], Class Loss: 0.0180, Discrepancy Loss: 0.1505
Epoch [48/50], Class Loss: 0.0253, Discrepancy Loss: 0.1542
Epoch [49/50], Class Loss: 0.0197, Discrepancy Loss: 0.1532
Epoch [50/50], Class Loss: 0.0240, Discrepancy Loss: 0.1564
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 48.36%, Precision: 39.34%, Recall: 47.30%, F1 Score: 41.25%

Run 10/10
Epoch [1/50], Class Loss: 3.4502, Discrepancy Loss: 0.0867
Epoch [2/50], Class Loss: 0.6574, Discrepancy Loss: 0.0827
Epoch [3/50], Class Loss: 0.5124, Discrepancy Loss: 0.0930
Epoch [4/50], Class Loss: 0.4283, Discrepancy Loss: 0.0962
Epoch [5/50], Class Loss: 0.3640, Discrepancy Loss: 0.0982
Epoch [6/50], Class Loss: 0.2977, Discrepancy Loss: 0.0942
Epoch [7/50], Class Loss: 0.3520, Discrepancy Loss: 0.1073
Epoch [8/50], Class Loss: 0.1903, Discrepancy Loss: 0.1022
Epoch [9/50], Class Loss: 0.3597, Discrepancy Loss: 0.0814
Epoch [10/50], Class Loss: 0.3521, Discrepancy Loss: 0.0906
Epoch [11/50], Class Loss: 0.2464, Discrepancy Loss: 0.0861
Epoch [12/50], Class Loss: 0.1374, Discrepancy Loss: 0.0751
Epoch [13/50], Class Loss: 0.0609, Discrepancy Loss: 0.1028
Epoch [14/50], Class Loss: 0.0456, Discrepancy Loss: 0.1146
Epoch [15/50], Class Loss: 0.0494, Discrepancy Loss: 0.1218
Epoch [16/50], Class Loss: 0.0415, Discrepancy Loss: 0.1195
Epoch [17/50], Class Loss: 0.0554, Discrepancy Loss: 0.1106
Epoch [18/50], Class Loss: 0.0556, Discrepancy Loss: 0.1045
Epoch [19/50], Class Loss: 0.0579, Discrepancy Loss: 0.1117
Epoch [20/50], Class Loss: 0.0440, Discrepancy Loss: 0.1258
Epoch [21/50], Class Loss: 0.0382, Discrepancy Loss: 0.1321
Epoch [22/50], Class Loss: 0.0351, Discrepancy Loss: 0.1343
Epoch [23/50], Class Loss: 0.0461, Discrepancy Loss: 0.1385
Epoch [24/50], Class Loss: 0.0396, Discrepancy Loss: 0.1389
Epoch [25/50], Class Loss: 0.0423, Discrepancy Loss: 0.1426
Epoch [26/50], Class Loss: 0.0388, Discrepancy Loss: 0.1485
Epoch [27/50], Class Loss: 0.0358, Discrepancy Loss: 0.1461
Epoch [28/50], Class Loss: 0.0340, Discrepancy Loss: 0.1468
Epoch [29/50], Class Loss: 0.0329, Discrepancy Loss: 0.1539
Epoch [30/50], Class Loss: 0.0379, Discrepancy Loss: 0.1541
Epoch [31/50], Class Loss: 0.0325, Discrepancy Loss: 0.1525
Epoch [32/50], Class Loss: 0.0344, Discrepancy Loss: 0.1529
Epoch [33/50], Class Loss: 0.0350, Discrepancy Loss: 0.1581
Epoch [34/50], Class Loss: 0.0359, Discrepancy Loss: 0.1523
Epoch [35/50], Class Loss: 0.0294, Discrepancy Loss: 0.1542
Epoch [36/50], Class Loss: 0.0366, Discrepancy Loss: 0.1612
Epoch [37/50], Class Loss: 0.0284, Discrepancy Loss: 0.1603
Epoch [38/50], Class Loss: 0.0302, Discrepancy Loss: 0.1558
Epoch [39/50], Class Loss: 0.0309, Discrepancy Loss: 0.1549
Epoch [40/50], Class Loss: 0.0307, Discrepancy Loss: 0.1520
Epoch [41/50], Class Loss: 0.0307, Discrepancy Loss: 0.1567
Epoch [42/50], Class Loss: 0.0355, Discrepancy Loss: 0.1560
Epoch [43/50], Class Loss: 0.0329, Discrepancy Loss: 0.1521
Epoch [44/50], Class Loss: 0.0333, Discrepancy Loss: 0.1542
Epoch [45/50], Class Loss: 0.0294, Discrepancy Loss: 0.1587
Epoch [46/50], Class Loss: 0.0349, Discrepancy Loss: 0.1546
Epoch [47/50], Class Loss: 0.0341, Discrepancy Loss: 0.1581
Epoch [48/50], Class Loss: 0.0310, Discrepancy Loss: 0.1524
Epoch [49/50], Class Loss: 0.0312, Discrepancy Loss: 0.1563
Epoch [50/50], Class Loss: 0.0348, Discrepancy Loss: 0.1587
Source Domain Performance - Accuracy: 95.43%, Precision: 96.03%, Recall: 95.43%, F1 Score: 95.27%
Target Domain Performance - Accuracy: 43.77%, Precision: 34.30%, Recall: 42.53%, F1 Score: 36.61%

Source performance: 99.15% 99.23% 99.15% 99.14%
Target performance: 45.28% 37.88% 44.18% 38.94%

Per-Class Accuracy on Target Domain:
bpsk: 95.96%
qpsk: 30.62%
4qam: 3.14%
16qam: 88.51%
apsk: 2.65%

Run 1/10
Epoch [1/50], Class Loss: 2.1106, Discrepancy Loss: 0.0287
Validation Loss: 0.8622
Epoch [2/50], Class Loss: 1.3878, Discrepancy Loss: 0.0176
Validation Loss: 0.7102
Epoch [3/50], Class Loss: 1.4723, Discrepancy Loss: 0.0262
Validation Loss: 0.6148
Epoch [4/50], Class Loss: 1.1755, Discrepancy Loss: 0.0360
Validation Loss: 4.8440
Epoch [5/50], Class Loss: 1.8502, Discrepancy Loss: 0.0546
Validation Loss: 1.0329
Epoch [6/50], Class Loss: 0.5286, Discrepancy Loss: 0.0185
Validation Loss: 0.6488
Epoch [7/50], Class Loss: 1.3820, Discrepancy Loss: 0.0255
Validation Loss: 0.6162
Epoch [8/50], Class Loss: 0.5079, Discrepancy Loss: 0.0147
Validation Loss: 0.2840
Epoch [9/50], Class Loss: 0.4433, Discrepancy Loss: 0.0122
Validation Loss: 0.5204
Epoch [10/50], Class Loss: 0.4189, Discrepancy Loss: 0.0145
Validation Loss: 0.2337
Epoch [11/50], Class Loss: 0.0828, Discrepancy Loss: 0.0075
Validation Loss: 0.9356
Epoch [12/50], Class Loss: 0.0624, Discrepancy Loss: 0.0063
Validation Loss: 0.0159
Epoch [13/50], Class Loss: 0.0451, Discrepancy Loss: 0.0049
Validation Loss: 0.0094
Epoch [14/50], Class Loss: 0.0240, Discrepancy Loss: 0.0055
Validation Loss: 0.0455
Epoch [15/50], Class Loss: 0.0293, Discrepancy Loss: 0.0069
Validation Loss: 0.0073
Epoch [16/50], Class Loss: 0.1118, Discrepancy Loss: 0.0077
Validation Loss: 0.9535
Epoch [17/50], Class Loss: 0.3188, Discrepancy Loss: 0.0108
Validation Loss: 0.0548
Epoch [18/50], Class Loss: 0.0651, Discrepancy Loss: 0.0071
Validation Loss: 0.0722
Epoch [19/50], Class Loss: 0.0593, Discrepancy Loss: 0.0070
Validation Loss: 0.0162
Epoch [20/50], Class Loss: 0.1977, Discrepancy Loss: 0.0079
Validation Loss: 4.7969
Early stopping!
Source Domain Performance - Accuracy: 80.74%, Precision: 90.28%, Recall: 79.92%, F1 Score: 73.61%
Target Domain Performance - Accuracy: 36.43%, Precision: 46.30%, Recall: 36.67%, F1 Score: 28.21%

Run 2/10
Epoch [1/50], Class Loss: 2.8530, Discrepancy Loss: 0.0428
Validation Loss: 1.1240
Epoch [2/50], Class Loss: 1.4032, Discrepancy Loss: 0.0318
Validation Loss: 1.7228
Epoch [3/50], Class Loss: 2.0810, Discrepancy Loss: 0.0328
Validation Loss: 5.5997
Epoch [4/50], Class Loss: 1.3333, Discrepancy Loss: 0.0411
Validation Loss: 0.2421
Epoch [5/50], Class Loss: 0.3019, Discrepancy Loss: 0.0119
Validation Loss: 0.1741
Epoch [6/50], Class Loss: 0.2627, Discrepancy Loss: 0.0101
Validation Loss: 0.0616
Epoch [7/50], Class Loss: 0.2168, Discrepancy Loss: 0.0166
Validation Loss: 0.3907
Epoch [8/50], Class Loss: 1.2728, Discrepancy Loss: 0.0378
Validation Loss: 2.5177
Epoch [9/50], Class Loss: 3.1773, Discrepancy Loss: 0.0434
Validation Loss: 3.2275
Epoch [10/50], Class Loss: 1.3202, Discrepancy Loss: 0.0265
Validation Loss: 0.7562
Epoch [11/50], Class Loss: 0.1543, Discrepancy Loss: 0.0080
Validation Loss: 0.0147
Epoch [12/50], Class Loss: 0.0235, Discrepancy Loss: 0.0049
Validation Loss: 0.0196
Epoch [13/50], Class Loss: 0.0766, Discrepancy Loss: 0.0071
Validation Loss: 0.0261
Epoch [14/50], Class Loss: 0.0351, Discrepancy Loss: 0.0099
Validation Loss: 0.0204
Epoch [15/50], Class Loss: 0.0368, Discrepancy Loss: 0.0116
Validation Loss: 0.0203
Epoch [16/50], Class Loss: 0.0444, Discrepancy Loss: 0.0146
Validation Loss: 0.0209
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 45.41%, Precision: 46.50%, Recall: 44.19%, F1 Score: 37.50%

Run 3/10
Epoch [1/50], Class Loss: 2.9516, Discrepancy Loss: 0.0531
Validation Loss: 0.6761
Epoch [2/50], Class Loss: 0.9578, Discrepancy Loss: 0.0319
Validation Loss: 0.6843
Epoch [3/50], Class Loss: 2.2107, Discrepancy Loss: 0.0498
Validation Loss: 12.7184
Epoch [4/50], Class Loss: 1.9011, Discrepancy Loss: 0.0435
Validation Loss: 1.9607
Epoch [5/50], Class Loss: 0.5798, Discrepancy Loss: 0.0101
Validation Loss: 0.0208
Epoch [6/50], Class Loss: 1.3963, Discrepancy Loss: 0.0272
Validation Loss: 2.2646
Epoch [7/50], Class Loss: 0.8009, Discrepancy Loss: 0.0350
Validation Loss: 0.4556
Epoch [8/50], Class Loss: 0.3726, Discrepancy Loss: 0.0125
Validation Loss: 0.2002
Epoch [9/50], Class Loss: 0.2932, Discrepancy Loss: 0.0079
Validation Loss: 0.3909
Epoch [10/50], Class Loss: 0.1996, Discrepancy Loss: 0.0130
Validation Loss: 0.0272
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 41.33%, Precision: 26.84%, Recall: 39.93%, F1 Score: 30.17%

Run 4/10
Epoch [1/50], Class Loss: 3.0719, Discrepancy Loss: 0.0315
Validation Loss: 1.9729
Epoch [2/50], Class Loss: 1.3550, Discrepancy Loss: 0.0212
Validation Loss: 0.9395
Epoch [3/50], Class Loss: 0.8780, Discrepancy Loss: 0.0145
Validation Loss: 0.3808
Epoch [4/50], Class Loss: 0.4711, Discrepancy Loss: 0.0122
Validation Loss: 0.3447
Epoch [5/50], Class Loss: 0.4253, Discrepancy Loss: 0.0079
Validation Loss: 0.4364
Epoch [6/50], Class Loss: 0.3889, Discrepancy Loss: 0.0097
Validation Loss: 0.4658
Epoch [7/50], Class Loss: 0.3622, Discrepancy Loss: 0.0074
Validation Loss: 0.3148
Epoch [8/50], Class Loss: 0.3576, Discrepancy Loss: 0.0171
Validation Loss: 0.3253
Epoch [9/50], Class Loss: 0.3091, Discrepancy Loss: 0.0092
Validation Loss: 0.8509
Epoch [10/50], Class Loss: 1.3247, Discrepancy Loss: 0.0488
Validation Loss: 0.4772
Epoch [11/50], Class Loss: 0.0721, Discrepancy Loss: 0.0076
Validation Loss: 0.0143
Epoch [12/50], Class Loss: 0.0355, Discrepancy Loss: 0.0062
Validation Loss: 0.0053
Epoch [13/50], Class Loss: 0.0726, Discrepancy Loss: 0.0085
Validation Loss: 0.0073
Epoch [14/50], Class Loss: 0.1178, Discrepancy Loss: 0.0080
Validation Loss: 0.0062
Epoch [15/50], Class Loss: 0.0970, Discrepancy Loss: 0.0103
Validation Loss: 0.0138
Epoch [16/50], Class Loss: 0.1048, Discrepancy Loss: 0.0101
Validation Loss: 0.1235
Epoch [17/50], Class Loss: 0.2863, Discrepancy Loss: 0.0147
Validation Loss: 0.0144
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 36.96%, Precision: 44.22%, Recall: 36.22%, F1 Score: 32.50%

Run 5/10
Epoch [1/50], Class Loss: 3.1499, Discrepancy Loss: 0.0216
Validation Loss: 2.8084
Epoch [2/50], Class Loss: 0.9722, Discrepancy Loss: 0.0229
Validation Loss: 3.1008
Epoch [3/50], Class Loss: 1.6782, Discrepancy Loss: 0.0270
Validation Loss: 2.3652
Epoch [4/50], Class Loss: 1.5046, Discrepancy Loss: 0.0531
Validation Loss: 0.1687
Epoch [5/50], Class Loss: 0.5943, Discrepancy Loss: 0.0169
Validation Loss: 0.0903
Epoch [6/50], Class Loss: 0.7411, Discrepancy Loss: 0.0225
Validation Loss: 0.4913
Epoch [7/50], Class Loss: 1.3271, Discrepancy Loss: 0.0323
Validation Loss: 0.3308
Epoch [8/50], Class Loss: 1.5783, Discrepancy Loss: 0.0464
Validation Loss: 0.0612
Epoch [9/50], Class Loss: 1.0933, Discrepancy Loss: 0.0325
Validation Loss: 0.1038
Epoch [10/50], Class Loss: 0.4545, Discrepancy Loss: 0.0094
Validation Loss: 0.1900
Epoch [11/50], Class Loss: 0.0262, Discrepancy Loss: 0.0073
Validation Loss: 0.0230
Epoch [12/50], Class Loss: 0.0594, Discrepancy Loss: 0.0104
Validation Loss: 0.0173
Epoch [13/50], Class Loss: 0.0659, Discrepancy Loss: 0.0084
Validation Loss: 0.0259
Epoch [14/50], Class Loss: 0.0550, Discrepancy Loss: 0.0065
Validation Loss: 0.0281
Epoch [15/50], Class Loss: 0.0278, Discrepancy Loss: 0.0058
Validation Loss: 0.0106
Epoch [16/50], Class Loss: 0.0387, Discrepancy Loss: 0.0078
Validation Loss: 0.0351
Epoch [17/50], Class Loss: 0.0847, Discrepancy Loss: 0.0076
Validation Loss: 0.0625
Epoch [18/50], Class Loss: 0.0475, Discrepancy Loss: 0.0104
Validation Loss: 0.0106
Epoch [19/50], Class Loss: 0.0306, Discrepancy Loss: 0.0107
Validation Loss: 0.0154
Epoch [20/50], Class Loss: 0.0744, Discrepancy Loss: 0.0114
Validation Loss: 0.0192
Epoch [21/50], Class Loss: 0.0252, Discrepancy Loss: 0.0097
Validation Loss: 0.0179
Epoch [22/50], Class Loss: 0.0216, Discrepancy Loss: 0.0092
Validation Loss: 0.0564
Epoch [23/50], Class Loss: 0.0233, Discrepancy Loss: 0.0090
Validation Loss: 0.0103
Epoch [24/50], Class Loss: 0.0323, Discrepancy Loss: 0.0089
Validation Loss: 0.0677
Epoch [25/50], Class Loss: 0.0237, Discrepancy Loss: 0.0086
Validation Loss: 0.0271
Epoch [26/50], Class Loss: 0.0221, Discrepancy Loss: 0.0082
Validation Loss: 0.0357
Epoch [27/50], Class Loss: 0.0227, Discrepancy Loss: 0.0083
Validation Loss: 0.0199
Epoch [28/50], Class Loss: 0.0221, Discrepancy Loss: 0.0084
Validation Loss: 0.0292
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.92%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 24.49%, Precision: 44.69%, Recall: 24.20%, F1 Score: 17.70%

Run 6/10
Epoch [1/50], Class Loss: 4.1501, Discrepancy Loss: 0.0435
Validation Loss: 2.4276
Epoch [2/50], Class Loss: 1.9440, Discrepancy Loss: 0.0413
Validation Loss: 0.9875
Epoch [3/50], Class Loss: 1.2315, Discrepancy Loss: 0.0160
Validation Loss: 1.8914
Epoch [4/50], Class Loss: 1.1560, Discrepancy Loss: 0.0220
Validation Loss: 0.5644
Epoch [5/50], Class Loss: 0.5407, Discrepancy Loss: 0.0130
Validation Loss: 0.2278
Epoch [6/50], Class Loss: 0.4695, Discrepancy Loss: 0.0168
Validation Loss: 0.3628
Epoch [7/50], Class Loss: 1.0461, Discrepancy Loss: 0.0393
Validation Loss: 1.0597
Epoch [8/50], Class Loss: 0.6999, Discrepancy Loss: 0.0256
Validation Loss: 0.1369
Epoch [9/50], Class Loss: 1.5298, Discrepancy Loss: 0.0409
Validation Loss: 1.6713
Epoch [10/50], Class Loss: 0.4278, Discrepancy Loss: 0.0213
Validation Loss: 0.1886
Epoch [11/50], Class Loss: 0.0446, Discrepancy Loss: 0.0082
Validation Loss: 0.0145
Epoch [12/50], Class Loss: 0.0423, Discrepancy Loss: 0.0056
Validation Loss: 0.0154
Epoch [13/50], Class Loss: 0.0266, Discrepancy Loss: 0.0062
Validation Loss: 0.0141
Epoch [14/50], Class Loss: 0.0274, Discrepancy Loss: 0.0058
Validation Loss: 0.0183
Epoch [15/50], Class Loss: 0.0319, Discrepancy Loss: 0.0072
Validation Loss: 0.0312
Epoch [16/50], Class Loss: 0.0384, Discrepancy Loss: 0.0078
Validation Loss: 0.0189
Epoch [17/50], Class Loss: 0.0348, Discrepancy Loss: 0.0082
Validation Loss: 0.0183
Epoch [18/50], Class Loss: 0.0445, Discrepancy Loss: 0.0087
Validation Loss: 0.0619
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.82%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 39.38%, Precision: 46.65%, Recall: 39.09%, F1 Score: 35.58%

Run 7/10
Epoch [1/50], Class Loss: 3.0247, Discrepancy Loss: 0.0448
Validation Loss: 2.6682
Epoch [2/50], Class Loss: 2.3043, Discrepancy Loss: 0.0637
Validation Loss: 1.9555
Epoch [3/50], Class Loss: 1.5729, Discrepancy Loss: 0.0393
Validation Loss: 1.7262
Epoch [4/50], Class Loss: 1.5850, Discrepancy Loss: 0.0461
Validation Loss: 0.7709
Epoch [5/50], Class Loss: 1.3443, Discrepancy Loss: 0.0385
Validation Loss: 1.0001
Epoch [6/50], Class Loss: 1.5627, Discrepancy Loss: 0.0287
Validation Loss: 0.6785
Epoch [7/50], Class Loss: 1.3606, Discrepancy Loss: 0.0530
Validation Loss: 2.6594
Epoch [8/50], Class Loss: 1.2314, Discrepancy Loss: 0.0433
Validation Loss: 0.6240
Epoch [9/50], Class Loss: 0.3957, Discrepancy Loss: 0.0183
Validation Loss: 0.7099
Epoch [10/50], Class Loss: 0.6760, Discrepancy Loss: 0.0233
Validation Loss: 0.2103
Epoch [11/50], Class Loss: 0.0506, Discrepancy Loss: 0.0078
Validation Loss: 0.0155
Epoch [12/50], Class Loss: 0.0457, Discrepancy Loss: 0.0067
Validation Loss: 0.0160
Epoch [13/50], Class Loss: 0.1045, Discrepancy Loss: 0.0073
Validation Loss: 0.0103
Epoch [14/50], Class Loss: 0.1414, Discrepancy Loss: 0.0072
Validation Loss: 0.0222
Epoch [15/50], Class Loss: 0.0611, Discrepancy Loss: 0.0076
Validation Loss: 0.0125
Epoch [16/50], Class Loss: 0.2053, Discrepancy Loss: 0.0087
Validation Loss: 0.0149
Epoch [17/50], Class Loss: 0.0497, Discrepancy Loss: 0.0072
Validation Loss: 0.0105
Epoch [18/50], Class Loss: 0.3635, Discrepancy Loss: 0.0094
Validation Loss: 0.3451
Early stopping!
Source Domain Performance - Accuracy: 80.79%, Precision: 70.34%, Recall: 79.97%, F1 Score: 73.63%
Target Domain Performance - Accuracy: 23.90%, Precision: 20.65%, Recall: 23.71%, F1 Score: 16.24%

Run 8/10
Epoch [1/50], Class Loss: 2.8673, Discrepancy Loss: 0.0393
Validation Loss: 1.4111
Epoch [2/50], Class Loss: 1.7777, Discrepancy Loss: 0.0548
Validation Loss: 0.4939
Epoch [3/50], Class Loss: 1.8102, Discrepancy Loss: 0.0506
Validation Loss: 3.7495
Epoch [4/50], Class Loss: 0.9749, Discrepancy Loss: 0.0390
Validation Loss: 0.2564
Epoch [5/50], Class Loss: 0.2979, Discrepancy Loss: 0.0188
Validation Loss: 0.3769
Epoch [6/50], Class Loss: 0.2346, Discrepancy Loss: 0.0197
Validation Loss: 0.0588
Epoch [7/50], Class Loss: 0.1700, Discrepancy Loss: 0.0221
Validation Loss: 0.1236
Epoch [8/50], Class Loss: 0.1583, Discrepancy Loss: 0.0217
Validation Loss: 0.1448
Epoch [9/50], Class Loss: 1.7534, Discrepancy Loss: 0.0492
Validation Loss: 0.7037
Epoch [10/50], Class Loss: 1.8530, Discrepancy Loss: 0.0386
Validation Loss: 18.4957
Epoch [11/50], Class Loss: 0.6624, Discrepancy Loss: 0.0106
Validation Loss: 0.0100
Epoch [12/50], Class Loss: 0.0539, Discrepancy Loss: 0.0154
Validation Loss: 0.0217
Epoch [13/50], Class Loss: 0.0608, Discrepancy Loss: 0.0144
Validation Loss: 0.0098
Epoch [14/50], Class Loss: 0.0888, Discrepancy Loss: 0.0149
Validation Loss: 0.0114
Epoch [15/50], Class Loss: 0.0599, Discrepancy Loss: 0.0151
Validation Loss: 0.0118
Epoch [16/50], Class Loss: 0.0564, Discrepancy Loss: 0.0144
Validation Loss: 0.0136
Epoch [17/50], Class Loss: 0.0793, Discrepancy Loss: 0.0161
Validation Loss: 0.0495
Epoch [18/50], Class Loss: 0.0596, Discrepancy Loss: 0.0180
Validation Loss: 0.0908
Early stopping!
Source Domain Performance - Accuracy: 99.71%, Precision: 99.71%, Recall: 99.69%, F1 Score: 99.70%
Target Domain Performance - Accuracy: 36.96%, Precision: 46.72%, Recall: 37.18%, F1 Score: 29.26%

Run 9/10
Epoch [1/50], Class Loss: 2.3307, Discrepancy Loss: 0.0232
Validation Loss: 1.4190
Epoch [2/50], Class Loss: 1.3010, Discrepancy Loss: 0.0156
Validation Loss: 0.8483
Epoch [3/50], Class Loss: 1.0126, Discrepancy Loss: 0.0167
Validation Loss: 2.0831
Epoch [4/50], Class Loss: 2.5533, Discrepancy Loss: 0.0393
Validation Loss: 3.4224
Epoch [5/50], Class Loss: 1.0224, Discrepancy Loss: 0.0252
Validation Loss: 0.1303
Epoch [6/50], Class Loss: 0.2987, Discrepancy Loss: 0.0066
Validation Loss: 0.6839
Epoch [7/50], Class Loss: 0.4850, Discrepancy Loss: 0.0146
Validation Loss: 0.2941
Epoch [8/50], Class Loss: 1.0283, Discrepancy Loss: 0.0306
Validation Loss: 1.3110
Epoch [9/50], Class Loss: 0.7433, Discrepancy Loss: 0.0299
Validation Loss: 0.0291
Epoch [10/50], Class Loss: 0.6753, Discrepancy Loss: 0.0192
Validation Loss: 0.0337
Epoch [11/50], Class Loss: 0.0451, Discrepancy Loss: 0.0079
Validation Loss: 0.0101
Epoch [12/50], Class Loss: 0.0471, Discrepancy Loss: 0.0092
Validation Loss: 0.0191
Epoch [13/50], Class Loss: 0.0644, Discrepancy Loss: 0.0135
Validation Loss: 0.0144
Epoch [14/50], Class Loss: 0.0620, Discrepancy Loss: 0.0156
Validation Loss: 0.0284
Epoch [15/50], Class Loss: 0.1945, Discrepancy Loss: 0.0190
Validation Loss: 0.0445
Epoch [16/50], Class Loss: 0.1066, Discrepancy Loss: 0.0157
Validation Loss: 0.0215
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.87%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 43.77%, Precision: 32.74%, Recall: 42.48%, F1 Score: 34.83%

Run 10/10
Epoch [1/50], Class Loss: 2.9304, Discrepancy Loss: 0.0457
Validation Loss: 5.2443
Epoch [2/50], Class Loss: 1.7503, Discrepancy Loss: 0.0376
Validation Loss: 0.8945
Epoch [3/50], Class Loss: 1.1097, Discrepancy Loss: 0.0288
Validation Loss: 0.0219
Epoch [4/50], Class Loss: 2.2227, Discrepancy Loss: 0.0343
Validation Loss: 1.6010
Epoch [5/50], Class Loss: 1.9052, Discrepancy Loss: 0.0433
Validation Loss: 1.0700
Epoch [6/50], Class Loss: 1.9205, Discrepancy Loss: 0.0519
Validation Loss: 1.3025
Epoch [7/50], Class Loss: 1.3465, Discrepancy Loss: 0.0303
Validation Loss: 10.4936
Epoch [8/50], Class Loss: 2.2719, Discrepancy Loss: 0.0653
Validation Loss: 1.1272
Early stopping!
Source Domain Performance - Accuracy: 80.20%, Precision: 89.39%, Recall: 80.81%, F1 Score: 75.31%
Target Domain Performance - Accuracy: 45.09%, Precision: 34.62%, Recall: 43.87%, F1 Score: 36.70%

Source performance: 94.07% 94.90% 93.97% 92.15%
Target performance: 37.37% 38.99% 36.75% 29.87%

Per-Class Accuracy on Target Domain:
bpsk: 49.48%
qpsk: 35.00%
4qam: 0.00%
16qam: 99.29%
apsk: 0.00%

Run 1/10
Epoch [1/50], Class Loss: 1.3015, CORAL Loss: 0.0068
Validation Loss: 0.8712
Epoch [2/50], Class Loss: 0.4721, CORAL Loss: 0.0338
Validation Loss: 0.2819
Epoch [3/50], Class Loss: 0.7365, CORAL Loss: 0.0278
Validation Loss: 0.2253
Epoch [4/50], Class Loss: 0.4065, CORAL Loss: 0.0221
Validation Loss: 0.8788
Epoch [5/50], Class Loss: 0.3428, CORAL Loss: 0.0116
Validation Loss: 0.1511
Epoch [6/50], Class Loss: 0.3492, CORAL Loss: 0.0130
Validation Loss: 0.2488
Epoch [7/50], Class Loss: 0.1879, CORAL Loss: 0.0097
Validation Loss: 0.0130
Epoch [8/50], Class Loss: 0.2204, CORAL Loss: 0.0061
Validation Loss: 0.1151
Epoch [9/50], Class Loss: 0.0882, CORAL Loss: 0.0094
Validation Loss: 0.0144
Epoch [10/50], Class Loss: 0.2233, CORAL Loss: 0.0085
Validation Loss: 0.0103
Epoch [11/50], Class Loss: 0.0163, CORAL Loss: 0.0065
Validation Loss: 0.0071
Epoch [12/50], Class Loss: 0.0129, CORAL Loss: 0.0059
Validation Loss: 0.0058
Epoch [13/50], Class Loss: 0.0102, CORAL Loss: 0.0053
Validation Loss: 0.0053
Epoch [14/50], Class Loss: 0.0090, CORAL Loss: 0.0047
Validation Loss: 0.0043
Epoch [15/50], Class Loss: 0.0078, CORAL Loss: 0.0042
Validation Loss: 0.0040
Epoch [16/50], Class Loss: 0.0068, CORAL Loss: 0.0038
Validation Loss: 0.0031
Epoch [17/50], Class Loss: 0.0065, CORAL Loss: 0.0033
Validation Loss: 0.0026
Epoch [18/50], Class Loss: 0.0060, CORAL Loss: 0.0029
Validation Loss: 0.0023
Epoch [19/50], Class Loss: 0.0057, CORAL Loss: 0.0025
Validation Loss: 0.0022
Epoch [20/50], Class Loss: 0.0051, CORAL Loss: 0.0022
Validation Loss: 0.0020
Epoch [21/50], Class Loss: 0.0049, CORAL Loss: 0.0021
Validation Loss: 0.0018
Epoch [22/50], Class Loss: 0.0049, CORAL Loss: 0.0021
Validation Loss: 0.0019
Epoch [23/50], Class Loss: 0.0050, CORAL Loss: 0.0020
Validation Loss: 0.0019
Epoch [24/50], Class Loss: 0.0049, CORAL Loss: 0.0020
Validation Loss: 0.0019
Epoch [25/50], Class Loss: 0.0047, CORAL Loss: 0.0020
Validation Loss: 0.0018
Epoch [26/50], Class Loss: 0.0046, CORAL Loss: 0.0019
Validation Loss: 0.0017
Epoch [27/50], Class Loss: 0.0044, CORAL Loss: 0.0019
Validation Loss: 0.0018
Epoch [28/50], Class Loss: 0.0046, CORAL Loss: 0.0018
Validation Loss: 0.0017
Epoch [29/50], Class Loss: 0.0045, CORAL Loss: 0.0018
Validation Loss: 0.0017
Epoch [30/50], Class Loss: 0.0047, CORAL Loss: 0.0018
Validation Loss: 0.0017
Epoch [31/50], Class Loss: 0.0042, CORAL Loss: 0.0017
Validation Loss: 0.0017
Epoch [32/50], Class Loss: 0.0042, CORAL Loss: 0.0017
Validation Loss: 0.0017
Epoch [33/50], Class Loss: 0.0044, CORAL Loss: 0.0017
Validation Loss: 0.0017
Epoch [34/50], Class Loss: 0.0042, CORAL Loss: 0.0017
Validation Loss: 0.0017
Epoch [35/50], Class Loss: 0.0047, CORAL Loss: 0.0017
Validation Loss: 0.0017
Epoch [36/50], Class Loss: 0.0043, CORAL Loss: 0.0017
Validation Loss: 0.0017
Epoch [37/50], Class Loss: 0.0040, CORAL Loss: 0.0017
Validation Loss: 0.0017
Epoch [38/50], Class Loss: 0.0044, CORAL Loss: 0.0017
Validation Loss: 0.0017
Epoch [39/50], Class Loss: 0.0042, CORAL Loss: 0.0017
Validation Loss: 0.0017
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.97%
Target Domain Performance - Accuracy: 46.09%, Precision: 45.21%, Recall: 44.86%, F1 Score: 38.05%

Run 2/10
Epoch [1/50], Class Loss: 1.4827, CORAL Loss: 0.0036
Validation Loss: 1.1820
Epoch [2/50], Class Loss: 0.5809, CORAL Loss: 0.0312
Validation Loss: 0.3662
Epoch [3/50], Class Loss: 15.4618, CORAL Loss: 15.3467
Validation Loss: 1.6126
Epoch [4/50], Class Loss: 1.6812, CORAL Loss: 0.0469
Validation Loss: 1.6226
Epoch [5/50], Class Loss: 1.6486, CORAL Loss: 0.0424
Validation Loss: 1.6856
Epoch [6/50], Class Loss: 1.6272, CORAL Loss: 0.0377
Validation Loss: 1.6123
Epoch [7/50], Class Loss: 1.6102, CORAL Loss: 0.0327
Validation Loss: 1.6110
Early stopping!
Source Domain Performance - Accuracy: 20.02%, Precision: 4.00%, Recall: 20.00%, F1 Score: 6.67%
Target Domain Performance - Accuracy: 20.31%, Precision: 4.06%, Recall: 20.00%, F1 Score: 6.75%

Run 3/10
Epoch [1/50], Class Loss: 1.3377, CORAL Loss: 0.0089
Validation Loss: 0.5625
Epoch [2/50], Class Loss: 0.4030, CORAL Loss: 0.0256
Validation Loss: 0.1795
Epoch [3/50], Class Loss: 0.3182, CORAL Loss: 0.0161
Validation Loss: 0.4186
Epoch [4/50], Class Loss: 0.3056, CORAL Loss: 0.0087
Validation Loss: 0.8130
Epoch [5/50], Class Loss: 0.1378, CORAL Loss: 0.0065
Validation Loss: 0.0093
Epoch [6/50], Class Loss: 0.2280, CORAL Loss: 0.0096
Validation Loss: 0.0044
Epoch [7/50], Class Loss: 0.1238, CORAL Loss: 0.0056
Validation Loss: 0.0069
Epoch [8/50], Class Loss: 0.0070, CORAL Loss: 0.0025
Validation Loss: 0.0041
Epoch [9/50], Class Loss: 0.1230, CORAL Loss: 0.0031
Validation Loss: 0.1350
Epoch [10/50], Class Loss: 0.0266, CORAL Loss: 0.0046
Validation Loss: 0.4366
Epoch [11/50], Class Loss: 0.0141, CORAL Loss: 0.0018
Validation Loss: 0.0015
Epoch [12/50], Class Loss: 0.0052, CORAL Loss: 0.0019
Validation Loss: 0.0015
Epoch [13/50], Class Loss: 0.0049, CORAL Loss: 0.0017
Validation Loss: 0.0014
Epoch [14/50], Class Loss: 0.0051, CORAL Loss: 0.0018
Validation Loss: 0.0014
Epoch [15/50], Class Loss: 0.0049, CORAL Loss: 0.0019
Validation Loss: 0.0013
Epoch [16/50], Class Loss: 0.0052, CORAL Loss: 0.0017
Validation Loss: 0.0012
Epoch [17/50], Class Loss: 0.0045, CORAL Loss: 0.0017
Validation Loss: 0.0014
Epoch [18/50], Class Loss: 0.0047, CORAL Loss: 0.0015
Validation Loss: 0.0012
Epoch [19/50], Class Loss: 0.0044, CORAL Loss: 0.0015
Validation Loss: 0.0011
Epoch [20/50], Class Loss: 0.0044, CORAL Loss: 0.0015
Validation Loss: 0.0011
Epoch [21/50], Class Loss: 0.0038, CORAL Loss: 0.0015
Validation Loss: 0.0011
Epoch [22/50], Class Loss: 0.0037, CORAL Loss: 0.0015
Validation Loss: 0.0011
Epoch [23/50], Class Loss: 0.0036, CORAL Loss: 0.0015
Validation Loss: 0.0011
Epoch [24/50], Class Loss: 0.0038, CORAL Loss: 0.0014
Validation Loss: 0.0011
Epoch [25/50], Class Loss: 0.0039, CORAL Loss: 0.0014
Validation Loss: 0.0011
Epoch [26/50], Class Loss: 0.0038, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [27/50], Class Loss: 0.0037, CORAL Loss: 0.0014
Validation Loss: 0.0011
Epoch [28/50], Class Loss: 0.0036, CORAL Loss: 0.0015
Validation Loss: 0.0010
Epoch [29/50], Class Loss: 0.0036, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [30/50], Class Loss: 0.0036, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [31/50], Class Loss: 0.0033, CORAL Loss: 0.0014
Validation Loss: 0.0011
Epoch [32/50], Class Loss: 0.0035, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [33/50], Class Loss: 0.0037, CORAL Loss: 0.0013
Validation Loss: 0.0010
Epoch [34/50], Class Loss: 0.0035, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [35/50], Class Loss: 0.0035, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [36/50], Class Loss: 0.0036, CORAL Loss: 0.0015
Validation Loss: 0.0011
Epoch [37/50], Class Loss: 0.0034, CORAL Loss: 0.0013
Validation Loss: 0.0010
Epoch [38/50], Class Loss: 0.0036, CORAL Loss: 0.0013
Validation Loss: 0.0010
Epoch [39/50], Class Loss: 0.0035, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [40/50], Class Loss: 0.0036, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [41/50], Class Loss: 0.0036, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [42/50], Class Loss: 0.0035, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [43/50], Class Loss: 0.0035, CORAL Loss: 0.0015
Validation Loss: 0.0010
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.97%
Target Domain Performance - Accuracy: 44.14%, Precision: 44.31%, Recall: 42.85%, F1 Score: 35.40%

Run 4/10
Epoch [1/50], Class Loss: 1.5381, CORAL Loss: 0.0039
Validation Loss: 0.9008
Epoch [2/50], Class Loss: 0.9506, CORAL Loss: 1.4045
Validation Loss: 0.8553
Epoch [3/50], Class Loss: 0.8011, CORAL Loss: 0.0177
Validation Loss: 0.5966
Epoch [4/50], Class Loss: 0.5856, CORAL Loss: 0.0457
Validation Loss: 0.3395
Epoch [5/50], Class Loss: 0.4713, CORAL Loss: 0.0501
Validation Loss: 0.2771
Epoch [6/50], Class Loss: 0.3434, CORAL Loss: 0.0438
Validation Loss: 0.1928
Epoch [7/50], Class Loss: 0.3491, CORAL Loss: 0.0329
Validation Loss: 0.2989
Epoch [8/50], Class Loss: 0.2333, CORAL Loss: 0.0219
Validation Loss: 0.1522
Epoch [9/50], Class Loss: 0.2600, CORAL Loss: 0.0119
Validation Loss: 0.1230
Epoch [10/50], Class Loss: 0.0692, CORAL Loss: 0.0097
Validation Loss: 0.0077
Epoch [11/50], Class Loss: 0.0109, CORAL Loss: 0.0078
Validation Loss: 0.0074
Epoch [12/50], Class Loss: 0.0104, CORAL Loss: 0.0073
Validation Loss: 0.0096
Epoch [13/50], Class Loss: 0.0107, CORAL Loss: 0.0065
Validation Loss: 0.0085
Epoch [14/50], Class Loss: 0.0099, CORAL Loss: 0.0064
Validation Loss: 0.0082
Epoch [15/50], Class Loss: 0.0105, CORAL Loss: 0.0065
Validation Loss: 0.0074
Epoch [16/50], Class Loss: 0.0102, CORAL Loss: 0.0062
Validation Loss: 0.0087
Epoch [17/50], Class Loss: 0.0089, CORAL Loss: 0.0060
Validation Loss: 0.0061
Epoch [18/50], Class Loss: 0.0098, CORAL Loss: 0.0057
Validation Loss: 0.0078
Epoch [19/50], Class Loss: 0.0094, CORAL Loss: 0.0052
Validation Loss: 0.0041
Epoch [20/50], Class Loss: 0.0089, CORAL Loss: 0.0052
Validation Loss: 0.0075
Epoch [21/50], Class Loss: 0.0091, CORAL Loss: 0.0048
Validation Loss: 0.0071
Epoch [22/50], Class Loss: 0.0076, CORAL Loss: 0.0048
Validation Loss: 0.0070
Epoch [23/50], Class Loss: 0.0079, CORAL Loss: 0.0050
Validation Loss: 0.0086
Epoch [24/50], Class Loss: 0.0082, CORAL Loss: 0.0046
Validation Loss: 0.0066
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.81%, Recall: 99.80%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 43.24%, Precision: 46.34%, Recall: 41.92%, F1 Score: 34.27%

Run 5/10
Epoch [1/50], Class Loss: 1.4406, CORAL Loss: 0.0015
Validation Loss: 0.8600
Epoch [2/50], Class Loss: 0.8756, CORAL Loss: 0.0213
Validation Loss: 0.4415
Epoch [3/50], Class Loss: 0.4311, CORAL Loss: 0.0271
Validation Loss: 0.8896
Epoch [4/50], Class Loss: 0.3558, CORAL Loss: 0.0180
Validation Loss: 0.2135
Epoch [5/50], Class Loss: 0.3334, CORAL Loss: 0.0170
Validation Loss: 0.4450
Epoch [6/50], Class Loss: 0.2905, CORAL Loss: 0.0094
Validation Loss: 0.0559
Epoch [7/50], Class Loss: 0.3471, CORAL Loss: 0.0058
Validation Loss: 0.0237
Epoch [8/50], Class Loss: 0.2179, CORAL Loss: 0.0057
Validation Loss: 0.0071
Epoch [9/50], Class Loss: 0.1344, CORAL Loss: 0.0031
Validation Loss: 0.0322
Epoch [10/50], Class Loss: 0.0462, CORAL Loss: 0.0025
Validation Loss: 0.0049
Epoch [11/50], Class Loss: 0.0076, CORAL Loss: 0.0015
Validation Loss: 0.0034
Epoch [12/50], Class Loss: 0.0066, CORAL Loss: 0.0014
Validation Loss: 0.0026
Epoch [13/50], Class Loss: 0.0062, CORAL Loss: 0.0013
Validation Loss: 0.0025
Epoch [14/50], Class Loss: 0.0060, CORAL Loss: 0.0014
Validation Loss: 0.0020
Epoch [15/50], Class Loss: 0.0056, CORAL Loss: 0.0013
Validation Loss: 0.0020
Epoch [16/50], Class Loss: 0.0050, CORAL Loss: 0.0013
Validation Loss: 0.0016
Epoch [17/50], Class Loss: 0.0051, CORAL Loss: 0.0013
Validation Loss: 0.0017
Epoch [18/50], Class Loss: 0.0044, CORAL Loss: 0.0014
Validation Loss: 0.0023
Epoch [19/50], Class Loss: 0.0044, CORAL Loss: 0.0013
Validation Loss: 0.0014
Epoch [20/50], Class Loss: 0.0044, CORAL Loss: 0.0014
Validation Loss: 0.0011
Epoch [21/50], Class Loss: 0.0043, CORAL Loss: 0.0014
Validation Loss: 0.0012
Epoch [22/50], Class Loss: 0.0039, CORAL Loss: 0.0014
Validation Loss: 0.0013
Epoch [23/50], Class Loss: 0.0039, CORAL Loss: 0.0014
Validation Loss: 0.0013
Epoch [24/50], Class Loss: 0.0042, CORAL Loss: 0.0013
Validation Loss: 0.0012
Epoch [25/50], Class Loss: 0.0038, CORAL Loss: 0.0013
Validation Loss: 0.0014
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.97%
Target Domain Performance - Accuracy: 44.46%, Precision: 45.97%, Recall: 43.22%, F1 Score: 36.36%

Run 6/10
Epoch [1/50], Class Loss: 1.2715, CORAL Loss: 0.0105
Validation Loss: 0.7332
Epoch [2/50], Class Loss: 0.5492, CORAL Loss: 0.0319
Validation Loss: 0.3080
Epoch [3/50], Class Loss: 0.3678, CORAL Loss: 0.0208
Validation Loss: 0.3184
Epoch [4/50], Class Loss: 0.2843, CORAL Loss: 0.0173
Validation Loss: 0.8665
Epoch [5/50], Class Loss: 0.5150, CORAL Loss: 0.0406
Validation Loss: 6.7595
Epoch [6/50], Class Loss: 1.0359, CORAL Loss: 0.0148
Validation Loss: 0.3886
Epoch [7/50], Class Loss: 0.3819, CORAL Loss: 0.0327
Validation Loss: 0.1733
Epoch [8/50], Class Loss: 0.2963, CORAL Loss: 0.0150
Validation Loss: 0.1202
Epoch [9/50], Class Loss: 0.2541, CORAL Loss: 0.0120
Validation Loss: 0.6151
Epoch [10/50], Class Loss: 0.1375, CORAL Loss: 0.0095
Validation Loss: 0.1654
Epoch [11/50], Class Loss: 0.0171, CORAL Loss: 0.0066
Validation Loss: 0.0068
Epoch [12/50], Class Loss: 0.0121, CORAL Loss: 0.0059
Validation Loss: 0.0061
Epoch [13/50], Class Loss: 0.0113, CORAL Loss: 0.0057
Validation Loss: 0.0061
Epoch [14/50], Class Loss: 0.0110, CORAL Loss: 0.0053
Validation Loss: 0.0055
Epoch [15/50], Class Loss: 0.0110, CORAL Loss: 0.0050
Validation Loss: 0.0058
Epoch [16/50], Class Loss: 0.0109, CORAL Loss: 0.0048
Validation Loss: 0.0057
Epoch [17/50], Class Loss: 0.0103, CORAL Loss: 0.0044
Validation Loss: 0.0051
Epoch [18/50], Class Loss: 0.0100, CORAL Loss: 0.0045
Validation Loss: 0.0081
Epoch [19/50], Class Loss: 0.0100, CORAL Loss: 0.0042
Validation Loss: 0.0057
Epoch [20/50], Class Loss: 0.0092, CORAL Loss: 0.0040
Validation Loss: 0.0054
Epoch [21/50], Class Loss: 0.0087, CORAL Loss: 0.0038
Validation Loss: 0.0047
Epoch [22/50], Class Loss: 0.0090, CORAL Loss: 0.0038
Validation Loss: 0.0045
Epoch [23/50], Class Loss: 0.0087, CORAL Loss: 0.0037
Validation Loss: 0.0052
Epoch [24/50], Class Loss: 0.0086, CORAL Loss: 0.0036
Validation Loss: 0.0048
Epoch [25/50], Class Loss: 0.0088, CORAL Loss: 0.0038
Validation Loss: 0.0047
Epoch [26/50], Class Loss: 0.0087, CORAL Loss: 0.0036
Validation Loss: 0.0044
Epoch [27/50], Class Loss: 0.0085, CORAL Loss: 0.0036
Validation Loss: 0.0047
Epoch [28/50], Class Loss: 0.0083, CORAL Loss: 0.0036
Validation Loss: 0.0040
Epoch [29/50], Class Loss: 0.0087, CORAL Loss: 0.0036
Validation Loss: 0.0045
Epoch [30/50], Class Loss: 0.0087, CORAL Loss: 0.0036
Validation Loss: 0.0036
Epoch [31/50], Class Loss: 0.0087, CORAL Loss: 0.0034
Validation Loss: 0.0042
Epoch [32/50], Class Loss: 0.0083, CORAL Loss: 0.0035
Validation Loss: 0.0044
Epoch [33/50], Class Loss: 0.0087, CORAL Loss: 0.0035
Validation Loss: 0.0044
Epoch [34/50], Class Loss: 0.0085, CORAL Loss: 0.0035
Validation Loss: 0.0042
Epoch [35/50], Class Loss: 0.0084, CORAL Loss: 0.0036
Validation Loss: 0.0043
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.92%, F1 Score: 99.92%
Target Domain Performance - Accuracy: 44.07%, Precision: 46.29%, Recall: 42.84%, F1 Score: 36.06%

Run 7/10
Epoch [1/50], Class Loss: 1.2403, CORAL Loss: 0.0157
Validation Loss: 0.5054
Epoch [2/50], Class Loss: 0.5403, CORAL Loss: 0.0319
Validation Loss: 2.2900
Epoch [3/50], Class Loss: 0.3384, CORAL Loss: 0.0143
Validation Loss: 0.0758
Epoch [4/50], Class Loss: 0.4003, CORAL Loss: 0.0196
Validation Loss: 1.1680
Epoch [5/50], Class Loss: 0.2217, CORAL Loss: 0.0266
Validation Loss: 0.0762
Epoch [6/50], Class Loss: 0.1634, CORAL Loss: 0.0127
Validation Loss: 0.0607
Epoch [7/50], Class Loss: 0.0157, CORAL Loss: 0.0060
Validation Loss: 0.0036
Epoch [8/50], Class Loss: 0.1748, CORAL Loss: 0.0063
Validation Loss: 0.0045
Epoch [9/50], Class Loss: 0.0080, CORAL Loss: 0.0029
Validation Loss: 0.0023
Epoch [10/50], Class Loss: 0.0058, CORAL Loss: 0.0025
Validation Loss: 0.0009
Epoch [11/50], Class Loss: 0.0042, CORAL Loss: 0.0021
Validation Loss: 0.0009
Epoch [12/50], Class Loss: 0.0039, CORAL Loss: 0.0018
Validation Loss: 0.0010
Epoch [13/50], Class Loss: 0.0043, CORAL Loss: 0.0016
Validation Loss: 0.0015
Epoch [14/50], Class Loss: 0.0042, CORAL Loss: 0.0016
Validation Loss: 0.0009
Epoch [15/50], Class Loss: 0.0041, CORAL Loss: 0.0015
Validation Loss: 0.0011
Epoch [16/50], Class Loss: 0.0038, CORAL Loss: 0.0017
Validation Loss: 0.0010
Epoch [17/50], Class Loss: 0.0039, CORAL Loss: 0.0016
Validation Loss: 0.0010
Epoch [18/50], Class Loss: 0.0039, CORAL Loss: 0.0014
Validation Loss: 0.0010
Epoch [19/50], Class Loss: 0.0038, CORAL Loss: 0.0013
Validation Loss: 0.0009
Epoch [20/50], Class Loss: 0.0038, CORAL Loss: 0.0014
Validation Loss: 0.0009
Epoch [21/50], Class Loss: 0.0034, CORAL Loss: 0.0013
Validation Loss: 0.0008
Epoch [22/50], Class Loss: 0.0033, CORAL Loss: 0.0014
Validation Loss: 0.0008
Epoch [23/50], Class Loss: 0.0032, CORAL Loss: 0.0015
Validation Loss: 0.0010
Epoch [24/50], Class Loss: 0.0032, CORAL Loss: 0.0012
Validation Loss: 0.0011
Epoch [25/50], Class Loss: 0.0034, CORAL Loss: 0.0012
Validation Loss: 0.0009
Epoch [26/50], Class Loss: 0.0032, CORAL Loss: 0.0012
Validation Loss: 0.0009
Epoch [27/50], Class Loss: 0.0031, CORAL Loss: 0.0014
Validation Loss: 0.0009
Early stopping!
Source Domain Performance - Accuracy: 100.00%, Precision: 100.00%, Recall: 100.00%, F1 Score: 100.00%
Target Domain Performance - Accuracy: 46.44%, Precision: 45.21%, Recall: 45.24%, F1 Score: 38.65%

Run 8/10
Epoch [1/50], Class Loss: 1.2223, CORAL Loss: 0.0110
Validation Loss: 1.0786
Epoch [2/50], Class Loss: 0.5182, CORAL Loss: 0.0255
Validation Loss: 0.2608
Epoch [3/50], Class Loss: 0.5446, CORAL Loss: 0.0199
Validation Loss: 0.3626
Epoch [4/50], Class Loss: 0.3108, CORAL Loss: 0.0165
Validation Loss: 0.4400
Epoch [5/50], Class Loss: 0.3168, CORAL Loss: 0.0138
Validation Loss: 0.8508
Epoch [6/50], Class Loss: 0.2395, CORAL Loss: 0.0114
Validation Loss: 0.1179
Epoch [7/50], Class Loss: 0.2578, CORAL Loss: 0.0085
Validation Loss: 0.1342
Epoch [8/50], Class Loss: 0.3100, CORAL Loss: 0.0081
Validation Loss: 0.0914
Epoch [9/50], Class Loss: 0.0994, CORAL Loss: 0.0056
Validation Loss: 0.0089
Epoch [10/50], Class Loss: 0.0446, CORAL Loss: 0.0042
Validation Loss: 1.1467
Epoch [11/50], Class Loss: 0.0502, CORAL Loss: 0.0126
Validation Loss: 0.0087
Epoch [12/50], Class Loss: 0.0115, CORAL Loss: 0.0066
Validation Loss: 0.0065
Epoch [13/50], Class Loss: 0.0089, CORAL Loss: 0.0047
Validation Loss: 0.0054
Epoch [14/50], Class Loss: 0.0078, CORAL Loss: 0.0041
Validation Loss: 0.0044
Epoch [15/50], Class Loss: 0.0073, CORAL Loss: 0.0037
Validation Loss: 0.0043
Epoch [16/50], Class Loss: 0.0068, CORAL Loss: 0.0032
Validation Loss: 0.0051
Epoch [17/50], Class Loss: 0.0063, CORAL Loss: 0.0028
Validation Loss: 0.0036
Epoch [18/50], Class Loss: 0.0062, CORAL Loss: 0.0027
Validation Loss: 0.0035
Epoch [19/50], Class Loss: 0.0058, CORAL Loss: 0.0024
Validation Loss: 0.0036
Epoch [20/50], Class Loss: 0.0055, CORAL Loss: 0.0023
Validation Loss: 0.0035
Epoch [21/50], Class Loss: 0.0052, CORAL Loss: 0.0021
Validation Loss: 0.0030
Epoch [22/50], Class Loss: 0.0052, CORAL Loss: 0.0021
Validation Loss: 0.0031
Epoch [23/50], Class Loss: 0.0051, CORAL Loss: 0.0020
Validation Loss: 0.0031
Epoch [24/50], Class Loss: 0.0050, CORAL Loss: 0.0021
Validation Loss: 0.0030
Epoch [25/50], Class Loss: 0.0051, CORAL Loss: 0.0022
Validation Loss: 0.0031
Epoch [26/50], Class Loss: 0.0052, CORAL Loss: 0.0020
Validation Loss: 0.0029
Epoch [27/50], Class Loss: 0.0051, CORAL Loss: 0.0021
Validation Loss: 0.0029
Epoch [28/50], Class Loss: 0.0050, CORAL Loss: 0.0020
Validation Loss: 0.0029
Epoch [29/50], Class Loss: 0.0047, CORAL Loss: 0.0020
Validation Loss: 0.0028
Epoch [30/50], Class Loss: 0.0049, CORAL Loss: 0.0019
Validation Loss: 0.0028
Epoch [31/50], Class Loss: 0.0046, CORAL Loss: 0.0019
Validation Loss: 0.0029
Epoch [32/50], Class Loss: 0.0048, CORAL Loss: 0.0019
Validation Loss: 0.0028
Epoch [33/50], Class Loss: 0.0046, CORAL Loss: 0.0018
Validation Loss: 0.0029
Epoch [34/50], Class Loss: 0.0048, CORAL Loss: 0.0018
Validation Loss: 0.0028
Epoch [35/50], Class Loss: 0.0049, CORAL Loss: 0.0019
Validation Loss: 0.0028
Epoch [36/50], Class Loss: 0.0048, CORAL Loss: 0.0019
Validation Loss: 0.0028
Epoch [37/50], Class Loss: 0.0049, CORAL Loss: 0.0019
Validation Loss: 0.0028
Epoch [38/50], Class Loss: 0.0049, CORAL Loss: 0.0019
Validation Loss: 0.0028
Epoch [39/50], Class Loss: 0.0046, CORAL Loss: 0.0018
Validation Loss: 0.0028
Epoch [40/50], Class Loss: 0.0048, CORAL Loss: 0.0018
Validation Loss: 0.0027
Epoch [41/50], Class Loss: 0.0049, CORAL Loss: 0.0019
Validation Loss: 0.0028
Epoch [42/50], Class Loss: 0.0046, CORAL Loss: 0.0018
Validation Loss: 0.0028
Epoch [43/50], Class Loss: 0.0048, CORAL Loss: 0.0018
Validation Loss: 0.0028
Epoch [44/50], Class Loss: 0.0046, CORAL Loss: 0.0019
Validation Loss: 0.0028
Epoch [45/50], Class Loss: 0.0049, CORAL Loss: 0.0018
Validation Loss: 0.0028
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 46.41%, Precision: 45.49%, Recall: 45.23%, F1 Score: 38.81%

Run 9/10
Epoch [1/50], Class Loss: 1.3471, CORAL Loss: 0.0114
Validation Loss: 0.6656
Epoch [2/50], Class Loss: 3.1746, CORAL Loss: 0.5620
Validation Loss: 1.6088
Epoch [3/50], Class Loss: 1.6105, CORAL Loss: 0.0001
Validation Loss: 1.6089
Epoch [4/50], Class Loss: 1.6098, CORAL Loss: 0.0001
Validation Loss: 1.6092
Epoch [5/50], Class Loss: 1.6096, CORAL Loss: 0.0001
Validation Loss: 1.6094
Epoch [6/50], Class Loss: 1.6095, CORAL Loss: 0.0001
Validation Loss: 1.6096
Early stopping!
Source Domain Performance - Accuracy: 18.97%, Precision: 3.79%, Recall: 20.00%, F1 Score: 6.38%
Target Domain Performance - Accuracy: 19.34%, Precision: 3.87%, Recall: 20.00%, F1 Score: 6.48%

Run 10/10
Epoch [1/50], Class Loss: 1.2782, CORAL Loss: 0.0086
Validation Loss: 0.7936
Epoch [2/50], Class Loss: 0.4712, CORAL Loss: 0.0279
Validation Loss: 0.3115
Epoch [3/50], Class Loss: 0.3367, CORAL Loss: 0.0184
Validation Loss: 0.2254
Epoch [4/50], Class Loss: 0.2872, CORAL Loss: 0.0114
Validation Loss: 0.0659
Epoch [5/50], Class Loss: 0.4159, CORAL Loss: 0.0115
Validation Loss: 0.1643
Epoch [6/50], Class Loss: 0.2070, CORAL Loss: 0.0168
Validation Loss: 0.1388
Epoch [7/50], Class Loss: 0.1634, CORAL Loss: 0.0097
Validation Loss: 0.0323
Epoch [8/50], Class Loss: 0.1304, CORAL Loss: 0.0058
Validation Loss: 0.0051
Epoch [9/50], Class Loss: 0.0094, CORAL Loss: 0.0041
Validation Loss: 0.0025
Epoch [10/50], Class Loss: 0.2716, CORAL Loss: 0.0088
Validation Loss: 0.0884
Epoch [11/50], Class Loss: 0.0394, CORAL Loss: 0.0138
Validation Loss: 0.0201
Epoch [12/50], Class Loss: 0.0266, CORAL Loss: 0.0128
Validation Loss: 0.0132
Epoch [13/50], Class Loss: 0.0192, CORAL Loss: 0.0108
Validation Loss: 0.0091
Epoch [14/50], Class Loss: 0.0151, CORAL Loss: 0.0088
Validation Loss: 0.0069
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.97%
Target Domain Performance - Accuracy: 42.09%, Precision: 37.27%, Recall: 40.74%, F1 Score: 32.15%

Source performance: 83.86% 80.74% 83.96% 81.26%
Target performance: 39.66% 36.40% 38.69% 30.30%

Per-Class Accuracy on Target Domain:
bpsk: 78.29%
qpsk: 25.39%
4qam: 0.00%
16qam: 89.77%
apsk: 0.00%

Run 1/10
Epoch [1/50], Class Loss: 1.6213, JMMD Loss: 0.0793
Validation Loss: 1.5985
Epoch [2/50], Class Loss: 0.9469, JMMD Loss: 0.4396
Validation Loss: 0.2439
Epoch [3/50], Class Loss: 0.3361, JMMD Loss: 0.4921
Validation Loss: 0.2809
Epoch [4/50], Class Loss: 0.2360, JMMD Loss: 0.5022
Validation Loss: 0.1270
Epoch [5/50], Class Loss: 0.1653, JMMD Loss: 0.5095
Validation Loss: 0.0274
Epoch [6/50], Class Loss: 0.3417, JMMD Loss: 0.5015
Validation Loss: 0.0386
Epoch [7/50], Class Loss: 0.0912, JMMD Loss: 0.5161
Validation Loss: 0.0279
Epoch [8/50], Class Loss: 0.1302, JMMD Loss: 0.5035
Validation Loss: 0.0172
Epoch [9/50], Class Loss: 0.0138, JMMD Loss: 0.4100
Validation Loss: 0.0061
Epoch [10/50], Class Loss: 0.5607, JMMD Loss: 0.4537
Validation Loss: 0.1662
Epoch [11/50], Class Loss: 0.0906, JMMD Loss: 0.4896
Validation Loss: 0.0538
Epoch [12/50], Class Loss: 0.0645, JMMD Loss: 0.4971
Validation Loss: 0.0386
Epoch [13/50], Class Loss: 0.0476, JMMD Loss: 0.4958
Validation Loss: 0.0242
Epoch [14/50], Class Loss: 0.0331, JMMD Loss: 0.4953
Validation Loss: 0.0205
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 41.36%, Precision: 30.87%, Recall: 39.96%, F1 Score: 30.44%

Run 2/10
Epoch [1/50], Class Loss: 1.3183, JMMD Loss: 0.3114
Validation Loss: 0.6500
Epoch [2/50], Class Loss: 0.6446, JMMD Loss: 0.4652
Validation Loss: 0.3059
Epoch [3/50], Class Loss: 0.2785, JMMD Loss: 0.4699
Validation Loss: 0.0884
Epoch [4/50], Class Loss: 0.2520, JMMD Loss: 0.4976
Validation Loss: 0.2689
Epoch [5/50], Class Loss: 0.2532, JMMD Loss: 0.5068
Validation Loss: 0.1619
Epoch [6/50], Class Loss: 0.1734, JMMD Loss: 0.4927
Validation Loss: 0.1970
Epoch [7/50], Class Loss: 0.2744, JMMD Loss: 0.4838
Validation Loss: 0.0810
Epoch [8/50], Class Loss: 0.0795, JMMD Loss: 0.5020
Validation Loss: 0.0089
Epoch [9/50], Class Loss: 0.0123, JMMD Loss: 0.3874
Validation Loss: 0.0068
Epoch [10/50], Class Loss: 0.2373, JMMD Loss: 0.4657
Validation Loss: 0.0282
Epoch [11/50], Class Loss: 0.0247, JMMD Loss: 0.5044
Validation Loss: 0.0164
Epoch [12/50], Class Loss: 0.0188, JMMD Loss: 0.4999
Validation Loss: 0.0127
Epoch [13/50], Class Loss: 0.0157, JMMD Loss: 0.4995
Validation Loss: 0.0103
Epoch [14/50], Class Loss: 0.0133, JMMD Loss: 0.4997
Validation Loss: 0.0092
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.97%
Target Domain Performance - Accuracy: 47.09%, Precision: 44.45%, Recall: 45.90%, F1 Score: 39.25%

Run 3/10
Epoch [1/50], Class Loss: 1.3749, JMMD Loss: 0.2787
Validation Loss: 0.5182
Epoch [2/50], Class Loss: 0.6035, JMMD Loss: 0.4483
Validation Loss: 0.2071
Epoch [3/50], Class Loss: 0.6442, JMMD Loss: 0.4727
Validation Loss: 0.1848
Epoch [4/50], Class Loss: 0.2222, JMMD Loss: 0.4980
Validation Loss: 0.1031
Epoch [5/50], Class Loss: 0.2653, JMMD Loss: 0.4985
Validation Loss: 0.0835
Epoch [6/50], Class Loss: 0.3226, JMMD Loss: 0.4962
Validation Loss: 0.0493
Epoch [7/50], Class Loss: 0.3188, JMMD Loss: 0.5014
Validation Loss: 0.2829
Epoch [8/50], Class Loss: 0.0483, JMMD Loss: 0.5039
Validation Loss: 0.0063
Epoch [9/50], Class Loss: 0.1665, JMMD Loss: 0.4950
Validation Loss: 0.0068
Epoch [10/50], Class Loss: 0.0121, JMMD Loss: 0.3647
Validation Loss: 0.0090
Epoch [11/50], Class Loss: 0.0105, JMMD Loss: 0.2457
Validation Loss: 0.0061
Epoch [12/50], Class Loss: 0.0105, JMMD Loss: 0.2219
Validation Loss: 0.0053
Epoch [13/50], Class Loss: 0.0098, JMMD Loss: 0.2174
Validation Loss: 0.0067
Epoch [14/50], Class Loss: 0.0098, JMMD Loss: 0.2151
Validation Loss: 0.0056
Epoch [15/50], Class Loss: 0.0096, JMMD Loss: 0.2188
Validation Loss: 0.0050
Epoch [16/50], Class Loss: 0.0092, JMMD Loss: 0.2147
Validation Loss: 0.0056
Epoch [17/50], Class Loss: 0.0089, JMMD Loss: 0.2182
Validation Loss: 0.0047
Epoch [18/50], Class Loss: 0.0085, JMMD Loss: 0.2052
Validation Loss: 0.0049
Epoch [19/50], Class Loss: 0.0082, JMMD Loss: 0.2027
Validation Loss: 0.0044
Epoch [20/50], Class Loss: 0.0082, JMMD Loss: 0.1993
Validation Loss: 0.0070
Epoch [21/50], Class Loss: 0.0081, JMMD Loss: 0.1964
Validation Loss: 0.0048
Epoch [22/50], Class Loss: 0.0079, JMMD Loss: 0.1953
Validation Loss: 0.0054
Epoch [23/50], Class Loss: 0.0079, JMMD Loss: 0.1998
Validation Loss: 0.0046
Epoch [24/50], Class Loss: 0.0080, JMMD Loss: 0.1997
Validation Loss: 0.0056
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 41.97%, Precision: 46.81%, Recall: 40.67%, F1 Score: 35.13%

Run 4/10
Epoch [1/50], Class Loss: 1.4358, JMMD Loss: 0.2750
Validation Loss: 0.7133
Epoch [2/50], Class Loss: 0.6930, JMMD Loss: 0.4604
Validation Loss: 0.3962
Epoch [3/50], Class Loss: 0.2905, JMMD Loss: 0.4790
Validation Loss: 1.3356
Epoch [4/50], Class Loss: 0.2338, JMMD Loss: 0.4724
Validation Loss: 0.0279
Epoch [5/50], Class Loss: 0.1940, JMMD Loss: 0.4886
Validation Loss: 0.0293
Epoch [6/50], Class Loss: 0.2889, JMMD Loss: 0.4989
Validation Loss: 0.1718
Epoch [7/50], Class Loss: 0.2214, JMMD Loss: 0.5043
Validation Loss: 0.2184
Epoch [8/50], Class Loss: 0.1699, JMMD Loss: 0.5122
Validation Loss: 0.0318
Epoch [9/50], Class Loss: 0.0154, JMMD Loss: 0.4954
Validation Loss: 0.0074
Epoch [10/50], Class Loss: 0.5165, JMMD Loss: 0.3398
Validation Loss: 0.8782
Epoch [11/50], Class Loss: 0.4743, JMMD Loss: 0.4686
Validation Loss: 0.3378
Epoch [12/50], Class Loss: 0.2541, JMMD Loss: 0.4881
Validation Loss: 0.1681
Epoch [13/50], Class Loss: 0.1695, JMMD Loss: 0.4954
Validation Loss: 0.1005
Epoch [14/50], Class Loss: 0.1072, JMMD Loss: 0.4925
Validation Loss: 0.0524
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 41.16%, Precision: 27.82%, Recall: 39.78%, F1 Score: 30.55%

Run 5/10
Epoch [1/50], Class Loss: 1.4558, JMMD Loss: 0.2370
Validation Loss: 1.0150
Epoch [2/50], Class Loss: 0.5417, JMMD Loss: 0.4865
Validation Loss: 0.5722
Epoch [3/50], Class Loss: 0.3008, JMMD Loss: 0.5100
Validation Loss: 1.6461
Epoch [4/50], Class Loss: 0.2567, JMMD Loss: 0.4997
Validation Loss: 0.0204
Epoch [5/50], Class Loss: 0.1623, JMMD Loss: 0.5043
Validation Loss: 0.0333
Epoch [6/50], Class Loss: 0.2712, JMMD Loss: 0.4408
Validation Loss: 0.1892
Epoch [7/50], Class Loss: 0.1564, JMMD Loss: 0.5085
Validation Loss: 0.0381
Epoch [8/50], Class Loss: 0.0161, JMMD Loss: 0.4989
Validation Loss: 0.0071
Epoch [9/50], Class Loss: 0.0138, JMMD Loss: 0.4007
Validation Loss: 0.0242
Epoch [10/50], Class Loss: 0.1920, JMMD Loss: 0.4537
Validation Loss: 0.5172
Epoch [11/50], Class Loss: 0.1219, JMMD Loss: 0.4900
Validation Loss: 0.0601
Epoch [12/50], Class Loss: 0.0410, JMMD Loss: 0.4374
Validation Loss: 0.0223
Epoch [13/50], Class Loss: 0.0224, JMMD Loss: 0.3934
Validation Loss: 0.0128
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.97%
Target Domain Performance - Accuracy: 56.27%, Precision: 45.88%, Recall: 55.39%, F1 Score: 47.29%

Run 6/10
Epoch [1/50], Class Loss: 1.3376, JMMD Loss: 0.2594
Validation Loss: 0.6654
Epoch [2/50], Class Loss: 0.8076, JMMD Loss: 0.4775
Validation Loss: 0.1312
Epoch [3/50], Class Loss: 0.2375, JMMD Loss: 0.4822
Validation Loss: 0.1559
Epoch [4/50], Class Loss: 0.1578, JMMD Loss: 0.4845
Validation Loss: 0.1035
Epoch [5/50], Class Loss: 0.1826, JMMD Loss: 0.4988
Validation Loss: 0.1297
Epoch [6/50], Class Loss: 0.1542, JMMD Loss: 0.5075
Validation Loss: 0.6909
Epoch [7/50], Class Loss: 0.2562, JMMD Loss: 0.5132
Validation Loss: 0.1625
Epoch [8/50], Class Loss: 0.0535, JMMD Loss: 0.5064
Validation Loss: 0.0130
Epoch [9/50], Class Loss: 0.1137, JMMD Loss: 0.3660
Validation Loss: 0.1488
Epoch [10/50], Class Loss: 0.0386, JMMD Loss: 0.4201
Validation Loss: 0.0094
Epoch [11/50], Class Loss: 0.0120, JMMD Loss: 0.2739
Validation Loss: 0.0069
Epoch [12/50], Class Loss: 0.0117, JMMD Loss: 0.2679
Validation Loss: 0.0063
Epoch [13/50], Class Loss: 0.0117, JMMD Loss: 0.2604
Validation Loss: 0.0072
Epoch [14/50], Class Loss: 0.0114, JMMD Loss: 0.2487
Validation Loss: 0.0062
Epoch [15/50], Class Loss: 0.0113, JMMD Loss: 0.2436
Validation Loss: 0.0058
Epoch [16/50], Class Loss: 0.0107, JMMD Loss: 0.2366
Validation Loss: 0.0071
Epoch [17/50], Class Loss: 0.0109, JMMD Loss: 0.2330
Validation Loss: 0.0055
Epoch [18/50], Class Loss: 0.0101, JMMD Loss: 0.2229
Validation Loss: 0.0056
Epoch [19/50], Class Loss: 0.0098, JMMD Loss: 0.2223
Validation Loss: 0.0055
Epoch [20/50], Class Loss: 0.0097, JMMD Loss: 0.2190
Validation Loss: 0.0058
Epoch [21/50], Class Loss: 0.0092, JMMD Loss: 0.2187
Validation Loss: 0.0056
Epoch [22/50], Class Loss: 0.0091, JMMD Loss: 0.2182
Validation Loss: 0.0056
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 49.22%, Precision: 46.38%, Recall: 48.11%, F1 Score: 41.84%

Run 7/10
Epoch [1/50], Class Loss: 1.4378, JMMD Loss: 0.2692
Validation Loss: 0.9311
Epoch [2/50], Class Loss: 0.5476, JMMD Loss: 0.4604
Validation Loss: 0.1287
Epoch [3/50], Class Loss: 0.3873, JMMD Loss: 0.4807
Validation Loss: 0.2127
Epoch [4/50], Class Loss: 0.2933, JMMD Loss: 0.5025
Validation Loss: 0.1966
Epoch [5/50], Class Loss: 0.1934, JMMD Loss: 0.5093
Validation Loss: 0.1799
Epoch [6/50], Class Loss: 0.2536, JMMD Loss: 0.4959
Validation Loss: 0.2038
Epoch [7/50], Class Loss: 0.1266, JMMD Loss: 0.5140
Validation Loss: 0.0272
Epoch [8/50], Class Loss: 0.1963, JMMD Loss: 0.5037
Validation Loss: 0.1839
Epoch [9/50], Class Loss: 0.3739, JMMD Loss: 0.4891
Validation Loss: 0.0939
Epoch [10/50], Class Loss: 0.0277, JMMD Loss: 0.4450
Validation Loss: 0.0088
Epoch [11/50], Class Loss: 0.0114, JMMD Loss: 0.3466
Validation Loss: 0.0075
Epoch [12/50], Class Loss: 0.0112, JMMD Loss: 0.3241
Validation Loss: 0.0075
Epoch [13/50], Class Loss: 0.0112, JMMD Loss: 0.2875
Validation Loss: 0.0069
Epoch [14/50], Class Loss: 0.0110, JMMD Loss: 0.2568
Validation Loss: 0.0064
Epoch [15/50], Class Loss: 0.0100, JMMD Loss: 0.2350
Validation Loss: 0.0058
Epoch [16/50], Class Loss: 0.0098, JMMD Loss: 0.2261
Validation Loss: 0.0052
Epoch [17/50], Class Loss: 0.0085, JMMD Loss: 0.2089
Validation Loss: 0.0050
Epoch [18/50], Class Loss: 0.0083, JMMD Loss: 0.2074
Validation Loss: 0.0044
Epoch [19/50], Class Loss: 0.0083, JMMD Loss: 0.2048
Validation Loss: 0.0042
Epoch [20/50], Class Loss: 0.0081, JMMD Loss: 0.1947
Validation Loss: 0.0052
Epoch [21/50], Class Loss: 0.0080, JMMD Loss: 0.1958
Validation Loss: 0.0045
Epoch [22/50], Class Loss: 0.0078, JMMD Loss: 0.1942
Validation Loss: 0.0043
Epoch [23/50], Class Loss: 0.0081, JMMD Loss: 0.1830
Validation Loss: 0.0044
Epoch [24/50], Class Loss: 0.0079, JMMD Loss: 0.1880
Validation Loss: 0.0043
Early stopping!
Source Domain Performance - Accuracy: 100.00%, Precision: 100.00%, Recall: 100.00%, F1 Score: 100.00%
Target Domain Performance - Accuracy: 43.90%, Precision: 43.44%, Recall: 42.59%, F1 Score: 34.93%

Run 8/10
Epoch [1/50], Class Loss: 1.6089, JMMD Loss: 0.1083
Validation Loss: 1.3883
Epoch [2/50], Class Loss: 0.9969, JMMD Loss: 0.4440
Validation Loss: 1.7922
Epoch [3/50], Class Loss: 0.4742, JMMD Loss: 0.4545
Validation Loss: 0.7719
Epoch [4/50], Class Loss: 0.2338, JMMD Loss: 0.4722
Validation Loss: 0.1441
Epoch [5/50], Class Loss: 0.3842, JMMD Loss: 0.4890
Validation Loss: 0.2111
Epoch [6/50], Class Loss: 0.1962, JMMD Loss: 0.4873
Validation Loss: 0.1006
Epoch [7/50], Class Loss: 0.0310, JMMD Loss: 0.4981
Validation Loss: 0.0102
Epoch [8/50], Class Loss: 0.2039, JMMD Loss: 0.5125
Validation Loss: 0.0198
Epoch [9/50], Class Loss: 0.0564, JMMD Loss: 0.5091
Validation Loss: 0.0167
Epoch [10/50], Class Loss: 0.1576, JMMD Loss: 0.4232
Validation Loss: 0.3423
Epoch [11/50], Class Loss: 0.1697, JMMD Loss: 0.4872
Validation Loss: 0.0915
Epoch [12/50], Class Loss: 0.0721, JMMD Loss: 0.4997
Validation Loss: 0.0416
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.97%
Target Domain Performance - Accuracy: 45.36%, Precision: 41.17%, Recall: 44.13%, F1 Score: 37.05%

Run 9/10
Epoch [1/50], Class Loss: 1.3922, JMMD Loss: 0.2718
Validation Loss: 1.0177
Epoch [2/50], Class Loss: 0.5044, JMMD Loss: 0.4892
Validation Loss: 0.2050
Epoch [3/50], Class Loss: 0.2821, JMMD Loss: 0.5056
Validation Loss: 0.5453
Epoch [4/50], Class Loss: 0.3170, JMMD Loss: 0.5179
Validation Loss: 0.1891
Epoch [5/50], Class Loss: 0.1651, JMMD Loss: 0.5176
Validation Loss: 0.1197
Epoch [6/50], Class Loss: 0.1069, JMMD Loss: 0.4776
Validation Loss: 0.0752
Epoch [7/50], Class Loss: 0.2365, JMMD Loss: 0.5076
Validation Loss: 0.0200
Epoch [8/50], Class Loss: 0.0161, JMMD Loss: 0.3639
Validation Loss: 0.0067
Epoch [9/50], Class Loss: 0.1348, JMMD Loss: 0.3040
Validation Loss: 0.0968
Epoch [10/50], Class Loss: 0.0313, JMMD Loss: 0.3942
Validation Loss: 0.0050
Epoch [11/50], Class Loss: 0.0083, JMMD Loss: 0.2645
Validation Loss: 0.0049
Epoch [12/50], Class Loss: 0.0085, JMMD Loss: 0.2443
Validation Loss: 0.0053
Epoch [13/50], Class Loss: 0.0083, JMMD Loss: 0.2236
Validation Loss: 0.0050
Epoch [14/50], Class Loss: 0.0079, JMMD Loss: 0.2165
Validation Loss: 0.0047
Epoch [15/50], Class Loss: 0.0075, JMMD Loss: 0.2011
Validation Loss: 0.0041
Epoch [16/50], Class Loss: 0.0073, JMMD Loss: 0.1955
Validation Loss: 0.0038
Epoch [17/50], Class Loss: 0.0072, JMMD Loss: 0.1786
Validation Loss: 0.0040
Epoch [18/50], Class Loss: 0.0066, JMMD Loss: 0.1698
Validation Loss: 0.0039
Epoch [19/50], Class Loss: 0.0063, JMMD Loss: 0.1694
Validation Loss: 0.0033
Epoch [20/50], Class Loss: 0.0058, JMMD Loss: 0.1716
Validation Loss: 0.0032
Epoch [21/50], Class Loss: 0.0056, JMMD Loss: 0.1552
Validation Loss: 0.0033
Epoch [22/50], Class Loss: 0.0055, JMMD Loss: 0.1620
Validation Loss: 0.0033
Epoch [23/50], Class Loss: 0.0058, JMMD Loss: 0.1589
Validation Loss: 0.0034
Epoch [24/50], Class Loss: 0.0055, JMMD Loss: 0.1586
Validation Loss: 0.0034
Epoch [25/50], Class Loss: 0.0053, JMMD Loss: 0.1601
Validation Loss: 0.0034
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.98%
Target Domain Performance - Accuracy: 43.60%, Precision: 42.52%, Recall: 42.31%, F1 Score: 34.69%

Run 10/10
Epoch [1/50], Class Loss: 1.5266, JMMD Loss: 0.2002
Validation Loss: 0.7523
Epoch [2/50], Class Loss: 0.8696, JMMD Loss: 0.4296
Validation Loss: 0.2752
Epoch [3/50], Class Loss: 0.3304, JMMD Loss: 0.4678
Validation Loss: 0.1719
Epoch [4/50], Class Loss: 0.2251, JMMD Loss: 0.4967
Validation Loss: 0.1074
Epoch [5/50], Class Loss: 0.0986, JMMD Loss: 0.5120
Validation Loss: 0.0100
Epoch [6/50], Class Loss: 0.2730, JMMD Loss: 0.4858
Validation Loss: 0.1918
Epoch [7/50], Class Loss: 0.1150, JMMD Loss: 0.5158
Validation Loss: 0.0231
Epoch [8/50], Class Loss: 0.1318, JMMD Loss: 0.5084
Validation Loss: 0.0426
Epoch [9/50], Class Loss: 0.0200, JMMD Loss: 0.5000
Validation Loss: 0.0186
Epoch [10/50], Class Loss: 0.0126, JMMD Loss: 0.3529
Validation Loss: 0.0043
Epoch [11/50], Class Loss: 0.0096, JMMD Loss: 0.2655
Validation Loss: 0.0064
Epoch [12/50], Class Loss: 0.0099, JMMD Loss: 0.2529
Validation Loss: 0.0057
Epoch [13/50], Class Loss: 0.0101, JMMD Loss: 0.2517
Validation Loss: 0.0055
Epoch [14/50], Class Loss: 0.0099, JMMD Loss: 0.2470
Validation Loss: 0.0057
Epoch [15/50], Class Loss: 0.0103, JMMD Loss: 0.2413
Validation Loss: 0.0053
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.97%, F1 Score: 99.97%
Target Domain Performance - Accuracy: 49.68%, Precision: 46.17%, Recall: 48.58%, F1 Score: 42.21%

Source performance: 99.96% 99.96% 99.96% 99.96%
Target performance: 45.96% 41.55% 44.74% 37.34%

Per-Class Accuracy on Target Domain (Mean over runs):
  Class 0: 98.82%
  Class 1: 25.72%
  Class 2: 0.00%
  Class 3: 99.17%
  Class 4: 0.00%

Run 1/10
Epoch 1/50, Train Loss: 1.2720, Train Acc: 0.3736, Val Loss: 0.3977, Val Acc: 0.9988
Epoch 2/50, Train Loss: 0.5633, Train Acc: 0.7174, Val Loss: 5.3943, Val Acc: 0.2048
Epoch 3/50, Train Loss: 0.7603, Train Acc: 0.7365, Val Loss: 0.2533, Val Acc: 0.8003
Epoch 4/50, Train Loss: 0.1745, Train Acc: 0.8986, Val Loss: 0.0453, Val Acc: 0.9993
Epoch 5/50, Train Loss: 0.4349, Train Acc: 0.8677, Val Loss: 0.9025, Val Acc: 0.8083
Epoch 6/50, Train Loss: 0.9558, Train Acc: 0.8306, Val Loss: 0.9204, Val Acc: 0.7051
Epoch 7/50, Train Loss: 0.7356, Train Acc: 0.7949, Val Loss: 0.3080, Val Acc: 0.8022
Epoch 8/50, Train Loss: 0.5896, Train Acc: 0.8033, Val Loss: 0.0957, Val Acc: 0.9990
Epoch 9/50, Train Loss: 0.4504, Train Acc: 0.8770, Val Loss: 1.7405, Val Acc: 0.7231
Early stopping!

Run 2/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.2677, Train Acc: 0.4179, Val Loss: 0.6894, Val Acc: 0.5403
Epoch 2/50, Train Loss: 1.2074, Train Acc: 0.6336, Val Loss: 1.0299, Val Acc: 0.5762
Epoch 3/50, Train Loss: 1.0436, Train Acc: 0.5939, Val Loss: 0.2384, Val Acc: 0.8088
Epoch 4/50, Train Loss: 0.5862, Train Acc: 0.8164, Val Loss: 0.4516, Val Acc: 0.8025
Epoch 5/50, Train Loss: 0.3659, Train Acc: 0.8714, Val Loss: 0.0187, Val Acc: 0.9990
Epoch 6/50, Train Loss: 0.2102, Train Acc: 0.9221, Val Loss: 0.0093, Val Acc: 0.9993
Epoch 7/50, Train Loss: 0.1598, Train Acc: 0.9512, Val Loss: 0.0138, Val Acc: 0.9988
Epoch 8/50, Train Loss: 0.7514, Train Acc: 0.8094, Val Loss: 0.0787, Val Acc: 0.9983
Epoch 9/50, Train Loss: 0.5698, Train Acc: 0.8464, Val Loss: 2.7955, Val Acc: 0.4739
Epoch 10/50, Train Loss: 0.6591, Train Acc: 0.8895, Val Loss: 0.0058, Val Acc: 0.9998
Epoch 11/50, Train Loss: 0.0042, Train Acc: 0.9993, Val Loss: 0.0052, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0044, Train Acc: 0.9993, Val Loss: 0.0037, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0028, Train Acc: 0.9995, Val Loss: 0.0024, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0023, Train Acc: 0.9995, Val Loss: 0.0027, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0023, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0021, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0022, Train Acc: 0.9997, Val Loss: 0.0020, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0018, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0021, Train Acc: 0.9997, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0026, Train Acc: 0.9995, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0020, Train Acc: 0.9997, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0018, Train Acc: 0.9998, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0017, Train Acc: 0.9998, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0018, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0018, Train Acc: 0.9997, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 26/50, Train Loss: 0.0018, Train Acc: 0.9998, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 27/50, Train Loss: 0.0017, Train Acc: 0.9998, Val Loss: 0.0019, Val Acc: 0.9995
Epoch 28/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 29/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 30/50, Train Loss: 0.0017, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9998
Early stopping!

Run 3/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.3898, Train Acc: 0.3945, Val Loss: 0.5038, Val Acc: 0.7961
Epoch 2/50, Train Loss: 0.6145, Train Acc: 0.6607, Val Loss: 0.8370, Val Acc: 0.4614
Epoch 3/50, Train Loss: 0.9089, Train Acc: 0.6672, Val Loss: 0.2233, Val Acc: 0.9983
Epoch 4/50, Train Loss: 0.3683, Train Acc: 0.8303, Val Loss: 0.3600, Val Acc: 0.7693
Epoch 5/50, Train Loss: 0.4831, Train Acc: 0.7872, Val Loss: 0.1434, Val Acc: 0.9060
Epoch 6/50, Train Loss: 0.3737, Train Acc: 0.8761, Val Loss: 0.1778, Val Acc: 0.8999
Epoch 7/50, Train Loss: 0.5998, Train Acc: 0.8204, Val Loss: 1.8892, Val Acc: 0.4072
Epoch 8/50, Train Loss: 0.5500, Train Acc: 0.8536, Val Loss: 1.0648, Val Acc: 0.8044
Epoch 9/50, Train Loss: 0.4349, Train Acc: 0.9083, Val Loss: 0.7834, Val Acc: 0.8027
Epoch 10/50, Train Loss: 0.4430, Train Acc: 0.9216, Val Loss: 0.0286, Val Acc: 0.9990
Epoch 11/50, Train Loss: 0.0087, Train Acc: 0.9993, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0073, Train Acc: 0.9993, Val Loss: 0.0011, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0062, Train Acc: 0.9994, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0057, Train Acc: 0.9993, Val Loss: 0.0005, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0039, Train Acc: 0.9995, Val Loss: 0.0005, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0040, Train Acc: 0.9993, Val Loss: 0.0022, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0035, Train Acc: 0.9992, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 19/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0005, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0109, Train Acc: 0.9977, Val Loss: 0.0002, Val Acc: 1.0000
Epoch 21/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 22/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0002, Val Acc: 1.0000
Epoch 23/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0002, Val Acc: 1.0000
Early stopping!

Run 4/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.5508, Train Acc: 0.3812, Val Loss: 0.7261, Val Acc: 0.4878
Epoch 2/50, Train Loss: 0.6423, Train Acc: 0.6352, Val Loss: 0.3348, Val Acc: 0.7942
Epoch 3/50, Train Loss: 0.8367, Train Acc: 0.7377, Val Loss: 1.0228, Val Acc: 0.5312
Epoch 4/50, Train Loss: 0.4441, Train Acc: 0.7747, Val Loss: 3.6701, Val Acc: 0.4004
Epoch 5/50, Train Loss: 1.1035, Train Acc: 0.5923, Val Loss: 0.4431, Val Acc: 0.7795
Epoch 6/50, Train Loss: 0.4750, Train Acc: 0.7910, Val Loss: 0.0447, Val Acc: 0.9988
Epoch 7/50, Train Loss: 0.6913, Train Acc: 0.8195, Val Loss: 0.0439, Val Acc: 0.9995
Epoch 8/50, Train Loss: 0.5961, Train Acc: 0.8871, Val Loss: 0.6456, Val Acc: 0.8027
Epoch 9/50, Train Loss: 0.4372, Train Acc: 0.8787, Val Loss: 0.0297, Val Acc: 0.9990
Epoch 10/50, Train Loss: 0.5020, Train Acc: 0.8696, Val Loss: 0.2043, Val Acc: 0.8618
Epoch 11/50, Train Loss: 0.0149, Train Acc: 0.9968, Val Loss: 0.0051, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0087, Train Acc: 0.9994, Val Loss: 0.0031, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0062, Train Acc: 0.9994, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0041, Train Acc: 0.9994, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0026, Train Acc: 0.9995, Val Loss: 0.0032, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0021, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0030, Train Acc: 0.9993, Val Loss: 0.0024, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0044, Train Acc: 0.9984, Val Loss: 0.0021, Val Acc: 0.9998
Early stopping!

Run 5/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.3119, Train Acc: 0.3895, Val Loss: 0.5551, Val Acc: 0.6743
Epoch 2/50, Train Loss: 0.5393, Train Acc: 0.6914, Val Loss: 0.5623, Val Acc: 0.7366
Epoch 3/50, Train Loss: 0.6872, Train Acc: 0.7469, Val Loss: 1.8285, Val Acc: 0.5991
Epoch 4/50, Train Loss: 0.8273, Train Acc: 0.6979, Val Loss: 0.3120, Val Acc: 0.8047
Epoch 5/50, Train Loss: 0.6668, Train Acc: 0.8133, Val Loss: 0.0857, Val Acc: 0.9988
Epoch 6/50, Train Loss: 0.4453, Train Acc: 0.8523, Val Loss: 0.1839, Val Acc: 0.8027
Epoch 7/50, Train Loss: 0.2465, Train Acc: 0.8804, Val Loss: 0.4087, Val Acc: 0.8020
Epoch 8/50, Train Loss: 0.5444, Train Acc: 0.8089, Val Loss: 0.2081, Val Acc: 0.8022
Epoch 9/50, Train Loss: 0.4973, Train Acc: 0.8717, Val Loss: 2.2716, Val Acc: 0.7581
Epoch 10/50, Train Loss: 0.4456, Train Acc: 0.9138, Val Loss: 0.0019, Val Acc: 0.9993
Epoch 11/50, Train Loss: 0.0089, Train Acc: 0.9992, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0072, Train Acc: 0.9993, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0058, Train Acc: 0.9991, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0048, Train Acc: 0.9991, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0040, Train Acc: 0.9992, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0009, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0043, Train Acc: 0.9996, Val Loss: 0.0007, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0034, Train Acc: 0.9995, Val Loss: 0.0000, Val Acc: 1.0000
Epoch 19/50, Train Loss: 0.0035, Train Acc: 0.9996, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0042, Train Acc: 0.9995, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0031, Train Acc: 0.9996, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0005, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0004, Val Acc: 0.9998
Early stopping!

Run 6/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.2452, Train Acc: 0.3904, Val Loss: 0.6214, Val Acc: 0.6018
Epoch 2/50, Train Loss: 0.5618, Train Acc: 0.6635, Val Loss: 0.3428, Val Acc: 0.7886
Epoch 3/50, Train Loss: 1.3034, Train Acc: 0.6694, Val Loss: 0.7926, Val Acc: 0.7495
Epoch 4/50, Train Loss: 0.7400, Train Acc: 0.7162, Val Loss: 0.4578, Val Acc: 0.8044
Epoch 5/50, Train Loss: 0.7192, Train Acc: 0.8747, Val Loss: 0.1929, Val Acc: 0.8975
Epoch 6/50, Train Loss: 0.2937, Train Acc: 0.9377, Val Loss: 0.0308, Val Acc: 0.9990
Epoch 7/50, Train Loss: 1.0078, Train Acc: 0.8259, Val Loss: 0.1251, Val Acc: 0.9985
Epoch 8/50, Train Loss: 0.0634, Train Acc: 0.9896, Val Loss: 0.0099, Val Acc: 0.9978
Epoch 9/50, Train Loss: 0.6682, Train Acc: 0.8312, Val Loss: 0.7360, Val Acc: 0.7959
Epoch 10/50, Train Loss: 0.5247, Train Acc: 0.8911, Val Loss: 0.3309, Val Acc: 0.8020
Epoch 11/50, Train Loss: 0.0103, Train Acc: 0.9962, Val Loss: 0.0031, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0023, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0022, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0023, Train Acc: 0.9997, Val Loss: 0.0020, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0016, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0031, Train Acc: 0.9997, Val Loss: 0.0019, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0028, Train Acc: 0.9997, Val Loss: 0.0020, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0026, Train Acc: 0.9998, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0021, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0024, Train Acc: 0.9998, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0013, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 26/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0014, Val Acc: 0.9998
Epoch 27/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0022, Val Acc: 0.9995
Early stopping!

Run 7/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.5199, Train Acc: 0.3972, Val Loss: 0.5844, Val Acc: 0.7507
Epoch 2/50, Train Loss: 0.6265, Train Acc: 0.7692, Val Loss: 0.7432, Val Acc: 0.8022
Epoch 3/50, Train Loss: 0.8136, Train Acc: 0.6050, Val Loss: 0.4334, Val Acc: 0.7849
Epoch 4/50, Train Loss: 0.5997, Train Acc: 0.6964, Val Loss: 0.2462, Val Acc: 0.8135
Epoch 5/50, Train Loss: 0.8268, Train Acc: 0.8292, Val Loss: 0.6437, Val Acc: 0.8030
Epoch 6/50, Train Loss: 0.8294, Train Acc: 0.7896, Val Loss: 0.0352, Val Acc: 0.9963
Epoch 7/50, Train Loss: 0.5157, Train Acc: 0.8522, Val Loss: 0.2467, Val Acc: 0.8193
Epoch 8/50, Train Loss: 0.1671, Train Acc: 0.9119, Val Loss: 0.1477, Val Acc: 0.8948
Epoch 9/50, Train Loss: 0.1718, Train Acc: 0.9264, Val Loss: 0.0749, Val Acc: 0.9983
Epoch 10/50, Train Loss: 0.4506, Train Acc: 0.8973, Val Loss: 0.0160, Val Acc: 0.9998
Epoch 11/50, Train Loss: 0.0107, Train Acc: 0.9991, Val Loss: 0.0004, Val Acc: 1.0000
Epoch 12/50, Train Loss: 0.0050, Train Acc: 0.9993, Val Loss: 0.0004, Val Acc: 1.0000
Epoch 13/50, Train Loss: 0.0042, Train Acc: 0.9995, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0031, Train Acc: 0.9995, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0031, Train Acc: 0.9995, Val Loss: 0.0007, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0021, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0012, Val Acc: 0.9995
Early stopping!

Run 8/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.2620, Train Acc: 0.3859, Val Loss: 0.6827, Val Acc: 0.6335
Epoch 2/50, Train Loss: 0.6028, Train Acc: 0.6879, Val Loss: 0.6190, Val Acc: 0.6323
Epoch 3/50, Train Loss: 0.4035, Train Acc: 0.7899, Val Loss: 0.4388, Val Acc: 0.7908
Epoch 4/50, Train Loss: 0.7351, Train Acc: 0.7589, Val Loss: 0.4749, Val Acc: 0.8040
Epoch 5/50, Train Loss: 0.9166, Train Acc: 0.7586, Val Loss: 0.0540, Val Acc: 0.9990
Epoch 6/50, Train Loss: 0.3121, Train Acc: 0.9103, Val Loss: 0.0089, Val Acc: 0.9990
Epoch 7/50, Train Loss: 0.5642, Train Acc: 0.9080, Val Loss: 1.3586, Val Acc: 0.7097
Epoch 8/50, Train Loss: 0.4416, Train Acc: 0.8732, Val Loss: 0.0694, Val Acc: 0.9851
Epoch 9/50, Train Loss: 0.3805, Train Acc: 0.9135, Val Loss: 0.2551, Val Acc: 0.8030
Epoch 10/50, Train Loss: 0.6578, Train Acc: 0.8754, Val Loss: 0.3315, Val Acc: 0.8093
Epoch 11/50, Train Loss: 0.0226, Train Acc: 0.9940, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0015, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0018, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0013, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0026, Train Acc: 0.9995, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0033, Train Acc: 0.9995, Val Loss: 0.0005, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0030, Train Acc: 0.9995, Val Loss: 0.0014, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0014, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0023, Train Acc: 0.9997, Val Loss: 0.0013, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0009, Val Acc: 0.9995
Early stopping!

Run 9/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.4544, Train Acc: 0.3536, Val Loss: 0.7257, Val Acc: 0.6006
Epoch 2/50, Train Loss: 0.7354, Train Acc: 0.7026, Val Loss: 1.1226, Val Acc: 0.5068
Epoch 3/50, Train Loss: 1.0269, Train Acc: 0.6029, Val Loss: 0.7724, Val Acc: 0.4619
Epoch 4/50, Train Loss: 0.7846, Train Acc: 0.6555, Val Loss: 0.4557, Val Acc: 0.7427
Epoch 5/50, Train Loss: 0.6765, Train Acc: 0.7506, Val Loss: 0.5703, Val Acc: 0.7632
Epoch 6/50, Train Loss: 1.2018, Train Acc: 0.7383, Val Loss: 0.7289, Val Acc: 0.7947
Epoch 7/50, Train Loss: 0.4767, Train Acc: 0.8075, Val Loss: 0.4680, Val Acc: 0.8027
Epoch 8/50, Train Loss: 0.2989, Train Acc: 0.8945, Val Loss: 0.1617, Val Acc: 0.8020
Epoch 9/50, Train Loss: 0.3550, Train Acc: 0.9283, Val Loss: 1.0608, Val Acc: 0.8027
Epoch 10/50, Train Loss: 0.4567, Train Acc: 0.8940, Val Loss: 0.0130, Val Acc: 0.9998
Epoch 11/50, Train Loss: 0.0078, Train Acc: 0.9993, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0068, Train Acc: 0.9993, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0056, Train Acc: 0.9994, Val Loss: 0.0026, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0051, Train Acc: 0.9993, Val Loss: 0.0012, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0038, Train Acc: 0.9996, Val Loss: 0.0031, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0039, Train Acc: 0.9993, Val Loss: 0.0030, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0008, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0017, Val Acc: 0.9993
Epoch 19/50, Train Loss: 0.0028, Train Acc: 0.9997, Val Loss: 0.0018, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0028, Train Acc: 0.9997, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0002, Val Acc: 1.0000
Epoch 22/50, Train Loss: 0.0026, Train Acc: 0.9998, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0003, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0025, Train Acc: 0.9998, Val Loss: 0.0004, Val Acc: 0.9998
Epoch 26/50, Train Loss: 0.0028, Train Acc: 0.9998, Val Loss: 0.0005, Val Acc: 0.9995
Early stopping!

Run 10/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.3824, Train Acc: 0.3639, Val Loss: 1.1192, Val Acc: 0.4548
Epoch 2/50, Train Loss: 0.6106, Train Acc: 0.7120, Val Loss: 1.0509, Val Acc: 0.4917
Epoch 3/50, Train Loss: 0.6651, Train Acc: 0.7203, Val Loss: 0.7606, Val Acc: 0.4902
Epoch 4/50, Train Loss: 0.5776, Train Acc: 0.6916, Val Loss: 1.6541, Val Acc: 0.6230
Epoch 5/50, Train Loss: 0.6185, Train Acc: 0.7881, Val Loss: 0.1800, Val Acc: 0.9985
Epoch 6/50, Train Loss: 1.0217, Train Acc: 0.7764, Val Loss: 3.4889, Val Acc: 0.4016
Epoch 7/50, Train Loss: 0.6022, Train Acc: 0.8126, Val Loss: 0.0788, Val Acc: 0.9902
Epoch 8/50, Train Loss: 0.2519, Train Acc: 0.8965, Val Loss: 0.0964, Val Acc: 0.9988
Epoch 9/50, Train Loss: 0.3702, Train Acc: 0.9019, Val Loss: 0.0414, Val Acc: 0.9990
Epoch 10/50, Train Loss: 0.4082, Train Acc: 0.8956, Val Loss: 1.1326, Val Acc: 0.7307
Epoch 11/50, Train Loss: 0.0438, Train Acc: 0.9909, Val Loss: 0.0034, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0040, Train Acc: 0.9995, Val Loss: 0.0010, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0018, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0018, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0039, Train Acc: 0.9995, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 16/50, Train Loss: 0.0034, Train Acc: 0.9995, Val Loss: 0.0006, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0031, Train Acc: 0.9994, Val Loss: 0.0024, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0001, Val Acc: 1.0000
Epoch 19/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0003, Val Acc: 1.0000
Epoch 20/50, Train Loss: 0.0088, Train Acc: 0.9972, Val Loss: 0.0004, Val Acc: 1.0000
Epoch 21/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0003, Val Acc: 1.0000
Epoch 22/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0002, Val Acc: 1.0000
Epoch 23/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0003, Val Acc: 1.0000
Early stopping!

Source performance: 97.20 96.91 97.18 96.81
Target performance: 50.86 50.22 52.49 39.08

bpsk: 99.92
qpsk: 72.42
4qam: 90.00
16qam: 0.11
apsk: 0.00
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1225, Domain Loss: 1.4201, Class Loss: 1.7023
Epoch 2/25, Loss: 3.1479, Domain Loss: 1.5176, Class Loss: 1.6303
Epoch 3/25, Loss: 3.0850, Domain Loss: 1.4368, Class Loss: 1.6481
Epoch 4/25, Loss: 3.0593, Domain Loss: 1.4380, Class Loss: 1.6213
Epoch 5/25, Loss: 3.1663, Domain Loss: 1.5814, Class Loss: 1.5849
Epoch 6/25, Loss: 2.5881, Domain Loss: 1.4517, Class Loss: 1.1364
Epoch 7/25, Loss: 2.4906, Domain Loss: 1.4185, Class Loss: 1.0721
Epoch 8/25, Loss: 2.4708, Domain Loss: 1.3801, Class Loss: 1.0907
Epoch 9/25, Loss: 2.5742, Domain Loss: 1.4246, Class Loss: 1.1496
Epoch 10/25, Loss: 2.7341, Domain Loss: 1.3917, Class Loss: 1.3424
Epoch 11/25, Loss: 1.7464, Domain Loss: 1.3025, Class Loss: 0.4439
Epoch 12/25, Loss: 1.4931, Domain Loss: 1.1834, Class Loss: 0.3096
Epoch 13/25, Loss: 2.0580, Domain Loss: 1.1737, Class Loss: 0.8843
Epoch 14/25, Loss: 1.9537, Domain Loss: 1.1946, Class Loss: 0.7591
Epoch 15/25, Loss: 1.4002, Domain Loss: 1.1148, Class Loss: 0.2855
Epoch 16/25, Loss: 1.3298, Domain Loss: 1.0992, Class Loss: 0.2306
Epoch 17/25, Loss: 1.7412, Domain Loss: 1.1112, Class Loss: 0.6300
Epoch 18/25, Loss: 1.4813, Domain Loss: 1.1163, Class Loss: 0.3650
Epoch 19/25, Loss: 1.3750, Domain Loss: 1.0961, Class Loss: 0.2789
Epoch 20/25, Loss: 1.2418, Domain Loss: 1.0590, Class Loss: 0.1829
Epoch 21/25, Loss: 1.2541, Domain Loss: 1.0511, Class Loss: 0.2030
Epoch 22/25, Loss: 1.2654, Domain Loss: 1.0300, Class Loss: 0.2354
Epoch 23/25, Loss: 1.1935, Domain Loss: 1.0375, Class Loss: 0.1560
Epoch 24/25, Loss: 1.1012, Domain Loss: 1.0117, Class Loss: 0.0895
Epoch 25/25, Loss: 1.3444, Domain Loss: 1.0310, Class Loss: 0.3135
38.94


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1280, Domain Loss: 1.4170, Class Loss: 1.7110
Epoch 2/25, Loss: 3.0390, Domain Loss: 1.4104, Class Loss: 1.6286
Epoch 3/25, Loss: 3.0868, Domain Loss: 1.4701, Class Loss: 1.6167
Epoch 4/25, Loss: 4.3789, Domain Loss: 2.7240, Class Loss: 1.6548
Epoch 5/25, Loss: 3.5055, Domain Loss: 1.8819, Class Loss: 1.6236
Epoch 6/25, Loss: 3.0349, Domain Loss: 1.4173, Class Loss: 1.6176
Epoch 7/25, Loss: 3.0067, Domain Loss: 1.3911, Class Loss: 1.6157
Epoch 8/25, Loss: 3.0249, Domain Loss: 1.4100, Class Loss: 1.6149
Epoch 9/25, Loss: 3.0439, Domain Loss: 1.4308, Class Loss: 1.6131
Epoch 10/25, Loss: 3.0456, Domain Loss: 1.4362, Class Loss: 1.6093
Epoch 11/25, Loss: 3.0625, Domain Loss: 1.3884, Class Loss: 1.6741
Epoch 12/25, Loss: 2.9067, Domain Loss: 1.3668, Class Loss: 1.5400
Epoch 13/25, Loss: 2.7713, Domain Loss: 1.3864, Class Loss: 1.3849
Epoch 14/25, Loss: 3.8595, Domain Loss: 2.1857, Class Loss: 1.6738
Epoch 15/25, Loss: 2.9452, Domain Loss: 1.3324, Class Loss: 1.6128
Epoch 16/25, Loss: 2.9215, Domain Loss: 1.3091, Class Loss: 1.6124
Epoch 17/25, Loss: 2.9413, Domain Loss: 1.3291, Class Loss: 1.6122
Epoch 18/25, Loss: 2.9848, Domain Loss: 1.3732, Class Loss: 1.6116
Epoch 19/25, Loss: 3.0597, Domain Loss: 1.4471, Class Loss: 1.6126
Epoch 20/25, Loss: 3.1028, Domain Loss: 1.4915, Class Loss: 1.6113
Epoch 21/25, Loss: 3.1569, Domain Loss: 1.5466, Class Loss: 1.6104
Epoch 22/25, Loss: 3.0620, Domain Loss: 1.4781, Class Loss: 1.5839
Epoch 23/25, Loss: 2.7806, Domain Loss: 1.4107, Class Loss: 1.3700
Epoch 24/25, Loss: 2.3754, Domain Loss: 1.2542, Class Loss: 1.1212
Epoch 25/25, Loss: 2.3709, Domain Loss: 1.2612, Class Loss: 1.1097
20.65


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.0937, Domain Loss: 1.4022, Class Loss: 1.6914
Epoch 2/25, Loss: 2.9492, Domain Loss: 1.3772, Class Loss: 1.5720
Epoch 3/25, Loss: 2.3655, Domain Loss: 1.2658, Class Loss: 1.0997
Epoch 4/25, Loss: 2.8233, Domain Loss: 1.5454, Class Loss: 1.2779
Epoch 5/25, Loss: 1.9177, Domain Loss: 1.1913, Class Loss: 0.7264
Epoch 6/25, Loss: 2.3253, Domain Loss: 1.2475, Class Loss: 1.0778
Epoch 7/25, Loss: 2.6193, Domain Loss: 1.4220, Class Loss: 1.1973
Epoch 8/25, Loss: 2.0760, Domain Loss: 1.2982, Class Loss: 0.7778
Epoch 9/25, Loss: 1.7685, Domain Loss: 1.2131, Class Loss: 0.5554
Epoch 10/25, Loss: 2.5098, Domain Loss: 1.2522, Class Loss: 1.2575
Epoch 11/25, Loss: 3.1494, Domain Loss: 1.8110, Class Loss: 1.3384
Epoch 12/25, Loss: 4.6349, Domain Loss: 2.8941, Class Loss: 1.7407
Epoch 13/25, Loss: 2.8744, Domain Loss: 1.2757, Class Loss: 1.5986
Epoch 14/25, Loss: 2.8075, Domain Loss: 1.2481, Class Loss: 1.5594
Epoch 15/25, Loss: 2.7162, Domain Loss: 1.2815, Class Loss: 1.4347
Epoch 16/25, Loss: 2.5341, Domain Loss: 1.3196, Class Loss: 1.2145
Epoch 17/25, Loss: 3.2095, Domain Loss: 1.4420, Class Loss: 1.7675
Epoch 18/25, Loss: 2.8981, Domain Loss: 1.7673, Class Loss: 1.1308
Epoch 19/25, Loss: 3.2614, Domain Loss: 2.0600, Class Loss: 1.2014
Epoch 20/25, Loss: 2.5300, Domain Loss: 1.5071, Class Loss: 1.0229
Epoch 21/25, Loss: 6.6261, Domain Loss: 4.8087, Class Loss: 1.8173
Epoch 22/25, Loss: 5.9738, Domain Loss: 4.5529, Class Loss: 1.4209
Epoch 23/25, Loss: 2.4324, Domain Loss: 1.2621, Class Loss: 1.1702
Epoch 24/25, Loss: 2.3930, Domain Loss: 1.2278, Class Loss: 1.1652
Epoch 25/25, Loss: 2.5417, Domain Loss: 1.2650, Class Loss: 1.2767
19.53


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1400, Domain Loss: 1.4484, Class Loss: 1.6916
Epoch 2/25, Loss: 3.0246, Domain Loss: 1.3953, Class Loss: 1.6294
Epoch 3/25, Loss: 3.3390, Domain Loss: 1.6932, Class Loss: 1.6458
Epoch 4/25, Loss: 3.1550, Domain Loss: 1.5374, Class Loss: 1.6176
Epoch 5/25, Loss: 3.2570, Domain Loss: 1.7367, Class Loss: 1.5203
Epoch 6/25, Loss: 3.4789, Domain Loss: 2.1002, Class Loss: 1.3787
Epoch 7/25, Loss: 3.0114, Domain Loss: 1.7726, Class Loss: 1.2388
Epoch 8/25, Loss: 3.0000, Domain Loss: 1.8117, Class Loss: 1.1883
Epoch 9/25, Loss: 4.5076, Domain Loss: 2.6518, Class Loss: 1.8558
Epoch 10/25, Loss: 2.9788, Domain Loss: 1.3720, Class Loss: 1.6068
Epoch 11/25, Loss: 2.9152, Domain Loss: 1.3230, Class Loss: 1.5922
Epoch 12/25, Loss: 2.8639, Domain Loss: 1.3121, Class Loss: 1.5518
Epoch 13/25, Loss: 2.5975, Domain Loss: 1.4057, Class Loss: 1.1917
Epoch 14/25, Loss: 3.4162, Domain Loss: 1.9932, Class Loss: 1.4230
Epoch 15/25, Loss: 2.8972, Domain Loss: 1.5796, Class Loss: 1.3176
Epoch 16/25, Loss: 2.1685, Domain Loss: 1.2117, Class Loss: 0.9568
Epoch 17/25, Loss: 3.8734, Domain Loss: 2.1860, Class Loss: 1.6874
Epoch 18/25, Loss: 3.2432, Domain Loss: 1.6778, Class Loss: 1.5654
Epoch 19/25, Loss: 2.9947, Domain Loss: 1.8216, Class Loss: 1.1731
Epoch 20/25, Loss: 3.0770, Domain Loss: 1.7973, Class Loss: 1.2797
Epoch 21/25, Loss: 2.4271, Domain Loss: 1.2620, Class Loss: 1.1651
Epoch 22/25, Loss: 2.3321, Domain Loss: 1.2250, Class Loss: 1.1071
Epoch 23/25, Loss: 2.4301, Domain Loss: 1.2874, Class Loss: 1.1426
Epoch 24/25, Loss: 2.1737, Domain Loss: 1.1526, Class Loss: 1.0211
Epoch 25/25, Loss: 2.8987, Domain Loss: 1.7172, Class Loss: 1.1815
19.53


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1268, Domain Loss: 1.4259, Class Loss: 1.7009
Epoch 2/25, Loss: 3.0122, Domain Loss: 1.3753, Class Loss: 1.6370
Epoch 3/25, Loss: 2.8221, Domain Loss: 1.4504, Class Loss: 1.3717
Epoch 4/25, Loss: 2.6701, Domain Loss: 1.3207, Class Loss: 1.3494
Epoch 5/25, Loss: 2.2290, Domain Loss: 1.2738, Class Loss: 0.9552
Epoch 6/25, Loss: 2.4779, Domain Loss: 1.3457, Class Loss: 1.1322
Epoch 7/25, Loss: 1.7490, Domain Loss: 1.1538, Class Loss: 0.5953
Epoch 8/25, Loss: 1.4381, Domain Loss: 1.1198, Class Loss: 0.3184
Epoch 9/25, Loss: 1.7729, Domain Loss: 1.1505, Class Loss: 0.6224
Epoch 10/25, Loss: 1.3965, Domain Loss: 1.1217, Class Loss: 0.2747
Epoch 11/25, Loss: 1.3288, Domain Loss: 1.1052, Class Loss: 0.2236
Epoch 12/25, Loss: 1.5060, Domain Loss: 1.1227, Class Loss: 0.3833
Epoch 13/25, Loss: 1.4272, Domain Loss: 1.1326, Class Loss: 0.2946
Epoch 14/25, Loss: 1.2612, Domain Loss: 1.1037, Class Loss: 0.1575
Epoch 15/25, Loss: 1.2223, Domain Loss: 1.1059, Class Loss: 0.1164
Epoch 16/25, Loss: 1.3115, Domain Loss: 1.1001, Class Loss: 0.2114
Epoch 17/25, Loss: 1.7344, Domain Loss: 1.1151, Class Loss: 0.6193
Epoch 18/25, Loss: 1.2905, Domain Loss: 1.0850, Class Loss: 0.2054
Epoch 19/25, Loss: 1.1283, Domain Loss: 1.0369, Class Loss: 0.0914
Epoch 20/25, Loss: 1.0659, Domain Loss: 1.0194, Class Loss: 0.0466
Epoch 21/25, Loss: 1.1828, Domain Loss: 0.9964, Class Loss: 0.1865
Epoch 22/25, Loss: 1.0363, Domain Loss: 0.9771, Class Loss: 0.0593
Epoch 23/25, Loss: 1.7676, Domain Loss: 1.0614, Class Loss: 0.7062
Epoch 24/25, Loss: 1.4703, Domain Loss: 1.0954, Class Loss: 0.3749
Epoch 25/25, Loss: 1.2425, Domain Loss: 1.0376, Class Loss: 0.2049
38.89


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1026, Domain Loss: 1.3942, Class Loss: 1.7084
Epoch 2/25, Loss: 3.0549, Domain Loss: 1.4512, Class Loss: 1.6037
Epoch 3/25, Loss: 3.0347, Domain Loss: 1.5451, Class Loss: 1.4896
Epoch 4/25, Loss: 2.5664, Domain Loss: 1.3577, Class Loss: 1.2087
Epoch 5/25, Loss: 3.6322, Domain Loss: 2.1315, Class Loss: 1.5007
Epoch 6/25, Loss: 3.0956, Domain Loss: 1.6441, Class Loss: 1.4515
Epoch 7/25, Loss: 2.3669, Domain Loss: 1.3149, Class Loss: 1.0520
Epoch 8/25, Loss: 2.1609, Domain Loss: 1.2749, Class Loss: 0.8860
Epoch 9/25, Loss: 1.8941, Domain Loss: 1.2420, Class Loss: 0.6521
Epoch 10/25, Loss: 1.9301, Domain Loss: 1.2147, Class Loss: 0.7154
Epoch 11/25, Loss: 1.8749, Domain Loss: 1.1914, Class Loss: 0.6836
Epoch 12/25, Loss: 1.5907, Domain Loss: 1.1634, Class Loss: 0.4274
Epoch 13/25, Loss: 1.7843, Domain Loss: 1.1754, Class Loss: 0.6089
Epoch 14/25, Loss: 1.5489, Domain Loss: 1.1803, Class Loss: 0.3686
Epoch 15/25, Loss: 1.3757, Domain Loss: 1.1263, Class Loss: 0.2494
Epoch 16/25, Loss: 1.6829, Domain Loss: 1.1499, Class Loss: 0.5331
Epoch 17/25, Loss: 1.3700, Domain Loss: 1.1243, Class Loss: 0.2457
Epoch 18/25, Loss: 1.3029, Domain Loss: 1.1165, Class Loss: 0.1863
Epoch 19/25, Loss: 1.2725, Domain Loss: 1.1037, Class Loss: 0.1688
Epoch 20/25, Loss: 1.4194, Domain Loss: 1.1201, Class Loss: 0.2992
Epoch 21/25, Loss: 1.3354, Domain Loss: 1.1129, Class Loss: 0.2225
Epoch 22/25, Loss: 1.3907, Domain Loss: 1.1043, Class Loss: 0.2864
Epoch 23/25, Loss: 1.2478, Domain Loss: 1.1048, Class Loss: 0.1430
Epoch 24/25, Loss: 1.1927, Domain Loss: 1.0987, Class Loss: 0.0941
Epoch 25/25, Loss: 1.1131, Domain Loss: 1.0711, Class Loss: 0.0420
52.00


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1366, Domain Loss: 1.4129, Class Loss: 1.7237
Epoch 2/25, Loss: 2.7767, Domain Loss: 1.3596, Class Loss: 1.4171
Epoch 3/25, Loss: 2.5070, Domain Loss: 1.2734, Class Loss: 1.2335
Epoch 4/25, Loss: 1.8503, Domain Loss: 1.1545, Class Loss: 0.6959
Epoch 5/25, Loss: 1.9112, Domain Loss: 1.1384, Class Loss: 0.7728
Epoch 6/25, Loss: 1.7403, Domain Loss: 1.1241, Class Loss: 0.6162
Epoch 7/25, Loss: 1.5682, Domain Loss: 1.1313, Class Loss: 0.4369
Epoch 8/25, Loss: 1.5985, Domain Loss: 1.1127, Class Loss: 0.4859
Epoch 9/25, Loss: 1.8395, Domain Loss: 1.1336, Class Loss: 0.7058
Epoch 10/25, Loss: 1.3917, Domain Loss: 1.0715, Class Loss: 0.3202
Epoch 11/25, Loss: 1.4308, Domain Loss: 1.0753, Class Loss: 0.3554
Epoch 12/25, Loss: 1.6057, Domain Loss: 1.0644, Class Loss: 0.5413
Epoch 13/25, Loss: 92.3219, Domain Loss: 88.1259, Class Loss: 4.1960
Epoch 14/25, Loss: 14.7266, Domain Loss: 13.0995, Class Loss: 1.6272
Epoch 15/25, Loss: 4.8954, Domain Loss: 3.2733, Class Loss: 1.6221
Epoch 16/25, Loss: 4.1355, Domain Loss: 2.5175, Class Loss: 1.6180
Epoch 17/25, Loss: 3.8813, Domain Loss: 2.2662, Class Loss: 1.6151
Epoch 18/25, Loss: 3.6452, Domain Loss: 2.0318, Class Loss: 1.6134
Epoch 19/25, Loss: 3.5252, Domain Loss: 1.9124, Class Loss: 1.6129
Epoch 20/25, Loss: 3.7794, Domain Loss: 2.1711, Class Loss: 1.6083
Epoch 21/25, Loss: 4.0982, Domain Loss: 2.4970, Class Loss: 1.6013
Epoch 22/25, Loss: 4.6389, Domain Loss: 3.0877, Class Loss: 1.5512
Epoch 23/25, Loss: 5.8466, Domain Loss: 4.4366, Class Loss: 1.4101
Epoch 24/25, Loss: 6.5083, Domain Loss: 5.4292, Class Loss: 1.0792
Epoch 25/25, Loss: 6.5835, Domain Loss: 5.6243, Class Loss: 0.9593
19.51


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1437, Domain Loss: 1.4298, Class Loss: 1.7139
Epoch 2/25, Loss: 2.8587, Domain Loss: 1.3650, Class Loss: 1.4937
Epoch 3/25, Loss: 2.5767, Domain Loss: 1.4050, Class Loss: 1.1717
Epoch 4/25, Loss: 2.2063, Domain Loss: 1.2067, Class Loss: 0.9996
Epoch 5/25, Loss: 2.2676, Domain Loss: 1.2192, Class Loss: 1.0484
Epoch 6/25, Loss: 1.5934, Domain Loss: 1.0953, Class Loss: 0.4980
Epoch 7/25, Loss: 23.1849, Domain Loss: 18.1894, Class Loss: 4.9955
Epoch 8/25, Loss: 7.3703, Domain Loss: 5.6391, Class Loss: 1.7312
Epoch 9/25, Loss: 4.3743, Domain Loss: 2.7447, Class Loss: 1.6296
Epoch 10/25, Loss: 3.1128, Domain Loss: 1.4963, Class Loss: 1.6166
Epoch 11/25, Loss: 3.1042, Domain Loss: 1.4817, Class Loss: 1.6224
Epoch 12/25, Loss: 3.1484, Domain Loss: 1.5602, Class Loss: 1.5882
Epoch 13/25, Loss: 3.2749, Domain Loss: 1.5944, Class Loss: 1.6804
Epoch 14/25, Loss: 3.1796, Domain Loss: 1.5819, Class Loss: 1.5977
Epoch 15/25, Loss: 3.3952, Domain Loss: 1.8139, Class Loss: 1.5813
Epoch 16/25, Loss: 3.1150, Domain Loss: 1.5419, Class Loss: 1.5730
Epoch 17/25, Loss: 3.0380, Domain Loss: 1.4936, Class Loss: 1.5444
Epoch 18/25, Loss: 3.0601, Domain Loss: 1.5069, Class Loss: 1.5532
Epoch 19/25, Loss: 5.6352, Domain Loss: 4.0170, Class Loss: 1.6182
Epoch 20/25, Loss: 4.6404, Domain Loss: 3.0625, Class Loss: 1.5779
Epoch 21/25, Loss: 3.0204, Domain Loss: 1.5477, Class Loss: 1.4727
Epoch 22/25, Loss: 3.2924, Domain Loss: 1.4474, Class Loss: 1.8450
Epoch 23/25, Loss: 2.9876, Domain Loss: 1.4086, Class Loss: 1.5790
Epoch 24/25, Loss: 2.9109, Domain Loss: 1.3330, Class Loss: 1.5779
Epoch 25/25, Loss: 2.8533, Domain Loss: 1.3244, Class Loss: 1.5289
19.38


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1197, Domain Loss: 1.4181, Class Loss: 1.7016
Epoch 2/25, Loss: 2.8221, Domain Loss: 1.3620, Class Loss: 1.4601
Epoch 3/25, Loss: 2.7560, Domain Loss: 1.3142, Class Loss: 1.4418
Epoch 4/25, Loss: 1.8742, Domain Loss: 1.1975, Class Loss: 0.6768
Epoch 5/25, Loss: 1.4880, Domain Loss: 1.0680, Class Loss: 0.4200
Epoch 6/25, Loss: 1.5739, Domain Loss: 1.0788, Class Loss: 0.4950
Epoch 7/25, Loss: 1.3085, Domain Loss: 1.0261, Class Loss: 0.2824
Epoch 8/25, Loss: 6.6992, Domain Loss: 4.5498, Class Loss: 2.1494
Epoch 9/25, Loss: 5.4579, Domain Loss: 3.8252, Class Loss: 1.6327
Epoch 10/25, Loss: 5.4391, Domain Loss: 3.8257, Class Loss: 1.6134
Epoch 11/25, Loss: 8.7136, Domain Loss: 7.2170, Class Loss: 1.4966
Epoch 12/25, Loss: 6.9401, Domain Loss: 5.5817, Class Loss: 1.3584
Epoch 13/25, Loss: 8.9016, Domain Loss: 7.4452, Class Loss: 1.4564
Epoch 14/25, Loss: 5.5685, Domain Loss: 4.6123, Class Loss: 0.9562
Epoch 15/25, Loss: 4.7183, Domain Loss: 3.1932, Class Loss: 1.5251
Epoch 16/25, Loss: 2.5873, Domain Loss: 1.6232, Class Loss: 0.9641
Epoch 17/25, Loss: 1.5683, Domain Loss: 1.1450, Class Loss: 0.4233
Epoch 18/25, Loss: 2.5221, Domain Loss: 1.2230, Class Loss: 1.2990
Epoch 19/25, Loss: 1.8436, Domain Loss: 1.1825, Class Loss: 0.6611
Epoch 20/25, Loss: 2.5548, Domain Loss: 1.6043, Class Loss: 0.9505
Epoch 21/25, Loss: 2.2224, Domain Loss: 1.2880, Class Loss: 0.9344
Epoch 22/25, Loss: 1.7599, Domain Loss: 1.1243, Class Loss: 0.6355
Epoch 23/25, Loss: 1.6195, Domain Loss: 1.1874, Class Loss: 0.4321
Epoch 24/25, Loss: 3.5820, Domain Loss: 2.1956, Class Loss: 1.3864
Epoch 25/25, Loss: 3.0926, Domain Loss: 1.7211, Class Loss: 1.3715
19.31


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1264, Domain Loss: 1.4231, Class Loss: 1.7033
Epoch 2/25, Loss: 2.9000, Domain Loss: 1.3713, Class Loss: 1.5287
Epoch 3/25, Loss: 2.5221, Domain Loss: 1.3092, Class Loss: 1.2128
Epoch 4/25, Loss: 2.4237, Domain Loss: 1.2839, Class Loss: 1.1399
Epoch 5/25, Loss: 1.7616, Domain Loss: 1.1552, Class Loss: 0.6063
Epoch 6/25, Loss: 1.4336, Domain Loss: 1.0895, Class Loss: 0.3440
Epoch 7/25, Loss: 1.3525, Domain Loss: 1.0672, Class Loss: 0.2853
Epoch 8/25, Loss: 2.2587, Domain Loss: 1.2564, Class Loss: 1.0023
Epoch 9/25, Loss: 1.5474, Domain Loss: 1.1032, Class Loss: 0.4442
Epoch 10/25, Loss: 1.6645, Domain Loss: 1.1083, Class Loss: 0.5562
Epoch 11/25, Loss: 1.3228, Domain Loss: 1.0399, Class Loss: 0.2829
Epoch 12/25, Loss: 1.2358, Domain Loss: 1.0282, Class Loss: 0.2077
Epoch 13/25, Loss: 1.2453, Domain Loss: 1.0142, Class Loss: 0.2311
Epoch 14/25, Loss: 1.3732, Domain Loss: 1.0531, Class Loss: 0.3201
Epoch 15/25, Loss: 1.4034, Domain Loss: 1.0544, Class Loss: 0.3490
Epoch 16/25, Loss: 1.4438, Domain Loss: 1.0850, Class Loss: 0.3588
Epoch 17/25, Loss: 1.2478, Domain Loss: 1.0441, Class Loss: 0.2037
Epoch 18/25, Loss: 1.2371, Domain Loss: 1.0221, Class Loss: 0.2151
Epoch 19/25, Loss: 1.2714, Domain Loss: 1.0327, Class Loss: 0.2387
Epoch 20/25, Loss: 1.1413, Domain Loss: 1.0251, Class Loss: 0.1162
Epoch 21/25, Loss: 1.9757, Domain Loss: 1.3473, Class Loss: 0.6284
Epoch 22/25, Loss: 1.5228, Domain Loss: 1.0821, Class Loss: 0.4407
Epoch 23/25, Loss: 1.2683, Domain Loss: 1.0420, Class Loss: 0.2264
Epoch 24/25, Loss: 1.4093, Domain Loss: 1.0314, Class Loss: 0.3779
Epoch 25/25, Loss: 1.4794, Domain Loss: 1.0593, Class Loss: 0.4201
41.33


Source performance:
60.54 53.08 60.46 52.96 
Target performance:
28.91 23.81 29.64 15.53 

Per-class target performance: 29.99 38.64 69.45 10.14 0.00 
Run 1/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch [1/50], Class Loss: 4.3475, Discrepancy Loss: 0.0820
Epoch [2/50], Class Loss: 0.8156, Discrepancy Loss: 0.0898
Epoch [3/50], Class Loss: 0.5186, Discrepancy Loss: 0.1013
Epoch [4/50], Class Loss: 0.5964, Discrepancy Loss: 0.1027
Epoch [5/50], Class Loss: 0.5567, Discrepancy Loss: 0.1001
Epoch [6/50], Class Loss: 0.3953, Discrepancy Loss: 0.1072
Epoch [7/50], Class Loss: 0.2810, Discrepancy Loss: 0.1234
Epoch [8/50], Class Loss: 0.2741, Discrepancy Loss: 0.1152
Epoch [9/50], Class Loss: 0.3401, Discrepancy Loss: 0.1134
Epoch [10/50], Class Loss: 0.1909, Discrepancy Loss: 0.1264
Epoch [11/50], Class Loss: 0.2655, Discrepancy Loss: 0.1041
Epoch [12/50], Class Loss: 0.1844, Discrepancy Loss: 0.1144
Epoch [13/50], Class Loss: 0.1253, Discrepancy Loss: 0.1395
Epoch [14/50], Class Loss: 0.0970, Discrepancy Loss: 0.1610
Epoch [15/50], Class Loss: 0.0575, Discrepancy Loss: 0.1598
Epoch [16/50], Class Loss: 0.0389, Discrepancy Loss: 0.1588
Epoch [17/50], Class Loss: 0.0379, Discrepancy Loss: 0.1623
Epoch [18/50], Class Loss: 0.0307, Discrepancy Loss: 0.1621
Epoch [19/50], Class Loss: 0.0254, Discrepancy Loss: 0.1541
Epoch [20/50], Class Loss: 0.0442, Discrepancy Loss: 0.1511
Epoch [21/50], Class Loss: 0.0233, Discrepancy Loss: 0.1650
Epoch [22/50], Class Loss: 0.0231, Discrepancy Loss: 0.1591
Epoch [23/50], Class Loss: 0.0265, Discrepancy Loss: 0.1491
Epoch [24/50], Class Loss: 0.0229, Discrepancy Loss: 0.1465
Epoch [25/50], Class Loss: 0.0237, Discrepancy Loss: 0.1498
Epoch [26/50], Class Loss: 0.0215, Discrepancy Loss: 0.1462
Epoch [27/50], Class Loss: 0.0203, Discrepancy Loss: 0.1439
Epoch [28/50], Class Loss: 0.0184, Discrepancy Loss: 0.1460
Epoch [29/50], Class Loss: 0.0200, Discrepancy Loss: 0.1448
Epoch [30/50], Class Loss: 0.0177, Discrepancy Loss: 0.1399
Epoch [31/50], Class Loss: 0.0192, Discrepancy Loss: 0.1408
Epoch [32/50], Class Loss: 0.0160, Discrepancy Loss: 0.1450
Epoch [33/50], Class Loss: 0.0174, Discrepancy Loss: 0.1441
Epoch [34/50], Class Loss: 0.0159, Discrepancy Loss: 0.1438
Epoch [35/50], Class Loss: 0.0182, Discrepancy Loss: 0.1441
Epoch [36/50], Class Loss: 0.0191, Discrepancy Loss: 0.1457
Epoch [37/50], Class Loss: 0.0198, Discrepancy Loss: 0.1443
Epoch [38/50], Class Loss: 0.0177, Discrepancy Loss: 0.1389
Epoch [39/50], Class Loss: 0.0179, Discrepancy Loss: 0.1442
Epoch [40/50], Class Loss: 0.0163, Discrepancy Loss: 0.1409
Epoch [41/50], Class Loss: 0.0148, Discrepancy Loss: 0.1410
Epoch [42/50], Class Loss: 0.0188, Discrepancy Loss: 0.1424
Epoch [43/50], Class Loss: 0.0173, Discrepancy Loss: 0.1445
Epoch [44/50], Class Loss: 0.0230, Discrepancy Loss: 0.1441
Epoch [45/50], Class Loss: 0.0161, Discrepancy Loss: 0.1439
Epoch [46/50], Class Loss: 0.0169, Discrepancy Loss: 0.1427
Epoch [47/50], Class Loss: 0.0195, Discrepancy Loss: 0.1392
Epoch [48/50], Class Loss: 0.0156, Discrepancy Loss: 0.1396
Epoch [49/50], Class Loss: 0.0183, Discrepancy Loss: 0.1427
Epoch [50/50], Class Loss: 0.0150, Discrepancy Loss: 0.1445
Source Domain Performance - Accuracy: 89.72%, Precision: 92.63%, Recall: 90.01%, F1 Score: 89.33%
Target Domain Performance - Accuracy: 60.89%, Precision: 59.59%, Recall: 62.64%, F1 Score: 51.43%

Run 2/10
Epoch [1/50], Class Loss: 3.9153, Discrepancy Loss: 0.0781
Epoch [2/50], Class Loss: 0.7485, Discrepancy Loss: 0.0954
Epoch [3/50], Class Loss: 0.5736, Discrepancy Loss: 0.1011
Epoch [4/50], Class Loss: 0.4942, Discrepancy Loss: 0.1085
Epoch [5/50], Class Loss: 0.3940, Discrepancy Loss: 0.1195
Epoch [6/50], Class Loss: 0.3386, Discrepancy Loss: 0.1222
Epoch [7/50], Class Loss: 0.2715, Discrepancy Loss: 0.1187
Epoch [8/50], Class Loss: 0.2697, Discrepancy Loss: 0.1023
Epoch [9/50], Class Loss: 0.2144, Discrepancy Loss: 0.1213
Epoch [10/50], Class Loss: 0.2365, Discrepancy Loss: 0.1106
Epoch [11/50], Class Loss: 0.1010, Discrepancy Loss: 0.1379
Epoch [12/50], Class Loss: 0.0678, Discrepancy Loss: 0.1448
Epoch [13/50], Class Loss: 0.0496, Discrepancy Loss: 0.1343
Epoch [14/50], Class Loss: 0.0356, Discrepancy Loss: 0.1420
Epoch [15/50], Class Loss: 0.0289, Discrepancy Loss: 0.1102
Epoch [16/50], Class Loss: 0.0335, Discrepancy Loss: 0.1175
Epoch [17/50], Class Loss: 0.0331, Discrepancy Loss: 0.1207
Epoch [18/50], Class Loss: 0.0350, Discrepancy Loss: 0.1150
Epoch [19/50], Class Loss: 0.0300, Discrepancy Loss: 0.1147
Epoch [20/50], Class Loss: 0.0215, Discrepancy Loss: 0.1226
Epoch [21/50], Class Loss: 0.0219, Discrepancy Loss: 0.1188
Epoch [22/50], Class Loss: 0.0197, Discrepancy Loss: 0.1184
Epoch [23/50], Class Loss: 0.0200, Discrepancy Loss: 0.1227
Epoch [24/50], Class Loss: 0.0204, Discrepancy Loss: 0.1222
Epoch [25/50], Class Loss: 0.0183, Discrepancy Loss: 0.1253
Epoch [26/50], Class Loss: 0.0168, Discrepancy Loss: 0.1273
Epoch [27/50], Class Loss: 0.0189, Discrepancy Loss: 0.1265
Epoch [28/50], Class Loss: 0.0178, Discrepancy Loss: 0.1255
Epoch [29/50], Class Loss: 0.0181, Discrepancy Loss: 0.1294
Epoch [30/50], Class Loss: 0.0214, Discrepancy Loss: 0.1287
Epoch [31/50], Class Loss: 0.0184, Discrepancy Loss: 0.1275
Epoch [32/50], Class Loss: 0.0167, Discrepancy Loss: 0.1252
Epoch [33/50], Class Loss: 0.0187, Discrepancy Loss: 0.1281
Epoch [34/50], Class Loss: 0.0175, Discrepancy Loss: 0.1280
Epoch [35/50], Class Loss: 0.0158, Discrepancy Loss: 0.1303
Epoch [36/50], Class Loss: 0.0173, Discrepancy Loss: 0.1296
Epoch [37/50], Class Loss: 0.0132, Discrepancy Loss: 0.1243
Epoch [38/50], Class Loss: 0.0192, Discrepancy Loss: 0.1254
Epoch [39/50], Class Loss: 0.0188, Discrepancy Loss: 0.1304
Epoch [40/50], Class Loss: 0.0196, Discrepancy Loss: 0.1277
Epoch [41/50], Class Loss: 0.0190, Discrepancy Loss: 0.1283
Epoch [42/50], Class Loss: 0.0187, Discrepancy Loss: 0.1270
Epoch [43/50], Class Loss: 0.0155, Discrepancy Loss: 0.1295
Epoch [44/50], Class Loss: 0.0173, Discrepancy Loss: 0.1303
Epoch [45/50], Class Loss: 0.0144, Discrepancy Loss: 0.1273
Epoch [46/50], Class Loss: 0.0155, Discrepancy Loss: 0.1256
Epoch [47/50], Class Loss: 0.0175, Discrepancy Loss: 0.1272
Epoch [48/50], Class Loss: 0.0157, Discrepancy Loss: 0.1310
Epoch [49/50], Class Loss: 0.0181, Discrepancy Loss: 0.1289
Epoch [50/50], Class Loss: 0.0178, Discrepancy Loss: 0.1272
Source Domain Performance - Accuracy: 79.00%, Precision: 72.67%, Recall: 79.62%, F1 Score: 72.95%
Target Domain Performance - Accuracy: 73.41%, Precision: 64.83%, Recall: 74.75%, F1 Score: 67.48%

Run 3/10
Epoch [1/50], Class Loss: 3.7697, Discrepancy Loss: 0.0794
Epoch [2/50], Class Loss: 0.7838, Discrepancy Loss: 0.0912
Epoch [3/50], Class Loss: 0.6533, Discrepancy Loss: 0.0862
Epoch [4/50], Class Loss: 0.4895, Discrepancy Loss: 0.1062
Epoch [5/50], Class Loss: 0.4253, Discrepancy Loss: 0.1161
Epoch [6/50], Class Loss: 0.3732, Discrepancy Loss: 0.1167
Epoch [7/50], Class Loss: 0.3490, Discrepancy Loss: 0.1150
Epoch [8/50], Class Loss: 0.2757, Discrepancy Loss: 0.1228
Epoch [9/50], Class Loss: 0.2517, Discrepancy Loss: 0.1204
Epoch [10/50], Class Loss: 0.4027, Discrepancy Loss: 0.1062
Epoch [11/50], Class Loss: 0.2503, Discrepancy Loss: 0.1199
Epoch [12/50], Class Loss: 0.2344, Discrepancy Loss: 0.1197
Epoch [13/50], Class Loss: 0.2092, Discrepancy Loss: 0.1306
Epoch [14/50], Class Loss: 0.1793, Discrepancy Loss: 0.1458
Epoch [15/50], Class Loss: 0.1138, Discrepancy Loss: 0.1685
Epoch [16/50], Class Loss: 0.0572, Discrepancy Loss: 0.1682
Epoch [17/50], Class Loss: 0.0699, Discrepancy Loss: 0.1578
Epoch [18/50], Class Loss: 0.0402, Discrepancy Loss: 0.1718
Epoch [19/50], Class Loss: 0.0355, Discrepancy Loss: 0.1634
Epoch [20/50], Class Loss: 0.0399, Discrepancy Loss: 0.1676
Epoch [21/50], Class Loss: 0.0271, Discrepancy Loss: 0.1565
Epoch [22/50], Class Loss: 0.0243, Discrepancy Loss: 0.1518
Epoch [23/50], Class Loss: 0.0227, Discrepancy Loss: 0.1581
Epoch [24/50], Class Loss: 0.0234, Discrepancy Loss: 0.1543
Epoch [25/50], Class Loss: 0.0230, Discrepancy Loss: 0.1610
Epoch [26/50], Class Loss: 0.0308, Discrepancy Loss: 0.1527
Epoch [27/50], Class Loss: 0.0241, Discrepancy Loss: 0.1539
Epoch [28/50], Class Loss: 0.0229, Discrepancy Loss: 0.1568
Epoch [29/50], Class Loss: 0.0204, Discrepancy Loss: 0.1572
Epoch [30/50], Class Loss: 0.0215, Discrepancy Loss: 0.1543
Epoch [31/50], Class Loss: 0.0287, Discrepancy Loss: 0.1524
Epoch [32/50], Class Loss: 0.0210, Discrepancy Loss: 0.1561
Epoch [33/50], Class Loss: 0.0212, Discrepancy Loss: 0.1517
Epoch [34/50], Class Loss: 0.0250, Discrepancy Loss: 0.1531
Epoch [35/50], Class Loss: 0.0207, Discrepancy Loss: 0.1549
Epoch [36/50], Class Loss: 0.0228, Discrepancy Loss: 0.1601
Epoch [37/50], Class Loss: 0.0218, Discrepancy Loss: 0.1530
Epoch [38/50], Class Loss: 0.0195, Discrepancy Loss: 0.1569
Epoch [39/50], Class Loss: 0.0215, Discrepancy Loss: 0.1503
Epoch [40/50], Class Loss: 0.0198, Discrepancy Loss: 0.1544
Epoch [41/50], Class Loss: 0.0222, Discrepancy Loss: 0.1512
Epoch [42/50], Class Loss: 0.0213, Discrepancy Loss: 0.1574
Epoch [43/50], Class Loss: 0.0233, Discrepancy Loss: 0.1537
Epoch [44/50], Class Loss: 0.0234, Discrepancy Loss: 0.1558
Epoch [45/50], Class Loss: 0.0207, Discrepancy Loss: 0.1576
Epoch [46/50], Class Loss: 0.0254, Discrepancy Loss: 0.1579
Epoch [47/50], Class Loss: 0.0208, Discrepancy Loss: 0.1552
Epoch [48/50], Class Loss: 0.0235, Discrepancy Loss: 0.1535
Epoch [49/50], Class Loss: 0.0262, Discrepancy Loss: 0.1543
Epoch [50/50], Class Loss: 0.0221, Discrepancy Loss: 0.1489
Source Domain Performance - Accuracy: 85.96%, Precision: 91.28%, Recall: 86.38%, F1 Score: 84.55%
Target Domain Performance - Accuracy: 61.35%, Precision: 59.76%, Recall: 63.09%, F1 Score: 52.10%

Run 4/10
Epoch [1/50], Class Loss: 4.2054, Discrepancy Loss: 0.0845
Epoch [2/50], Class Loss: 0.8313, Discrepancy Loss: 0.1028
Epoch [3/50], Class Loss: 0.5790, Discrepancy Loss: 0.1014
Epoch [4/50], Class Loss: 0.5168, Discrepancy Loss: 0.0916
Epoch [5/50], Class Loss: 0.4437, Discrepancy Loss: 0.1038
Epoch [6/50], Class Loss: 0.3961, Discrepancy Loss: 0.1025
Epoch [7/50], Class Loss: 0.2973, Discrepancy Loss: 0.1002
Epoch [8/50], Class Loss: 0.2459, Discrepancy Loss: 0.1033
Epoch [9/50], Class Loss: 0.2681, Discrepancy Loss: 0.1001
Epoch [10/50], Class Loss: 0.1905, Discrepancy Loss: 0.1068
Epoch [11/50], Class Loss: 0.0864, Discrepancy Loss: 0.1273
Epoch [12/50], Class Loss: 0.0560, Discrepancy Loss: 0.1277
Epoch [13/50], Class Loss: 0.0569, Discrepancy Loss: 0.1223
Epoch [14/50], Class Loss: 0.0369, Discrepancy Loss: 0.1199
Epoch [15/50], Class Loss: 0.0319, Discrepancy Loss: 0.1354
Epoch [16/50], Class Loss: 0.0404, Discrepancy Loss: 0.1282
Epoch [17/50], Class Loss: 0.0268, Discrepancy Loss: 0.1260
Epoch [18/50], Class Loss: 0.0286, Discrepancy Loss: 0.1401
Epoch [19/50], Class Loss: 0.0287, Discrepancy Loss: 0.1422
Epoch [20/50], Class Loss: 0.0482, Discrepancy Loss: 0.1435
Epoch [21/50], Class Loss: 0.0240, Discrepancy Loss: 0.1335
Epoch [22/50], Class Loss: 0.0221, Discrepancy Loss: 0.1297
Epoch [23/50], Class Loss: 0.0239, Discrepancy Loss: 0.1298
Epoch [24/50], Class Loss: 0.0300, Discrepancy Loss: 0.1317
Epoch [25/50], Class Loss: 0.0218, Discrepancy Loss: 0.1352
Epoch [26/50], Class Loss: 0.0237, Discrepancy Loss: 0.1307
Epoch [27/50], Class Loss: 0.0210, Discrepancy Loss: 0.1313
Epoch [28/50], Class Loss: 0.0226, Discrepancy Loss: 0.1335
Epoch [29/50], Class Loss: 0.0272, Discrepancy Loss: 0.1316
Epoch [30/50], Class Loss: 0.0220, Discrepancy Loss: 0.1370
Epoch [31/50], Class Loss: 0.0254, Discrepancy Loss: 0.1306
Epoch [32/50], Class Loss: 0.0289, Discrepancy Loss: 0.1313
Epoch [33/50], Class Loss: 0.0264, Discrepancy Loss: 0.1281
Epoch [34/50], Class Loss: 0.0220, Discrepancy Loss: 0.1335
Epoch [35/50], Class Loss: 0.0223, Discrepancy Loss: 0.1295
Epoch [36/50], Class Loss: 0.0269, Discrepancy Loss: 0.1327
Epoch [37/50], Class Loss: 0.0269, Discrepancy Loss: 0.1317
Epoch [38/50], Class Loss: 0.0238, Discrepancy Loss: 0.1310
Epoch [39/50], Class Loss: 0.0258, Discrepancy Loss: 0.1350
Epoch [40/50], Class Loss: 0.0237, Discrepancy Loss: 0.1297
Epoch [41/50], Class Loss: 0.0254, Discrepancy Loss: 0.1337
Epoch [42/50], Class Loss: 0.0258, Discrepancy Loss: 0.1285
Epoch [43/50], Class Loss: 0.0207, Discrepancy Loss: 0.1328
Epoch [44/50], Class Loss: 0.0215, Discrepancy Loss: 0.1340
Epoch [45/50], Class Loss: 0.0201, Discrepancy Loss: 0.1352
Epoch [46/50], Class Loss: 0.0241, Discrepancy Loss: 0.1336
Epoch [47/50], Class Loss: 0.0224, Discrepancy Loss: 0.1315
Epoch [48/50], Class Loss: 0.0220, Discrepancy Loss: 0.1332
Epoch [49/50], Class Loss: 0.0202, Discrepancy Loss: 0.1335
Epoch [50/50], Class Loss: 0.0243, Discrepancy Loss: 0.1313
Source Domain Performance - Accuracy: 79.17%, Precision: 85.74%, Recall: 79.79%, F1 Score: 73.22%
Target Domain Performance - Accuracy: 71.70%, Precision: 62.55%, Recall: 72.96%, F1 Score: 65.81%

Run 5/10
Epoch [1/50], Class Loss: 3.3499, Discrepancy Loss: 0.0783
Epoch [2/50], Class Loss: 0.7110, Discrepancy Loss: 0.0872
Epoch [3/50], Class Loss: 0.5975, Discrepancy Loss: 0.0965
Epoch [4/50], Class Loss: 0.4664, Discrepancy Loss: 0.0978
Epoch [5/50], Class Loss: 0.3971, Discrepancy Loss: 0.1129
Epoch [6/50], Class Loss: 0.2820, Discrepancy Loss: 0.1147
Epoch [7/50], Class Loss: 0.3365, Discrepancy Loss: 0.1082
Epoch [8/50], Class Loss: 0.1831, Discrepancy Loss: 0.1188
Epoch [9/50], Class Loss: 0.2599, Discrepancy Loss: 0.1248
Epoch [10/50], Class Loss: 0.0671, Discrepancy Loss: 0.1540
Epoch [11/50], Class Loss: 0.0497, Discrepancy Loss: 0.1402
Epoch [12/50], Class Loss: 0.0455, Discrepancy Loss: 0.1343
Epoch [13/50], Class Loss: 0.0402, Discrepancy Loss: 0.1331
Epoch [14/50], Class Loss: 0.0601, Discrepancy Loss: 0.1508
Epoch [15/50], Class Loss: 0.0205, Discrepancy Loss: 0.1469
Epoch [16/50], Class Loss: 0.0277, Discrepancy Loss: 0.1552
Epoch [17/50], Class Loss: 0.0407, Discrepancy Loss: 0.1806
Epoch [18/50], Class Loss: 0.0167, Discrepancy Loss: 0.2025
Epoch [19/50], Class Loss: 0.0144, Discrepancy Loss: 0.1858
Epoch [20/50], Class Loss: 0.0337, Discrepancy Loss: 0.1783
Epoch [21/50], Class Loss: 0.0103, Discrepancy Loss: 0.1879
Epoch [22/50], Class Loss: 0.0088, Discrepancy Loss: 0.1876
Epoch [23/50], Class Loss: 0.0114, Discrepancy Loss: 0.1933
Epoch [24/50], Class Loss: 0.0109, Discrepancy Loss: 0.1878
Epoch [25/50], Class Loss: 0.0119, Discrepancy Loss: 0.1846
Epoch [26/50], Class Loss: 0.0103, Discrepancy Loss: 0.1839
Epoch [27/50], Class Loss: 0.0113, Discrepancy Loss: 0.1856
Epoch [28/50], Class Loss: 0.0117, Discrepancy Loss: 0.1913
Epoch [29/50], Class Loss: 0.0127, Discrepancy Loss: 0.1871
Epoch [30/50], Class Loss: 0.0136, Discrepancy Loss: 0.1866
Epoch [31/50], Class Loss: 0.0154, Discrepancy Loss: 0.1930
Epoch [32/50], Class Loss: 0.0112, Discrepancy Loss: 0.1910
Epoch [33/50], Class Loss: 0.0109, Discrepancy Loss: 0.1865
Epoch [34/50], Class Loss: 0.0112, Discrepancy Loss: 0.1922
Epoch [35/50], Class Loss: 0.0123, Discrepancy Loss: 0.1909
Epoch [36/50], Class Loss: 0.0144, Discrepancy Loss: 0.1908
Epoch [37/50], Class Loss: 0.0116, Discrepancy Loss: 0.1812
Epoch [38/50], Class Loss: 0.0141, Discrepancy Loss: 0.1890
Epoch [39/50], Class Loss: 0.0117, Discrepancy Loss: 0.1880
Epoch [40/50], Class Loss: 0.0132, Discrepancy Loss: 0.1881
Epoch [41/50], Class Loss: 0.0122, Discrepancy Loss: 0.1917
Epoch [42/50], Class Loss: 0.0123, Discrepancy Loss: 0.1875
Epoch [43/50], Class Loss: 0.0140, Discrepancy Loss: 0.1891
Epoch [44/50], Class Loss: 0.0127, Discrepancy Loss: 0.1877
Epoch [45/50], Class Loss: 0.0122, Discrepancy Loss: 0.1879
Epoch [46/50], Class Loss: 0.0126, Discrepancy Loss: 0.1853
Epoch [47/50], Class Loss: 0.0125, Discrepancy Loss: 0.1885
Epoch [48/50], Class Loss: 0.0121, Discrepancy Loss: 0.1892
Epoch [49/50], Class Loss: 0.0145, Discrepancy Loss: 0.1857
Epoch [50/50], Class Loss: 0.0133, Discrepancy Loss: 0.1881
Source Domain Performance - Accuracy: 98.32%, Precision: 98.41%, Recall: 98.36%, F1 Score: 98.33%
Target Domain Performance - Accuracy: 58.45%, Precision: 56.90%, Recall: 60.28%, F1 Score: 46.68%

Run 6/10
Epoch [1/50], Class Loss: 4.0502, Discrepancy Loss: 0.0814
Epoch [2/50], Class Loss: 1.0239, Discrepancy Loss: 0.0830
Epoch [3/50], Class Loss: 0.5812, Discrepancy Loss: 0.1002
Epoch [4/50], Class Loss: 0.4859, Discrepancy Loss: 0.0989
Epoch [5/50], Class Loss: 0.3892, Discrepancy Loss: 0.1097
Epoch [6/50], Class Loss: 0.3395, Discrepancy Loss: 0.1051
Epoch [7/50], Class Loss: 0.4014, Discrepancy Loss: 0.0910
Epoch [8/50], Class Loss: 0.3281, Discrepancy Loss: 0.1047
Epoch [9/50], Class Loss: 0.2107, Discrepancy Loss: 0.1105
Epoch [10/50], Class Loss: 0.2314, Discrepancy Loss: 0.1239
Epoch [11/50], Class Loss: 0.0627, Discrepancy Loss: 0.1613
Epoch [12/50], Class Loss: 0.0741, Discrepancy Loss: 0.1531
Epoch [13/50], Class Loss: 0.0582, Discrepancy Loss: 0.1439
Epoch [14/50], Class Loss: 0.0577, Discrepancy Loss: 0.1408
Epoch [15/50], Class Loss: 0.0571, Discrepancy Loss: 0.1446
Epoch [16/50], Class Loss: 0.0471, Discrepancy Loss: 0.1529
Epoch [17/50], Class Loss: 0.0435, Discrepancy Loss: 0.1399
Epoch [18/50], Class Loss: 0.0354, Discrepancy Loss: 0.1445
Epoch [19/50], Class Loss: 0.0399, Discrepancy Loss: 0.1526
Epoch [20/50], Class Loss: 0.0288, Discrepancy Loss: 0.1471
Epoch [21/50], Class Loss: 0.0337, Discrepancy Loss: 0.1625
Epoch [22/50], Class Loss: 0.0182, Discrepancy Loss: 0.1554
Epoch [23/50], Class Loss: 0.0128, Discrepancy Loss: 0.1532
Epoch [24/50], Class Loss: 0.0125, Discrepancy Loss: 0.1489
Epoch [25/50], Class Loss: 0.0115, Discrepancy Loss: 0.1415
Epoch [26/50], Class Loss: 0.0093, Discrepancy Loss: 0.1453
Epoch [27/50], Class Loss: 0.0116, Discrepancy Loss: 0.1503
Epoch [28/50], Class Loss: 0.0109, Discrepancy Loss: 0.1439
Epoch [29/50], Class Loss: 0.0131, Discrepancy Loss: 0.1398
Epoch [30/50], Class Loss: 0.0142, Discrepancy Loss: 0.1369
Epoch [31/50], Class Loss: 0.0148, Discrepancy Loss: 0.1321
Epoch [32/50], Class Loss: 0.0143, Discrepancy Loss: 0.1395
Epoch [33/50], Class Loss: 0.0123, Discrepancy Loss: 0.1330
Epoch [34/50], Class Loss: 0.0143, Discrepancy Loss: 0.1363
Epoch [35/50], Class Loss: 0.0156, Discrepancy Loss: 0.1351
Epoch [36/50], Class Loss: 0.0122, Discrepancy Loss: 0.1366
Epoch [37/50], Class Loss: 0.0109, Discrepancy Loss: 0.1370
Epoch [38/50], Class Loss: 0.0143, Discrepancy Loss: 0.1372
Epoch [39/50], Class Loss: 0.0158, Discrepancy Loss: 0.1360
Epoch [40/50], Class Loss: 0.0125, Discrepancy Loss: 0.1342
Epoch [41/50], Class Loss: 0.0150, Discrepancy Loss: 0.1329
Epoch [42/50], Class Loss: 0.0147, Discrepancy Loss: 0.1331
Epoch [43/50], Class Loss: 0.0147, Discrepancy Loss: 0.1355
Epoch [44/50], Class Loss: 0.0159, Discrepancy Loss: 0.1382
Epoch [45/50], Class Loss: 0.0159, Discrepancy Loss: 0.1334
Epoch [46/50], Class Loss: 0.0141, Discrepancy Loss: 0.1334
Epoch [47/50], Class Loss: 0.0112, Discrepancy Loss: 0.1374
Epoch [48/50], Class Loss: 0.0166, Discrepancy Loss: 0.1342
Epoch [49/50], Class Loss: 0.0144, Discrepancy Loss: 0.1327
Epoch [50/50], Class Loss: 0.0142, Discrepancy Loss: 0.1339
Source Domain Performance - Accuracy: 84.30%, Precision: 90.92%, Recall: 84.78%, F1 Score: 82.07%
Target Domain Performance - Accuracy: 62.01%, Precision: 60.22%, Recall: 63.73%, F1 Score: 53.22%

Run 7/10
Epoch [1/50], Class Loss: 3.8888, Discrepancy Loss: 0.0784
Epoch [2/50], Class Loss: 0.9544, Discrepancy Loss: 0.0900
Epoch [3/50], Class Loss: 0.5340, Discrepancy Loss: 0.1020
Epoch [4/50], Class Loss: 0.4509, Discrepancy Loss: 0.0963
Epoch [5/50], Class Loss: 0.4981, Discrepancy Loss: 0.0925
Epoch [6/50], Class Loss: 0.3516, Discrepancy Loss: 0.0995
Epoch [7/50], Class Loss: 0.3029, Discrepancy Loss: 0.1034
Epoch [8/50], Class Loss: 0.3978, Discrepancy Loss: 0.0895
Epoch [9/50], Class Loss: 0.2430, Discrepancy Loss: 0.0955
Epoch [10/50], Class Loss: 0.1392, Discrepancy Loss: 0.1047
Epoch [11/50], Class Loss: 0.0655, Discrepancy Loss: 0.1056
Epoch [12/50], Class Loss: 0.0452, Discrepancy Loss: 0.1128
Epoch [13/50], Class Loss: 0.0405, Discrepancy Loss: 0.1207
Epoch [14/50], Class Loss: 0.0317, Discrepancy Loss: 0.1322
Epoch [15/50], Class Loss: 0.0390, Discrepancy Loss: 0.1121
Epoch [16/50], Class Loss: 0.0329, Discrepancy Loss: 0.1146
Epoch [17/50], Class Loss: 0.0269, Discrepancy Loss: 0.1190
Epoch [18/50], Class Loss: 0.0356, Discrepancy Loss: 0.1265
Epoch [19/50], Class Loss: 0.0193, Discrepancy Loss: 0.1125
Epoch [20/50], Class Loss: 0.0211, Discrepancy Loss: 0.1220
Epoch [21/50], Class Loss: 0.0200, Discrepancy Loss: 0.1259
Epoch [22/50], Class Loss: 0.0154, Discrepancy Loss: 0.1209
Epoch [23/50], Class Loss: 0.0203, Discrepancy Loss: 0.1260
Epoch [24/50], Class Loss: 0.0174, Discrepancy Loss: 0.1261
Epoch [25/50], Class Loss: 0.0208, Discrepancy Loss: 0.1272
Epoch [26/50], Class Loss: 0.0184, Discrepancy Loss: 0.1313
Epoch [27/50], Class Loss: 0.0214, Discrepancy Loss: 0.1297
Epoch [28/50], Class Loss: 0.0184, Discrepancy Loss: 0.1331
Epoch [29/50], Class Loss: 0.0230, Discrepancy Loss: 0.1314
Epoch [30/50], Class Loss: 0.0192, Discrepancy Loss: 0.1297
Epoch [31/50], Class Loss: 0.0187, Discrepancy Loss: 0.1362
Epoch [32/50], Class Loss: 0.0186, Discrepancy Loss: 0.1311
Epoch [33/50], Class Loss: 0.0214, Discrepancy Loss: 0.1308
Epoch [34/50], Class Loss: 0.0166, Discrepancy Loss: 0.1301
Epoch [35/50], Class Loss: 0.0279, Discrepancy Loss: 0.1283
Epoch [36/50], Class Loss: 0.0178, Discrepancy Loss: 0.1361
Epoch [37/50], Class Loss: 0.0162, Discrepancy Loss: 0.1390
Epoch [38/50], Class Loss: 0.0176, Discrepancy Loss: 0.1216
Epoch [39/50], Class Loss: 0.0156, Discrepancy Loss: 0.1310
Epoch [40/50], Class Loss: 0.0187, Discrepancy Loss: 0.1361
Epoch [41/50], Class Loss: 0.0200, Discrepancy Loss: 0.1342
Epoch [42/50], Class Loss: 0.0175, Discrepancy Loss: 0.1378
Epoch [43/50], Class Loss: 0.0202, Discrepancy Loss: 0.1382
Epoch [44/50], Class Loss: 0.0216, Discrepancy Loss: 0.1313
Epoch [45/50], Class Loss: 0.0194, Discrepancy Loss: 0.1310
Epoch [46/50], Class Loss: 0.0194, Discrepancy Loss: 0.1328
Epoch [47/50], Class Loss: 0.0184, Discrepancy Loss: 0.1361
Epoch [48/50], Class Loss: 0.0216, Discrepancy Loss: 0.1340
Epoch [49/50], Class Loss: 0.0190, Discrepancy Loss: 0.1310
Epoch [50/50], Class Loss: 0.0198, Discrepancy Loss: 0.1329
Source Domain Performance - Accuracy: 75.27%, Precision: 65.50%, Recall: 75.84%, F1 Score: 69.43%
Target Domain Performance - Accuracy: 75.73%, Precision: 66.48%, Recall: 76.94%, F1 Score: 69.84%

Run 8/10
Epoch [1/50], Class Loss: 3.9244, Discrepancy Loss: 0.0771
Epoch [2/50], Class Loss: 0.7769, Discrepancy Loss: 0.0879
Epoch [3/50], Class Loss: 0.5292, Discrepancy Loss: 0.0947
Epoch [4/50], Class Loss: 0.4557, Discrepancy Loss: 0.0956
Epoch [5/50], Class Loss: 0.4137, Discrepancy Loss: 0.1042
Epoch [6/50], Class Loss: 0.3656, Discrepancy Loss: 0.1099
Epoch [7/50], Class Loss: 0.4321, Discrepancy Loss: 0.0979
Epoch [8/50], Class Loss: 0.2659, Discrepancy Loss: 0.1298
Epoch [9/50], Class Loss: 0.2623, Discrepancy Loss: 0.1108
Epoch [10/50], Class Loss: 0.2424, Discrepancy Loss: 0.1101
Epoch [11/50], Class Loss: 0.1926, Discrepancy Loss: 0.1075
Epoch [12/50], Class Loss: 0.1160, Discrepancy Loss: 0.1324
Epoch [13/50], Class Loss: 0.0885, Discrepancy Loss: 0.1470
Epoch [14/50], Class Loss: 0.0524, Discrepancy Loss: 0.1557
Epoch [15/50], Class Loss: 0.0587, Discrepancy Loss: 0.1582
Epoch [16/50], Class Loss: 0.0756, Discrepancy Loss: 0.1547
Epoch [17/50], Class Loss: 0.0413, Discrepancy Loss: 0.1682
Epoch [18/50], Class Loss: 0.0372, Discrepancy Loss: 0.1655
Epoch [19/50], Class Loss: 0.0302, Discrepancy Loss: 0.1470
Epoch [20/50], Class Loss: 0.0387, Discrepancy Loss: 0.1711
Epoch [21/50], Class Loss: 0.0240, Discrepancy Loss: 0.1364
Epoch [22/50], Class Loss: 0.0172, Discrepancy Loss: 0.1367
Epoch [23/50], Class Loss: 0.0247, Discrepancy Loss: 0.1332
Epoch [24/50], Class Loss: 0.0188, Discrepancy Loss: 0.1352
Epoch [25/50], Class Loss: 0.0251, Discrepancy Loss: 0.1334
Epoch [26/50], Class Loss: 0.0247, Discrepancy Loss: 0.1340
Epoch [27/50], Class Loss: 0.0208, Discrepancy Loss: 0.1320
Epoch [28/50], Class Loss: 0.0215, Discrepancy Loss: 0.1320
Epoch [29/50], Class Loss: 0.0191, Discrepancy Loss: 0.1346
Epoch [30/50], Class Loss: 0.0205, Discrepancy Loss: 0.1338
Epoch [31/50], Class Loss: 0.0241, Discrepancy Loss: 0.1373
Epoch [32/50], Class Loss: 0.0221, Discrepancy Loss: 0.1321
Epoch [33/50], Class Loss: 0.0201, Discrepancy Loss: 0.1342
Epoch [34/50], Class Loss: 0.0205, Discrepancy Loss: 0.1344
Epoch [35/50], Class Loss: 0.0198, Discrepancy Loss: 0.1364
Epoch [36/50], Class Loss: 0.0202, Discrepancy Loss: 0.1367
Epoch [37/50], Class Loss: 0.0159, Discrepancy Loss: 0.1352
Epoch [38/50], Class Loss: 0.0230, Discrepancy Loss: 0.1335
Epoch [39/50], Class Loss: 0.0203, Discrepancy Loss: 0.1342
Epoch [40/50], Class Loss: 0.0189, Discrepancy Loss: 0.1340
Epoch [41/50], Class Loss: 0.0202, Discrepancy Loss: 0.1366
Epoch [42/50], Class Loss: 0.0252, Discrepancy Loss: 0.1358
Epoch [43/50], Class Loss: 0.0225, Discrepancy Loss: 0.1339
Epoch [44/50], Class Loss: 0.0205, Discrepancy Loss: 0.1329
Epoch [45/50], Class Loss: 0.0257, Discrepancy Loss: 0.1357
Epoch [46/50], Class Loss: 0.0188, Discrepancy Loss: 0.1352
Epoch [47/50], Class Loss: 0.0204, Discrepancy Loss: 0.1335
Epoch [48/50], Class Loss: 0.0207, Discrepancy Loss: 0.1355
Epoch [49/50], Class Loss: 0.0198, Discrepancy Loss: 0.1358
Epoch [50/50], Class Loss: 0.0221, Discrepancy Loss: 0.1382
Source Domain Performance - Accuracy: 79.57%, Precision: 88.20%, Recall: 80.18%, F1 Score: 73.67%
Target Domain Performance - Accuracy: 69.24%, Precision: 62.68%, Recall: 70.72%, F1 Score: 62.95%

Run 9/10
Epoch [1/50], Class Loss: 4.4396, Discrepancy Loss: 0.0779
Epoch [2/50], Class Loss: 0.8482, Discrepancy Loss: 0.0937
Epoch [3/50], Class Loss: 0.5385, Discrepancy Loss: 0.1057
Epoch [4/50], Class Loss: 0.6096, Discrepancy Loss: 0.0906
Epoch [5/50], Class Loss: 0.6045, Discrepancy Loss: 0.0879
Epoch [6/50], Class Loss: 0.4053, Discrepancy Loss: 0.1047
Epoch [7/50], Class Loss: 0.3625, Discrepancy Loss: 0.0932
Epoch [8/50], Class Loss: 0.2602, Discrepancy Loss: 0.1128
Epoch [9/50], Class Loss: 0.2418, Discrepancy Loss: 0.1148
Epoch [10/50], Class Loss: 0.2599, Discrepancy Loss: 0.1160
Epoch [11/50], Class Loss: 0.1239, Discrepancy Loss: 0.1388
Epoch [12/50], Class Loss: 0.0551, Discrepancy Loss: 0.1538
Epoch [13/50], Class Loss: 0.0498, Discrepancy Loss: 0.1645
Epoch [14/50], Class Loss: 0.0461, Discrepancy Loss: 0.1739
Epoch [15/50], Class Loss: 0.0555, Discrepancy Loss: 0.1378
Epoch [16/50], Class Loss: 0.0601, Discrepancy Loss: 0.1302
Epoch [17/50], Class Loss: 0.0417, Discrepancy Loss: 0.1289
Epoch [18/50], Class Loss: 0.0716, Discrepancy Loss: 0.1311
Epoch [19/50], Class Loss: 0.0334, Discrepancy Loss: 0.1453
Epoch [20/50], Class Loss: 0.0317, Discrepancy Loss: 0.1573
Epoch [21/50], Class Loss: 0.0281, Discrepancy Loss: 0.1431
Epoch [22/50], Class Loss: 0.0184, Discrepancy Loss: 0.1460
Epoch [23/50], Class Loss: 0.0180, Discrepancy Loss: 0.1375
Epoch [24/50], Class Loss: 0.0215, Discrepancy Loss: 0.1366
Epoch [25/50], Class Loss: 0.0203, Discrepancy Loss: 0.1438
Epoch [26/50], Class Loss: 0.0152, Discrepancy Loss: 0.1379
Epoch [27/50], Class Loss: 0.0170, Discrepancy Loss: 0.1328
Epoch [28/50], Class Loss: 0.0158, Discrepancy Loss: 0.1314
Epoch [29/50], Class Loss: 0.0180, Discrepancy Loss: 0.1274
Epoch [30/50], Class Loss: 0.0217, Discrepancy Loss: 0.1291
Epoch [31/50], Class Loss: 0.0164, Discrepancy Loss: 0.1295
Epoch [32/50], Class Loss: 0.0173, Discrepancy Loss: 0.1270
Epoch [33/50], Class Loss: 0.0168, Discrepancy Loss: 0.1282
Epoch [34/50], Class Loss: 0.0199, Discrepancy Loss: 0.1292
Epoch [35/50], Class Loss: 0.0186, Discrepancy Loss: 0.1326
Epoch [36/50], Class Loss: 0.0164, Discrepancy Loss: 0.1258
Epoch [37/50], Class Loss: 0.0135, Discrepancy Loss: 0.1269
Epoch [38/50], Class Loss: 0.0180, Discrepancy Loss: 0.1267
Epoch [39/50], Class Loss: 0.0159, Discrepancy Loss: 0.1306
Epoch [40/50], Class Loss: 0.0167, Discrepancy Loss: 0.1213
Epoch [41/50], Class Loss: 0.0145, Discrepancy Loss: 0.1261
Epoch [42/50], Class Loss: 0.0168, Discrepancy Loss: 0.1295
Epoch [43/50], Class Loss: 0.0174, Discrepancy Loss: 0.1281
Epoch [44/50], Class Loss: 0.0161, Discrepancy Loss: 0.1215
Epoch [45/50], Class Loss: 0.0185, Discrepancy Loss: 0.1251
Epoch [46/50], Class Loss: 0.0222, Discrepancy Loss: 0.1272
Epoch [47/50], Class Loss: 0.0151, Discrepancy Loss: 0.1286
Epoch [48/50], Class Loss: 0.0193, Discrepancy Loss: 0.1254
Epoch [49/50], Class Loss: 0.0151, Discrepancy Loss: 0.1230
Epoch [50/50], Class Loss: 0.0150, Discrepancy Loss: 0.1240
Source Domain Performance - Accuracy: 78.96%, Precision: 69.73%, Recall: 79.57%, F1 Score: 72.90%
Target Domain Performance - Accuracy: 73.80%, Precision: 65.11%, Recall: 75.11%, F1 Score: 67.90%

Run 10/10
Epoch [1/50], Class Loss: 3.6053, Discrepancy Loss: 0.0750
Epoch [2/50], Class Loss: 0.7917, Discrepancy Loss: 0.0803
Epoch [3/50], Class Loss: 0.5488, Discrepancy Loss: 0.1029
Epoch [4/50], Class Loss: 0.5046, Discrepancy Loss: 0.1193
Epoch [5/50], Class Loss: 0.4129, Discrepancy Loss: 0.1288
Epoch [6/50], Class Loss: 0.4250, Discrepancy Loss: 0.1327
Epoch [7/50], Class Loss: 0.3258, Discrepancy Loss: 0.1283
Epoch [8/50], Class Loss: 0.2720, Discrepancy Loss: 0.1411
Epoch [9/50], Class Loss: 0.5410, Discrepancy Loss: 0.1064
Epoch [10/50], Class Loss: 0.3001, Discrepancy Loss: 0.1091
Epoch [11/50], Class Loss: 0.0779, Discrepancy Loss: 0.1470
Epoch [12/50], Class Loss: 0.0345, Discrepancy Loss: 0.1434
Epoch [13/50], Class Loss: 0.0294, Discrepancy Loss: 0.1272
Epoch [14/50], Class Loss: 0.0419, Discrepancy Loss: 0.1369
Epoch [15/50], Class Loss: 0.0389, Discrepancy Loss: 0.1379
Epoch [16/50], Class Loss: 0.0276, Discrepancy Loss: 0.1300
Epoch [17/50], Class Loss: 0.0210, Discrepancy Loss: 0.1414
Epoch [18/50], Class Loss: 0.0281, Discrepancy Loss: 0.1477
Epoch [19/50], Class Loss: 0.0214, Discrepancy Loss: 0.1473
Epoch [20/50], Class Loss: 0.0336, Discrepancy Loss: 0.1584
Epoch [21/50], Class Loss: 0.0357, Discrepancy Loss: 0.1641
Epoch [22/50], Class Loss: 0.0276, Discrepancy Loss: 0.1501
Epoch [23/50], Class Loss: 0.0296, Discrepancy Loss: 0.1420
Epoch [24/50], Class Loss: 0.0244, Discrepancy Loss: 0.1478
Epoch [25/50], Class Loss: 0.0275, Discrepancy Loss: 0.1436
Epoch [26/50], Class Loss: 0.0239, Discrepancy Loss: 0.1410
Epoch [27/50], Class Loss: 0.0227, Discrepancy Loss: 0.1420
Epoch [28/50], Class Loss: 0.0227, Discrepancy Loss: 0.1421
Epoch [29/50], Class Loss: 0.0223, Discrepancy Loss: 0.1458
Epoch [30/50], Class Loss: 0.0192, Discrepancy Loss: 0.1475
Epoch [31/50], Class Loss: 0.0259, Discrepancy Loss: 0.1462
Epoch [32/50], Class Loss: 0.0243, Discrepancy Loss: 0.1497
Epoch [33/50], Class Loss: 0.0211, Discrepancy Loss: 0.1462
Epoch [34/50], Class Loss: 0.0219, Discrepancy Loss: 0.1432
Epoch [35/50], Class Loss: 0.0228, Discrepancy Loss: 0.1476
Epoch [36/50], Class Loss: 0.0199, Discrepancy Loss: 0.1455
Epoch [37/50], Class Loss: 0.0218, Discrepancy Loss: 0.1474
Epoch [38/50], Class Loss: 0.0207, Discrepancy Loss: 0.1505
Epoch [39/50], Class Loss: 0.0187, Discrepancy Loss: 0.1479
Epoch [40/50], Class Loss: 0.0221, Discrepancy Loss: 0.1460
Epoch [41/50], Class Loss: 0.0210, Discrepancy Loss: 0.1477
Epoch [42/50], Class Loss: 0.0236, Discrepancy Loss: 0.1474
Epoch [43/50], Class Loss: 0.0274, Discrepancy Loss: 0.1452
Epoch [44/50], Class Loss: 0.0183, Discrepancy Loss: 0.1455
Epoch [45/50], Class Loss: 0.0224, Discrepancy Loss: 0.1464
Epoch [46/50], Class Loss: 0.0202, Discrepancy Loss: 0.1436
Epoch [47/50], Class Loss: 0.0223, Discrepancy Loss: 0.1515
Epoch [48/50], Class Loss: 0.0194, Discrepancy Loss: 0.1443
Epoch [49/50], Class Loss: 0.0217, Discrepancy Loss: 0.1480
Epoch [50/50], Class Loss: 0.0171, Discrepancy Loss: 0.1448
Source Domain Performance - Accuracy: 79.17%, Precision: 74.12%, Recall: 79.80%, F1 Score: 73.07%
Target Domain Performance - Accuracy: 71.68%, Precision: 63.82%, Recall: 73.08%, F1 Score: 65.67%

Source performance: 82.94% 82.92% 83.43% 78.95%
Target performance: 67.83% 62.19% 69.33% 60.31%

Per-Class Accuracy on Target Domain:
bpsk: 99.91%
qpsk: 97.41%
4qam: 99.60%
16qam: 49.73%
apsk: 0.00%

Run 1/10
Epoch [1/50], Class Loss: 3.2608, Discrepancy Loss: 0.0311
Validation Loss: 1.8219
Epoch [2/50], Class Loss: 1.6909, Discrepancy Loss: 0.0313
Validation Loss: 1.2623
Epoch [3/50], Class Loss: 1.3093, Discrepancy Loss: 0.0388
Validation Loss: 0.4177
Epoch [4/50], Class Loss: 0.3840, Discrepancy Loss: 0.0162
Validation Loss: 0.2620
Epoch [5/50], Class Loss: 0.4155, Discrepancy Loss: 0.0090
Validation Loss: 10.1211
Epoch [6/50], Class Loss: 1.4983, Discrepancy Loss: 0.0296
Validation Loss: 0.8183
Epoch [7/50], Class Loss: 0.5436, Discrepancy Loss: 0.0118
Validation Loss: 1.9098
Epoch [8/50], Class Loss: 0.9311, Discrepancy Loss: 0.0250
Validation Loss: 0.2027
Epoch [9/50], Class Loss: 1.5630, Discrepancy Loss: 0.0276
Validation Loss: 0.2418
Epoch [10/50], Class Loss: 0.3616, Discrepancy Loss: 0.0115
Validation Loss: 0.3700
Epoch [11/50], Class Loss: 0.0727, Discrepancy Loss: 0.0042
Validation Loss: 0.0336
Epoch [12/50], Class Loss: 0.1146, Discrepancy Loss: 0.0084
Validation Loss: 0.0271
Epoch [13/50], Class Loss: 0.0757, Discrepancy Loss: 0.0089
Validation Loss: 0.0338
Epoch [14/50], Class Loss: 0.0806, Discrepancy Loss: 0.0082
Validation Loss: 0.0480
Epoch [15/50], Class Loss: 0.0504, Discrepancy Loss: 0.0087
Validation Loss: 0.0607
Epoch [16/50], Class Loss: 0.0848, Discrepancy Loss: 0.0090
Validation Loss: 0.0339
Epoch [17/50], Class Loss: 0.1081, Discrepancy Loss: 0.0082
Validation Loss: 0.0304
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 45.87%, Precision: 46.72%, Recall: 47.33%, F1 Score: 34.01%

Run 2/10
Epoch [1/50], Class Loss: 2.9451, Discrepancy Loss: 0.0397
Validation Loss: 1.2285
Epoch [2/50], Class Loss: 1.5518, Discrepancy Loss: 0.0299
Validation Loss: 0.3635
Epoch [3/50], Class Loss: 0.3539, Discrepancy Loss: 0.0099
Validation Loss: 0.1927
Epoch [4/50], Class Loss: 0.8739, Discrepancy Loss: 0.0158
Validation Loss: 1.2398
Epoch [5/50], Class Loss: 0.8500, Discrepancy Loss: 0.0252
Validation Loss: 0.4456
Epoch [6/50], Class Loss: 0.7616, Discrepancy Loss: 0.0214
Validation Loss: 1.4594
Epoch [7/50], Class Loss: 2.8943, Discrepancy Loss: 0.0460
Validation Loss: 1.9845
Epoch [8/50], Class Loss: 1.9312, Discrepancy Loss: 0.0802
Validation Loss: 0.6928
Early stopping!
Source Domain Performance - Accuracy: 94.60%, Precision: 95.04%, Recall: 94.74%, F1 Score: 94.49%
Target Domain Performance - Accuracy: 39.36%, Precision: 35.50%, Recall: 40.57%, F1 Score: 24.88%

Run 3/10
Epoch [1/50], Class Loss: 3.2863, Discrepancy Loss: 0.0121
Validation Loss: 3.4706
Epoch [2/50], Class Loss: 2.1006, Discrepancy Loss: 0.0363
Validation Loss: 1.5374
Epoch [3/50], Class Loss: 1.2170, Discrepancy Loss: 0.0409
Validation Loss: 0.4869
Epoch [4/50], Class Loss: 0.4593, Discrepancy Loss: 0.0121
Validation Loss: 12.1022
Epoch [5/50], Class Loss: 0.8690, Discrepancy Loss: 0.0186
Validation Loss: 0.2338
Epoch [6/50], Class Loss: 0.2710, Discrepancy Loss: 0.0166
Validation Loss: 0.0506
Epoch [7/50], Class Loss: 0.9081, Discrepancy Loss: 0.0328
Validation Loss: 0.0337
Epoch [8/50], Class Loss: 0.5037, Discrepancy Loss: 0.0162
Validation Loss: 0.1589
Epoch [9/50], Class Loss: 1.1094, Discrepancy Loss: 0.0166
Validation Loss: 0.2095
Epoch [10/50], Class Loss: 0.4006, Discrepancy Loss: 0.0059
Validation Loss: 0.3960
Epoch [11/50], Class Loss: 0.0479, Discrepancy Loss: 0.0010
Validation Loss: 0.0070
Epoch [12/50], Class Loss: 0.0086, Discrepancy Loss: 0.0002
Validation Loss: 0.0046
Epoch [13/50], Class Loss: 0.0195, Discrepancy Loss: 0.0016
Validation Loss: 0.0067
Epoch [14/50], Class Loss: 0.0139, Discrepancy Loss: 0.0020
Validation Loss: 0.0148
Epoch [15/50], Class Loss: 0.0670, Discrepancy Loss: 0.0028
Validation Loss: 0.0158
Epoch [16/50], Class Loss: 0.0676, Discrepancy Loss: 0.0034
Validation Loss: 0.0118
Epoch [17/50], Class Loss: 0.3240, Discrepancy Loss: 0.0188
Validation Loss: 0.0640
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 57.79%, Precision: 58.74%, Recall: 59.62%, F1 Score: 45.63%

Run 4/10
Epoch [1/50], Class Loss: 3.4451, Discrepancy Loss: 0.0418
Validation Loss: 1.4697
Epoch [2/50], Class Loss: 1.9884, Discrepancy Loss: 0.0367
Validation Loss: 1.2840
Epoch [3/50], Class Loss: 1.5805, Discrepancy Loss: 0.0410
Validation Loss: 1.0287
Epoch [4/50], Class Loss: 1.8146, Discrepancy Loss: 0.0310
Validation Loss: 2.8081
Epoch [5/50], Class Loss: 2.0456, Discrepancy Loss: 0.0333
Validation Loss: 1.1430
Epoch [6/50], Class Loss: 0.6249, Discrepancy Loss: 0.0233
Validation Loss: 0.5676
Epoch [7/50], Class Loss: 0.8419, Discrepancy Loss: 0.0243
Validation Loss: 1.3489
Epoch [8/50], Class Loss: 1.3176, Discrepancy Loss: 0.0380
Validation Loss: 0.5274
Epoch [9/50], Class Loss: 0.4636, Discrepancy Loss: 0.0245
Validation Loss: 0.9946
Epoch [10/50], Class Loss: 0.4340, Discrepancy Loss: 0.0194
Validation Loss: 0.2867
Epoch [11/50], Class Loss: 0.0412, Discrepancy Loss: 0.0057
Validation Loss: 0.0162
Epoch [12/50], Class Loss: 0.0157, Discrepancy Loss: 0.0046
Validation Loss: 0.0188
Epoch [13/50], Class Loss: 0.0151, Discrepancy Loss: 0.0048
Validation Loss: 0.0195
Epoch [14/50], Class Loss: 0.0480, Discrepancy Loss: 0.0073
Validation Loss: 0.0233
Epoch [15/50], Class Loss: 0.0497, Discrepancy Loss: 0.0099
Validation Loss: 0.0242
Epoch [16/50], Class Loss: 0.0843, Discrepancy Loss: 0.0097
Validation Loss: 0.0196
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 51.71%, Precision: 52.23%, Recall: 53.35%, F1 Score: 39.86%

Run 5/10
Epoch [1/50], Class Loss: 2.9539, Discrepancy Loss: 0.0310
Validation Loss: 1.4528
Epoch [2/50], Class Loss: 1.2661, Discrepancy Loss: 0.0405
Validation Loss: 0.3349
Epoch [3/50], Class Loss: 0.5265, Discrepancy Loss: 0.0269
Validation Loss: 0.6451
Epoch [4/50], Class Loss: 2.1064, Discrepancy Loss: 0.0730
Validation Loss: 7.5382
Epoch [5/50], Class Loss: 2.5548, Discrepancy Loss: 0.0601
Validation Loss: 1.4166
Epoch [6/50], Class Loss: 3.6835, Discrepancy Loss: 0.0765
Validation Loss: 4.9919
Epoch [7/50], Class Loss: 1.7351, Discrepancy Loss: 0.0606
Validation Loss: 1.5789
Early stopping!
Source Domain Performance - Accuracy: 74.78%, Precision: 73.46%, Recall: 74.23%, F1 Score: 67.67%
Target Domain Performance - Accuracy: 21.83%, Precision: 28.99%, Recall: 22.64%, F1 Score: 12.54%

Run 6/10
Epoch [1/50], Class Loss: 2.6767, Discrepancy Loss: 0.0411
Validation Loss: 0.6519
Epoch [2/50], Class Loss: 1.6688, Discrepancy Loss: 0.0280
Validation Loss: 0.9040
Epoch [3/50], Class Loss: 1.5439, Discrepancy Loss: 0.0517
Validation Loss: 0.3819
Epoch [4/50], Class Loss: 0.5334, Discrepancy Loss: 0.0242
Validation Loss: 0.5977
Epoch [5/50], Class Loss: 1.6735, Discrepancy Loss: 0.0229
Validation Loss: 1.4278
Epoch [6/50], Class Loss: 1.3383, Discrepancy Loss: 0.0363
Validation Loss: 0.7747
Epoch [7/50], Class Loss: 2.7135, Discrepancy Loss: 0.0455
Validation Loss: 0.8853
Epoch [8/50], Class Loss: 1.5558, Discrepancy Loss: 0.0228
Validation Loss: 0.5200
Early stopping!
Source Domain Performance - Accuracy: 97.61%, Precision: 97.79%, Recall: 97.67%, F1 Score: 97.62%
Target Domain Performance - Accuracy: 51.27%, Precision: 51.64%, Recall: 52.88%, F1 Score: 39.83%

Run 7/10
Epoch [1/50], Class Loss: 2.3179, Discrepancy Loss: 0.0363
Validation Loss: 2.6242
Epoch [2/50], Class Loss: 2.1385, Discrepancy Loss: 0.0512
Validation Loss: 0.6523
Epoch [3/50], Class Loss: 0.5707, Discrepancy Loss: 0.0259
Validation Loss: 0.4575
Epoch [4/50], Class Loss: 1.1001, Discrepancy Loss: 0.0299
Validation Loss: 5.4810
Epoch [5/50], Class Loss: 1.5794, Discrepancy Loss: 0.0403
Validation Loss: 2.5339
Epoch [6/50], Class Loss: 0.8178, Discrepancy Loss: 0.0299
Validation Loss: 0.3451
Epoch [7/50], Class Loss: 0.5462, Discrepancy Loss: 0.0214
Validation Loss: 0.5761
Epoch [8/50], Class Loss: 0.5672, Discrepancy Loss: 0.0144
Validation Loss: 0.7454
Epoch [9/50], Class Loss: 1.6842, Discrepancy Loss: 0.0374
Validation Loss: 0.1030
Epoch [10/50], Class Loss: 0.8530, Discrepancy Loss: 0.0186
Validation Loss: 0.5523
Epoch [11/50], Class Loss: 0.1080, Discrepancy Loss: 0.0023
Validation Loss: 0.4384
Epoch [12/50], Class Loss: 0.0426, Discrepancy Loss: 0.0018
Validation Loss: 0.0036
Epoch [13/50], Class Loss: 0.0294, Discrepancy Loss: 0.0013
Validation Loss: 0.0117
Epoch [14/50], Class Loss: 0.0504, Discrepancy Loss: 0.0046
Validation Loss: 0.0179
Epoch [15/50], Class Loss: 0.3471, Discrepancy Loss: 0.0166
Validation Loss: 0.0176
Epoch [16/50], Class Loss: 0.1457, Discrepancy Loss: 0.0218
Validation Loss: 0.0764
Epoch [17/50], Class Loss: 0.4008, Discrepancy Loss: 0.0226
Validation Loss: 0.0081
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 42.63%, Precision: 43.79%, Recall: 43.98%, F1 Score: 30.75%

Run 8/10
Epoch [1/50], Class Loss: 2.2078, Discrepancy Loss: 0.0321
Validation Loss: 1.0895
Epoch [2/50], Class Loss: 1.4150, Discrepancy Loss: 0.0349
Validation Loss: 0.3378
Epoch [3/50], Class Loss: 2.0028, Discrepancy Loss: 0.0318
Validation Loss: 0.4698
Epoch [4/50], Class Loss: 1.6160, Discrepancy Loss: 0.0426
Validation Loss: 0.7940
Epoch [5/50], Class Loss: 1.0900, Discrepancy Loss: 0.0287
Validation Loss: 1.0849
Epoch [6/50], Class Loss: 0.6857, Discrepancy Loss: 0.0257
Validation Loss: 0.3329
Epoch [7/50], Class Loss: 0.2315, Discrepancy Loss: 0.0169
Validation Loss: 0.0750
Epoch [8/50], Class Loss: 0.6214, Discrepancy Loss: 0.0153
Validation Loss: 0.0179
Epoch [9/50], Class Loss: 0.7118, Discrepancy Loss: 0.0229
Validation Loss: 1.1538
Epoch [10/50], Class Loss: 0.4648, Discrepancy Loss: 0.0164
Validation Loss: 0.2626
Epoch [11/50], Class Loss: 0.0506, Discrepancy Loss: 0.0019
Validation Loss: 0.0131
Epoch [12/50], Class Loss: 0.0116, Discrepancy Loss: 0.0003
Validation Loss: 0.0043
Epoch [13/50], Class Loss: 0.0223, Discrepancy Loss: 0.0015
Validation Loss: 0.0059
Epoch [14/50], Class Loss: 0.0141, Discrepancy Loss: 0.0022
Validation Loss: 0.0035
Epoch [15/50], Class Loss: 0.1968, Discrepancy Loss: 0.0030
Validation Loss: 0.0076
Epoch [16/50], Class Loss: 0.0297, Discrepancy Loss: 0.0026
Validation Loss: 0.1237
Epoch [17/50], Class Loss: 0.0288, Discrepancy Loss: 0.0029
Validation Loss: 0.0082
Epoch [18/50], Class Loss: 0.0303, Discrepancy Loss: 0.0040
Validation Loss: 0.0182
Epoch [19/50], Class Loss: 0.3168, Discrepancy Loss: 0.0132
Validation Loss: 0.0472
Early stopping!
Source Domain Performance - Accuracy: 99.73%, Precision: 99.73%, Recall: 99.73%, F1 Score: 99.73%
Target Domain Performance - Accuracy: 57.67%, Precision: 48.99%, Recall: 59.50%, F1 Score: 45.61%

Run 9/10
Epoch [1/50], Class Loss: 2.6589, Discrepancy Loss: 0.0325
Validation Loss: 0.6812
Epoch [2/50], Class Loss: 1.9153, Discrepancy Loss: 0.0488
Validation Loss: 1.5160
Epoch [3/50], Class Loss: 2.4150, Discrepancy Loss: 0.0454
Validation Loss: 2.3731
Epoch [4/50], Class Loss: 1.4510, Discrepancy Loss: 0.0451
Validation Loss: 0.2899
Epoch [5/50], Class Loss: 0.3165, Discrepancy Loss: 0.0139
Validation Loss: 0.0966
Epoch [6/50], Class Loss: 0.2709, Discrepancy Loss: 0.0170
Validation Loss: 1.2854
Epoch [7/50], Class Loss: 1.3219, Discrepancy Loss: 0.0382
Validation Loss: 0.1070
Epoch [8/50], Class Loss: 0.9298, Discrepancy Loss: 0.0220
Validation Loss: 0.3920
Epoch [9/50], Class Loss: 0.3956, Discrepancy Loss: 0.0080
Validation Loss: 0.3610
Epoch [10/50], Class Loss: 0.3420, Discrepancy Loss: 0.0089
Validation Loss: 0.5764
Early stopping!
Source Domain Performance - Accuracy: 81.01%, Precision: 90.11%, Recall: 80.53%, F1 Score: 74.56%
Target Domain Performance - Accuracy: 26.12%, Precision: 22.62%, Recall: 27.07%, F1 Score: 16.44%

Run 10/10
Epoch [1/50], Class Loss: 2.5086, Discrepancy Loss: 0.0423
Validation Loss: 2.2466
Epoch [2/50], Class Loss: 1.2774, Discrepancy Loss: 0.0285
Validation Loss: 0.9180
Epoch [3/50], Class Loss: 0.5728, Discrepancy Loss: 0.0283
Validation Loss: 0.1572
Epoch [4/50], Class Loss: 1.0433, Discrepancy Loss: 0.0221
Validation Loss: 4.3146
Epoch [5/50], Class Loss: 1.9356, Discrepancy Loss: 0.0475
Validation Loss: 0.3345
Epoch [6/50], Class Loss: 1.3823, Discrepancy Loss: 0.0489
Validation Loss: 0.1066
Epoch [7/50], Class Loss: 1.2264, Discrepancy Loss: 0.0343
Validation Loss: 0.0755
Epoch [8/50], Class Loss: 0.8361, Discrepancy Loss: 0.0270
Validation Loss: 0.5031
Epoch [9/50], Class Loss: 0.4341, Discrepancy Loss: 0.0160
Validation Loss: 0.5094
Epoch [10/50], Class Loss: 0.3824, Discrepancy Loss: 0.0176
Validation Loss: 0.2408
Epoch [11/50], Class Loss: 0.0352, Discrepancy Loss: 0.0022
Validation Loss: 0.0093
Epoch [12/50], Class Loss: 0.0126, Discrepancy Loss: 0.0019
Validation Loss: 0.0146
Epoch [13/50], Class Loss: 0.0162, Discrepancy Loss: 0.0031
Validation Loss: 0.0126
Epoch [14/50], Class Loss: 0.0092, Discrepancy Loss: 0.0028
Validation Loss: 0.0093
Epoch [15/50], Class Loss: 0.0382, Discrepancy Loss: 0.0031
Validation Loss: 0.0133
Epoch [16/50], Class Loss: 0.0204, Discrepancy Loss: 0.0036
Validation Loss: 0.0148
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 48.49%, Precision: 49.30%, Recall: 50.02%, F1 Score: 36.79%

Source performance: 94.73% 95.57% 94.64% 93.36%
Target performance: 44.27% 43.85% 45.69% 32.63%

Per-Class Accuracy on Target Domain:
bpsk: 99.61%
qpsk: 47.81%
4qam: 80.44%
16qam: 0.61%
apsk: 0.00%

Run 1/10
Epoch [1/50], Class Loss: 1.2721, CORAL Loss: 0.0132
Validation Loss: 0.6193
Epoch [2/50], Class Loss: 1.0006, CORAL Loss: 0.6779
Validation Loss: 1.4199
Epoch [3/50], Class Loss: 0.9282, CORAL Loss: 0.0245
Validation Loss: 0.6353
Epoch [4/50], Class Loss: 0.5683, CORAL Loss: 0.0514
Validation Loss: 0.2899
Epoch [5/50], Class Loss: 0.3919, CORAL Loss: 0.0354
Validation Loss: 0.2662
Epoch [6/50], Class Loss: 0.3112, CORAL Loss: 0.0208
Validation Loss: 1.0367
Epoch [7/50], Class Loss: 0.2754, CORAL Loss: 0.0192
Validation Loss: 0.0349
Epoch [8/50], Class Loss: 0.2487, CORAL Loss: 0.0175
Validation Loss: 0.1351
Epoch [9/50], Class Loss: 0.7698, CORAL Loss: 0.0115
Validation Loss: 0.5434
Epoch [10/50], Class Loss: 0.4920, CORAL Loss: 0.0310
Validation Loss: 0.2421
Epoch [11/50], Class Loss: 0.3299, CORAL Loss: 0.0333
Validation Loss: 0.2278
Epoch [12/50], Class Loss: 0.3177, CORAL Loss: 0.0330
Validation Loss: 0.2137
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 57.69%, Precision: 58.61%, Recall: 59.52%, F1 Score: 45.58%

Run 2/10
Epoch [1/50], Class Loss: 1.6186, CORAL Loss: 0.0000
Validation Loss: 1.6095
Epoch [2/50], Class Loss: 1.6095, CORAL Loss: 0.0000
Validation Loss: 1.6095
Epoch [3/50], Class Loss: 1.6095, CORAL Loss: 0.0000
Validation Loss: 1.6096
Epoch [4/50], Class Loss: 1.6095, CORAL Loss: 0.0000
Validation Loss: 1.6096
Epoch [5/50], Class Loss: 1.6095, CORAL Loss: 0.0000
Validation Loss: 1.6096
Epoch [6/50], Class Loss: 1.6095, CORAL Loss: 0.0000
Validation Loss: 1.6096
Early stopping!
Source Domain Performance - Accuracy: 19.51%, Precision: 3.90%, Recall: 20.00%, F1 Score: 6.53%
Target Domain Performance - Accuracy: 19.51%, Precision: 3.90%, Recall: 20.00%, F1 Score: 6.53%

Run 3/10
Epoch [1/50], Class Loss: 1.3480, CORAL Loss: 0.0115
Validation Loss: 1.0531
Epoch [2/50], Class Loss: 0.6345, CORAL Loss: 0.0361
Validation Loss: 0.7061
Epoch [3/50], Class Loss: 5.5545, CORAL Loss: 0.4543
Validation Loss: 1.6105
Epoch [4/50], Class Loss: 1.6101, CORAL Loss: 0.0028
Validation Loss: 1.6100
Epoch [5/50], Class Loss: 1.6098, CORAL Loss: 0.0027
Validation Loss: 1.6097
Epoch [6/50], Class Loss: 1.6096, CORAL Loss: 0.0025
Validation Loss: 1.6097
Epoch [7/50], Class Loss: 1.6095, CORAL Loss: 0.0026
Validation Loss: 1.6096
Early stopping!
Source Domain Performance - Accuracy: 19.51%, Precision: 3.90%, Recall: 20.00%, F1 Score: 6.53%
Target Domain Performance - Accuracy: 19.51%, Precision: 3.90%, Recall: 20.00%, F1 Score: 6.53%

Run 4/10
Epoch [1/50], Class Loss: 1.4103, CORAL Loss: 0.0043
Validation Loss: 0.7695
Epoch [2/50], Class Loss: 0.6431, CORAL Loss: 0.0313
Validation Loss: 0.2592
Epoch [3/50], Class Loss: 0.4239, CORAL Loss: 0.0202
Validation Loss: 0.3478
Epoch [4/50], Class Loss: 0.2178, CORAL Loss: 0.0118
Validation Loss: 0.1187
Epoch [5/50], Class Loss: 0.3621, CORAL Loss: 0.0177
Validation Loss: 0.3565
Epoch [6/50], Class Loss: 0.3146, CORAL Loss: 0.0184
Validation Loss: 0.0930
Epoch [7/50], Class Loss: 0.3491, CORAL Loss: 0.0136
Validation Loss: 0.6836
Epoch [8/50], Class Loss: 0.1622, CORAL Loss: 0.0182
Validation Loss: 0.0195
Epoch [9/50], Class Loss: 0.2778, CORAL Loss: 0.0079
Validation Loss: 0.0107
Epoch [10/50], Class Loss: 0.0640, CORAL Loss: 0.0078
Validation Loss: 0.0176
Epoch [11/50], Class Loss: 0.0152, CORAL Loss: 0.0125
Validation Loss: 0.0106
Epoch [12/50], Class Loss: 0.0115, CORAL Loss: 0.0096
Validation Loss: 0.0086
Epoch [13/50], Class Loss: 0.0097, CORAL Loss: 0.0077
Validation Loss: 0.0073
Epoch [14/50], Class Loss: 0.0085, CORAL Loss: 0.0064
Validation Loss: 0.0066
Epoch [15/50], Class Loss: 0.0078, CORAL Loss: 0.0053
Validation Loss: 0.0056
Epoch [16/50], Class Loss: 0.0071, CORAL Loss: 0.0045
Validation Loss: 0.0051
Epoch [17/50], Class Loss: 0.0063, CORAL Loss: 0.0040
Validation Loss: 0.0051
Epoch [18/50], Class Loss: 0.0061, CORAL Loss: 0.0034
Validation Loss: 0.0037
Epoch [19/50], Class Loss: 0.0056, CORAL Loss: 0.0030
Validation Loss: 0.0034
Epoch [20/50], Class Loss: 0.0053, CORAL Loss: 0.0026
Validation Loss: 0.0030
Epoch [21/50], Class Loss: 0.0048, CORAL Loss: 0.0025
Validation Loss: 0.0030
Epoch [22/50], Class Loss: 0.0050, CORAL Loss: 0.0024
Validation Loss: 0.0029
Epoch [23/50], Class Loss: 0.0049, CORAL Loss: 0.0024
Validation Loss: 0.0029
Epoch [24/50], Class Loss: 0.0049, CORAL Loss: 0.0024
Validation Loss: 0.0029
Epoch [25/50], Class Loss: 0.0048, CORAL Loss: 0.0024
Validation Loss: 0.0030
Epoch [26/50], Class Loss: 0.0046, CORAL Loss: 0.0023
Validation Loss: 0.0030
Epoch [27/50], Class Loss: 0.0048, CORAL Loss: 0.0023
Validation Loss: 0.0028
Epoch [28/50], Class Loss: 0.0047, CORAL Loss: 0.0022
Validation Loss: 0.0030
Epoch [29/50], Class Loss: 0.0048, CORAL Loss: 0.0022
Validation Loss: 0.0028
Epoch [30/50], Class Loss: 0.0047, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [31/50], Class Loss: 0.0045, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [32/50], Class Loss: 0.0046, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [33/50], Class Loss: 0.0047, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [34/50], Class Loss: 0.0047, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [35/50], Class Loss: 0.0047, CORAL Loss: 0.0021
Validation Loss: 0.0026
Epoch [36/50], Class Loss: 0.0048, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [37/50], Class Loss: 0.0046, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [38/50], Class Loss: 0.0046, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [39/50], Class Loss: 0.0045, CORAL Loss: 0.0021
Validation Loss: 0.0026
Epoch [40/50], Class Loss: 0.0045, CORAL Loss: 0.0020
Validation Loss: 0.0027
Epoch [41/50], Class Loss: 0.0047, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [42/50], Class Loss: 0.0046, CORAL Loss: 0.0020
Validation Loss: 0.0027
Epoch [43/50], Class Loss: 0.0045, CORAL Loss: 0.0021
Validation Loss: 0.0027
Epoch [44/50], Class Loss: 0.0044, CORAL Loss: 0.0021
Validation Loss: 0.0027
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 57.79%, Precision: 58.72%, Recall: 59.62%, F1 Score: 45.63%

Run 5/10
Epoch [1/50], Class Loss: 1.4452, CORAL Loss: 0.0055
Validation Loss: 1.0843
Epoch [2/50], Class Loss: 0.6116, CORAL Loss: 0.0318
Validation Loss: 0.2806
Epoch [3/50], Class Loss: 0.3155, CORAL Loss: 0.0190
Validation Loss: 0.4238
Epoch [4/50], Class Loss: 0.2675, CORAL Loss: 0.0089
Validation Loss: 0.0675
Epoch [5/50], Class Loss: 0.2731, CORAL Loss: 0.0107
Validation Loss: 0.0561
Epoch [6/50], Class Loss: 0.0875, CORAL Loss: 0.0075
Validation Loss: 0.0049
Epoch [7/50], Class Loss: 0.2699, CORAL Loss: 0.0063
Validation Loss: 0.2599
Epoch [8/50], Class Loss: 0.1832, CORAL Loss: 0.0111
Validation Loss: 0.0713
Epoch [9/50], Class Loss: 0.0169, CORAL Loss: 0.0066
Validation Loss: 0.0040
Epoch [10/50], Class Loss: 0.1705, CORAL Loss: 0.0069
Validation Loss: 0.1081
Epoch [11/50], Class Loss: 0.0822, CORAL Loss: 0.0089
Validation Loss: 0.0470
Epoch [12/50], Class Loss: 0.0397, CORAL Loss: 0.0083
Validation Loss: 0.0230
Epoch [13/50], Class Loss: 0.0222, CORAL Loss: 0.0073
Validation Loss: 0.0149
Epoch [14/50], Class Loss: 0.0151, CORAL Loss: 0.0063
Validation Loss: 0.0109
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 57.79%, Precision: 58.72%, Recall: 59.62%, F1 Score: 45.63%

Run 6/10
Epoch [1/50], Class Loss: 1.4286, CORAL Loss: 0.0077
Validation Loss: 0.5599
Epoch [2/50], Class Loss: 0.7186, CORAL Loss: 0.0326
Validation Loss: 0.4025
Epoch [3/50], Class Loss: 1.0812, CORAL Loss: 0.6816
Validation Loss: 1.1126
Epoch [4/50], Class Loss: 0.8798, CORAL Loss: 0.0227
Validation Loss: 0.7276
Epoch [5/50], Class Loss: 0.5957, CORAL Loss: 0.0469
Validation Loss: 0.3709
Epoch [6/50], Class Loss: 0.4375, CORAL Loss: 0.0467
Validation Loss: 0.2520
Epoch [7/50], Class Loss: 0.4449, CORAL Loss: 0.0326
Validation Loss: 0.4267
Epoch [8/50], Class Loss: 0.3970, CORAL Loss: 0.0211
Validation Loss: 0.2121
Epoch [9/50], Class Loss: 0.2956, CORAL Loss: 0.0191
Validation Loss: 0.1042
Epoch [10/50], Class Loss: 0.2573, CORAL Loss: 0.0171
Validation Loss: 0.1667
Epoch [11/50], Class Loss: 0.0825, CORAL Loss: 0.0106
Validation Loss: 0.0388
Epoch [12/50], Class Loss: 0.0382, CORAL Loss: 0.0113
Validation Loss: 0.0237
Epoch [13/50], Class Loss: 0.0258, CORAL Loss: 0.0117
Validation Loss: 0.0186
Epoch [14/50], Class Loss: 0.0217, CORAL Loss: 0.0114
Validation Loss: 0.0169
Epoch [15/50], Class Loss: 0.0186, CORAL Loss: 0.0108
Validation Loss: 0.0136
Epoch [16/50], Class Loss: 0.0183, CORAL Loss: 0.0106
Validation Loss: 0.0150
Epoch [17/50], Class Loss: 0.0166, CORAL Loss: 0.0101
Validation Loss: 0.0083
Epoch [18/50], Class Loss: 0.0167, CORAL Loss: 0.0095
Validation Loss: 0.0187
Epoch [19/50], Class Loss: 0.0148, CORAL Loss: 0.0095
Validation Loss: 0.0118
Epoch [20/50], Class Loss: 0.0146, CORAL Loss: 0.0088
Validation Loss: 0.0143
Epoch [21/50], Class Loss: 0.0137, CORAL Loss: 0.0080
Validation Loss: 0.0102
Epoch [22/50], Class Loss: 0.0124, CORAL Loss: 0.0080
Validation Loss: 0.0093
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 58.03%, Precision: 58.98%, Recall: 59.87%, F1 Score: 45.92%

Run 7/10
Epoch [1/50], Class Loss: 1.3557, CORAL Loss: 0.0101
Validation Loss: 1.0795
Epoch [2/50], Class Loss: 0.6823, CORAL Loss: 0.0314
Validation Loss: 0.2797
Epoch [3/50], Class Loss: 1.2095, CORAL Loss: 187.1191
Validation Loss: 1.6254
Epoch [4/50], Class Loss: 1.1673, CORAL Loss: 0.0000
Validation Loss: 0.8618
Epoch [5/50], Class Loss: 0.9332, CORAL Loss: 0.0001
Validation Loss: 0.7788
Epoch [6/50], Class Loss: 0.8614, CORAL Loss: 0.0003
Validation Loss: 0.6329
Epoch [7/50], Class Loss: 0.8105, CORAL Loss: 0.0007
Validation Loss: 0.5833
Early stopping!
Source Domain Performance - Accuracy: 80.27%, Precision: 69.87%, Recall: 79.93%, F1 Score: 73.22%
Target Domain Performance - Accuracy: 25.37%, Precision: 23.06%, Recall: 26.04%, F1 Score: 13.57%

Run 8/10
Epoch [1/50], Class Loss: 1.5837, CORAL Loss: 0.0039
Validation Loss: 1.1075
Epoch [2/50], Class Loss: 0.5836, CORAL Loss: 0.0494
Validation Loss: 0.3065
Epoch [3/50], Class Loss: 0.4627, CORAL Loss: 0.0270
Validation Loss: 0.2220
Epoch [4/50], Class Loss: 0.2431, CORAL Loss: 0.0211
Validation Loss: 0.0871
Epoch [5/50], Class Loss: 0.3608, CORAL Loss: 0.0166
Validation Loss: 0.1113
Epoch [6/50], Class Loss: 0.1378, CORAL Loss: 0.0155
Validation Loss: 0.0216
Epoch [7/50], Class Loss: 0.2068, CORAL Loss: 0.0159
Validation Loss: 0.0424
Epoch [8/50], Class Loss: 0.1708, CORAL Loss: 0.0103
Validation Loss: 0.2438
Epoch [9/50], Class Loss: 0.0532, CORAL Loss: 0.0095
Validation Loss: 0.0112
Epoch [10/50], Class Loss: 0.0094, CORAL Loss: 0.0056
Validation Loss: 0.0051
Epoch [11/50], Class Loss: 0.0069, CORAL Loss: 0.0041
Validation Loss: 0.0035
Epoch [12/50], Class Loss: 0.0066, CORAL Loss: 0.0041
Validation Loss: 0.0033
Epoch [13/50], Class Loss: 0.0065, CORAL Loss: 0.0039
Validation Loss: 0.0031
Epoch [14/50], Class Loss: 0.0063, CORAL Loss: 0.0038
Validation Loss: 0.0031
Epoch [15/50], Class Loss: 0.0062, CORAL Loss: 0.0037
Validation Loss: 0.0030
Epoch [16/50], Class Loss: 0.0060, CORAL Loss: 0.0035
Validation Loss: 0.0027
Epoch [17/50], Class Loss: 0.0058, CORAL Loss: 0.0034
Validation Loss: 0.0024
Epoch [18/50], Class Loss: 0.0057, CORAL Loss: 0.0033
Validation Loss: 0.0032
Epoch [19/50], Class Loss: 0.0055, CORAL Loss: 0.0031
Validation Loss: 0.0024
Epoch [20/50], Class Loss: 0.0057, CORAL Loss: 0.0030
Validation Loss: 0.0019
Epoch [21/50], Class Loss: 0.0048, CORAL Loss: 0.0028
Validation Loss: 0.0019
Epoch [22/50], Class Loss: 0.0050, CORAL Loss: 0.0027
Validation Loss: 0.0018
Epoch [23/50], Class Loss: 0.0049, CORAL Loss: 0.0027
Validation Loss: 0.0018
Epoch [24/50], Class Loss: 0.0049, CORAL Loss: 0.0027
Validation Loss: 0.0019
Epoch [25/50], Class Loss: 0.0052, CORAL Loss: 0.0027
Validation Loss: 0.0019
Epoch [26/50], Class Loss: 0.0048, CORAL Loss: 0.0026
Validation Loss: 0.0017
Epoch [27/50], Class Loss: 0.0048, CORAL Loss: 0.0027
Validation Loss: 0.0019
Epoch [28/50], Class Loss: 0.0048, CORAL Loss: 0.0026
Validation Loss: 0.0017
Epoch [29/50], Class Loss: 0.0049, CORAL Loss: 0.0026
Validation Loss: 0.0018
Epoch [30/50], Class Loss: 0.0048, CORAL Loss: 0.0026
Validation Loss: 0.0018
Epoch [31/50], Class Loss: 0.0046, CORAL Loss: 0.0025
Validation Loss: 0.0017
Epoch [32/50], Class Loss: 0.0049, CORAL Loss: 0.0025
Validation Loss: 0.0017
Epoch [33/50], Class Loss: 0.0045, CORAL Loss: 0.0025
Validation Loss: 0.0017
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.98%, F1 Score: 99.98%
Target Domain Performance - Accuracy: 57.96%, Precision: 58.93%, Recall: 59.80%, F1 Score: 45.79%

Run 9/10
Epoch [1/50], Class Loss: 1.3729, CORAL Loss: 0.0047
Validation Loss: 0.6721
Epoch [2/50], Class Loss: 0.6810, CORAL Loss: 0.0254
Validation Loss: 0.2763
Epoch [3/50], Class Loss: 0.4118, CORAL Loss: 0.0255
Validation Loss: 0.2096
Epoch [4/50], Class Loss: 0.3962, CORAL Loss: 0.0185
Validation Loss: 0.2007
Epoch [5/50], Class Loss: 0.2705, CORAL Loss: 0.0139
Validation Loss: 0.1516
Epoch [6/50], Class Loss: 9.9532, CORAL Loss: 20.7317
Validation Loss: 1.6125
Epoch [7/50], Class Loss: 1.6113, CORAL Loss: 0.0103
Validation Loss: 1.6103
Epoch [8/50], Class Loss: 1.6100, CORAL Loss: 0.0109
Validation Loss: 1.6098
Epoch [9/50], Class Loss: 1.6097, CORAL Loss: 0.0108
Validation Loss: 1.6096
Epoch [10/50], Class Loss: 1.6095, CORAL Loss: 0.0095
Validation Loss: 1.6096
Early stopping!
Source Domain Performance - Accuracy: 19.73%, Precision: 3.95%, Recall: 20.00%, F1 Score: 6.59%
Target Domain Performance - Accuracy: 20.65%, Precision: 4.13%, Recall: 20.00%, F1 Score: 6.85%

Run 10/10
Epoch [1/50], Class Loss: 1.5783, CORAL Loss: 0.0031
Validation Loss: 1.0869
Epoch [2/50], Class Loss: 1.0463, CORAL Loss: 0.3019
Validation Loss: 1.2678
Epoch [3/50], Class Loss: 0.7805, CORAL Loss: 0.0256
Validation Loss: 1.2820
Epoch [4/50], Class Loss: 0.5073, CORAL Loss: 0.0386
Validation Loss: 0.2737
Epoch [5/50], Class Loss: 0.3303, CORAL Loss: 0.0351
Validation Loss: 0.3333
Epoch [6/50], Class Loss: 0.3019, CORAL Loss: 0.0206
Validation Loss: 0.0689
Epoch [7/50], Class Loss: 0.3010, CORAL Loss: 0.0166
Validation Loss: 0.1447
Epoch [8/50], Class Loss: 0.0560, CORAL Loss: 0.0104
Validation Loss: 0.0144
Epoch [9/50], Class Loss: 0.1887, CORAL Loss: 0.0146
Validation Loss: 0.0060
Epoch [10/50], Class Loss: 0.0109, CORAL Loss: 0.0055
Validation Loss: 0.0346
Epoch [11/50], Class Loss: 0.0091, CORAL Loss: 0.0053
Validation Loss: 0.0058
Epoch [12/50], Class Loss: 0.0079, CORAL Loss: 0.0049
Validation Loss: 0.0056
Epoch [13/50], Class Loss: 0.0077, CORAL Loss: 0.0046
Validation Loss: 0.0131
Epoch [14/50], Class Loss: 0.0075, CORAL Loss: 0.0044
Validation Loss: 0.0062
Epoch [15/50], Class Loss: 0.0079, CORAL Loss: 0.0042
Validation Loss: 0.0046
Epoch [16/50], Class Loss: 0.0074, CORAL Loss: 0.0041
Validation Loss: 0.0054
Epoch [17/50], Class Loss: 0.0076, CORAL Loss: 0.0040
Validation Loss: 0.0090
Epoch [18/50], Class Loss: 0.0075, CORAL Loss: 0.0038
Validation Loss: 0.0036
Epoch [19/50], Class Loss: 0.0080, CORAL Loss: 0.0038
Validation Loss: 0.0042
Epoch [20/50], Class Loss: 0.0077, CORAL Loss: 0.0035
Validation Loss: 0.0045
Epoch [21/50], Class Loss: 0.0068, CORAL Loss: 0.0035
Validation Loss: 0.0054
Epoch [22/50], Class Loss: 0.0064, CORAL Loss: 0.0035
Validation Loss: 0.0056
Epoch [23/50], Class Loss: 0.0065, CORAL Loss: 0.0034
Validation Loss: 0.0061
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.86%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 58.15%, Precision: 59.13%, Recall: 60.00%, F1 Score: 46.04%

Source performance: 73.85% 68.11% 73.94% 69.23%
Target performance: 43.24% 38.81% 44.45% 30.81%

Per-Class Accuracy on Target Domain:
bpsk: 59.92%
qpsk: 62.18%
4qam: 89.97%
16qam: 10.15%
apsk: 0.00%

Run 1/10
Epoch [1/50], Class Loss: 1.5438, JMMD Loss: 0.1894
Validation Loss: 0.8991
Epoch [2/50], Class Loss: 0.9205, JMMD Loss: 0.4994
Validation Loss: 0.2320
Epoch [3/50], Class Loss: 0.4249, JMMD Loss: 0.5317
Validation Loss: 0.5919
Epoch [4/50], Class Loss: 0.2429, JMMD Loss: 0.5094
Validation Loss: 0.5636
Epoch [5/50], Class Loss: 0.2173, JMMD Loss: 0.5299
Validation Loss: 0.2083
Epoch [6/50], Class Loss: 0.1357, JMMD Loss: 0.5266
Validation Loss: 0.0577
Epoch [7/50], Class Loss: 0.0385, JMMD Loss: 0.5637
Validation Loss: 0.0200
Epoch [8/50], Class Loss: 0.1687, JMMD Loss: 0.5630
Validation Loss: 0.1037
Epoch [9/50], Class Loss: 0.0331, JMMD Loss: 0.5453
Validation Loss: 0.1203
Epoch [10/50], Class Loss: 0.1895, JMMD Loss: 0.4651
Validation Loss: 0.0500
Epoch [11/50], Class Loss: 0.0232, JMMD Loss: 0.4953
Validation Loss: 0.0186
Epoch [12/50], Class Loss: 0.0190, JMMD Loss: 0.4996
Validation Loss: 0.0178
Epoch [13/50], Class Loss: 0.0167, JMMD Loss: 0.4966
Validation Loss: 0.0167
Epoch [14/50], Class Loss: 0.0147, JMMD Loss: 0.4956
Validation Loss: 0.0145
Epoch [15/50], Class Loss: 0.0130, JMMD Loss: 0.4928
Validation Loss: 0.0134
Epoch [16/50], Class Loss: 0.0117, JMMD Loss: 0.4931
Validation Loss: 0.0141
Epoch [17/50], Class Loss: 0.0104, JMMD Loss: 0.4719
Validation Loss: 0.0129
Epoch [18/50], Class Loss: 0.0094, JMMD Loss: 0.4707
Validation Loss: 0.0133
Epoch [19/50], Class Loss: 0.0087, JMMD Loss: 0.4489
Validation Loss: 0.0138
Epoch [20/50], Class Loss: 0.0082, JMMD Loss: 0.4422
Validation Loss: 0.0127
Epoch [21/50], Class Loss: 0.0076, JMMD Loss: 0.4436
Validation Loss: 0.0123
Epoch [22/50], Class Loss: 0.0069, JMMD Loss: 0.4409
Validation Loss: 0.0123
Epoch [23/50], Class Loss: 0.0074, JMMD Loss: 0.4425
Validation Loss: 0.0124
Epoch [24/50], Class Loss: 0.0076, JMMD Loss: 0.4376
Validation Loss: 0.0124
Epoch [25/50], Class Loss: 0.0071, JMMD Loss: 0.4380
Validation Loss: 0.0124
Epoch [26/50], Class Loss: 0.0070, JMMD Loss: 0.4367
Validation Loss: 0.0125
Epoch [27/50], Class Loss: 0.0072, JMMD Loss: 0.4287
Validation Loss: 0.0124
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 58.08%, Precision: 59.13%, Recall: 59.92%, F1 Score: 45.92%

Run 2/10
Epoch [1/50], Class Loss: 1.6016, JMMD Loss: 0.1918
Validation Loss: 1.1623
Epoch [2/50], Class Loss: 1.0750, JMMD Loss: 0.5420
Validation Loss: 0.7558
Epoch [3/50], Class Loss: 0.7260, JMMD Loss: 0.4997
Validation Loss: 0.6470
Epoch [4/50], Class Loss: 0.3602, JMMD Loss: 0.5394
Validation Loss: 0.1270
Epoch [5/50], Class Loss: 0.1599, JMMD Loss: 0.6071
Validation Loss: 3.1393
Epoch [6/50], Class Loss: 0.3359, JMMD Loss: 0.5754
Validation Loss: 0.0427
Epoch [7/50], Class Loss: 0.2495, JMMD Loss: 0.6222
Validation Loss: 0.0558
Epoch [8/50], Class Loss: 0.2718, JMMD Loss: 0.6151
Validation Loss: 0.0528
Epoch [9/50], Class Loss: 0.0465, JMMD Loss: 0.6764
Validation Loss: 0.0237
Epoch [10/50], Class Loss: 0.0192, JMMD Loss: 0.7219
Validation Loss: 0.0116
Epoch [11/50], Class Loss: 0.0121, JMMD Loss: 0.7243
Validation Loss: 0.0092
Epoch [12/50], Class Loss: 0.0119, JMMD Loss: 0.7185
Validation Loss: 0.0091
Epoch [13/50], Class Loss: 0.0116, JMMD Loss: 0.7234
Validation Loss: 0.0094
Epoch [14/50], Class Loss: 0.0119, JMMD Loss: 0.7249
Validation Loss: 0.0103
Epoch [15/50], Class Loss: 0.0119, JMMD Loss: 0.7217
Validation Loss: 0.0095
Epoch [16/50], Class Loss: 0.0118, JMMD Loss: 0.7265
Validation Loss: 0.0091
Epoch [17/50], Class Loss: 0.0116, JMMD Loss: 0.7293
Validation Loss: 0.0091
Epoch [18/50], Class Loss: 0.0115, JMMD Loss: 0.7305
Validation Loss: 0.0091
Epoch [19/50], Class Loss: 0.0113, JMMD Loss: 0.7332
Validation Loss: 0.0127
Epoch [20/50], Class Loss: 0.0108, JMMD Loss: 0.7314
Validation Loss: 0.0090
Epoch [21/50], Class Loss: 0.0103, JMMD Loss: 0.7326
Validation Loss: 0.0086
Epoch [22/50], Class Loss: 0.0103, JMMD Loss: 0.7296
Validation Loss: 0.0086
Epoch [23/50], Class Loss: 0.0101, JMMD Loss: 0.7293
Validation Loss: 0.0086
Epoch [24/50], Class Loss: 0.0101, JMMD Loss: 0.7301
Validation Loss: 0.0085
Epoch [25/50], Class Loss: 0.0102, JMMD Loss: 0.7333
Validation Loss: 0.0084
Epoch [26/50], Class Loss: 0.0100, JMMD Loss: 0.7343
Validation Loss: 0.0086
Epoch [27/50], Class Loss: 0.0102, JMMD Loss: 0.7350
Validation Loss: 0.0087
Epoch [28/50], Class Loss: 0.0100, JMMD Loss: 0.7321
Validation Loss: 0.0084
Epoch [29/50], Class Loss: 0.0099, JMMD Loss: 0.7333
Validation Loss: 0.0085
Epoch [30/50], Class Loss: 0.0099, JMMD Loss: 0.7366
Validation Loss: 0.0084
Epoch [31/50], Class Loss: 0.0099, JMMD Loss: 0.7343
Validation Loss: 0.0083
Epoch [32/50], Class Loss: 0.0097, JMMD Loss: 0.7317
Validation Loss: 0.0083
Epoch [33/50], Class Loss: 0.0098, JMMD Loss: 0.7321
Validation Loss: 0.0083
Epoch [34/50], Class Loss: 0.0096, JMMD Loss: 0.7311
Validation Loss: 0.0083
Epoch [35/50], Class Loss: 0.0098, JMMD Loss: 0.7353
Validation Loss: 0.0083
Epoch [36/50], Class Loss: 0.0101, JMMD Loss: 0.7344
Validation Loss: 0.0084
Epoch [37/50], Class Loss: 0.0096, JMMD Loss: 0.7354
Validation Loss: 0.0083
Epoch [38/50], Class Loss: 0.0099, JMMD Loss: 0.7320
Validation Loss: 0.0082
Epoch [39/50], Class Loss: 0.0095, JMMD Loss: 0.7404
Validation Loss: 0.0083
Epoch [40/50], Class Loss: 0.0097, JMMD Loss: 0.7358
Validation Loss: 0.0083
Epoch [41/50], Class Loss: 0.0095, JMMD Loss: 0.7322
Validation Loss: 0.0083
Epoch [42/50], Class Loss: 0.0095, JMMD Loss: 0.7324
Validation Loss: 0.0082
Epoch [43/50], Class Loss: 0.0098, JMMD Loss: 0.7380
Validation Loss: 0.0082
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 55.66%, Precision: 56.26%, Recall: 57.43%, F1 Score: 43.61%

Run 3/10
Epoch [1/50], Class Loss: 1.5341, JMMD Loss: 0.2505
Validation Loss: 1.2704
Epoch [2/50], Class Loss: 0.7972, JMMD Loss: 0.5268
Validation Loss: 0.2189
Epoch [3/50], Class Loss: 0.4922, JMMD Loss: 0.5235
Validation Loss: 0.2464
Epoch [4/50], Class Loss: 0.2059, JMMD Loss: 0.5346
Validation Loss: 0.0765
Epoch [5/50], Class Loss: 0.2150, JMMD Loss: 0.5405
Validation Loss: 0.1364
Epoch [6/50], Class Loss: 0.1326, JMMD Loss: 0.5786
Validation Loss: 0.0198
Epoch [7/50], Class Loss: 0.1697, JMMD Loss: 0.6160
Validation Loss: 0.0445
Epoch [8/50], Class Loss: 0.2723, JMMD Loss: 0.5673
Validation Loss: 0.0348
Epoch [9/50], Class Loss: 0.0737, JMMD Loss: 0.6009
Validation Loss: 0.0116
Epoch [10/50], Class Loss: 0.0125, JMMD Loss: 0.6026
Validation Loss: 0.0140
Epoch [11/50], Class Loss: 0.0080, JMMD Loss: 0.5888
Validation Loss: 0.0073
Epoch [12/50], Class Loss: 0.0067, JMMD Loss: 0.5847
Validation Loss: 0.0059
Epoch [13/50], Class Loss: 0.0072, JMMD Loss: 0.5721
Validation Loss: 0.0062
Epoch [14/50], Class Loss: 0.0068, JMMD Loss: 0.5598
Validation Loss: 0.0069
Epoch [15/50], Class Loss: 0.0066, JMMD Loss: 0.5575
Validation Loss: 0.0059
Epoch [16/50], Class Loss: 0.0058, JMMD Loss: 0.5507
Validation Loss: 0.0062
Epoch [17/50], Class Loss: 0.0063, JMMD Loss: 0.5479
Validation Loss: 0.0059
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 58.06%, Precision: 59.10%, Recall: 59.90%, F1 Score: 45.90%

Run 4/10
Epoch [1/50], Class Loss: 1.5522, JMMD Loss: 0.2194
Validation Loss: 0.8670
Epoch [2/50], Class Loss: 0.7418, JMMD Loss: 0.6259
Validation Loss: 0.2401
Epoch [3/50], Class Loss: 0.4791, JMMD Loss: 0.6271
Validation Loss: 0.1620
Epoch [4/50], Class Loss: 0.2436, JMMD Loss: 0.6181
Validation Loss: 0.2052
Epoch [5/50], Class Loss: 0.2588, JMMD Loss: 0.6474
Validation Loss: 0.4299
Epoch [6/50], Class Loss: 0.1810, JMMD Loss: 0.6415
Validation Loss: 0.1086
Epoch [7/50], Class Loss: 0.0719, JMMD Loss: 0.6280
Validation Loss: 0.0285
Epoch [8/50], Class Loss: 0.2121, JMMD Loss: 0.6252
Validation Loss: 0.0277
Epoch [9/50], Class Loss: 0.0686, JMMD Loss: 0.6081
Validation Loss: 0.3420
Epoch [10/50], Class Loss: 0.0392, JMMD Loss: 0.5616
Validation Loss: 0.0248
Epoch [11/50], Class Loss: 0.0093, JMMD Loss: 0.5256
Validation Loss: 0.0059
Epoch [12/50], Class Loss: 0.0078, JMMD Loss: 0.5213
Validation Loss: 0.0059
Epoch [13/50], Class Loss: 0.0072, JMMD Loss: 0.4975
Validation Loss: 0.0057
Epoch [14/50], Class Loss: 0.0067, JMMD Loss: 0.4632
Validation Loss: 0.0069
Epoch [15/50], Class Loss: 0.0067, JMMD Loss: 0.4122
Validation Loss: 0.0083
Epoch [16/50], Class Loss: 0.0070, JMMD Loss: 0.3710
Validation Loss: 0.0078
Epoch [17/50], Class Loss: 0.0064, JMMD Loss: 0.3472
Validation Loss: 0.0054
Epoch [18/50], Class Loss: 0.0066, JMMD Loss: 0.3348
Validation Loss: 0.0062
Epoch [19/50], Class Loss: 0.0066, JMMD Loss: 0.3252
Validation Loss: 0.0078
Epoch [20/50], Class Loss: 0.0066, JMMD Loss: 0.3171
Validation Loss: 0.0071
Epoch [21/50], Class Loss: 0.0059, JMMD Loss: 0.3250
Validation Loss: 0.0068
Epoch [22/50], Class Loss: 0.0054, JMMD Loss: 0.3221
Validation Loss: 0.0068
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.98%, F1 Score: 99.98%
Target Domain Performance - Accuracy: 58.13%, Precision: 59.17%, Recall: 59.97%, F1 Score: 45.96%

Run 5/10
Epoch [1/50], Class Loss: 1.5892, JMMD Loss: 0.2165
Validation Loss: 1.4717
Epoch [2/50], Class Loss: 0.8867, JMMD Loss: 0.6384
Validation Loss: 0.4594
Epoch [3/50], Class Loss: 0.3901, JMMD Loss: 0.6100
Validation Loss: 0.5768
Epoch [4/50], Class Loss: 0.2577, JMMD Loss: 0.5816
Validation Loss: 0.1143
Epoch [5/50], Class Loss: 0.1773, JMMD Loss: 0.5864
Validation Loss: 0.1249
Epoch [6/50], Class Loss: 0.0619, JMMD Loss: 0.6000
Validation Loss: 0.0161
Epoch [7/50], Class Loss: 0.0888, JMMD Loss: 0.5958
Validation Loss: 0.0536
Epoch [8/50], Class Loss: 0.1085, JMMD Loss: 0.5898
Validation Loss: 0.0590
Epoch [9/50], Class Loss: 0.2927, JMMD Loss: 0.5635
Validation Loss: 0.1118
Epoch [10/50], Class Loss: 0.0357, JMMD Loss: 0.5720
Validation Loss: 0.0089
Epoch [11/50], Class Loss: 0.0096, JMMD Loss: 0.5594
Validation Loss: 0.0075
Epoch [12/50], Class Loss: 0.0087, JMMD Loss: 0.5385
Validation Loss: 0.0073
Epoch [13/50], Class Loss: 0.0079, JMMD Loss: 0.5368
Validation Loss: 0.0079
Epoch [14/50], Class Loss: 0.0075, JMMD Loss: 0.5274
Validation Loss: 0.0079
Epoch [15/50], Class Loss: 0.0072, JMMD Loss: 0.5183
Validation Loss: 0.0078
Epoch [16/50], Class Loss: 0.0075, JMMD Loss: 0.5219
Validation Loss: 0.0076
Epoch [17/50], Class Loss: 0.0070, JMMD Loss: 0.5109
Validation Loss: 0.0090
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 58.11%, Precision: 59.16%, Recall: 59.95%, F1 Score: 45.95%

Run 6/10
Epoch [1/50], Class Loss: 1.6299, JMMD Loss: 0.2245
Validation Loss: 1.4785
Epoch [2/50], Class Loss: 1.0016, JMMD Loss: 0.5749
Validation Loss: 0.2988
Epoch [3/50], Class Loss: 0.3580, JMMD Loss: 0.5915
Validation Loss: 0.2628
Epoch [4/50], Class Loss: 0.2095, JMMD Loss: 0.6534
Validation Loss: 0.1313
Epoch [5/50], Class Loss: 0.4104, JMMD Loss: 0.6218
Validation Loss: 0.3380
Epoch [6/50], Class Loss: 0.1433, JMMD Loss: 0.6550
Validation Loss: 0.0221
Epoch [7/50], Class Loss: 0.1249, JMMD Loss: 0.6803
Validation Loss: 0.0150
Epoch [8/50], Class Loss: 0.1028, JMMD Loss: 0.6874
Validation Loss: 0.0204
Epoch [9/50], Class Loss: 0.0144, JMMD Loss: 0.6756
Validation Loss: 0.0115
Epoch [10/50], Class Loss: 0.1973, JMMD Loss: 0.6328
Validation Loss: 0.0596
Epoch [11/50], Class Loss: 0.0489, JMMD Loss: 0.6417
Validation Loss: 0.0286
Epoch [12/50], Class Loss: 0.0316, JMMD Loss: 0.6462
Validation Loss: 0.0175
Epoch [13/50], Class Loss: 0.0226, JMMD Loss: 0.6343
Validation Loss: 0.0120
Epoch [14/50], Class Loss: 0.0173, JMMD Loss: 0.6255
Validation Loss: 0.0089
Epoch [15/50], Class Loss: 0.0140, JMMD Loss: 0.6114
Validation Loss: 0.0077
Epoch [16/50], Class Loss: 0.0118, JMMD Loss: 0.6124
Validation Loss: 0.0060
Epoch [17/50], Class Loss: 0.0104, JMMD Loss: 0.5940
Validation Loss: 0.0054
Epoch [18/50], Class Loss: 0.0091, JMMD Loss: 0.5811
Validation Loss: 0.0050
Epoch [19/50], Class Loss: 0.0089, JMMD Loss: 0.5761
Validation Loss: 0.0048
Epoch [20/50], Class Loss: 0.0078, JMMD Loss: 0.5613
Validation Loss: 0.0046
Epoch [21/50], Class Loss: 0.0073, JMMD Loss: 0.5563
Validation Loss: 0.0042
Epoch [22/50], Class Loss: 0.0071, JMMD Loss: 0.5553
Validation Loss: 0.0042
Epoch [23/50], Class Loss: 0.0073, JMMD Loss: 0.5538
Validation Loss: 0.0042
Epoch [24/50], Class Loss: 0.0070, JMMD Loss: 0.5473
Validation Loss: 0.0041
Epoch [25/50], Class Loss: 0.0071, JMMD Loss: 0.5524
Validation Loss: 0.0041
Epoch [26/50], Class Loss: 0.0070, JMMD Loss: 0.5493
Validation Loss: 0.0041
Epoch [27/50], Class Loss: 0.0071, JMMD Loss: 0.5466
Validation Loss: 0.0041
Epoch [28/50], Class Loss: 0.0071, JMMD Loss: 0.5438
Validation Loss: 0.0040
Epoch [29/50], Class Loss: 0.0069, JMMD Loss: 0.5393
Validation Loss: 0.0040
Epoch [30/50], Class Loss: 0.0071, JMMD Loss: 0.5390
Validation Loss: 0.0045
Epoch [31/50], Class Loss: 0.0069, JMMD Loss: 0.5378
Validation Loss: 0.0040
Epoch [32/50], Class Loss: 0.0067, JMMD Loss: 0.5402
Validation Loss: 0.0039
Epoch [33/50], Class Loss: 0.0064, JMMD Loss: 0.5388
Validation Loss: 0.0040
Epoch [34/50], Class Loss: 0.0068, JMMD Loss: 0.5394
Validation Loss: 0.0040
Epoch [35/50], Class Loss: 0.0065, JMMD Loss: 0.5372
Validation Loss: 0.0040
Epoch [36/50], Class Loss: 0.0068, JMMD Loss: 0.5411
Validation Loss: 0.0040
Epoch [37/50], Class Loss: 0.0066, JMMD Loss: 0.5368
Validation Loss: 0.0040
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 58.11%, Precision: 59.14%, Recall: 59.95%, F1 Score: 45.94%

Run 7/10
Epoch [1/50], Class Loss: 1.6141, JMMD Loss: 0.0845
Validation Loss: 1.6068
Epoch [2/50], Class Loss: 1.5867, JMMD Loss: 0.2153
Validation Loss: 1.6099
Epoch [3/50], Class Loss: 1.6099, JMMD Loss: 0.0942
Validation Loss: 1.6095
Epoch [4/50], Class Loss: 1.6096, JMMD Loss: 0.0779
Validation Loss: 1.6096
Epoch [5/50], Class Loss: 1.6095, JMMD Loss: 0.0777
Validation Loss: 1.6095
Epoch [6/50], Class Loss: 1.6095, JMMD Loss: 0.0786
Validation Loss: 1.6096
Early stopping!
Source Domain Performance - Accuracy: 19.63%, Precision: 3.93%, Recall: 19.98%, F1 Score: 6.56%
Target Domain Performance - Accuracy: 19.26%, Precision: 3.85%, Recall: 20.00%, F1 Score: 6.46%

Run 8/10
Epoch [1/50], Class Loss: 1.6236, JMMD Loss: 0.0897
Validation Loss: 1.6052
Epoch [2/50], Class Loss: 1.1793, JMMD Loss: 0.4879
Validation Loss: 0.9891
Epoch [3/50], Class Loss: 0.5671, JMMD Loss: 0.4792
Validation Loss: 0.2134
Epoch [4/50], Class Loss: 0.2592, JMMD Loss: 0.5775
Validation Loss: 0.0912
Epoch [5/50], Class Loss: 0.2837, JMMD Loss: 0.6345
Validation Loss: 0.8651
Epoch [6/50], Class Loss: 0.2081, JMMD Loss: 0.6715
Validation Loss: 0.0389
Epoch [7/50], Class Loss: 0.2251, JMMD Loss: 0.6719
Validation Loss: 0.2298
Epoch [8/50], Class Loss: 0.1205, JMMD Loss: 0.6604
Validation Loss: 0.1907
Epoch [9/50], Class Loss: 0.0564, JMMD Loss: 0.6997
Validation Loss: 0.0164
Epoch [10/50], Class Loss: 0.0506, JMMD Loss: 0.6844
Validation Loss: 0.0192
Epoch [11/50], Class Loss: 0.0194, JMMD Loss: 0.6764
Validation Loss: 0.0147
Epoch [12/50], Class Loss: 0.0161, JMMD Loss: 0.6825
Validation Loss: 0.0132
Epoch [13/50], Class Loss: 0.0135, JMMD Loss: 0.6841
Validation Loss: 0.0119
Epoch [14/50], Class Loss: 0.0114, JMMD Loss: 0.6878
Validation Loss: 0.0110
Epoch [15/50], Class Loss: 0.0107, JMMD Loss: 0.6782
Validation Loss: 0.0107
Epoch [16/50], Class Loss: 0.0097, JMMD Loss: 0.6682
Validation Loss: 0.0098
Epoch [17/50], Class Loss: 0.0093, JMMD Loss: 0.6544
Validation Loss: 0.0089
Epoch [18/50], Class Loss: 0.0084, JMMD Loss: 0.6495
Validation Loss: 0.0082
Epoch [19/50], Class Loss: 0.0080, JMMD Loss: 0.6286
Validation Loss: 0.0080
Epoch [20/50], Class Loss: 0.0077, JMMD Loss: 0.6096
Validation Loss: 0.0069
Epoch [21/50], Class Loss: 0.0071, JMMD Loss: 0.5994
Validation Loss: 0.0067
Epoch [22/50], Class Loss: 0.0066, JMMD Loss: 0.5976
Validation Loss: 0.0066
Epoch [23/50], Class Loss: 0.0068, JMMD Loss: 0.5967
Validation Loss: 0.0064
Epoch [24/50], Class Loss: 0.0065, JMMD Loss: 0.5879
Validation Loss: 0.0064
Epoch [25/50], Class Loss: 0.0068, JMMD Loss: 0.5859
Validation Loss: 0.0063
Epoch [26/50], Class Loss: 0.0065, JMMD Loss: 0.5846
Validation Loss: 0.0062
Epoch [27/50], Class Loss: 0.0065, JMMD Loss: 0.5808
Validation Loss: 0.0062
Epoch [28/50], Class Loss: 0.0067, JMMD Loss: 0.5757
Validation Loss: 0.0060
Epoch [29/50], Class Loss: 0.0064, JMMD Loss: 0.5700
Validation Loss: 0.0060
Epoch [30/50], Class Loss: 0.0067, JMMD Loss: 0.5637
Validation Loss: 0.0059
Epoch [31/50], Class Loss: 0.0065, JMMD Loss: 0.5588
Validation Loss: 0.0059
Epoch [32/50], Class Loss: 0.0069, JMMD Loss: 0.5571
Validation Loss: 0.0060
Epoch [33/50], Class Loss: 0.0068, JMMD Loss: 0.5546
Validation Loss: 0.0059
Epoch [34/50], Class Loss: 0.0070, JMMD Loss: 0.5565
Validation Loss: 0.0059
Epoch [35/50], Class Loss: 0.0067, JMMD Loss: 0.5474
Validation Loss: 0.0060
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 58.11%, Precision: 59.12%, Recall: 59.95%, F1 Score: 45.93%

Run 9/10
Epoch [1/50], Class Loss: 1.6188, JMMD Loss: 0.0795
Validation Loss: 1.6094
Epoch [2/50], Class Loss: 1.6066, JMMD Loss: 0.1268
Validation Loss: 1.6092
Epoch [3/50], Class Loss: 1.2130, JMMD Loss: 0.5562
Validation Loss: 0.6821
Epoch [4/50], Class Loss: 0.3541, JMMD Loss: 0.6759
Validation Loss: 0.2380
Epoch [5/50], Class Loss: 0.2012, JMMD Loss: 0.6559
Validation Loss: 0.1449
Epoch [6/50], Class Loss: 0.1530, JMMD Loss: 0.6599
Validation Loss: 0.0974
Epoch [7/50], Class Loss: 0.0587, JMMD Loss: 0.6994
Validation Loss: 0.0155
Epoch [8/50], Class Loss: 0.2330, JMMD Loss: 0.6519
Validation Loss: 0.0614
Epoch [9/50], Class Loss: 0.0261, JMMD Loss: 0.6284
Validation Loss: 0.0123
Epoch [10/50], Class Loss: 0.0111, JMMD Loss: 0.5462
Validation Loss: 0.0074
Epoch [11/50], Class Loss: 0.0069, JMMD Loss: 0.4809
Validation Loss: 0.0074
Epoch [12/50], Class Loss: 0.0067, JMMD Loss: 0.4574
Validation Loss: 0.0064
Epoch [13/50], Class Loss: 0.0068, JMMD Loss: 0.4330
Validation Loss: 0.0068
Epoch [14/50], Class Loss: 0.0068, JMMD Loss: 0.4216
Validation Loss: 0.0060
Epoch [15/50], Class Loss: 0.0069, JMMD Loss: 0.4020
Validation Loss: 0.0058
Epoch [16/50], Class Loss: 0.0064, JMMD Loss: 0.3829
Validation Loss: 0.0065
Epoch [17/50], Class Loss: 0.0063, JMMD Loss: 0.3649
Validation Loss: 0.0056
Epoch [18/50], Class Loss: 0.0076, JMMD Loss: 0.3608
Validation Loss: 0.0050
Epoch [19/50], Class Loss: 0.0058, JMMD Loss: 0.3683
Validation Loss: 0.0049
Epoch [20/50], Class Loss: 0.0061, JMMD Loss: 0.3537
Validation Loss: 0.0056
Epoch [21/50], Class Loss: 0.0056, JMMD Loss: 0.3578
Validation Loss: 0.0052
Epoch [22/50], Class Loss: 0.0062, JMMD Loss: 0.3585
Validation Loss: 0.0053
Epoch [23/50], Class Loss: 0.0053, JMMD Loss: 0.3618
Validation Loss: 0.0052
Epoch [24/50], Class Loss: 0.0057, JMMD Loss: 0.3604
Validation Loss: 0.0053
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 58.13%, Precision: 59.15%, Recall: 59.97%, F1 Score: 45.96%

Run 10/10
Epoch [1/50], Class Loss: 1.6174, JMMD Loss: 0.1080
Validation Loss: 1.5714
Epoch [2/50], Class Loss: 1.0171, JMMD Loss: 0.5238
Validation Loss: 0.3482
Epoch [3/50], Class Loss: 0.3617, JMMD Loss: 0.5202
Validation Loss: 0.1428
Epoch [4/50], Class Loss: 0.1999, JMMD Loss: 0.5144
Validation Loss: 0.2600
Epoch [5/50], Class Loss: 0.2100, JMMD Loss: 0.5327
Validation Loss: 0.6034
Epoch [6/50], Class Loss: 0.2326, JMMD Loss: 0.5731
Validation Loss: 0.1307
Epoch [7/50], Class Loss: 0.2525, JMMD Loss: 0.5550
Validation Loss: 0.0745
Epoch [8/50], Class Loss: 0.0746, JMMD Loss: 0.5609
Validation Loss: 0.0169
Epoch [9/50], Class Loss: 0.0246, JMMD Loss: 0.5886
Validation Loss: 0.0177
Epoch [10/50], Class Loss: 0.0118, JMMD Loss: 0.5850
Validation Loss: 0.0119
Epoch [11/50], Class Loss: 0.0101, JMMD Loss: 0.5977
Validation Loss: 0.0086
Epoch [12/50], Class Loss: 0.0085, JMMD Loss: 0.5729
Validation Loss: 0.0094
Epoch [13/50], Class Loss: 0.0084, JMMD Loss: 0.5632
Validation Loss: 0.0086
Epoch [14/50], Class Loss: 0.0080, JMMD Loss: 0.5540
Validation Loss: 0.0089
Epoch [15/50], Class Loss: 0.0081, JMMD Loss: 0.5538
Validation Loss: 0.0086
Epoch [16/50], Class Loss: 0.0080, JMMD Loss: 0.5412
Validation Loss: 0.0088
Epoch [17/50], Class Loss: 0.0077, JMMD Loss: 0.5213
Validation Loss: 0.0087
Epoch [18/50], Class Loss: 0.0077, JMMD Loss: 0.5056
Validation Loss: 0.0097
Epoch [19/50], Class Loss: 0.0081, JMMD Loss: 0.4893
Validation Loss: 0.0082
Epoch [20/50], Class Loss: 0.0077, JMMD Loss: 0.4658
Validation Loss: 0.0093
Epoch [21/50], Class Loss: 0.0072, JMMD Loss: 0.4518
Validation Loss: 0.0091
Epoch [22/50], Class Loss: 0.0084, JMMD Loss: 0.4491
Validation Loss: 0.0096
Epoch [23/50], Class Loss: 0.0073, JMMD Loss: 0.4485
Validation Loss: 0.0095
Epoch [24/50], Class Loss: 0.0073, JMMD Loss: 0.4488
Validation Loss: 0.0093
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 57.91%, Precision: 58.91%, Recall: 59.75%, F1 Score: 45.76%

Source performance: 91.89% 90.32% 91.92% 90.58%
Target performance: 53.96% 53.30% 55.68% 41.74%

Per-Class Accuracy on Target Domain (Mean over runs):
  Class 0: 99.90%
  Class 1: 88.48%
  Class 2: 89.91%
  Class 3: 0.11%
  Class 4: 0.00%

Run 1/10
Epoch 1/50, Train Loss: 1.1202, Train Acc: 0.4830, Val Loss: 0.4550, Val Acc: 0.7417
Epoch 2/50, Train Loss: 0.5464, Train Acc: 0.7851, Val Loss: 2.0562, Val Acc: 0.4182
Epoch 3/50, Train Loss: 0.8699, Train Acc: 0.5721, Val Loss: 0.6962, Val Acc: 0.5566
Epoch 4/50, Train Loss: 1.0456, Train Acc: 0.7123, Val Loss: 0.6097, Val Acc: 0.8071
Epoch 5/50, Train Loss: 0.6494, Train Acc: 0.8009, Val Loss: 2.2917, Val Acc: 0.5002
Epoch 6/50, Train Loss: 0.8151, Train Acc: 0.7364, Val Loss: 0.1374, Val Acc: 0.9976
Epoch 7/50, Train Loss: 0.5252, Train Acc: 0.8768, Val Loss: 0.0869, Val Acc: 0.9822
Epoch 8/50, Train Loss: 0.2675, Train Acc: 0.8787, Val Loss: 0.2444, Val Acc: 0.8293
Epoch 9/50, Train Loss: 0.1849, Train Acc: 0.9009, Val Loss: 0.1335, Val Acc: 0.9187
Epoch 10/50, Train Loss: 0.3466, Train Acc: 0.8970, Val Loss: 0.0350, Val Acc: 0.9968
Epoch 11/50, Train Loss: 0.0101, Train Acc: 0.9991, Val Loss: 0.0194, Val Acc: 0.9988
Epoch 12/50, Train Loss: 0.0055, Train Acc: 0.9995, Val Loss: 0.0165, Val Acc: 0.9990
Epoch 13/50, Train Loss: 0.0045, Train Acc: 0.9997, Val Loss: 0.0165, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0040, Train Acc: 0.9996, Val Loss: 0.0149, Val Acc: 0.9990
Epoch 15/50, Train Loss: 0.0034, Train Acc: 0.9997, Val Loss: 0.0139, Val Acc: 0.9993
Epoch 16/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0121, Val Acc: 0.9988
Epoch 17/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0108, Val Acc: 0.9990
Epoch 18/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0103, Val Acc: 0.9985
Epoch 19/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0116, Val Acc: 0.9990
Epoch 20/50, Train Loss: 0.0017, Train Acc: 0.9996, Val Loss: 0.0145, Val Acc: 0.9978
Epoch 21/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0121, Val Acc: 0.9990
Epoch 22/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0122, Val Acc: 0.9990
Epoch 23/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0111, Val Acc: 0.9985
Early stopping!

Run 2/10
Epoch 1/50, Train Loss: 1.3692, Train Acc: 0.3886, Val Loss: 0.5568, Val Acc: 0.7349
Epoch 2/50, Train Loss: 1.2209, Train Acc: 0.6556, Val Loss: 0.5283, Val Acc: 0.7021
Epoch 3/50, Train Loss: 0.3636, Train Acc: 0.8418, Val Loss: 0.6675, Val Acc: 0.7825
Epoch 4/50, Train Loss: 0.5402, Train Acc: 0.8166, Val Loss: 1.1029, Val Acc: 0.7781
Epoch 5/50, Train Loss: 0.7461, Train Acc: 0.7385, Val Loss: 0.1440, Val Acc: 0.9978
Epoch 6/50, Train Loss: 0.5656, Train Acc: 0.8658, Val Loss: 0.6826, Val Acc: 0.8079
Epoch 7/50, Train Loss: 0.4828, Train Acc: 0.8660, Val Loss: 0.0114, Val Acc: 0.9990
Epoch 8/50, Train Loss: 0.6904, Train Acc: 0.8726, Val Loss: 0.0131, Val Acc: 0.9990
Epoch 9/50, Train Loss: 0.2701, Train Acc: 0.9333, Val Loss: 0.2777, Val Acc: 0.7859
Epoch 10/50, Train Loss: 0.2909, Train Acc: 0.9417, Val Loss: 0.0166, Val Acc: 0.9985
Epoch 11/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0148, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0027, Train Acc: 0.9997, Val Loss: 0.0146, Val Acc: 0.9990
Early stopping!

Run 3/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.2589, Train Acc: 0.4099, Val Loss: 0.5307, Val Acc: 0.7363
Epoch 2/50, Train Loss: 0.6475, Train Acc: 0.6487, Val Loss: 0.6282, Val Acc: 0.6150
Epoch 3/50, Train Loss: 0.8292, Train Acc: 0.7135, Val Loss: 0.2708, Val Acc: 0.8035
Epoch 4/50, Train Loss: 0.5659, Train Acc: 0.7771, Val Loss: 0.7634, Val Acc: 0.5891
Epoch 5/50, Train Loss: 1.2548, Train Acc: 0.7181, Val Loss: 0.5332, Val Acc: 0.8018
Epoch 6/50, Train Loss: 0.7704, Train Acc: 0.8019, Val Loss: 0.0620, Val Acc: 0.9978
Epoch 7/50, Train Loss: 0.5747, Train Acc: 0.8896, Val Loss: 0.0179, Val Acc: 0.9983
Epoch 8/50, Train Loss: 0.5287, Train Acc: 0.8576, Val Loss: 0.1398, Val Acc: 0.9553
Epoch 9/50, Train Loss: 0.7171, Train Acc: 0.8990, Val Loss: 0.9996, Val Acc: 0.8062
Epoch 10/50, Train Loss: 0.4886, Train Acc: 0.9332, Val Loss: 1.7257, Val Acc: 0.7957
Epoch 11/50, Train Loss: 0.0320, Train Acc: 0.9935, Val Loss: 0.0134, Val Acc: 0.9988
Epoch 12/50, Train Loss: 0.0033, Train Acc: 0.9997, Val Loss: 0.0117, Val Acc: 0.9990
Epoch 13/50, Train Loss: 0.0027, Train Acc: 0.9997, Val Loss: 0.0121, Val Acc: 0.9985
Epoch 14/50, Train Loss: 0.0023, Train Acc: 0.9997, Val Loss: 0.0097, Val Acc: 0.9988
Epoch 15/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0088, Val Acc: 0.9985
Epoch 16/50, Train Loss: 0.0013, Train Acc: 0.9998, Val Loss: 0.0099, Val Acc: 0.9988
Epoch 17/50, Train Loss: 0.0009, Train Acc: 0.9998, Val Loss: 0.0096, Val Acc: 0.9988
Epoch 18/50, Train Loss: 0.0010, Train Acc: 0.9998, Val Loss: 0.0097, Val Acc: 0.9988
Epoch 19/50, Train Loss: 0.0010, Train Acc: 0.9999, Val Loss: 0.0096, Val Acc: 0.9985
Epoch 20/50, Train Loss: 0.0010, Train Acc: 0.9999, Val Loss: 0.0101, Val Acc: 0.9988
Early stopping!

Run 4/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.1370, Train Acc: 0.4690, Val Loss: 0.4268, Val Acc: 0.7900
Epoch 2/50, Train Loss: 0.3589, Train Acc: 0.8152, Val Loss: 0.1272, Val Acc: 0.9976
Epoch 3/50, Train Loss: 0.9041, Train Acc: 0.7023, Val Loss: 0.7507, Val Acc: 0.7607
Epoch 4/50, Train Loss: 0.9372, Train Acc: 0.7341, Val Loss: 0.3523, Val Acc: 0.8071
Epoch 5/50, Train Loss: 0.9580, Train Acc: 0.7542, Val Loss: 1.4885, Val Acc: 0.5693
Epoch 6/50, Train Loss: 0.5277, Train Acc: 0.8585, Val Loss: 0.8729, Val Acc: 0.8113
Epoch 7/50, Train Loss: 0.5527, Train Acc: 0.8412, Val Loss: 0.0799, Val Acc: 0.9978
Epoch 8/50, Train Loss: 0.2999, Train Acc: 0.8900, Val Loss: 0.6723, Val Acc: 0.7844
Epoch 9/50, Train Loss: 1.1333, Train Acc: 0.8137, Val Loss: 0.1212, Val Acc: 0.9526
Epoch 10/50, Train Loss: 0.1936, Train Acc: 0.9651, Val Loss: 1.3941, Val Acc: 0.5825
Epoch 11/50, Train Loss: 0.0230, Train Acc: 0.9912, Val Loss: 0.0120, Val Acc: 0.9988
Epoch 12/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0105, Val Acc: 0.9990
Epoch 13/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0101, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0104, Val Acc: 0.9990
Epoch 15/50, Train Loss: 0.0049, Train Acc: 0.9985, Val Loss: 0.0106, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0104, Val Acc: 0.9990
Epoch 17/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0111, Val Acc: 0.9990
Epoch 18/50, Train Loss: 0.0022, Train Acc: 0.9995, Val Loss: 0.0109, Val Acc: 0.9988
Early stopping!

Run 5/10
Epoch 1/50, Train Loss: 1.2759, Train Acc: 0.3892, Val Loss: 0.3541, Val Acc: 0.9929
Epoch 2/50, Train Loss: 0.8441, Train Acc: 0.7104, Val Loss: 0.2935, Val Acc: 0.8074
Epoch 3/50, Train Loss: 0.8842, Train Acc: 0.6978, Val Loss: 1.5123, Val Acc: 0.4253
Epoch 4/50, Train Loss: 0.3342, Train Acc: 0.8057, Val Loss: 0.2983, Val Acc: 0.7852
Epoch 5/50, Train Loss: 0.2965, Train Acc: 0.8413, Val Loss: 0.1603, Val Acc: 0.9131
Epoch 6/50, Train Loss: 0.6310, Train Acc: 0.7993, Val Loss: 0.0832, Val Acc: 0.9976
Epoch 7/50, Train Loss: 0.3795, Train Acc: 0.8861, Val Loss: 0.0347, Val Acc: 0.9980
Epoch 8/50, Train Loss: 0.6038, Train Acc: 0.8889, Val Loss: 0.0218, Val Acc: 0.9978
Epoch 9/50, Train Loss: 0.3483, Train Acc: 0.8865, Val Loss: 0.2194, Val Acc: 0.7854
Epoch 10/50, Train Loss: 0.2308, Train Acc: 0.8809, Val Loss: 0.1038, Val Acc: 0.9705
Epoch 11/50, Train Loss: 0.0080, Train Acc: 0.9991, Val Loss: 0.0093, Val Acc: 0.9983
Epoch 12/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0093, Val Acc: 0.9985
Epoch 13/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0091, Val Acc: 0.9988
Epoch 14/50, Train Loss: 0.0013, Train Acc: 0.9998, Val Loss: 0.0091, Val Acc: 0.9985
Epoch 15/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0088, Val Acc: 0.9988
Epoch 16/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0084, Val Acc: 0.9988
Epoch 17/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0083, Val Acc: 0.9988
Epoch 18/50, Train Loss: 0.0010, Train Acc: 0.9999, Val Loss: 0.0085, Val Acc: 0.9990
Epoch 19/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0095, Val Acc: 0.9988
Epoch 20/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0107, Val Acc: 0.9985
Epoch 21/50, Train Loss: 0.0008, Train Acc: 0.9999, Val Loss: 0.0094, Val Acc: 0.9988
Epoch 22/50, Train Loss: 0.0009, Train Acc: 0.9998, Val Loss: 0.0093, Val Acc: 0.9988
Early stopping!

Run 6/10
Epoch 1/50, Train Loss: 1.3517, Train Acc: 0.4027, Val Loss: 0.9414, Val Acc: 0.5920
Epoch 2/50, Train Loss: 0.8867, Train Acc: 0.5834, Val Loss: 0.8847, Val Acc: 0.4990
Epoch 3/50, Train Loss: 0.6797, Train Acc: 0.6591, Val Loss: 0.5050, Val Acc: 0.6487
Epoch 4/50, Train Loss: 0.9778, Train Acc: 0.5548, Val Loss: 0.6280, Val Acc: 0.5576
Epoch 5/50, Train Loss: 0.4034, Train Acc: 0.8412, Val Loss: 0.9717, Val Acc: 0.8047
Epoch 6/50, Train Loss: 0.5303, Train Acc: 0.8608, Val Loss: 0.1003, Val Acc: 0.9978
Epoch 7/50, Train Loss: 0.2065, Train Acc: 0.9073, Val Loss: 0.4318, Val Acc: 0.8142
Epoch 8/50, Train Loss: 0.3413, Train Acc: 0.8978, Val Loss: 0.1815, Val Acc: 0.8955
Epoch 9/50, Train Loss: 0.5339, Train Acc: 0.8718, Val Loss: 1.7010, Val Acc: 0.5930
Epoch 10/50, Train Loss: 0.2289, Train Acc: 0.9250, Val Loss: 0.1865, Val Acc: 0.9121
Epoch 11/50, Train Loss: 0.0060, Train Acc: 0.9978, Val Loss: 0.0111, Val Acc: 0.9988
Epoch 12/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0100, Val Acc: 0.9990
Epoch 13/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0090, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0094, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0013, Train Acc: 0.9998, Val Loss: 0.0078, Val Acc: 0.9993
Epoch 16/50, Train Loss: 0.0011, Train Acc: 0.9999, Val Loss: 0.0081, Val Acc: 0.9990
Epoch 17/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0082, Val Acc: 0.9993
Epoch 18/50, Train Loss: 0.0010, Train Acc: 0.9999, Val Loss: 0.0083, Val Acc: 0.9993
Epoch 19/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0085, Val Acc: 0.9993
Epoch 20/50, Train Loss: 0.0009, Train Acc: 0.9999, Val Loss: 0.0086, Val Acc: 0.9990
Early stopping!

Run 7/10
Epoch 1/50, Train Loss: 1.5751, Train Acc: 0.3490, Val Loss: 1.5282, Val Acc: 0.3972
Epoch 2/50, Train Loss: 0.6327, Train Acc: 0.7015, Val Loss: 0.3584, Val Acc: 0.8047
Epoch 3/50, Train Loss: 0.5002, Train Acc: 0.8088, Val Loss: 0.0178, Val Acc: 0.9988
Epoch 4/50, Train Loss: 0.7683, Train Acc: 0.8220, Val Loss: 1.1212, Val Acc: 0.5232
Epoch 5/50, Train Loss: 0.3214, Train Acc: 0.8494, Val Loss: 0.1158, Val Acc: 0.9978
Epoch 6/50, Train Loss: 0.2237, Train Acc: 0.8538, Val Loss: 0.2333, Val Acc: 0.7856
Epoch 7/50, Train Loss: 0.2040, Train Acc: 0.8711, Val Loss: 0.2945, Val Acc: 0.8135
Epoch 8/50, Train Loss: 0.4565, Train Acc: 0.8893, Val Loss: 1.0166, Val Acc: 0.7852
Early stopping!

Run 8/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.6845, Train Acc: 0.3817, Val Loss: 1.2681, Val Acc: 0.5176
Epoch 2/50, Train Loss: 0.5021, Train Acc: 0.7538, Val Loss: 0.3949, Val Acc: 0.8047
Epoch 3/50, Train Loss: 0.9588, Train Acc: 0.6690, Val Loss: 0.5348, Val Acc: 0.5864
Epoch 4/50, Train Loss: 0.5823, Train Acc: 0.6686, Val Loss: 0.7267, Val Acc: 0.5869
Epoch 5/50, Train Loss: 0.7508, Train Acc: 0.7625, Val Loss: 0.2863, Val Acc: 0.8171
Epoch 6/50, Train Loss: 0.5785, Train Acc: 0.8490, Val Loss: 0.4446, Val Acc: 0.7839
Epoch 7/50, Train Loss: 0.5817, Train Acc: 0.8453, Val Loss: 0.3002, Val Acc: 0.8325
Epoch 8/50, Train Loss: 1.2059, Train Acc: 0.7950, Val Loss: 0.1079, Val Acc: 0.9978
Epoch 9/50, Train Loss: 0.2791, Train Acc: 0.9163, Val Loss: 0.1756, Val Acc: 0.7861
Epoch 10/50, Train Loss: 0.2951, Train Acc: 0.9149, Val Loss: 0.0362, Val Acc: 0.9976
Epoch 11/50, Train Loss: 0.0043, Train Acc: 0.9996, Val Loss: 0.0148, Val Acc: 0.9990
Epoch 12/50, Train Loss: 0.0033, Train Acc: 0.9998, Val Loss: 0.0126, Val Acc: 0.9990
Epoch 13/50, Train Loss: 0.0027, Train Acc: 0.9998, Val Loss: 0.0116, Val Acc: 0.9988
Epoch 14/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0115, Val Acc: 0.9985
Epoch 15/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0106, Val Acc: 0.9985
Epoch 16/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0092, Val Acc: 0.9990
Epoch 17/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0102, Val Acc: 0.9985
Epoch 18/50, Train Loss: 0.0010, Train Acc: 0.9999, Val Loss: 0.0106, Val Acc: 0.9988
Epoch 19/50, Train Loss: 0.0009, Train Acc: 0.9999, Val Loss: 0.0104, Val Acc: 0.9988
Epoch 20/50, Train Loss: 0.0010, Train Acc: 0.9998, Val Loss: 0.0096, Val Acc: 0.9988
Epoch 21/50, Train Loss: 0.0010, Train Acc: 0.9999, Val Loss: 0.0098, Val Acc: 0.9988
Early stopping!

Run 9/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.2175, Train Acc: 0.3924, Val Loss: 0.5013, Val Acc: 0.7588
Epoch 2/50, Train Loss: 0.5346, Train Acc: 0.6862, Val Loss: 0.6294, Val Acc: 0.5613
Epoch 3/50, Train Loss: 0.5377, Train Acc: 0.7489, Val Loss: 0.3051, Val Acc: 0.7842
Epoch 4/50, Train Loss: 0.5564, Train Acc: 0.7830, Val Loss: 0.2460, Val Acc: 0.8132
Epoch 5/50, Train Loss: 0.6207, Train Acc: 0.7982, Val Loss: 0.1878, Val Acc: 0.9888
Epoch 6/50, Train Loss: 0.4415, Train Acc: 0.8569, Val Loss: 0.4010, Val Acc: 0.8059
Epoch 7/50, Train Loss: 0.2934, Train Acc: 0.8499, Val Loss: 0.1258, Val Acc: 0.9980
Epoch 8/50, Train Loss: 0.2154, Train Acc: 0.8707, Val Loss: 0.1493, Val Acc: 0.9114
Epoch 9/50, Train Loss: 0.1867, Train Acc: 0.8951, Val Loss: 0.5827, Val Acc: 0.8069
Epoch 10/50, Train Loss: 0.7281, Train Acc: 0.8215, Val Loss: 0.1858, Val Acc: 0.9910
Epoch 11/50, Train Loss: 0.0468, Train Acc: 0.9987, Val Loss: 0.0176, Val Acc: 0.9980
Epoch 12/50, Train Loss: 0.0059, Train Acc: 0.9995, Val Loss: 0.0140, Val Acc: 0.9983
Epoch 13/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0198, Val Acc: 0.9980
Epoch 14/50, Train Loss: 0.0017, Train Acc: 0.9998, Val Loss: 0.0098, Val Acc: 0.9985
Epoch 15/50, Train Loss: 0.0013, Train Acc: 0.9998, Val Loss: 0.0090, Val Acc: 0.9985
Epoch 16/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0124, Val Acc: 0.9985
Epoch 17/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0105, Val Acc: 0.9985
Epoch 18/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0131, Val Acc: 0.9985
Epoch 19/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0116, Val Acc: 0.9985
Epoch 20/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0106, Val Acc: 0.9988
Early stopping!

Run 10/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.0076, Train Acc: 0.5313, Val Loss: 0.4358, Val Acc: 0.7739
Epoch 2/50, Train Loss: 0.9584, Train Acc: 0.5631, Val Loss: 1.2128, Val Acc: 0.6450
Epoch 3/50, Train Loss: 1.0756, Train Acc: 0.5530, Val Loss: 0.8659, Val Acc: 0.4001
Epoch 4/50, Train Loss: 0.3306, Train Acc: 0.8016, Val Loss: 0.2933, Val Acc: 0.7854
Epoch 5/50, Train Loss: 0.2046, Train Acc: 0.8353, Val Loss: 0.1571, Val Acc: 0.9978
Epoch 6/50, Train Loss: 0.8677, Train Acc: 0.7728, Val Loss: 1.7154, Val Acc: 0.4419
Epoch 7/50, Train Loss: 0.9023, Train Acc: 0.8053, Val Loss: 0.0416, Val Acc: 0.9980
Epoch 8/50, Train Loss: 0.7270, Train Acc: 0.7979, Val Loss: 5.5831, Val Acc: 0.3979
Epoch 9/50, Train Loss: 0.5120, Train Acc: 0.8431, Val Loss: 0.1742, Val Acc: 0.9941
Epoch 10/50, Train Loss: 0.4659, Train Acc: 0.9392, Val Loss: 1.2558, Val Acc: 0.7839
Epoch 11/50, Train Loss: 0.0207, Train Acc: 0.9951, Val Loss: 0.0102, Val Acc: 0.9985
Epoch 12/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0107, Val Acc: 0.9983
Epoch 13/50, Train Loss: 0.0020, Train Acc: 0.9997, Val Loss: 0.0122, Val Acc: 0.9983
Epoch 14/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0117, Val Acc: 0.9983
Epoch 15/50, Train Loss: 0.0017, Train Acc: 0.9998, Val Loss: 0.0120, Val Acc: 0.9983
Epoch 16/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0120, Val Acc: 0.9985
Early stopping!

Source performance: 97.74 96.82 97.87 97.16
Target performance: 57.03 50.69 57.60 44.48

bpsk: 89.89
qpsk: 0.04
4qam: 10.06
16qam: 99.95
apsk: 88.05
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1227, Domain Loss: 1.4195, Class Loss: 1.7033
Epoch 2/25, Loss: 2.7150, Domain Loss: 1.3836, Class Loss: 1.3314
Epoch 3/25, Loss: 2.1159, Domain Loss: 1.2887, Class Loss: 0.8272
Epoch 4/25, Loss: 3.5831, Domain Loss: 1.4123, Class Loss: 2.1708
Epoch 5/25, Loss: 2.5665, Domain Loss: 1.3455, Class Loss: 1.2210
Epoch 6/25, Loss: 2.2537, Domain Loss: 1.3107, Class Loss: 0.9430
Epoch 7/25, Loss: 2.0576, Domain Loss: 1.2909, Class Loss: 0.7667
Epoch 8/25, Loss: 2.0651, Domain Loss: 1.2706, Class Loss: 0.7946
Epoch 9/25, Loss: 1.7103, Domain Loss: 1.2249, Class Loss: 0.4854
Epoch 10/25, Loss: 1.4591, Domain Loss: 1.1883, Class Loss: 0.2709
Epoch 11/25, Loss: 1.3854, Domain Loss: 1.1701, Class Loss: 0.2153
Epoch 12/25, Loss: 1.5804, Domain Loss: 1.1636, Class Loss: 0.4168
Epoch 13/25, Loss: 1.3498, Domain Loss: 1.1590, Class Loss: 0.1907
Epoch 14/25, Loss: 1.3404, Domain Loss: 1.1048, Class Loss: 0.2356
Epoch 15/25, Loss: 5.4305, Domain Loss: 3.6134, Class Loss: 1.8171
Epoch 16/25, Loss: 17.6526, Domain Loss: 15.8673, Class Loss: 1.7853
Epoch 17/25, Loss: 10.1478, Domain Loss: 8.6233, Class Loss: 1.5244
Epoch 18/25, Loss: 5.8912, Domain Loss: 4.5394, Class Loss: 1.3518
Epoch 19/25, Loss: 9.8157, Domain Loss: 8.1219, Class Loss: 1.6938
Epoch 20/25, Loss: 11.4309, Domain Loss: 9.4707, Class Loss: 1.9601
Epoch 21/25, Loss: 9.2775, Domain Loss: 7.7949, Class Loss: 1.4826
Epoch 22/25, Loss: 11.5272, Domain Loss: 10.1373, Class Loss: 1.3899
Epoch 23/25, Loss: 18.9385, Domain Loss: 17.2636, Class Loss: 1.6750
Epoch 24/25, Loss: 6.6512, Domain Loss: 5.0480, Class Loss: 1.6031
Epoch 25/25, Loss: 8.7035, Domain Loss: 7.1666, Class Loss: 1.5369
39.48


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1279, Domain Loss: 1.4250, Class Loss: 1.7029
Epoch 2/25, Loss: 2.9531, Domain Loss: 1.4142, Class Loss: 1.5389
Epoch 3/25, Loss: 2.8293, Domain Loss: 1.3918, Class Loss: 1.4375
Epoch 4/25, Loss: 2.3044, Domain Loss: 1.3633, Class Loss: 0.9411
Epoch 5/25, Loss: 2.4742, Domain Loss: 1.3161, Class Loss: 1.1581
Epoch 6/25, Loss: 1.6627, Domain Loss: 1.1634, Class Loss: 0.4993
Epoch 7/25, Loss: 1.4978, Domain Loss: 1.1434, Class Loss: 0.3544
Epoch 8/25, Loss: 2.9425, Domain Loss: 1.3653, Class Loss: 1.5772
Epoch 9/25, Loss: 2.2692, Domain Loss: 1.1991, Class Loss: 1.0701
Epoch 10/25, Loss: 5.6157, Domain Loss: 2.8863, Class Loss: 2.7294
Epoch 11/25, Loss: 3.2628, Domain Loss: 1.6380, Class Loss: 1.6248
Epoch 12/25, Loss: 3.0102, Domain Loss: 1.3998, Class Loss: 1.6103
Epoch 13/25, Loss: 3.0025, Domain Loss: 1.3986, Class Loss: 1.6040
Epoch 14/25, Loss: 2.9978, Domain Loss: 1.3994, Class Loss: 1.5984
Epoch 15/25, Loss: 2.9518, Domain Loss: 1.4032, Class Loss: 1.5486
Epoch 16/25, Loss: 2.8965, Domain Loss: 1.4387, Class Loss: 1.4578
Epoch 17/25, Loss: 2.7770, Domain Loss: 1.4087, Class Loss: 1.3683
Epoch 18/25, Loss: 2.5924, Domain Loss: 1.3935, Class Loss: 1.1989
Epoch 19/25, Loss: 2.3268, Domain Loss: 1.3862, Class Loss: 0.9407
Epoch 20/25, Loss: 2.1831, Domain Loss: 1.3855, Class Loss: 0.7976
Epoch 21/25, Loss: 2.9210, Domain Loss: 1.3870, Class Loss: 1.5339
Epoch 22/25, Loss: 2.1121, Domain Loss: 1.3840, Class Loss: 0.7281
Epoch 23/25, Loss: 1.8757, Domain Loss: 1.3846, Class Loss: 0.4910
Epoch 24/25, Loss: 1.7695, Domain Loss: 1.3847, Class Loss: 0.3848
Epoch 25/25, Loss: 1.9716, Domain Loss: 1.4029, Class Loss: 0.5687
59.40


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1393, Domain Loss: 1.4276, Class Loss: 1.7117
Epoch 2/25, Loss: 2.9135, Domain Loss: 1.4068, Class Loss: 1.5067
Epoch 3/25, Loss: 2.4941, Domain Loss: 1.3856, Class Loss: 1.1085
Epoch 4/25, Loss: 2.3148, Domain Loss: 1.2983, Class Loss: 1.0165
Epoch 5/25, Loss: 2.2167, Domain Loss: 1.3092, Class Loss: 0.9076
Epoch 6/25, Loss: 4.5444, Domain Loss: 2.0436, Class Loss: 2.5008
Epoch 7/25, Loss: 2.9749, Domain Loss: 1.4164, Class Loss: 1.5585
Epoch 8/25, Loss: 2.7460, Domain Loss: 1.4220, Class Loss: 1.3240
Epoch 9/25, Loss: 2.3307, Domain Loss: 1.3966, Class Loss: 0.9341
Epoch 10/25, Loss: 2.1595, Domain Loss: 1.3955, Class Loss: 0.7641
Epoch 11/25, Loss: 2.0343, Domain Loss: 1.3966, Class Loss: 0.6377
Epoch 12/25, Loss: 1.8328, Domain Loss: 1.3974, Class Loss: 0.4354
Epoch 13/25, Loss: 2.6289, Domain Loss: 1.4001, Class Loss: 1.2288
Epoch 14/25, Loss: 2.0857, Domain Loss: 1.3926, Class Loss: 0.6931
Epoch 15/25, Loss: 1.7774, Domain Loss: 1.3903, Class Loss: 0.3871
Epoch 16/25, Loss: 1.6163, Domain Loss: 1.3845, Class Loss: 0.2319
Epoch 17/25, Loss: 2.1599, Domain Loss: 1.3717, Class Loss: 0.7882
Epoch 18/25, Loss: 1.7952, Domain Loss: 1.3383, Class Loss: 0.4568
Epoch 19/25, Loss: 1.5378, Domain Loss: 1.3088, Class Loss: 0.2290
Epoch 20/25, Loss: 1.3972, Domain Loss: 1.2308, Class Loss: 0.1664
Epoch 21/25, Loss: 1.9373, Domain Loss: 1.1909, Class Loss: 0.7464
Epoch 22/25, Loss: 1.6142, Domain Loss: 1.2137, Class Loss: 0.4006
Epoch 23/25, Loss: 1.5242, Domain Loss: 1.1997, Class Loss: 0.3245
Epoch 24/25, Loss: 1.4938, Domain Loss: 1.1952, Class Loss: 0.2986
Epoch 25/25, Loss: 1.3996, Domain Loss: 1.1738, Class Loss: 0.2258
59.28


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1144, Domain Loss: 1.4327, Class Loss: 1.6817
Epoch 2/25, Loss: 2.7482, Domain Loss: 1.3904, Class Loss: 1.3578
Epoch 3/25, Loss: 2.4103, Domain Loss: 1.2980, Class Loss: 1.1123
Epoch 4/25, Loss: 3.5650, Domain Loss: 1.7605, Class Loss: 1.8045
Epoch 5/25, Loss: 2.5905, Domain Loss: 1.3926, Class Loss: 1.1978
Epoch 6/25, Loss: 2.4321, Domain Loss: 1.4056, Class Loss: 1.0265
Epoch 7/25, Loss: 1.9752, Domain Loss: 1.3640, Class Loss: 0.6112
Epoch 8/25, Loss: 1.8080, Domain Loss: 1.2673, Class Loss: 0.5407
Epoch 9/25, Loss: 2.0110, Domain Loss: 1.2939, Class Loss: 0.7171
Epoch 10/25, Loss: 1.5797, Domain Loss: 1.1912, Class Loss: 0.3886
Epoch 11/25, Loss: 2.0819, Domain Loss: 1.4096, Class Loss: 0.6723
Epoch 12/25, Loss: 1.7970, Domain Loss: 1.3306, Class Loss: 0.4664
Epoch 13/25, Loss: 1.4757, Domain Loss: 1.2003, Class Loss: 0.2755
Epoch 14/25, Loss: 1.3534, Domain Loss: 1.1106, Class Loss: 0.2428
Epoch 15/25, Loss: 1.3453, Domain Loss: 1.0275, Class Loss: 0.3179
Epoch 16/25, Loss: 1.4044, Domain Loss: 1.0591, Class Loss: 0.3454
Epoch 17/25, Loss: 1.2993, Domain Loss: 1.0326, Class Loss: 0.2667
Epoch 18/25, Loss: 1.2580, Domain Loss: 1.0256, Class Loss: 0.2325
Epoch 19/25, Loss: 1.7921, Domain Loss: 1.1610, Class Loss: 0.6311
Epoch 20/25, Loss: 1.5845, Domain Loss: 1.2062, Class Loss: 0.3782
Epoch 21/25, Loss: 1.3505, Domain Loss: 1.1150, Class Loss: 0.2355
Epoch 22/25, Loss: 1.2700, Domain Loss: 1.0896, Class Loss: 0.1804
Epoch 23/25, Loss: 1.3089, Domain Loss: 1.0656, Class Loss: 0.2433
Epoch 24/25, Loss: 1.1933, Domain Loss: 1.0621, Class Loss: 0.1311
Epoch 25/25, Loss: 11.0388, Domain Loss: 8.5840, Class Loss: 2.4548
20.02


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1300, Domain Loss: 1.4113, Class Loss: 1.7187
Epoch 2/25, Loss: 2.9662, Domain Loss: 1.3952, Class Loss: 1.5709
Epoch 3/25, Loss: 3.0669, Domain Loss: 1.5522, Class Loss: 1.5147
Epoch 4/25, Loss: 2.5809, Domain Loss: 1.3660, Class Loss: 1.2149
Epoch 5/25, Loss: 1.6562, Domain Loss: 1.1722, Class Loss: 0.4840
Epoch 6/25, Loss: 1.7886, Domain Loss: 1.1512, Class Loss: 0.6375
Epoch 7/25, Loss: 2.1733, Domain Loss: 1.2903, Class Loss: 0.8830
Epoch 8/25, Loss: 2.1415, Domain Loss: 1.3984, Class Loss: 0.7430
Epoch 9/25, Loss: 1.6301, Domain Loss: 1.3464, Class Loss: 0.2837
Epoch 10/25, Loss: 1.3964, Domain Loss: 1.2064, Class Loss: 0.1900
Epoch 11/25, Loss: 1.4356, Domain Loss: 1.1601, Class Loss: 0.2756
Epoch 12/25, Loss: 1.2685, Domain Loss: 1.1219, Class Loss: 0.1466
Epoch 13/25, Loss: 1.1889, Domain Loss: 1.0959, Class Loss: 0.0929
Epoch 14/25, Loss: 2.7155, Domain Loss: 1.3851, Class Loss: 1.3304
Epoch 15/25, Loss: 1.5806, Domain Loss: 1.2786, Class Loss: 0.3021
Epoch 16/25, Loss: 3.3666, Domain Loss: 2.4591, Class Loss: 0.9075
Epoch 17/25, Loss: 4.2618, Domain Loss: 3.5616, Class Loss: 0.7002
Epoch 18/25, Loss: 5.3226, Domain Loss: 3.4770, Class Loss: 1.8457
Epoch 19/25, Loss: 14.3877, Domain Loss: 12.2421, Class Loss: 2.1456
Epoch 20/25, Loss: 6.4339, Domain Loss: 4.7948, Class Loss: 1.6391
Epoch 21/25, Loss: 2.9902, Domain Loss: 1.4025, Class Loss: 1.5877
Epoch 22/25, Loss: 2.9521, Domain Loss: 1.3893, Class Loss: 1.5627
Epoch 23/25, Loss: 2.8918, Domain Loss: 1.3886, Class Loss: 1.5032
Epoch 24/25, Loss: 2.6575, Domain Loss: 1.3875, Class Loss: 1.2700
Epoch 25/25, Loss: 2.9871, Domain Loss: 1.3903, Class Loss: 1.5968
32.28


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1225, Domain Loss: 1.4072, Class Loss: 1.7153
Epoch 2/25, Loss: 2.8543, Domain Loss: 1.3896, Class Loss: 1.4647
Epoch 3/25, Loss: 2.3176, Domain Loss: 1.3092, Class Loss: 1.0083
Epoch 4/25, Loss: 3.1463, Domain Loss: 1.4862, Class Loss: 1.6601
Epoch 5/25, Loss: 2.6603, Domain Loss: 1.4922, Class Loss: 1.1681
Epoch 6/25, Loss: 2.5658, Domain Loss: 1.4877, Class Loss: 1.0782
Epoch 7/25, Loss: 1.7909, Domain Loss: 1.2159, Class Loss: 0.5750
Epoch 8/25, Loss: 3.8545, Domain Loss: 2.2397, Class Loss: 1.6148
Epoch 9/25, Loss: 2.5585, Domain Loss: 1.4613, Class Loss: 1.0972
Epoch 10/25, Loss: 2.1388, Domain Loss: 1.3307, Class Loss: 0.8081
Epoch 11/25, Loss: 1.8738, Domain Loss: 1.3108, Class Loss: 0.5630
Epoch 12/25, Loss: 1.8853, Domain Loss: 1.2934, Class Loss: 0.5919
Epoch 13/25, Loss: 2.1970, Domain Loss: 1.3635, Class Loss: 0.8334
Epoch 14/25, Loss: 2.1539, Domain Loss: 1.2817, Class Loss: 0.8722
Epoch 15/25, Loss: 1.9620, Domain Loss: 1.3571, Class Loss: 0.6049
Epoch 16/25, Loss: 1.5015, Domain Loss: 1.2457, Class Loss: 0.2559
Epoch 17/25, Loss: 1.3944, Domain Loss: 1.1507, Class Loss: 0.2436
Epoch 18/25, Loss: 1.4408, Domain Loss: 1.1983, Class Loss: 0.2425
Epoch 19/25, Loss: 1.4894, Domain Loss: 1.2883, Class Loss: 0.2010
Epoch 20/25, Loss: 1.4071, Domain Loss: 1.2158, Class Loss: 0.1912
Epoch 21/25, Loss: 1.3998, Domain Loss: 1.1887, Class Loss: 0.2111
Epoch 22/25, Loss: 1.4418, Domain Loss: 1.2468, Class Loss: 0.1950
Epoch 23/25, Loss: 1.9872, Domain Loss: 1.5872, Class Loss: 0.4000
Epoch 24/25, Loss: 2.2785, Domain Loss: 1.2833, Class Loss: 0.9952
Epoch 25/25, Loss: 1.2496, Domain Loss: 1.0140, Class Loss: 0.2357
59.33


Epoch 1/25, Loss: 3.1226, Domain Loss: 1.4144, Class Loss: 1.7082
Epoch 2/25, Loss: 3.0368, Domain Loss: 1.3908, Class Loss: 1.6460
Epoch 3/25, Loss: 2.5959, Domain Loss: 1.3471, Class Loss: 1.2488
Epoch 4/25, Loss: 2.6054, Domain Loss: 1.3321, Class Loss: 1.2734
Epoch 5/25, Loss: 1.8656, Domain Loss: 1.2207, Class Loss: 0.6449
Epoch 6/25, Loss: 1.6999, Domain Loss: 1.1806, Class Loss: 0.5192
Epoch 7/25, Loss: 1.4458, Domain Loss: 1.1739, Class Loss: 0.2719
Epoch 8/25, Loss: 3.1345, Domain Loss: 1.4240, Class Loss: 1.7104
Epoch 9/25, Loss: 5.5023, Domain Loss: 4.2162, Class Loss: 1.2862
Epoch 10/25, Loss: 3.8406, Domain Loss: 2.3923, Class Loss: 1.4484
Epoch 11/25, Loss: 2.9118, Domain Loss: 1.9286, Class Loss: 0.9833
Epoch 12/25, Loss: 5.1052, Domain Loss: 3.8804, Class Loss: 1.2248
Epoch 13/25, Loss: 7.2199, Domain Loss: 5.6242, Class Loss: 1.5957
Epoch 14/25, Loss: 5.7991, Domain Loss: 4.3664, Class Loss: 1.4327
Epoch 15/25, Loss: 4.8844, Domain Loss: 3.4431, Class Loss: 1.4414
Epoch 16/25, Loss: 3.2891, Domain Loss: 2.2388, Class Loss: 1.0503
Epoch 17/25, Loss: 3.1153, Domain Loss: 2.1350, Class Loss: 0.9803
Epoch 18/25, Loss: 3.6061, Domain Loss: 2.7803, Class Loss: 0.8257
Epoch 19/25, Loss: 3.3503, Domain Loss: 2.5551, Class Loss: 0.7951
Epoch 20/25, Loss: 5.9206, Domain Loss: 4.6560, Class Loss: 1.2646
Epoch 21/25, Loss: 5.7455, Domain Loss: 4.6838, Class Loss: 1.0617
Epoch 22/25, Loss: 4.4266, Domain Loss: 3.6502, Class Loss: 0.7764
Epoch 23/25, Loss: 4.7246, Domain Loss: 3.9261, Class Loss: 0.7985
Epoch 24/25, Loss: 4.2392, Domain Loss: 3.4271, Class Loss: 0.8121
Epoch 25/25, Loss: 3.8929, Domain Loss: 3.1453, Class Loss: 0.7475
58.47


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1116, Domain Loss: 1.4218, Class Loss: 1.6898
Epoch 2/25, Loss: 2.6443, Domain Loss: 1.3775, Class Loss: 1.2668
Epoch 3/25, Loss: 3.2438, Domain Loss: 1.4363, Class Loss: 1.8074
Epoch 4/25, Loss: 2.1579, Domain Loss: 1.3823, Class Loss: 0.7755
Epoch 5/25, Loss: 2.5181, Domain Loss: 1.3844, Class Loss: 1.1337
Epoch 6/25, Loss: 2.1354, Domain Loss: 1.3785, Class Loss: 0.7569
Epoch 7/25, Loss: 1.7284, Domain Loss: 1.3278, Class Loss: 0.4006
Epoch 8/25, Loss: 1.3834, Domain Loss: 1.1413, Class Loss: 0.2421
Epoch 9/25, Loss: 2.8642, Domain Loss: 1.3730, Class Loss: 1.4912
Epoch 10/25, Loss: 1.6738, Domain Loss: 1.1996, Class Loss: 0.4742
Epoch 11/25, Loss: 1.4111, Domain Loss: 1.1274, Class Loss: 0.2837
Epoch 12/25, Loss: 1.2705, Domain Loss: 1.0787, Class Loss: 0.1918
Epoch 13/25, Loss: 1.4165, Domain Loss: 1.0046, Class Loss: 0.4119
Epoch 14/25, Loss: 1.8934, Domain Loss: 1.1038, Class Loss: 0.7896
Epoch 15/25, Loss: 1.3754, Domain Loss: 1.0103, Class Loss: 0.3651
Epoch 16/25, Loss: 1.2491, Domain Loss: 0.9842, Class Loss: 0.2649
Epoch 17/25, Loss: 1.2443, Domain Loss: 0.9959, Class Loss: 0.2484
Epoch 18/25, Loss: 5.3855, Domain Loss: 3.2925, Class Loss: 2.0930
Epoch 19/25, Loss: 10.6921, Domain Loss: 4.0003, Class Loss: 6.6918
Epoch 20/25, Loss: 2.9656, Domain Loss: 1.4217, Class Loss: 1.5439
Epoch 21/25, Loss: 2.7445, Domain Loss: 1.3901, Class Loss: 1.3544
Epoch 22/25, Loss: 3.2139, Domain Loss: 2.0993, Class Loss: 1.1146
Epoch 23/25, Loss: 2.8445, Domain Loss: 1.8694, Class Loss: 0.9751
Epoch 24/25, Loss: 2.0922, Domain Loss: 1.4790, Class Loss: 0.6133
Epoch 25/25, Loss: 1.8975, Domain Loss: 1.4720, Class Loss: 0.4256
58.52


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1363, Domain Loss: 1.4282, Class Loss: 1.7081
Epoch 2/25, Loss: 2.9035, Domain Loss: 1.3864, Class Loss: 1.5171
Epoch 3/25, Loss: 2.6585, Domain Loss: 1.3494, Class Loss: 1.3092
Epoch 4/25, Loss: 2.2325, Domain Loss: 1.2421, Class Loss: 0.9903
Epoch 5/25, Loss: 3.0457, Domain Loss: 1.3610, Class Loss: 1.6847
Epoch 6/25, Loss: 2.6884, Domain Loss: 1.3788, Class Loss: 1.3096
Epoch 7/25, Loss: 2.4801, Domain Loss: 1.3366, Class Loss: 1.1435
Epoch 8/25, Loss: 1.9584, Domain Loss: 1.2682, Class Loss: 0.6902
Epoch 9/25, Loss: 1.6711, Domain Loss: 1.2447, Class Loss: 0.4263
Epoch 10/25, Loss: 2.6422, Domain Loss: 1.3974, Class Loss: 1.2447
Epoch 11/25, Loss: 2.3910, Domain Loss: 1.3654, Class Loss: 1.0256
Epoch 12/25, Loss: 2.0397, Domain Loss: 1.3104, Class Loss: 0.7293
Epoch 13/25, Loss: 1.6958, Domain Loss: 1.2823, Class Loss: 0.4135
Epoch 14/25, Loss: 1.9045, Domain Loss: 1.3122, Class Loss: 0.5923
Epoch 15/25, Loss: 2.3175, Domain Loss: 1.3004, Class Loss: 1.0172
Epoch 16/25, Loss: 1.5364, Domain Loss: 1.0947, Class Loss: 0.4417
Epoch 17/25, Loss: 1.2777, Domain Loss: 1.0011, Class Loss: 0.2766
Epoch 18/25, Loss: 1.3071, Domain Loss: 1.0593, Class Loss: 0.2478
Epoch 19/25, Loss: 1.4682, Domain Loss: 1.2210, Class Loss: 0.2472
Epoch 20/25, Loss: 2.1042, Domain Loss: 1.3802, Class Loss: 0.7240
Epoch 21/25, Loss: 1.5022, Domain Loss: 1.1733, Class Loss: 0.3289
Epoch 22/25, Loss: 1.5338, Domain Loss: 1.2154, Class Loss: 0.3184
Epoch 23/25, Loss: 2.2448, Domain Loss: 1.2607, Class Loss: 0.9841
Epoch 24/25, Loss: 1.4850, Domain Loss: 1.1295, Class Loss: 0.3555
Epoch 25/25, Loss: 1.4054, Domain Loss: 1.1187, Class Loss: 0.2867
59.25


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1141, Domain Loss: 1.4112, Class Loss: 1.7028
Epoch 2/25, Loss: 2.9494, Domain Loss: 1.3866, Class Loss: 1.5628
Epoch 3/25, Loss: 2.3700, Domain Loss: 1.3450, Class Loss: 1.0250
Epoch 4/25, Loss: 2.3086, Domain Loss: 1.2948, Class Loss: 1.0138
Epoch 5/25, Loss: 1.9077, Domain Loss: 1.2067, Class Loss: 0.7010
Epoch 6/25, Loss: 2.0636, Domain Loss: 1.3569, Class Loss: 0.7067
Epoch 7/25, Loss: 2.7642, Domain Loss: 1.3808, Class Loss: 1.3835
Epoch 8/25, Loss: 1.8404, Domain Loss: 1.1420, Class Loss: 0.6984
Epoch 9/25, Loss: 1.5183, Domain Loss: 1.0856, Class Loss: 0.4327
Epoch 10/25, Loss: 2.7833, Domain Loss: 1.7073, Class Loss: 1.0759
Epoch 11/25, Loss: 2.4409, Domain Loss: 1.5596, Class Loss: 0.8813
Epoch 12/25, Loss: 1.9163, Domain Loss: 1.2946, Class Loss: 0.6217
Epoch 13/25, Loss: 1.6608, Domain Loss: 1.1954, Class Loss: 0.4653
Epoch 14/25, Loss: 1.3931, Domain Loss: 1.0967, Class Loss: 0.2965
Epoch 15/25, Loss: 2.3033, Domain Loss: 1.2416, Class Loss: 1.0617
Epoch 16/25, Loss: 5.3318, Domain Loss: 3.9017, Class Loss: 1.4301
Epoch 17/25, Loss: 4.6362, Domain Loss: 3.3868, Class Loss: 1.2493
Epoch 18/25, Loss: 20.0937, Domain Loss: 18.5158, Class Loss: 1.5780
Epoch 19/25, Loss: 6.3854, Domain Loss: 4.7516, Class Loss: 1.6338
Epoch 20/25, Loss: 6.8484, Domain Loss: 5.2295, Class Loss: 1.6190
Epoch 21/25, Loss: 9.2494, Domain Loss: 7.6355, Class Loss: 1.6139
Epoch 22/25, Loss: 13.2002, Domain Loss: 11.5903, Class Loss: 1.6098
Epoch 23/25, Loss: 11.4145, Domain Loss: 9.8444, Class Loss: 1.5701
Epoch 24/25, Loss: 6.6240, Domain Loss: 5.4803, Class Loss: 1.1437
Epoch 25/25, Loss: 3.2700, Domain Loss: 1.6618, Class Loss: 1.6081
20.90


Source performance:
61.99 56.09 61.95 54.63 
Target performance:
46.69 35.37 47.23 34.43 

Per-class target performance: 49.95 2.85 40.01 63.54 79.81 
Run 1/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch [1/50], Class Loss: 4.1116, Discrepancy Loss: 0.0896
Epoch [2/50], Class Loss: 0.7023, Discrepancy Loss: 0.0816
Epoch [3/50], Class Loss: 0.5866, Discrepancy Loss: 0.0776
Epoch [4/50], Class Loss: 0.4849, Discrepancy Loss: 0.0802
Epoch [5/50], Class Loss: 0.3786, Discrepancy Loss: 0.0764
Epoch [6/50], Class Loss: 0.3107, Discrepancy Loss: 0.0737
Epoch [7/50], Class Loss: 0.3322, Discrepancy Loss: 0.0755
Epoch [8/50], Class Loss: 0.2260, Discrepancy Loss: 0.0764
Epoch [9/50], Class Loss: 0.2995, Discrepancy Loss: 0.0783
Epoch [10/50], Class Loss: 0.2115, Discrepancy Loss: 0.0853
Epoch [11/50], Class Loss: 0.1517, Discrepancy Loss: 0.0849
Epoch [12/50], Class Loss: 0.0778, Discrepancy Loss: 0.0996
Epoch [13/50], Class Loss: 0.0548, Discrepancy Loss: 0.0941
Epoch [14/50], Class Loss: 0.0406, Discrepancy Loss: 0.0849
Epoch [15/50], Class Loss: 0.0586, Discrepancy Loss: 0.0935
Epoch [16/50], Class Loss: 0.0622, Discrepancy Loss: 0.0884
Epoch [17/50], Class Loss: 0.0642, Discrepancy Loss: 0.0770
Epoch [18/50], Class Loss: 0.0334, Discrepancy Loss: 0.0944
Epoch [19/50], Class Loss: 0.0327, Discrepancy Loss: 0.0929
Epoch [20/50], Class Loss: 0.0153, Discrepancy Loss: 0.1160
Epoch [21/50], Class Loss: 0.0206, Discrepancy Loss: 0.1118
Epoch [22/50], Class Loss: 0.0119, Discrepancy Loss: 0.1073
Epoch [23/50], Class Loss: 0.0326, Discrepancy Loss: 0.0927
Epoch [24/50], Class Loss: 0.0357, Discrepancy Loss: 0.0933
Epoch [25/50], Class Loss: 0.0427, Discrepancy Loss: 0.0981
Epoch [26/50], Class Loss: 0.0422, Discrepancy Loss: 0.1022
Epoch [27/50], Class Loss: 0.0355, Discrepancy Loss: 0.1049
Epoch [28/50], Class Loss: 0.0291, Discrepancy Loss: 0.1064
Epoch [29/50], Class Loss: 0.0297, Discrepancy Loss: 0.1041
Epoch [30/50], Class Loss: 0.0370, Discrepancy Loss: 0.1081
Epoch [31/50], Class Loss: 0.0273, Discrepancy Loss: 0.1032
Epoch [32/50], Class Loss: 0.0244, Discrepancy Loss: 0.1055
Epoch [33/50], Class Loss: 0.0308, Discrepancy Loss: 0.1020
Epoch [34/50], Class Loss: 0.0306, Discrepancy Loss: 0.1132
Epoch [35/50], Class Loss: 0.0263, Discrepancy Loss: 0.1040
Epoch [36/50], Class Loss: 0.0315, Discrepancy Loss: 0.1070
Epoch [37/50], Class Loss: 0.0314, Discrepancy Loss: 0.1043
Epoch [38/50], Class Loss: 0.0354, Discrepancy Loss: 0.1084
Epoch [39/50], Class Loss: 0.0262, Discrepancy Loss: 0.1044
Epoch [40/50], Class Loss: 0.0281, Discrepancy Loss: 0.1091
Epoch [41/50], Class Loss: 0.0363, Discrepancy Loss: 0.1041
Epoch [42/50], Class Loss: 0.0287, Discrepancy Loss: 0.1069
Epoch [43/50], Class Loss: 0.0295, Discrepancy Loss: 0.1090
Epoch [44/50], Class Loss: 0.0296, Discrepancy Loss: 0.1108
Epoch [45/50], Class Loss: 0.0306, Discrepancy Loss: 0.1097
Epoch [46/50], Class Loss: 0.0323, Discrepancy Loss: 0.1047
Epoch [47/50], Class Loss: 0.0282, Discrepancy Loss: 0.1076
Epoch [48/50], Class Loss: 0.0284, Discrepancy Loss: 0.1098
Epoch [49/50], Class Loss: 0.0259, Discrepancy Loss: 0.1084
Epoch [50/50], Class Loss: 0.0358, Discrepancy Loss: 0.1081
Source Domain Performance - Accuracy: 99.76%, Precision: 99.75%, Recall: 99.75%, F1 Score: 99.75%
Target Domain Performance - Accuracy: 68.75%, Precision: 72.69%, Recall: 69.39%, F1 Score: 62.36%

Run 2/10
Epoch [1/50], Class Loss: 3.3860, Discrepancy Loss: 0.0875
Epoch [2/50], Class Loss: 0.9310, Discrepancy Loss: 0.0946
Epoch [3/50], Class Loss: 0.7265, Discrepancy Loss: 0.0810
Epoch [4/50], Class Loss: 0.4393, Discrepancy Loss: 0.0845
Epoch [5/50], Class Loss: 0.3957, Discrepancy Loss: 0.0757
Epoch [6/50], Class Loss: 0.3437, Discrepancy Loss: 0.0750
Epoch [7/50], Class Loss: 0.3250, Discrepancy Loss: 0.0727
Epoch [8/50], Class Loss: 0.2347, Discrepancy Loss: 0.0733
Epoch [9/50], Class Loss: 0.2051, Discrepancy Loss: 0.0836
Epoch [10/50], Class Loss: 0.2627, Discrepancy Loss: 0.0815
Epoch [11/50], Class Loss: 0.0513, Discrepancy Loss: 0.1010
Epoch [12/50], Class Loss: 0.0524, Discrepancy Loss: 0.0923
Epoch [13/50], Class Loss: 0.0330, Discrepancy Loss: 0.1117
Epoch [14/50], Class Loss: 0.0464, Discrepancy Loss: 0.1126
Epoch [15/50], Class Loss: 0.0340, Discrepancy Loss: 0.0993
Epoch [16/50], Class Loss: 0.0372, Discrepancy Loss: 0.1008
Epoch [17/50], Class Loss: 0.0370, Discrepancy Loss: 0.0971
Epoch [18/50], Class Loss: 0.0386, Discrepancy Loss: 0.0921
Epoch [19/50], Class Loss: 0.0276, Discrepancy Loss: 0.0967
Epoch [20/50], Class Loss: 0.0284, Discrepancy Loss: 0.1109
Epoch [21/50], Class Loss: 0.0153, Discrepancy Loss: 0.1213
Epoch [22/50], Class Loss: 0.0162, Discrepancy Loss: 0.1166
Epoch [23/50], Class Loss: 0.0329, Discrepancy Loss: 0.1067
Epoch [24/50], Class Loss: 0.0312, Discrepancy Loss: 0.1026
Epoch [25/50], Class Loss: 0.0363, Discrepancy Loss: 0.1054
Epoch [26/50], Class Loss: 0.0367, Discrepancy Loss: 0.1091
Epoch [27/50], Class Loss: 0.0319, Discrepancy Loss: 0.1120
Epoch [28/50], Class Loss: 0.0321, Discrepancy Loss: 0.1050
Epoch [29/50], Class Loss: 0.0325, Discrepancy Loss: 0.1030
Epoch [30/50], Class Loss: 0.0316, Discrepancy Loss: 0.1004
Epoch [31/50], Class Loss: 0.0391, Discrepancy Loss: 0.1043
Epoch [32/50], Class Loss: 0.0354, Discrepancy Loss: 0.1072
Epoch [33/50], Class Loss: 0.0354, Discrepancy Loss: 0.1110
Epoch [34/50], Class Loss: 0.0280, Discrepancy Loss: 0.1065
Epoch [35/50], Class Loss: 0.0334, Discrepancy Loss: 0.1082
Epoch [36/50], Class Loss: 0.0361, Discrepancy Loss: 0.1091
Epoch [37/50], Class Loss: 0.0373, Discrepancy Loss: 0.1041
Epoch [38/50], Class Loss: 0.0355, Discrepancy Loss: 0.1047
Epoch [39/50], Class Loss: 0.0363, Discrepancy Loss: 0.1060
Epoch [40/50], Class Loss: 0.0390, Discrepancy Loss: 0.1085
Epoch [41/50], Class Loss: 0.0328, Discrepancy Loss: 0.1062
Epoch [42/50], Class Loss: 0.0331, Discrepancy Loss: 0.1088
Epoch [43/50], Class Loss: 0.0360, Discrepancy Loss: 0.1054
Epoch [44/50], Class Loss: 0.0338, Discrepancy Loss: 0.1033
Epoch [45/50], Class Loss: 0.0415, Discrepancy Loss: 0.1059
Epoch [46/50], Class Loss: 0.0308, Discrepancy Loss: 0.1083
Epoch [47/50], Class Loss: 0.0271, Discrepancy Loss: 0.1072
Epoch [48/50], Class Loss: 0.0344, Discrepancy Loss: 0.1010
Epoch [49/50], Class Loss: 0.0353, Discrepancy Loss: 0.1051
Epoch [50/50], Class Loss: 0.0349, Discrepancy Loss: 0.1039
Source Domain Performance - Accuracy: 91.06%, Precision: 93.53%, Recall: 90.86%, F1 Score: 90.34%
Target Domain Performance - Accuracy: 62.50%, Precision: 59.40%, Recall: 62.81%, F1 Score: 58.61%

Run 3/10
Epoch [1/50], Class Loss: 3.7450, Discrepancy Loss: 0.1043
Epoch [2/50], Class Loss: 0.6719, Discrepancy Loss: 0.0910
Epoch [3/50], Class Loss: 0.5675, Discrepancy Loss: 0.0860
Epoch [4/50], Class Loss: 0.3949, Discrepancy Loss: 0.0824
Epoch [5/50], Class Loss: 0.4805, Discrepancy Loss: 0.0696
Epoch [6/50], Class Loss: 0.2948, Discrepancy Loss: 0.0668
Epoch [7/50], Class Loss: 0.3541, Discrepancy Loss: 0.0750
Epoch [8/50], Class Loss: 0.2194, Discrepancy Loss: 0.0784
Epoch [9/50], Class Loss: 0.1579, Discrepancy Loss: 0.0684
Epoch [10/50], Class Loss: 0.1424, Discrepancy Loss: 0.0795
Epoch [11/50], Class Loss: 0.0664, Discrepancy Loss: 0.0809
Epoch [12/50], Class Loss: 0.0347, Discrepancy Loss: 0.0784
Epoch [13/50], Class Loss: 0.0296, Discrepancy Loss: 0.0809
Epoch [14/50], Class Loss: 0.0383, Discrepancy Loss: 0.0729
Epoch [15/50], Class Loss: 0.0483, Discrepancy Loss: 0.0798
Epoch [16/50], Class Loss: 0.0441, Discrepancy Loss: 0.0761
Epoch [17/50], Class Loss: 0.0333, Discrepancy Loss: 0.0879
Epoch [18/50], Class Loss: 0.0355, Discrepancy Loss: 0.0953
Epoch [19/50], Class Loss: 0.0250, Discrepancy Loss: 0.0985
Epoch [20/50], Class Loss: 0.0255, Discrepancy Loss: 0.0992
Epoch [21/50], Class Loss: 0.0134, Discrepancy Loss: 0.1105
Epoch [22/50], Class Loss: 0.0151, Discrepancy Loss: 0.1107
Epoch [23/50], Class Loss: 0.0193, Discrepancy Loss: 0.0987
Epoch [24/50], Class Loss: 0.0146, Discrepancy Loss: 0.1202
Epoch [25/50], Class Loss: 0.0228, Discrepancy Loss: 0.1043
Epoch [26/50], Class Loss: 0.0154, Discrepancy Loss: 0.1179
Epoch [27/50], Class Loss: 0.0146, Discrepancy Loss: 0.1088
Epoch [28/50], Class Loss: 0.0143, Discrepancy Loss: 0.1132
Epoch [29/50], Class Loss: 0.0155, Discrepancy Loss: 0.1162
Epoch [30/50], Class Loss: 0.0115, Discrepancy Loss: 0.0998
Epoch [31/50], Class Loss: 0.0130, Discrepancy Loss: 0.1050
Epoch [32/50], Class Loss: 0.0137, Discrepancy Loss: 0.1070
Epoch [33/50], Class Loss: 0.0147, Discrepancy Loss: 0.0814
Epoch [34/50], Class Loss: 0.0160, Discrepancy Loss: 0.0740
Epoch [35/50], Class Loss: 0.0145, Discrepancy Loss: 0.0700
Epoch [36/50], Class Loss: 0.0139, Discrepancy Loss: 0.0692
Epoch [37/50], Class Loss: 0.0193, Discrepancy Loss: 0.0685
Epoch [38/50], Class Loss: 0.0166, Discrepancy Loss: 0.0664
Epoch [39/50], Class Loss: 0.0176, Discrepancy Loss: 0.0669
Epoch [40/50], Class Loss: 0.0142, Discrepancy Loss: 0.0671
Epoch [41/50], Class Loss: 0.0164, Discrepancy Loss: 0.0639
Epoch [42/50], Class Loss: 0.0151, Discrepancy Loss: 0.0681
Epoch [43/50], Class Loss: 0.0200, Discrepancy Loss: 0.0689
Epoch [44/50], Class Loss: 0.0153, Discrepancy Loss: 0.0699
Epoch [45/50], Class Loss: 0.0182, Discrepancy Loss: 0.0674
Epoch [46/50], Class Loss: 0.0184, Discrepancy Loss: 0.0686
Epoch [47/50], Class Loss: 0.0182, Discrepancy Loss: 0.0677
Epoch [48/50], Class Loss: 0.0209, Discrepancy Loss: 0.0672
Epoch [49/50], Class Loss: 0.0184, Discrepancy Loss: 0.0691
Epoch [50/50], Class Loss: 0.0162, Discrepancy Loss: 0.0673
Source Domain Performance - Accuracy: 95.46%, Precision: 96.12%, Recall: 95.36%, F1 Score: 95.28%
Target Domain Performance - Accuracy: 71.02%, Precision: 64.99%, Recall: 71.70%, F1 Score: 65.88%

Run 4/10
Epoch [1/50], Class Loss: 3.0537, Discrepancy Loss: 0.0918
Epoch [2/50], Class Loss: 0.7294, Discrepancy Loss: 0.0851
Epoch [3/50], Class Loss: 0.6029, Discrepancy Loss: 0.0781
Epoch [4/50], Class Loss: 0.4371, Discrepancy Loss: 0.0784
Epoch [5/50], Class Loss: 0.5745, Discrepancy Loss: 0.0821
Epoch [6/50], Class Loss: 0.4789, Discrepancy Loss: 0.0806
Epoch [7/50], Class Loss: 0.3891, Discrepancy Loss: 0.0791
Epoch [8/50], Class Loss: 0.3083, Discrepancy Loss: 0.0732
Epoch [9/50], Class Loss: 0.3055, Discrepancy Loss: 0.0925
Epoch [10/50], Class Loss: 0.1873, Discrepancy Loss: 0.0717
Epoch [11/50], Class Loss: 0.0639, Discrepancy Loss: 0.0928
Epoch [12/50], Class Loss: 0.0568, Discrepancy Loss: 0.0956
Epoch [13/50], Class Loss: 0.0535, Discrepancy Loss: 0.0835
Epoch [14/50], Class Loss: 0.0606, Discrepancy Loss: 0.0776
Epoch [15/50], Class Loss: 0.0460, Discrepancy Loss: 0.0770
Epoch [16/50], Class Loss: 0.0359, Discrepancy Loss: 0.0825
Epoch [17/50], Class Loss: 0.0362, Discrepancy Loss: 0.0883
Epoch [18/50], Class Loss: 0.0286, Discrepancy Loss: 0.0807
Epoch [19/50], Class Loss: 0.0300, Discrepancy Loss: 0.0922
Epoch [20/50], Class Loss: 0.0340, Discrepancy Loss: 0.0915
Epoch [21/50], Class Loss: 0.0252, Discrepancy Loss: 0.0873
Epoch [22/50], Class Loss: 0.0231, Discrepancy Loss: 0.0876
Epoch [23/50], Class Loss: 0.0266, Discrepancy Loss: 0.0857
Epoch [24/50], Class Loss: 0.0235, Discrepancy Loss: 0.0848
Epoch [25/50], Class Loss: 0.0248, Discrepancy Loss: 0.0842
Epoch [26/50], Class Loss: 0.0234, Discrepancy Loss: 0.0873
Epoch [27/50], Class Loss: 0.0259, Discrepancy Loss: 0.0901
Epoch [28/50], Class Loss: 0.0241, Discrepancy Loss: 0.0899
Epoch [29/50], Class Loss: 0.0222, Discrepancy Loss: 0.0841
Epoch [30/50], Class Loss: 0.0220, Discrepancy Loss: 0.0884
Epoch [31/50], Class Loss: 0.0244, Discrepancy Loss: 0.0797
Epoch [32/50], Class Loss: 0.0224, Discrepancy Loss: 0.0687
Epoch [33/50], Class Loss: 0.0249, Discrepancy Loss: 0.0689
Epoch [34/50], Class Loss: 0.0234, Discrepancy Loss: 0.0676
Epoch [35/50], Class Loss: 0.0201, Discrepancy Loss: 0.0692
Epoch [36/50], Class Loss: 0.0222, Discrepancy Loss: 0.0702
Epoch [37/50], Class Loss: 0.0182, Discrepancy Loss: 0.0712
Epoch [38/50], Class Loss: 0.0217, Discrepancy Loss: 0.0693
Epoch [39/50], Class Loss: 0.0225, Discrepancy Loss: 0.0701
Epoch [40/50], Class Loss: 0.0206, Discrepancy Loss: 0.0735
Epoch [41/50], Class Loss: 0.0208, Discrepancy Loss: 0.0694
Epoch [42/50], Class Loss: 0.0285, Discrepancy Loss: 0.0748
Epoch [43/50], Class Loss: 0.0227, Discrepancy Loss: 0.0698
Epoch [44/50], Class Loss: 0.0230, Discrepancy Loss: 0.0709
Epoch [45/50], Class Loss: 0.0237, Discrepancy Loss: 0.0683
Epoch [46/50], Class Loss: 0.0203, Discrepancy Loss: 0.0683
Epoch [47/50], Class Loss: 0.0225, Discrepancy Loss: 0.0727
Epoch [48/50], Class Loss: 0.0200, Discrepancy Loss: 0.0690
Epoch [49/50], Class Loss: 0.0207, Discrepancy Loss: 0.0715
Epoch [50/50], Class Loss: 0.0233, Discrepancy Loss: 0.0729
Source Domain Performance - Accuracy: 98.90%, Precision: 98.91%, Recall: 98.88%, F1 Score: 98.87%
Target Domain Performance - Accuracy: 72.78%, Precision: 71.11%, Recall: 73.50%, F1 Score: 67.29%

Run 5/10
Epoch [1/50], Class Loss: 3.4661, Discrepancy Loss: 0.0934
Epoch [2/50], Class Loss: 0.7736, Discrepancy Loss: 0.0961
Epoch [3/50], Class Loss: 0.5341, Discrepancy Loss: 0.0867
Epoch [4/50], Class Loss: 0.4986, Discrepancy Loss: 0.0846
Epoch [5/50], Class Loss: 0.4508, Discrepancy Loss: 0.0777
Epoch [6/50], Class Loss: 0.2940, Discrepancy Loss: 0.0871
Epoch [7/50], Class Loss: 0.2797, Discrepancy Loss: 0.0848
Epoch [8/50], Class Loss: 0.2024, Discrepancy Loss: 0.0944
Epoch [9/50], Class Loss: 0.1499, Discrepancy Loss: 0.0788
Epoch [10/50], Class Loss: 0.1583, Discrepancy Loss: 0.0803
Epoch [11/50], Class Loss: 0.0811, Discrepancy Loss: 0.1023
Epoch [12/50], Class Loss: 0.0487, Discrepancy Loss: 0.0988
Epoch [13/50], Class Loss: 0.0410, Discrepancy Loss: 0.0976
Epoch [14/50], Class Loss: 0.0425, Discrepancy Loss: 0.0854
Epoch [15/50], Class Loss: 0.0519, Discrepancy Loss: 0.0935
Epoch [16/50], Class Loss: 0.0465, Discrepancy Loss: 0.0922
Epoch [17/50], Class Loss: 0.0421, Discrepancy Loss: 0.0936
Epoch [18/50], Class Loss: 0.0323, Discrepancy Loss: 0.0952
Epoch [19/50], Class Loss: 0.0379, Discrepancy Loss: 0.0978
Epoch [20/50], Class Loss: 0.0308, Discrepancy Loss: 0.1083
Epoch [21/50], Class Loss: 0.0181, Discrepancy Loss: 0.1066
Epoch [22/50], Class Loss: 0.0183, Discrepancy Loss: 0.1064
Epoch [23/50], Class Loss: 0.0173, Discrepancy Loss: 0.1149
Epoch [24/50], Class Loss: 0.0251, Discrepancy Loss: 0.1150
Epoch [25/50], Class Loss: 0.0279, Discrepancy Loss: 0.1074
Epoch [26/50], Class Loss: 0.0188, Discrepancy Loss: 0.1138
Epoch [27/50], Class Loss: 0.0226, Discrepancy Loss: 0.1130
Epoch [28/50], Class Loss: 0.0207, Discrepancy Loss: 0.0997
Epoch [29/50], Class Loss: 0.0334, Discrepancy Loss: 0.1031
Epoch [30/50], Class Loss: 0.0151, Discrepancy Loss: 0.0923
Epoch [31/50], Class Loss: 0.0192, Discrepancy Loss: 0.1081
Epoch [32/50], Class Loss: 0.0138, Discrepancy Loss: 0.1155
Epoch [33/50], Class Loss: 0.0101, Discrepancy Loss: 0.1180
Epoch [34/50], Class Loss: 0.0136, Discrepancy Loss: 0.1132
Epoch [35/50], Class Loss: 0.0099, Discrepancy Loss: 0.1170
Epoch [36/50], Class Loss: 0.0107, Discrepancy Loss: 0.1130
Epoch [37/50], Class Loss: 0.0158, Discrepancy Loss: 0.1188
Epoch [38/50], Class Loss: 0.0121, Discrepancy Loss: 0.1182
Epoch [39/50], Class Loss: 0.0146, Discrepancy Loss: 0.1190
Epoch [40/50], Class Loss: 0.0148, Discrepancy Loss: 0.1145
Epoch [41/50], Class Loss: 0.0150, Discrepancy Loss: 0.1193
Epoch [42/50], Class Loss: 0.0104, Discrepancy Loss: 0.1188
Epoch [43/50], Class Loss: 0.0124, Discrepancy Loss: 0.1176
Epoch [44/50], Class Loss: 0.0111, Discrepancy Loss: 0.1221
Epoch [45/50], Class Loss: 0.0140, Discrepancy Loss: 0.1180
Epoch [46/50], Class Loss: 0.0139, Discrepancy Loss: 0.1173
Epoch [47/50], Class Loss: 0.0115, Discrepancy Loss: 0.1191
Epoch [48/50], Class Loss: 0.0203, Discrepancy Loss: 0.1182
Epoch [49/50], Class Loss: 0.0159, Discrepancy Loss: 0.1154
Epoch [50/50], Class Loss: 0.0112, Discrepancy Loss: 0.1200
Source Domain Performance - Accuracy: 99.73%, Precision: 99.73%, Recall: 99.72%, F1 Score: 99.73%
Target Domain Performance - Accuracy: 75.93%, Precision: 77.63%, Recall: 76.60%, F1 Score: 69.55%

Run 6/10
Epoch [1/50], Class Loss: 2.8626, Discrepancy Loss: 0.0934
Epoch [2/50], Class Loss: 0.7294, Discrepancy Loss: 0.0920
Epoch [3/50], Class Loss: 0.6129, Discrepancy Loss: 0.0839
Epoch [4/50], Class Loss: 0.4623, Discrepancy Loss: 0.0825
Epoch [5/50], Class Loss: 0.4320, Discrepancy Loss: 0.0829
Epoch [6/50], Class Loss: 0.3208, Discrepancy Loss: 0.0781
Epoch [7/50], Class Loss: 0.2760, Discrepancy Loss: 0.0716
Epoch [8/50], Class Loss: 0.3072, Discrepancy Loss: 0.0802
Epoch [9/50], Class Loss: 0.1531, Discrepancy Loss: 0.0771
Epoch [10/50], Class Loss: 0.1652, Discrepancy Loss: 0.0816
Epoch [11/50], Class Loss: 0.0694, Discrepancy Loss: 0.0928
Epoch [12/50], Class Loss: 0.0435, Discrepancy Loss: 0.0866
Epoch [13/50], Class Loss: 0.0412, Discrepancy Loss: 0.0776
Epoch [14/50], Class Loss: 0.0535, Discrepancy Loss: 0.0830
Epoch [15/50], Class Loss: 0.0764, Discrepancy Loss: 0.1051
Epoch [16/50], Class Loss: 0.0503, Discrepancy Loss: 0.0865
Epoch [17/50], Class Loss: 0.0436, Discrepancy Loss: 0.0904
Epoch [18/50], Class Loss: 0.0290, Discrepancy Loss: 0.0857
Epoch [19/50], Class Loss: 0.0333, Discrepancy Loss: 0.0959
Epoch [20/50], Class Loss: 0.0281, Discrepancy Loss: 0.0958
Epoch [21/50], Class Loss: 0.0157, Discrepancy Loss: 0.1071
Epoch [22/50], Class Loss: 0.0174, Discrepancy Loss: 0.0941
Epoch [23/50], Class Loss: 0.0178, Discrepancy Loss: 0.0967
Epoch [24/50], Class Loss: 0.0197, Discrepancy Loss: 0.0986
Epoch [25/50], Class Loss: 0.0184, Discrepancy Loss: 0.0990
Epoch [26/50], Class Loss: 0.0163, Discrepancy Loss: 0.1033
Epoch [27/50], Class Loss: 0.0199, Discrepancy Loss: 0.1072
Epoch [28/50], Class Loss: 0.0148, Discrepancy Loss: 0.1004
Epoch [29/50], Class Loss: 0.0223, Discrepancy Loss: 0.0949
Epoch [30/50], Class Loss: 0.0156, Discrepancy Loss: 0.1028
Epoch [31/50], Class Loss: 0.0131, Discrepancy Loss: 0.1026
Epoch [32/50], Class Loss: 0.0137, Discrepancy Loss: 0.0856
Epoch [33/50], Class Loss: 0.0212, Discrepancy Loss: 0.0815
Epoch [34/50], Class Loss: 0.0176, Discrepancy Loss: 0.0817
Epoch [35/50], Class Loss: 0.0156, Discrepancy Loss: 0.0786
Epoch [36/50], Class Loss: 0.0157, Discrepancy Loss: 0.0843
Epoch [37/50], Class Loss: 0.0168, Discrepancy Loss: 0.0849
Epoch [38/50], Class Loss: 0.0156, Discrepancy Loss: 0.0818
Epoch [39/50], Class Loss: 0.0184, Discrepancy Loss: 0.0821
Epoch [40/50], Class Loss: 0.0229, Discrepancy Loss: 0.0863
Epoch [41/50], Class Loss: 0.0204, Discrepancy Loss: 0.0831
Epoch [42/50], Class Loss: 0.0245, Discrepancy Loss: 0.0877
Epoch [43/50], Class Loss: 0.0202, Discrepancy Loss: 0.0841
Epoch [44/50], Class Loss: 0.0227, Discrepancy Loss: 0.0872
Epoch [45/50], Class Loss: 0.0191, Discrepancy Loss: 0.0906
Epoch [46/50], Class Loss: 0.0184, Discrepancy Loss: 0.0880
Epoch [47/50], Class Loss: 0.0220, Discrepancy Loss: 0.0854
Epoch [48/50], Class Loss: 0.0248, Discrepancy Loss: 0.0851
Epoch [49/50], Class Loss: 0.0242, Discrepancy Loss: 0.0879
Epoch [50/50], Class Loss: 0.0188, Discrepancy Loss: 0.0902
Source Domain Performance - Accuracy: 97.83%, Precision: 97.94%, Recall: 97.78%, F1 Score: 97.76%
Target Domain Performance - Accuracy: 71.58%, Precision: 64.89%, Recall: 72.21%, F1 Score: 66.06%

Run 7/10
Epoch [1/50], Class Loss: 3.1163, Discrepancy Loss: 0.0914
Epoch [2/50], Class Loss: 0.8129, Discrepancy Loss: 0.0928
Epoch [3/50], Class Loss: 0.5513, Discrepancy Loss: 0.0874
Epoch [4/50], Class Loss: 0.7915, Discrepancy Loss: 0.0878
Epoch [5/50], Class Loss: 0.5639, Discrepancy Loss: 0.0794
Epoch [6/50], Class Loss: 0.3732, Discrepancy Loss: 0.0718
Epoch [7/50], Class Loss: 0.2876, Discrepancy Loss: 0.0693
Epoch [8/50], Class Loss: 0.2316, Discrepancy Loss: 0.0647
Epoch [9/50], Class Loss: 0.2456, Discrepancy Loss: 0.0649
Epoch [10/50], Class Loss: 0.1670, Discrepancy Loss: 0.0801
Epoch [11/50], Class Loss: 0.0715, Discrepancy Loss: 0.0936
Epoch [12/50], Class Loss: 0.0623, Discrepancy Loss: 0.0846
Epoch [13/50], Class Loss: 0.0539, Discrepancy Loss: 0.0738
Epoch [14/50], Class Loss: 0.0418, Discrepancy Loss: 0.0836
Epoch [15/50], Class Loss: 0.0320, Discrepancy Loss: 0.0845
Epoch [16/50], Class Loss: 0.0329, Discrepancy Loss: 0.1014
Epoch [17/50], Class Loss: 0.0311, Discrepancy Loss: 0.0969
Epoch [18/50], Class Loss: 0.0178, Discrepancy Loss: 0.1055
Epoch [19/50], Class Loss: 0.0356, Discrepancy Loss: 0.1041
Epoch [20/50], Class Loss: 0.2000, Discrepancy Loss: 0.1076
Epoch [21/50], Class Loss: 1.5049, Discrepancy Loss: 0.1002
Epoch [22/50], Class Loss: 0.9200, Discrepancy Loss: 0.1057
Epoch [23/50], Class Loss: 0.6339, Discrepancy Loss: 0.1034
Epoch [24/50], Class Loss: 0.4510, Discrepancy Loss: 0.0944
Epoch [25/50], Class Loss: 0.3406, Discrepancy Loss: 0.0927
Epoch [26/50], Class Loss: 0.2848, Discrepancy Loss: 0.0903
Epoch [27/50], Class Loss: 0.2579, Discrepancy Loss: 0.0855
Epoch [28/50], Class Loss: 0.1563, Discrepancy Loss: 0.0816
Epoch [29/50], Class Loss: 0.0933, Discrepancy Loss: 0.0933
Epoch [30/50], Class Loss: 0.0778, Discrepancy Loss: 0.0978
Epoch [31/50], Class Loss: 0.0628, Discrepancy Loss: 0.0945
Epoch [32/50], Class Loss: 0.0549, Discrepancy Loss: 0.0977
Epoch [33/50], Class Loss: 0.0584, Discrepancy Loss: 0.1027
Epoch [34/50], Class Loss: 0.0685, Discrepancy Loss: 0.1013
Epoch [35/50], Class Loss: 0.0622, Discrepancy Loss: 0.0971
Epoch [36/50], Class Loss: 0.0626, Discrepancy Loss: 0.1016
Epoch [37/50], Class Loss: 0.0600, Discrepancy Loss: 0.1025
Epoch [38/50], Class Loss: 0.0536, Discrepancy Loss: 0.1029
Epoch [39/50], Class Loss: 0.0465, Discrepancy Loss: 0.1069
Epoch [40/50], Class Loss: 0.0443, Discrepancy Loss: 0.0982
Epoch [41/50], Class Loss: 0.0493, Discrepancy Loss: 0.1040
Epoch [42/50], Class Loss: 0.0466, Discrepancy Loss: 0.1085
Epoch [43/50], Class Loss: 0.0481, Discrepancy Loss: 0.1007
Epoch [44/50], Class Loss: 0.0527, Discrepancy Loss: 0.0994
Epoch [45/50], Class Loss: 0.0390, Discrepancy Loss: 0.0999
Epoch [46/50], Class Loss: 0.0467, Discrepancy Loss: 0.1071
Epoch [47/50], Class Loss: 0.0483, Discrepancy Loss: 0.0990
Epoch [48/50], Class Loss: 0.0472, Discrepancy Loss: 0.1095
Epoch [49/50], Class Loss: 0.0381, Discrepancy Loss: 0.1105
Epoch [50/50], Class Loss: 0.0472, Discrepancy Loss: 0.1048
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 59.45%, Precision: 63.58%, Recall: 60.00%, F1 Score: 46.75%

Run 8/10
Epoch [1/50], Class Loss: 3.9915, Discrepancy Loss: 0.0889
Epoch [2/50], Class Loss: 0.6265, Discrepancy Loss: 0.0868
Epoch [3/50], Class Loss: 0.5637, Discrepancy Loss: 0.0724
Epoch [4/50], Class Loss: 0.3611, Discrepancy Loss: 0.0697
Epoch [5/50], Class Loss: 0.3540, Discrepancy Loss: 0.0662
Epoch [6/50], Class Loss: 0.4043, Discrepancy Loss: 0.0708
Epoch [7/50], Class Loss: 0.2635, Discrepancy Loss: 0.0674
Epoch [8/50], Class Loss: 0.2346, Discrepancy Loss: 0.0712
Epoch [9/50], Class Loss: 0.1982, Discrepancy Loss: 0.0817
Epoch [10/50], Class Loss: 0.1682, Discrepancy Loss: 0.0693
Epoch [11/50], Class Loss: 0.1264, Discrepancy Loss: 0.0548
Epoch [12/50], Class Loss: 0.0674, Discrepancy Loss: 0.0641
Epoch [13/50], Class Loss: 0.0482, Discrepancy Loss: 0.0598
Epoch [14/50], Class Loss: 0.0423, Discrepancy Loss: 0.0731
Epoch [15/50], Class Loss: 0.0427, Discrepancy Loss: 0.0823
Epoch [16/50], Class Loss: 0.0475, Discrepancy Loss: 0.0827
Epoch [17/50], Class Loss: 0.0344, Discrepancy Loss: 0.0773
Epoch [18/50], Class Loss: 0.0517, Discrepancy Loss: 0.0838
Epoch [19/50], Class Loss: 0.0372, Discrepancy Loss: 0.0846
Epoch [20/50], Class Loss: 0.1014, Discrepancy Loss: 0.0822
Epoch [21/50], Class Loss: 0.0476, Discrepancy Loss: 0.0902
Epoch [22/50], Class Loss: 0.0410, Discrepancy Loss: 0.0877
Epoch [23/50], Class Loss: 0.0432, Discrepancy Loss: 0.0824
Epoch [24/50], Class Loss: 0.0397, Discrepancy Loss: 0.0849
Epoch [25/50], Class Loss: 0.0321, Discrepancy Loss: 0.0835
Epoch [26/50], Class Loss: 0.0300, Discrepancy Loss: 0.0875
Epoch [27/50], Class Loss: 0.0258, Discrepancy Loss: 0.0867
Epoch [28/50], Class Loss: 0.0297, Discrepancy Loss: 0.0878
Epoch [29/50], Class Loss: 0.0299, Discrepancy Loss: 0.0945
Epoch [30/50], Class Loss: 0.0342, Discrepancy Loss: 0.0975
Epoch [31/50], Class Loss: 0.0306, Discrepancy Loss: 0.1021
Epoch [32/50], Class Loss: 0.0273, Discrepancy Loss: 0.0955
Epoch [33/50], Class Loss: 0.0305, Discrepancy Loss: 0.1039
Epoch [34/50], Class Loss: 0.0320, Discrepancy Loss: 0.0997
Epoch [35/50], Class Loss: 0.0322, Discrepancy Loss: 0.1019
Epoch [36/50], Class Loss: 0.0310, Discrepancy Loss: 0.0934
Epoch [37/50], Class Loss: 0.0306, Discrepancy Loss: 0.0978
Epoch [38/50], Class Loss: 0.0267, Discrepancy Loss: 0.0997
Epoch [39/50], Class Loss: 0.0281, Discrepancy Loss: 0.1022
Epoch [40/50], Class Loss: 0.0300, Discrepancy Loss: 0.0985
Epoch [41/50], Class Loss: 0.0318, Discrepancy Loss: 0.1003
Epoch [42/50], Class Loss: 0.0313, Discrepancy Loss: 0.1023
Epoch [43/50], Class Loss: 0.0327, Discrepancy Loss: 0.1022
Epoch [44/50], Class Loss: 0.0298, Discrepancy Loss: 0.0983
Epoch [45/50], Class Loss: 0.0322, Discrepancy Loss: 0.0998
Epoch [46/50], Class Loss: 0.0309, Discrepancy Loss: 0.1064
Epoch [47/50], Class Loss: 0.0343, Discrepancy Loss: 0.1009
Epoch [48/50], Class Loss: 0.0307, Discrepancy Loss: 0.1036
Epoch [49/50], Class Loss: 0.0301, Discrepancy Loss: 0.0985
Epoch [50/50], Class Loss: 0.0343, Discrepancy Loss: 0.0995
Source Domain Performance - Accuracy: 98.22%, Precision: 98.29%, Recall: 98.18%, F1 Score: 98.17%
Target Domain Performance - Accuracy: 76.15%, Precision: 74.00%, Recall: 76.71%, F1 Score: 71.08%

Run 9/10
Epoch [1/50], Class Loss: 3.3930, Discrepancy Loss: 0.0951
Epoch [2/50], Class Loss: 0.7350, Discrepancy Loss: 0.0933
Epoch [3/50], Class Loss: 0.5147, Discrepancy Loss: 0.0817
Epoch [4/50], Class Loss: 0.4709, Discrepancy Loss: 0.0834
Epoch [5/50], Class Loss: 0.3899, Discrepancy Loss: 0.0917
Epoch [6/50], Class Loss: 0.2795, Discrepancy Loss: 0.0810
Epoch [7/50], Class Loss: 0.2588, Discrepancy Loss: 0.0706
Epoch [8/50], Class Loss: 0.2104, Discrepancy Loss: 0.0794
Epoch [9/50], Class Loss: 0.1788, Discrepancy Loss: 0.0734
Epoch [10/50], Class Loss: 0.1325, Discrepancy Loss: 0.0682
Epoch [11/50], Class Loss: 0.0479, Discrepancy Loss: 0.0658
Epoch [12/50], Class Loss: 0.0379, Discrepancy Loss: 0.0690
Epoch [13/50], Class Loss: 0.0286, Discrepancy Loss: 0.0758
Epoch [14/50], Class Loss: 0.0364, Discrepancy Loss: 0.0817
Epoch [15/50], Class Loss: 0.0325, Discrepancy Loss: 0.0920
Epoch [16/50], Class Loss: 0.0347, Discrepancy Loss: 0.0894
Epoch [17/50], Class Loss: 0.0339, Discrepancy Loss: 0.0948
Epoch [18/50], Class Loss: 0.0377, Discrepancy Loss: 0.0967
Epoch [19/50], Class Loss: 0.0207, Discrepancy Loss: 0.1014
Epoch [20/50], Class Loss: 0.0255, Discrepancy Loss: 0.0906
Epoch [21/50], Class Loss: 0.0256, Discrepancy Loss: 0.0861
Epoch [22/50], Class Loss: 0.0236, Discrepancy Loss: 0.0840
Epoch [23/50], Class Loss: 0.0263, Discrepancy Loss: 0.0823
Epoch [24/50], Class Loss: 0.0201, Discrepancy Loss: 0.0825
Epoch [25/50], Class Loss: 0.0241, Discrepancy Loss: 0.0815
Epoch [26/50], Class Loss: 0.0198, Discrepancy Loss: 0.0819
Epoch [27/50], Class Loss: 0.0219, Discrepancy Loss: 0.0816
Epoch [28/50], Class Loss: 0.0210, Discrepancy Loss: 0.0804
Epoch [29/50], Class Loss: 0.0188, Discrepancy Loss: 0.0843
Epoch [30/50], Class Loss: 0.0253, Discrepancy Loss: 0.0865
Epoch [31/50], Class Loss: 0.0222, Discrepancy Loss: 0.0731
Epoch [32/50], Class Loss: 0.0243, Discrepancy Loss: 0.0699
Epoch [33/50], Class Loss: 0.0262, Discrepancy Loss: 0.0715
Epoch [34/50], Class Loss: 0.0217, Discrepancy Loss: 0.0739
Epoch [35/50], Class Loss: 0.0237, Discrepancy Loss: 0.0669
Epoch [36/50], Class Loss: 0.0261, Discrepancy Loss: 0.0724
Epoch [37/50], Class Loss: 0.0264, Discrepancy Loss: 0.0694
Epoch [38/50], Class Loss: 0.0266, Discrepancy Loss: 0.0721
Epoch [39/50], Class Loss: 0.0241, Discrepancy Loss: 0.0711
Epoch [40/50], Class Loss: 0.0247, Discrepancy Loss: 0.0703
Epoch [41/50], Class Loss: 0.0253, Discrepancy Loss: 0.0684
Epoch [42/50], Class Loss: 0.0243, Discrepancy Loss: 0.0735
Epoch [43/50], Class Loss: 0.0244, Discrepancy Loss: 0.0741
Epoch [44/50], Class Loss: 0.0216, Discrepancy Loss: 0.0688
Epoch [45/50], Class Loss: 0.0249, Discrepancy Loss: 0.0733
Epoch [46/50], Class Loss: 0.0253, Discrepancy Loss: 0.0671
Epoch [47/50], Class Loss: 0.0265, Discrepancy Loss: 0.0722
Epoch [48/50], Class Loss: 0.0274, Discrepancy Loss: 0.0719
Epoch [49/50], Class Loss: 0.0293, Discrepancy Loss: 0.0742
Epoch [50/50], Class Loss: 0.0234, Discrepancy Loss: 0.0700
Source Domain Performance - Accuracy: 92.41%, Precision: 94.30%, Recall: 92.24%, F1 Score: 91.91%
Target Domain Performance - Accuracy: 69.12%, Precision: 65.35%, Recall: 69.70%, F1 Score: 65.19%

Run 10/10
Epoch [1/50], Class Loss: 3.6915, Discrepancy Loss: 0.1006
Epoch [2/50], Class Loss: 0.8602, Discrepancy Loss: 0.0902
Epoch [3/50], Class Loss: 0.6003, Discrepancy Loss: 0.0875
Epoch [4/50], Class Loss: 0.4271, Discrepancy Loss: 0.0870
Epoch [5/50], Class Loss: 0.3922, Discrepancy Loss: 0.0852
Epoch [6/50], Class Loss: 0.3564, Discrepancy Loss: 0.0812
Epoch [7/50], Class Loss: 0.2545, Discrepancy Loss: 0.0836
Epoch [8/50], Class Loss: 0.3762, Discrepancy Loss: 0.0803
Epoch [9/50], Class Loss: 0.3110, Discrepancy Loss: 0.0685
Epoch [10/50], Class Loss: 0.1519, Discrepancy Loss: 0.0751
Epoch [11/50], Class Loss: 0.0650, Discrepancy Loss: 0.0844
Epoch [12/50], Class Loss: 0.0522, Discrepancy Loss: 0.0911
Epoch [13/50], Class Loss: 0.0461, Discrepancy Loss: 0.0882
Epoch [14/50], Class Loss: 0.0503, Discrepancy Loss: 0.0876
Epoch [15/50], Class Loss: 0.0470, Discrepancy Loss: 0.0811
Epoch [16/50], Class Loss: 0.0403, Discrepancy Loss: 0.0863
Epoch [17/50], Class Loss: 0.0474, Discrepancy Loss: 0.0814
Epoch [18/50], Class Loss: 0.0371, Discrepancy Loss: 0.0957
Epoch [19/50], Class Loss: 0.0413, Discrepancy Loss: 0.1059
Epoch [20/50], Class Loss: 0.0210, Discrepancy Loss: 0.0913
Epoch [21/50], Class Loss: 0.0238, Discrepancy Loss: 0.1029
Epoch [22/50], Class Loss: 0.0275, Discrepancy Loss: 0.1107
Epoch [23/50], Class Loss: 0.0244, Discrepancy Loss: 0.1106
Epoch [24/50], Class Loss: 0.0254, Discrepancy Loss: 0.1156
Epoch [25/50], Class Loss: 0.0289, Discrepancy Loss: 0.1113
Epoch [26/50], Class Loss: 0.0211, Discrepancy Loss: 0.1166
Epoch [27/50], Class Loss: 0.0296, Discrepancy Loss: 0.1155
Epoch [28/50], Class Loss: 0.0332, Discrepancy Loss: 0.1119
Epoch [29/50], Class Loss: 0.0217, Discrepancy Loss: 0.1194
Epoch [30/50], Class Loss: 0.0254, Discrepancy Loss: 0.1221
Epoch [31/50], Class Loss: 0.0246, Discrepancy Loss: 0.1180
Epoch [32/50], Class Loss: 0.0224, Discrepancy Loss: 0.1166
Epoch [33/50], Class Loss: 0.0213, Discrepancy Loss: 0.1114
Epoch [34/50], Class Loss: 0.0201, Discrepancy Loss: 0.1141
Epoch [35/50], Class Loss: 0.0224, Discrepancy Loss: 0.1176
Epoch [36/50], Class Loss: 0.0213, Discrepancy Loss: 0.1215
Epoch [37/50], Class Loss: 0.0283, Discrepancy Loss: 0.1208
Epoch [38/50], Class Loss: 0.0253, Discrepancy Loss: 0.1134
Epoch [39/50], Class Loss: 0.0242, Discrepancy Loss: 0.1244
Epoch [40/50], Class Loss: 0.0266, Discrepancy Loss: 0.1158
Epoch [41/50], Class Loss: 0.0251, Discrepancy Loss: 0.1202
Epoch [42/50], Class Loss: 0.0245, Discrepancy Loss: 0.1204
Epoch [43/50], Class Loss: 0.0328, Discrepancy Loss: 0.1192
Epoch [44/50], Class Loss: 0.0258, Discrepancy Loss: 0.1187
Epoch [45/50], Class Loss: 0.0254, Discrepancy Loss: 0.1172
Epoch [46/50], Class Loss: 0.0246, Discrepancy Loss: 0.1195
Epoch [47/50], Class Loss: 0.0238, Discrepancy Loss: 0.1135
Epoch [48/50], Class Loss: 0.0295, Discrepancy Loss: 0.1180
Epoch [49/50], Class Loss: 0.0246, Discrepancy Loss: 0.1174
Epoch [50/50], Class Loss: 0.0256, Discrepancy Loss: 0.1152
Source Domain Performance - Accuracy: 99.12%, Precision: 99.14%, Recall: 99.10%, F1 Score: 99.11%
Target Domain Performance - Accuracy: 65.23%, Precision: 65.72%, Recall: 65.84%, F1 Score: 59.00%

Source performance: 97.23% 97.76% 97.17% 97.08%
Target performance: 69.25% 67.94% 69.84% 63.18%

Per-Class Accuracy on Target Domain:
bpsk: 83.41%
qpsk: 2.00%
4qam: 73.15%
16qam: 90.86%
apsk: 99.81%

Run 1/10
Epoch [1/50], Class Loss: 2.9028, Discrepancy Loss: 0.0345
Validation Loss: 1.8671
Epoch [2/50], Class Loss: 1.2249, Discrepancy Loss: 0.0309
Validation Loss: 0.8422
Epoch [3/50], Class Loss: 1.4170, Discrepancy Loss: 0.0435
Validation Loss: 0.9627
Epoch [4/50], Class Loss: 1.6915, Discrepancy Loss: 0.0444
Validation Loss: 1.0763
Epoch [5/50], Class Loss: 1.6085, Discrepancy Loss: 0.0587
Validation Loss: 1.6807
Epoch [6/50], Class Loss: 0.5019, Discrepancy Loss: 0.0207
Validation Loss: 0.4309
Epoch [7/50], Class Loss: 0.9631, Discrepancy Loss: 0.0412
Validation Loss: 0.2020
Epoch [8/50], Class Loss: 0.7419, Discrepancy Loss: 0.0293
Validation Loss: 1.9805
Epoch [9/50], Class Loss: 1.4531, Discrepancy Loss: 0.0430
Validation Loss: 0.5212
Epoch [10/50], Class Loss: 0.5313, Discrepancy Loss: 0.0198
Validation Loss: 0.1563
Epoch [11/50], Class Loss: 0.0260, Discrepancy Loss: 0.0013
Validation Loss: 0.1845
Epoch [12/50], Class Loss: 0.0101, Discrepancy Loss: 0.0003
Validation Loss: 0.0319
Epoch [13/50], Class Loss: 0.1028, Discrepancy Loss: 0.0080
Validation Loss: 0.0394
Epoch [14/50], Class Loss: 0.0454, Discrepancy Loss: 0.0122
Validation Loss: 0.1234
Epoch [15/50], Class Loss: 0.3105, Discrepancy Loss: 0.0157
Validation Loss: 0.0325
Epoch [16/50], Class Loss: 0.0827, Discrepancy Loss: 0.0117
Validation Loss: 0.5175
Epoch [17/50], Class Loss: 0.1256, Discrepancy Loss: 0.0171
Validation Loss: 0.0325
Early stopping!
Source Domain Performance - Accuracy: 99.78%, Precision: 99.77%, Recall: 99.78%, F1 Score: 99.78%
Target Domain Performance - Accuracy: 50.59%, Precision: 68.05%, Recall: 50.88%, F1 Score: 39.02%

Run 2/10
Epoch [1/50], Class Loss: 2.9589, Discrepancy Loss: 0.0321
Validation Loss: 1.2061
Epoch [2/50], Class Loss: 0.9554, Discrepancy Loss: 0.0251
Validation Loss: 1.6880
Epoch [3/50], Class Loss: 0.7128, Discrepancy Loss: 0.0265
Validation Loss: 0.3521
Epoch [4/50], Class Loss: 0.6426, Discrepancy Loss: 0.0282
Validation Loss: 0.8597
Epoch [5/50], Class Loss: 0.4337, Discrepancy Loss: 0.0048
Validation Loss: 0.4460
Epoch [6/50], Class Loss: 1.3714, Discrepancy Loss: 0.0375
Validation Loss: 0.4952
Epoch [7/50], Class Loss: 0.5232, Discrepancy Loss: 0.0131
Validation Loss: 0.4770
Epoch [8/50], Class Loss: 0.3833, Discrepancy Loss: 0.0032
Validation Loss: 0.3193
Epoch [9/50], Class Loss: 0.4019, Discrepancy Loss: 0.0056
Validation Loss: 0.0760
Epoch [10/50], Class Loss: 1.4294, Discrepancy Loss: 0.0336
Validation Loss: 0.1928
Epoch [11/50], Class Loss: 0.0426, Discrepancy Loss: 0.0080
Validation Loss: 0.0256
Epoch [12/50], Class Loss: 0.0287, Discrepancy Loss: 0.0023
Validation Loss: 0.0366
Epoch [13/50], Class Loss: 0.0821, Discrepancy Loss: 0.0046
Validation Loss: 1.0863
Epoch [14/50], Class Loss: 0.0625, Discrepancy Loss: 0.0039
Validation Loss: 0.0510
Epoch [15/50], Class Loss: 0.1157, Discrepancy Loss: 0.0043
Validation Loss: 0.0303
Epoch [16/50], Class Loss: 0.2060, Discrepancy Loss: 0.0031
Validation Loss: 0.0312
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 59.16%, Precision: 43.53%, Recall: 59.72%, F1 Score: 46.52%

Run 3/10
Epoch [1/50], Class Loss: 2.2803, Discrepancy Loss: 0.0220
Validation Loss: 1.0926
Epoch [2/50], Class Loss: 0.7230, Discrepancy Loss: 0.0163
Validation Loss: 0.5827
Epoch [3/50], Class Loss: 0.5715, Discrepancy Loss: 0.0211
Validation Loss: 0.2947
Epoch [4/50], Class Loss: 0.9863, Discrepancy Loss: 0.0286
Validation Loss: 0.5087
Epoch [5/50], Class Loss: 0.4314, Discrepancy Loss: 0.0114
Validation Loss: 0.3593
Epoch [6/50], Class Loss: 1.0153, Discrepancy Loss: 0.0186
Validation Loss: 0.3539
Epoch [7/50], Class Loss: 0.3208, Discrepancy Loss: 0.0051
Validation Loss: 0.3299
Epoch [8/50], Class Loss: 0.2516, Discrepancy Loss: 0.0041
Validation Loss: 0.0891
Epoch [9/50], Class Loss: 1.5075, Discrepancy Loss: 0.0354
Validation Loss: 1.3986
Epoch [10/50], Class Loss: 0.9253, Discrepancy Loss: 0.0278
Validation Loss: 0.4471
Epoch [11/50], Class Loss: 0.0793, Discrepancy Loss: 0.0062
Validation Loss: 0.0373
Epoch [12/50], Class Loss: 0.0819, Discrepancy Loss: 0.0044
Validation Loss: 0.0363
Epoch [13/50], Class Loss: 0.0672, Discrepancy Loss: 0.0050
Validation Loss: 0.0314
Epoch [14/50], Class Loss: 0.0791, Discrepancy Loss: 0.0053
Validation Loss: 0.0510
Epoch [15/50], Class Loss: 0.0578, Discrepancy Loss: 0.0040
Validation Loss: 0.0411
Epoch [16/50], Class Loss: 0.0815, Discrepancy Loss: 0.0043
Validation Loss: 0.0439
Epoch [17/50], Class Loss: 0.0803, Discrepancy Loss: 0.0030
Validation Loss: 0.2183
Epoch [18/50], Class Loss: 0.0963, Discrepancy Loss: 0.0061
Validation Loss: 0.0571
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 59.35%, Precision: 39.78%, Recall: 59.90%, F1 Score: 46.46%

Run 4/10
Epoch [1/50], Class Loss: 2.2907, Discrepancy Loss: 0.0203
Validation Loss: 1.1756
Epoch [2/50], Class Loss: 2.1367, Discrepancy Loss: 0.0423
Validation Loss: 0.9645
Epoch [3/50], Class Loss: 2.1850, Discrepancy Loss: 0.0455
Validation Loss: 0.3954
Epoch [4/50], Class Loss: 1.8992, Discrepancy Loss: 0.0288
Validation Loss: 0.3269
Epoch [5/50], Class Loss: 1.0466, Discrepancy Loss: 0.0243
Validation Loss: 0.3533
Epoch [6/50], Class Loss: 0.4051, Discrepancy Loss: 0.0071
Validation Loss: 0.2876
Epoch [7/50], Class Loss: 0.4270, Discrepancy Loss: 0.0222
Validation Loss: 0.3500
Epoch [8/50], Class Loss: 0.3593, Discrepancy Loss: 0.0140
Validation Loss: 0.2565
Epoch [9/50], Class Loss: 0.3611, Discrepancy Loss: 0.0162
Validation Loss: 0.3597
Epoch [10/50], Class Loss: 0.3065, Discrepancy Loss: 0.0149
Validation Loss: 0.1384
Epoch [11/50], Class Loss: 0.1062, Discrepancy Loss: 0.0129
Validation Loss: 0.0430
Epoch [12/50], Class Loss: 0.0899, Discrepancy Loss: 0.0051
Validation Loss: 0.0426
Epoch [13/50], Class Loss: 0.1527, Discrepancy Loss: 0.0045
Validation Loss: 0.3431
Epoch [14/50], Class Loss: 0.0503, Discrepancy Loss: 0.0046
Validation Loss: 0.0485
Epoch [15/50], Class Loss: 0.0900, Discrepancy Loss: 0.0160
Validation Loss: 0.0365
Epoch [16/50], Class Loss: 0.0751, Discrepancy Loss: 0.0152
Validation Loss: 0.0603
Epoch [17/50], Class Loss: 0.2648, Discrepancy Loss: 0.0182
Validation Loss: 0.1536
Epoch [18/50], Class Loss: 0.1378, Discrepancy Loss: 0.0117
Validation Loss: 0.0458
Epoch [19/50], Class Loss: 0.1775, Discrepancy Loss: 0.0143
Validation Loss: 0.0580
Epoch [20/50], Class Loss: 0.1810, Discrepancy Loss: 0.0193
Validation Loss: 0.0693
Early stopping!
Source Domain Performance - Accuracy: 99.78%, Precision: 99.78%, Recall: 99.78%, F1 Score: 99.78%
Target Domain Performance - Accuracy: 43.65%, Precision: 44.97%, Recall: 43.75%, F1 Score: 30.34%

Run 5/10
Epoch [1/50], Class Loss: 2.8304, Discrepancy Loss: 0.0535
Validation Loss: 0.6178
Epoch [2/50], Class Loss: 1.7892, Discrepancy Loss: 0.0590
Validation Loss: 0.4971
Epoch [3/50], Class Loss: 2.1999, Discrepancy Loss: 0.0483
Validation Loss: 0.7150
Epoch [4/50], Class Loss: 2.0292, Discrepancy Loss: 0.0371
Validation Loss: 0.7643
Epoch [5/50], Class Loss: 1.5555, Discrepancy Loss: 0.0269
Validation Loss: 0.3494
Epoch [6/50], Class Loss: 0.9823, Discrepancy Loss: 0.0138
Validation Loss: 2.7702
Epoch [7/50], Class Loss: 0.6940, Discrepancy Loss: 0.0220
Validation Loss: 0.1114
Epoch [8/50], Class Loss: 1.9004, Discrepancy Loss: 0.0413
Validation Loss: 12.7207
Epoch [9/50], Class Loss: 0.6140, Discrepancy Loss: 0.0141
Validation Loss: 0.1178
Epoch [10/50], Class Loss: 1.3592, Discrepancy Loss: 0.0303
Validation Loss: 1.4434
Epoch [11/50], Class Loss: 0.1682, Discrepancy Loss: 0.0063
Validation Loss: 0.0425
Epoch [12/50], Class Loss: 0.1568, Discrepancy Loss: 0.0063
Validation Loss: 0.0299
Epoch [13/50], Class Loss: 0.1101, Discrepancy Loss: 0.0026
Validation Loss: 0.0277
Epoch [14/50], Class Loss: 0.1466, Discrepancy Loss: 0.0032
Validation Loss: 0.0591
Epoch [15/50], Class Loss: 0.0246, Discrepancy Loss: 0.0019
Validation Loss: 0.0273
Epoch [16/50], Class Loss: 0.1352, Discrepancy Loss: 0.0035
Validation Loss: 2.1921
Epoch [17/50], Class Loss: 0.1314, Discrepancy Loss: 0.0054
Validation Loss: 0.0496
Epoch [18/50], Class Loss: 0.1801, Discrepancy Loss: 0.0058
Validation Loss: 0.1284
Epoch [19/50], Class Loss: 0.0623, Discrepancy Loss: 0.0038
Validation Loss: 0.0175
Epoch [20/50], Class Loss: 0.0705, Discrepancy Loss: 0.0036
Validation Loss: 0.0180
Epoch [21/50], Class Loss: 0.0092, Discrepancy Loss: 0.0012
Validation Loss: 0.0161
Epoch [22/50], Class Loss: 0.0072, Discrepancy Loss: 0.0009
Validation Loss: 0.0147
Epoch [23/50], Class Loss: 0.0074, Discrepancy Loss: 0.0009
Validation Loss: 0.0161
Epoch [24/50], Class Loss: 0.0072, Discrepancy Loss: 0.0009
Validation Loss: 0.0158
Epoch [25/50], Class Loss: 0.0087, Discrepancy Loss: 0.0010
Validation Loss: 0.0167
Epoch [26/50], Class Loss: 0.0075, Discrepancy Loss: 0.0008
Validation Loss: 0.0150
Epoch [27/50], Class Loss: 0.0089, Discrepancy Loss: 0.0012
Validation Loss: 0.0164
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.86%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 59.38%, Precision: 59.79%, Recall: 59.93%, F1 Score: 46.56%

Run 6/10
Epoch [1/50], Class Loss: 2.9671, Discrepancy Loss: 0.0287
Validation Loss: 0.4381
Epoch [2/50], Class Loss: 2.3360, Discrepancy Loss: 0.0444
Validation Loss: 0.7566
Epoch [3/50], Class Loss: 1.4972, Discrepancy Loss: 0.0438
Validation Loss: 0.8769
Epoch [4/50], Class Loss: 1.2281, Discrepancy Loss: 0.0285
Validation Loss: 0.3189
Epoch [5/50], Class Loss: 1.2302, Discrepancy Loss: 0.0369
Validation Loss: 2.4197
Epoch [6/50], Class Loss: 1.5437, Discrepancy Loss: 0.0310
Validation Loss: 0.8743
Epoch [7/50], Class Loss: 1.2790, Discrepancy Loss: 0.0394
Validation Loss: 5.2414
Epoch [8/50], Class Loss: 1.7866, Discrepancy Loss: 0.0772
Validation Loss: 0.4517
Epoch [9/50], Class Loss: 0.7199, Discrepancy Loss: 0.0261
Validation Loss: 0.5136
Early stopping!
Source Domain Performance - Accuracy: 81.52%, Precision: 89.08%, Recall: 80.96%, F1 Score: 76.10%
Target Domain Performance - Accuracy: 59.20%, Precision: 62.63%, Recall: 59.75%, F1 Score: 46.46%

Run 7/10
Epoch [1/50], Class Loss: 2.8153, Discrepancy Loss: 0.0430
Validation Loss: 2.0422
Epoch [2/50], Class Loss: 1.0945, Discrepancy Loss: 0.0226
Validation Loss: 0.5629
Epoch [3/50], Class Loss: 1.0411, Discrepancy Loss: 0.0292
Validation Loss: 5.6421
Epoch [4/50], Class Loss: 1.7455, Discrepancy Loss: 0.0534
Validation Loss: 0.4854
Epoch [5/50], Class Loss: 1.9006, Discrepancy Loss: 0.0494
Validation Loss: 0.5808
Epoch [6/50], Class Loss: 1.9316, Discrepancy Loss: 0.0420
Validation Loss: 0.9399
Epoch [7/50], Class Loss: 1.6430, Discrepancy Loss: 0.0376
Validation Loss: 18.4531
Epoch [8/50], Class Loss: 1.0168, Discrepancy Loss: 0.0365
Validation Loss: 0.2966
Epoch [9/50], Class Loss: 0.4118, Discrepancy Loss: 0.0061
Validation Loss: 0.5435
Epoch [10/50], Class Loss: 0.3573, Discrepancy Loss: 0.0045
Validation Loss: 0.0783
Epoch [11/50], Class Loss: 0.0186, Discrepancy Loss: 0.0014
Validation Loss: 0.0225
Epoch [12/50], Class Loss: 0.0480, Discrepancy Loss: 0.0044
Validation Loss: 0.0823
Epoch [13/50], Class Loss: 0.0787, Discrepancy Loss: 0.0114
Validation Loss: 0.0288
Epoch [14/50], Class Loss: 0.1323, Discrepancy Loss: 0.0098
Validation Loss: 0.0304
Epoch [15/50], Class Loss: 0.2624, Discrepancy Loss: 0.0120
Validation Loss: 0.0287
Epoch [16/50], Class Loss: 0.2203, Discrepancy Loss: 0.0099
Validation Loss: 0.0272
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 60.33%, Precision: 60.08%, Recall: 60.88%, F1 Score: 48.48%

Run 8/10
Epoch [1/50], Class Loss: 3.0607, Discrepancy Loss: 0.0464
Validation Loss: 1.4859
Epoch [2/50], Class Loss: 1.2685, Discrepancy Loss: 0.0368
Validation Loss: 0.6303
Epoch [3/50], Class Loss: 0.6600, Discrepancy Loss: 0.0117
Validation Loss: 0.5780
Epoch [4/50], Class Loss: 1.3852, Discrepancy Loss: 0.0340
Validation Loss: 5.5857
Epoch [5/50], Class Loss: 1.7322, Discrepancy Loss: 0.0318
Validation Loss: 0.7350
Epoch [6/50], Class Loss: 1.6336, Discrepancy Loss: 0.0522
Validation Loss: 0.5257
Epoch [7/50], Class Loss: 0.3588, Discrepancy Loss: 0.0069
Validation Loss: 0.2327
Epoch [8/50], Class Loss: 0.3204, Discrepancy Loss: 0.0035
Validation Loss: 0.2702
Epoch [9/50], Class Loss: 0.2773, Discrepancy Loss: 0.0037
Validation Loss: 0.5194
Epoch [10/50], Class Loss: 0.5195, Discrepancy Loss: 0.0154
Validation Loss: 14.5343
Epoch [11/50], Class Loss: 0.7400, Discrepancy Loss: 0.0054
Validation Loss: 0.0762
Epoch [12/50], Class Loss: 0.0944, Discrepancy Loss: 0.0107
Validation Loss: 1.0209
Epoch [13/50], Class Loss: 0.1115, Discrepancy Loss: 0.0119
Validation Loss: 0.0471
Epoch [14/50], Class Loss: 0.1119, Discrepancy Loss: 0.0114
Validation Loss: 0.2484
Epoch [15/50], Class Loss: 0.1804, Discrepancy Loss: 0.0159
Validation Loss: 0.0762
Epoch [16/50], Class Loss: 0.2198, Discrepancy Loss: 0.0099
Validation Loss: 0.1737
Epoch [17/50], Class Loss: 0.0565, Discrepancy Loss: 0.0096
Validation Loss: 0.0277
Epoch [18/50], Class Loss: 0.0489, Discrepancy Loss: 0.0111
Validation Loss: 0.0298
Epoch [19/50], Class Loss: 0.0907, Discrepancy Loss: 0.0116
Validation Loss: 0.0300
Epoch [20/50], Class Loss: 0.1693, Discrepancy Loss: 0.0110
Validation Loss: 2.0066
Epoch [21/50], Class Loss: 0.0681, Discrepancy Loss: 0.0083
Validation Loss: 0.0308
Epoch [22/50], Class Loss: 0.0156, Discrepancy Loss: 0.0089
Validation Loss: 0.0328
Early stopping!
Source Domain Performance - Accuracy: 99.76%, Precision: 99.75%, Recall: 99.76%, F1 Score: 99.75%
Target Domain Performance - Accuracy: 57.45%, Precision: 59.39%, Recall: 57.94%, F1 Score: 45.09%

Run 9/10
Epoch [1/50], Class Loss: 2.1844, Discrepancy Loss: 0.0206
Validation Loss: 1.6195
Epoch [2/50], Class Loss: 2.2296, Discrepancy Loss: 0.0428
Validation Loss: 1.3579
Epoch [3/50], Class Loss: 2.2872, Discrepancy Loss: 0.0631
Validation Loss: 0.7200
Epoch [4/50], Class Loss: 2.1455, Discrepancy Loss: 0.0479
Validation Loss: 0.6391
Epoch [5/50], Class Loss: 0.5462, Discrepancy Loss: 0.0203
Validation Loss: 0.3914
Epoch [6/50], Class Loss: 0.3731, Discrepancy Loss: 0.0073
Validation Loss: 0.3090
Epoch [7/50], Class Loss: 0.3499, Discrepancy Loss: 0.0046
Validation Loss: 0.5500
Epoch [8/50], Class Loss: 0.3611, Discrepancy Loss: 0.0040
Validation Loss: 0.7993
Epoch [9/50], Class Loss: 0.8950, Discrepancy Loss: 0.0146
Validation Loss: 1.0426
Epoch [10/50], Class Loss: 1.8781, Discrepancy Loss: 0.0375
Validation Loss: 0.6476
Epoch [11/50], Class Loss: 0.1890, Discrepancy Loss: 0.0143
Validation Loss: 0.0371
Epoch [12/50], Class Loss: 0.1613, Discrepancy Loss: 0.0055
Validation Loss: 0.0473
Epoch [13/50], Class Loss: 0.1159, Discrepancy Loss: 0.0022
Validation Loss: 0.0284
Epoch [14/50], Class Loss: 0.1886, Discrepancy Loss: 0.0022
Validation Loss: 0.0398
Epoch [15/50], Class Loss: 0.1240, Discrepancy Loss: 0.0022
Validation Loss: 0.0232
Epoch [16/50], Class Loss: 0.0891, Discrepancy Loss: 0.0018
Validation Loss: 0.0211
Epoch [17/50], Class Loss: 0.0799, Discrepancy Loss: 0.0023
Validation Loss: 0.0225
Epoch [18/50], Class Loss: 0.0586, Discrepancy Loss: 0.0028
Validation Loss: 0.0219
Epoch [19/50], Class Loss: 0.0899, Discrepancy Loss: 0.0038
Validation Loss: 0.0376
Epoch [20/50], Class Loss: 0.0823, Discrepancy Loss: 0.0029
Validation Loss: 0.1204
Epoch [21/50], Class Loss: 0.0210, Discrepancy Loss: 0.0021
Validation Loss: 0.0182
Epoch [22/50], Class Loss: 0.0175, Discrepancy Loss: 0.0019
Validation Loss: 0.0182
Epoch [23/50], Class Loss: 0.0139, Discrepancy Loss: 0.0017
Validation Loss: 0.0185
Epoch [24/50], Class Loss: 0.0151, Discrepancy Loss: 0.0020
Validation Loss: 0.0177
Epoch [25/50], Class Loss: 0.0146, Discrepancy Loss: 0.0021
Validation Loss: 0.0183
Epoch [26/50], Class Loss: 0.0157, Discrepancy Loss: 0.0022
Validation Loss: 0.0191
Epoch [27/50], Class Loss: 0.0153, Discrepancy Loss: 0.0021
Validation Loss: 0.0178
Epoch [28/50], Class Loss: 0.0152, Discrepancy Loss: 0.0022
Validation Loss: 0.0180
Epoch [29/50], Class Loss: 0.0165, Discrepancy Loss: 0.0023
Validation Loss: 0.0181
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 58.67%, Precision: 43.15%, Recall: 59.26%, F1 Score: 46.48%

Run 10/10
Epoch [1/50], Class Loss: 2.9020, Discrepancy Loss: 0.0290
Validation Loss: 1.3623
Epoch [2/50], Class Loss: 1.0900, Discrepancy Loss: 0.0360
Validation Loss: 0.0995
Epoch [3/50], Class Loss: 1.6741, Discrepancy Loss: 0.0356
Validation Loss: 2.3073
Epoch [4/50], Class Loss: 1.7272, Discrepancy Loss: 0.0387
Validation Loss: 0.3857
Epoch [5/50], Class Loss: 1.5439, Discrepancy Loss: 0.0263
Validation Loss: 2.0391
Epoch [6/50], Class Loss: 1.4463, Discrepancy Loss: 0.0326
Validation Loss: 3.1374
Epoch [7/50], Class Loss: 1.0005, Discrepancy Loss: 0.0308
Validation Loss: 0.7449
Early stopping!
Source Domain Performance - Accuracy: 78.59%, Precision: 69.44%, Recall: 79.88%, F1 Score: 72.81%
Target Domain Performance - Accuracy: 58.01%, Precision: 39.29%, Recall: 59.42%, F1 Score: 45.74%

Source performance: 95.88% 95.71% 95.95% 94.76%
Target performance: 56.58% 52.07% 57.14% 44.12%

Per-Class Accuracy on Target Domain:
bpsk: 89.22%
qpsk: 0.04%
4qam: 10.72%
16qam: 99.86%
apsk: 85.88%

Run 1/10
Epoch [1/50], Class Loss: 1.3769, CORAL Loss: 0.0045
Validation Loss: 1.0671
Epoch [2/50], Class Loss: 0.6767, CORAL Loss: 0.0234
Validation Loss: 0.5976
Epoch [3/50], Class Loss: 0.3774, CORAL Loss: 0.0102
Validation Loss: 0.2500
Epoch [4/50], Class Loss: 0.2737, CORAL Loss: 0.0052
Validation Loss: 0.1824
Epoch [5/50], Class Loss: 0.3549, CORAL Loss: 0.0108
Validation Loss: 0.1928
Epoch [6/50], Class Loss: 0.4474, CORAL Loss: 0.0215
Validation Loss: 0.1829
Epoch [7/50], Class Loss: 0.2231, CORAL Loss: 0.0145
Validation Loss: 0.0269
Epoch [8/50], Class Loss: 0.1948, CORAL Loss: 0.0086
Validation Loss: 0.1577
Epoch [9/50], Class Loss: 0.1445, CORAL Loss: 0.0037
Validation Loss: 0.0763
Epoch [10/50], Class Loss: 0.0156, CORAL Loss: 0.0064
Validation Loss: 0.0132
Epoch [11/50], Class Loss: 0.0064, CORAL Loss: 0.0053
Validation Loss: 0.0096
Epoch [12/50], Class Loss: 0.0058, CORAL Loss: 0.0051
Validation Loss: 0.0095
Epoch [13/50], Class Loss: 0.0060, CORAL Loss: 0.0040
Validation Loss: 0.0094
Epoch [14/50], Class Loss: 0.0055, CORAL Loss: 0.0044
Validation Loss: 0.0103
Epoch [15/50], Class Loss: 0.0059, CORAL Loss: 0.0043
Validation Loss: 0.0092
Epoch [16/50], Class Loss: 0.0054, CORAL Loss: 0.0036
Validation Loss: 0.0092
Epoch [17/50], Class Loss: 0.0051, CORAL Loss: 0.0039
Validation Loss: 0.0093
Epoch [18/50], Class Loss: 0.0048, CORAL Loss: 0.0037
Validation Loss: 0.0090
Epoch [19/50], Class Loss: 0.0049, CORAL Loss: 0.0036
Validation Loss: 0.0086
Epoch [20/50], Class Loss: 0.0051, CORAL Loss: 0.0030
Validation Loss: 0.0089
Epoch [21/50], Class Loss: 0.0042, CORAL Loss: 0.0032
Validation Loss: 0.0089
Epoch [22/50], Class Loss: 0.0039, CORAL Loss: 0.0030
Validation Loss: 0.0088
Epoch [23/50], Class Loss: 0.0043, CORAL Loss: 0.0029
Validation Loss: 0.0087
Epoch [24/50], Class Loss: 0.0039, CORAL Loss: 0.0031
Validation Loss: 0.0088
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 59.40%, Precision: 49.84%, Recall: 59.95%, F1 Score: 46.54%

Run 2/10
Epoch [1/50], Class Loss: 1.2799, CORAL Loss: 0.0114
Validation Loss: 1.0354
Epoch [2/50], Class Loss: 0.6914, CORAL Loss: 0.0228
Validation Loss: 0.5074
Epoch [3/50], Class Loss: 0.4885, CORAL Loss: 0.0156
Validation Loss: 0.1547
Epoch [4/50], Class Loss: 0.3239, CORAL Loss: 0.0093
Validation Loss: 0.1733
Epoch [5/50], Class Loss: 0.3622, CORAL Loss: 2.5583
Validation Loss: 16.1966
Epoch [6/50], Class Loss: 1.3049, CORAL Loss: 0.0032
Validation Loss: 0.4419
Epoch [7/50], Class Loss: 0.4216, CORAL Loss: 0.0426
Validation Loss: 0.7791
Epoch [8/50], Class Loss: 0.2144, CORAL Loss: 0.0129
Validation Loss: 0.2318
Early stopping!
Source Domain Performance - Accuracy: 78.30%, Precision: 69.08%, Recall: 79.57%, F1 Score: 72.50%
Target Domain Performance - Accuracy: 58.50%, Precision: 39.35%, Recall: 59.92%, F1 Score: 46.09%

Run 3/10
Epoch [1/50], Class Loss: 1.5230, CORAL Loss: 0.0009
Validation Loss: 0.7877
Epoch [2/50], Class Loss: 0.6124, CORAL Loss: 0.0307
Validation Loss: 0.3932
Epoch [3/50], Class Loss: 0.3860, CORAL Loss: 0.0129
Validation Loss: 0.7027
Epoch [4/50], Class Loss: 0.2587, CORAL Loss: 0.0125
Validation Loss: 0.0573
Epoch [5/50], Class Loss: 0.2531, CORAL Loss: 0.0079
Validation Loss: 0.2240
Epoch [6/50], Class Loss: 0.0641, CORAL Loss: 0.0077
Validation Loss: 3.8340
Epoch [7/50], Class Loss: 0.1822, CORAL Loss: 0.0042
Validation Loss: 0.0158
Epoch [8/50], Class Loss: 0.0109, CORAL Loss: 0.0059
Validation Loss: 0.0126
Epoch [9/50], Class Loss: 0.0076, CORAL Loss: 0.0041
Validation Loss: 0.0104
Epoch [10/50], Class Loss: 0.2621, CORAL Loss: 0.0045
Validation Loss: 0.2010
Epoch [11/50], Class Loss: 0.1325, CORAL Loss: 0.0063
Validation Loss: 0.0777
Epoch [12/50], Class Loss: 0.0419, CORAL Loss: 0.0078
Validation Loss: 0.0222
Epoch [13/50], Class Loss: 0.0152, CORAL Loss: 0.0083
Validation Loss: 0.0143
Epoch [14/50], Class Loss: 0.0102, CORAL Loss: 0.0078
Validation Loss: 0.0112
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 59.40%, Precision: 39.84%, Recall: 59.95%, F1 Score: 46.50%

Run 4/10
Epoch [1/50], Class Loss: 1.4386, CORAL Loss: 0.0034
Validation Loss: 1.0609
Epoch [2/50], Class Loss: 0.7019, CORAL Loss: 0.0258
Validation Loss: 0.2483
Epoch [3/50], Class Loss: 0.3358, CORAL Loss: 0.0138
Validation Loss: 0.1235
Epoch [4/50], Class Loss: 0.2254, CORAL Loss: 0.0036
Validation Loss: 0.1096
Epoch [5/50], Class Loss: 0.2551, CORAL Loss: 0.0073
Validation Loss: 0.0244
Epoch [6/50], Class Loss: 0.0580, CORAL Loss: 0.0058
Validation Loss: 0.0110
Epoch [7/50], Class Loss: 0.0067, CORAL Loss: 0.0050
Validation Loss: 0.0101
Epoch [8/50], Class Loss: 0.0067, CORAL Loss: 0.0040
Validation Loss: 0.0107
Epoch [9/50], Class Loss: 0.0050, CORAL Loss: 0.0030
Validation Loss: 0.0107
Epoch [10/50], Class Loss: 0.5481, CORAL Loss: 0.0238
Validation Loss: 0.1630
Epoch [11/50], Class Loss: 0.1398, CORAL Loss: 0.0218
Validation Loss: 0.1067
Epoch [12/50], Class Loss: 0.0996, CORAL Loss: 0.0224
Validation Loss: 0.0677
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.81%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 48.46%, Precision: 57.71%, Recall: 48.69%, F1 Score: 36.64%

Run 5/10
Epoch [1/50], Class Loss: 1.4820, CORAL Loss: 0.0025
Validation Loss: 1.2895
Epoch [2/50], Class Loss: 0.6648, CORAL Loss: 0.0226
Validation Loss: 0.3329
Epoch [3/50], Class Loss: 0.3689, CORAL Loss: 0.0197
Validation Loss: 0.2641
Epoch [4/50], Class Loss: 0.2947, CORAL Loss: 0.0051
Validation Loss: 0.1762
Epoch [5/50], Class Loss: 0.2208, CORAL Loss: 0.0052
Validation Loss: 0.1327
Epoch [6/50], Class Loss: 0.1332, CORAL Loss: 0.0089
Validation Loss: 0.9074
Epoch [7/50], Class Loss: 0.1517, CORAL Loss: 0.0059
Validation Loss: 0.0179
Epoch [8/50], Class Loss: 0.0152, CORAL Loss: 0.0080
Validation Loss: 0.0125
Epoch [9/50], Class Loss: 0.0075, CORAL Loss: 0.0054
Validation Loss: 0.0109
Epoch [10/50], Class Loss: 0.2899, CORAL Loss: 0.0055
Validation Loss: 0.0500
Epoch [11/50], Class Loss: 0.0260, CORAL Loss: 0.0144
Validation Loss: 0.0194
Epoch [12/50], Class Loss: 0.0132, CORAL Loss: 0.0110
Validation Loss: 0.0142
Epoch [13/50], Class Loss: 0.0096, CORAL Loss: 0.0100
Validation Loss: 0.0120
Epoch [14/50], Class Loss: 0.0083, CORAL Loss: 0.0089
Validation Loss: 0.0109
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 59.20%, Precision: 39.77%, Recall: 59.75%, F1 Score: 46.35%

Run 6/10
Epoch [1/50], Class Loss: 1.6388, CORAL Loss: 0.0003
Validation Loss: 1.4962
Epoch [2/50], Class Loss: 0.8441, CORAL Loss: 0.0317
Validation Loss: 0.7182
Epoch [3/50], Class Loss: 1.1239, CORAL Loss: 0.0395
Validation Loss: 0.6643
Epoch [4/50], Class Loss: 0.6419, CORAL Loss: 0.0547
Validation Loss: 0.4360
Epoch [5/50], Class Loss: 0.5467, CORAL Loss: 0.0429
Validation Loss: 0.1825
Epoch [6/50], Class Loss: 0.2776, CORAL Loss: 0.0186
Validation Loss: 0.2637
Epoch [7/50], Class Loss: 0.1493, CORAL Loss: 0.0159
Validation Loss: 0.0414
Epoch [8/50], Class Loss: 0.0783, CORAL Loss: 0.0152
Validation Loss: 0.0655
Epoch [9/50], Class Loss: 0.2297, CORAL Loss: 0.0166
Validation Loss: 0.0444
Epoch [10/50], Class Loss: 0.0170, CORAL Loss: 0.0102
Validation Loss: 0.0166
Epoch [11/50], Class Loss: 0.0125, CORAL Loss: 0.0067
Validation Loss: 0.0180
Epoch [12/50], Class Loss: 0.0122, CORAL Loss: 0.0071
Validation Loss: 0.0159
Epoch [13/50], Class Loss: 0.0114, CORAL Loss: 0.0073
Validation Loss: 0.0156
Epoch [14/50], Class Loss: 0.0112, CORAL Loss: 0.0072
Validation Loss: 0.0167
Epoch [15/50], Class Loss: 0.0114, CORAL Loss: 0.0073
Validation Loss: 0.0155
Epoch [16/50], Class Loss: 0.0110, CORAL Loss: 0.0064
Validation Loss: 0.0155
Epoch [17/50], Class Loss: 0.0109, CORAL Loss: 0.0072
Validation Loss: 0.0168
Epoch [18/50], Class Loss: 0.0103, CORAL Loss: 0.0062
Validation Loss: 0.0159
Epoch [19/50], Class Loss: 0.0103, CORAL Loss: 0.0054
Validation Loss: 0.0147
Epoch [20/50], Class Loss: 0.0099, CORAL Loss: 0.0055
Validation Loss: 0.0146
Epoch [21/50], Class Loss: 0.0097, CORAL Loss: 0.0054
Validation Loss: 0.0142
Epoch [22/50], Class Loss: 0.0096, CORAL Loss: 0.0057
Validation Loss: 0.0142
Epoch [23/50], Class Loss: 0.0095, CORAL Loss: 0.0056
Validation Loss: 0.0141
Epoch [24/50], Class Loss: 0.0094, CORAL Loss: 0.0049
Validation Loss: 0.0138
Epoch [25/50], Class Loss: 0.0099, CORAL Loss: 0.0049
Validation Loss: 0.0140
Epoch [26/50], Class Loss: 0.0096, CORAL Loss: 0.0054
Validation Loss: 0.0147
Epoch [27/50], Class Loss: 0.0093, CORAL Loss: 0.0043
Validation Loss: 0.0141
Epoch [28/50], Class Loss: 0.0095, CORAL Loss: 0.0051
Validation Loss: 0.0140
Epoch [29/50], Class Loss: 0.0094, CORAL Loss: 0.0051
Validation Loss: 0.0140
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 59.40%, Precision: 39.84%, Recall: 59.95%, F1 Score: 46.50%

Run 7/10
Epoch [1/50], Class Loss: 1.4472, CORAL Loss: 0.0022
Validation Loss: 0.6745
Epoch [2/50], Class Loss: 0.4762, CORAL Loss: 0.0233
Validation Loss: 0.3510
Epoch [3/50], Class Loss: 0.3919, CORAL Loss: 0.0244
Validation Loss: 0.6333
Epoch [4/50], Class Loss: 0.5251, CORAL Loss: 0.0199
Validation Loss: 0.1698
Epoch [5/50], Class Loss: 25.0937, CORAL Loss: 63.5401
Validation Loss: 1.6128
Epoch [6/50], Class Loss: 1.6105, CORAL Loss: 0.0312
Validation Loss: 1.6114
Epoch [7/50], Class Loss: 1.6098, CORAL Loss: 0.0364
Validation Loss: 1.6107
Epoch [8/50], Class Loss: 1.6096, CORAL Loss: 0.0344
Validation Loss: 1.6103
Epoch [9/50], Class Loss: 1.6095, CORAL Loss: 0.0289
Validation Loss: 1.6100
Early stopping!
Source Domain Performance - Accuracy: 19.36%, Precision: 3.87%, Recall: 20.00%, F1 Score: 6.49%
Target Domain Performance - Accuracy: 20.53%, Precision: 4.11%, Recall: 20.00%, F1 Score: 6.81%

Run 8/10
Epoch [1/50], Class Loss: 1.2837, CORAL Loss: 0.0080
Validation Loss: 0.5577
Epoch [2/50], Class Loss: 0.4792, CORAL Loss: 0.0287
Validation Loss: 1.2818
Epoch [3/50], Class Loss: 0.3380, CORAL Loss: 0.0133
Validation Loss: 0.2734
Epoch [4/50], Class Loss: 0.2973, CORAL Loss: 0.0055
Validation Loss: 0.1809
Epoch [5/50], Class Loss: 0.1101, CORAL Loss: 0.0109
Validation Loss: 0.0245
Epoch [6/50], Class Loss: 0.3820, CORAL Loss: 0.0120
Validation Loss: 0.1292
Epoch [7/50], Class Loss: 0.2423, CORAL Loss: 0.0091
Validation Loss: 0.1439
Epoch [8/50], Class Loss: 0.0426, CORAL Loss: 0.0042
Validation Loss: 0.0198
Epoch [9/50], Class Loss: 0.1952, CORAL Loss: 0.0063
Validation Loss: 0.0137
Epoch [10/50], Class Loss: 0.4406, CORAL Loss: 0.0102
Validation Loss: 0.0790
Epoch [11/50], Class Loss: 0.0667, CORAL Loss: 0.0132
Validation Loss: 0.0490
Epoch [12/50], Class Loss: 0.0452, CORAL Loss: 0.0121
Validation Loss: 0.0350
Epoch [13/50], Class Loss: 0.0308, CORAL Loss: 0.0110
Validation Loss: 0.0255
Epoch [14/50], Class Loss: 0.0227, CORAL Loss: 0.0093
Validation Loss: 0.0200
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 44.09%, Precision: 37.16%, Recall: 44.20%, F1 Score: 30.80%

Run 9/10
Epoch [1/50], Class Loss: 1.2868, CORAL Loss: 0.0059
Validation Loss: 0.5254
Epoch [2/50], Class Loss: 0.4421, CORAL Loss: 0.0230
Validation Loss: 0.2321
Epoch [3/50], Class Loss: 0.3355, CORAL Loss: 0.0079
Validation Loss: 0.0817
Epoch [4/50], Class Loss: 0.3446, CORAL Loss: 0.0072
Validation Loss: 1.0505
Epoch [5/50], Class Loss: 0.2744, CORAL Loss: 0.0046
Validation Loss: 0.2648
Epoch [6/50], Class Loss: 0.1464, CORAL Loss: 0.0093
Validation Loss: 0.0308
Epoch [7/50], Class Loss: 0.0129, CORAL Loss: 0.0080
Validation Loss: 0.0201
Epoch [8/50], Class Loss: 0.0072, CORAL Loss: 0.0044
Validation Loss: 0.0105
Epoch [9/50], Class Loss: 0.5898, CORAL Loss: 0.0050
Validation Loss: 0.2303
Epoch [10/50], Class Loss: 0.3448, CORAL Loss: 0.0153
Validation Loss: 0.1937
Epoch [11/50], Class Loss: 0.1445, CORAL Loss: 0.0147
Validation Loss: 0.1198
Epoch [12/50], Class Loss: 0.1271, CORAL Loss: 0.0154
Validation Loss: 0.0713
Epoch [13/50], Class Loss: 0.1130, CORAL Loss: 0.0148
Validation Loss: 0.0634
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.86%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 59.45%, Precision: 59.83%, Recall: 60.00%, F1 Score: 46.60%

Run 10/10
Epoch [1/50], Class Loss: 1.5070, CORAL Loss: 0.0008
Validation Loss: 1.1184
Epoch [2/50], Class Loss: 0.7843, CORAL Loss: 0.0201
Validation Loss: 0.3113
Epoch [3/50], Class Loss: 0.3756, CORAL Loss: 0.0177
Validation Loss: 0.1322
Epoch [4/50], Class Loss: 0.2664, CORAL Loss: 0.0070
Validation Loss: 0.1075
Epoch [5/50], Class Loss: 1.1971, CORAL Loss: 0.0282
Validation Loss: 0.6303
Epoch [6/50], Class Loss: 0.5953, CORAL Loss: 0.0265
Validation Loss: 0.3583
Epoch [7/50], Class Loss: 0.3284, CORAL Loss: 0.0343
Validation Loss: 0.4418
Epoch [8/50], Class Loss: 0.4229, CORAL Loss: 0.0102
Validation Loss: 0.4674
Epoch [9/50], Class Loss: 0.1643, CORAL Loss: 0.0111
Validation Loss: 0.0240
Epoch [10/50], Class Loss: 0.1051, CORAL Loss: 0.0099
Validation Loss: 0.0193
Epoch [11/50], Class Loss: 0.0134, CORAL Loss: 0.0109
Validation Loss: 0.0178
Epoch [12/50], Class Loss: 0.0133, CORAL Loss: 0.0085
Validation Loss: 0.0166
Epoch [13/50], Class Loss: 0.0127, CORAL Loss: 0.0086
Validation Loss: 0.0154
Epoch [14/50], Class Loss: 0.0118, CORAL Loss: 0.0085
Validation Loss: 0.0150
Epoch [15/50], Class Loss: 0.0111, CORAL Loss: 0.0078
Validation Loss: 0.0141
Epoch [16/50], Class Loss: 0.0110, CORAL Loss: 0.0072
Validation Loss: 0.0136
Epoch [17/50], Class Loss: 0.0102, CORAL Loss: 0.0065
Validation Loss: 0.0136
Epoch [18/50], Class Loss: 0.0094, CORAL Loss: 0.0071
Validation Loss: 0.0127
Epoch [19/50], Class Loss: 0.0101, CORAL Loss: 0.0066
Validation Loss: 0.0128
Epoch [20/50], Class Loss: 0.0087, CORAL Loss: 0.0057
Validation Loss: 0.0125
Epoch [21/50], Class Loss: 0.0088, CORAL Loss: 0.0062
Validation Loss: 0.0119
Epoch [22/50], Class Loss: 0.0091, CORAL Loss: 0.0060
Validation Loss: 0.0123
Epoch [23/50], Class Loss: 0.0085, CORAL Loss: 0.0055
Validation Loss: 0.0120
Epoch [24/50], Class Loss: 0.0087, CORAL Loss: 0.0053
Validation Loss: 0.0118
Epoch [25/50], Class Loss: 0.0087, CORAL Loss: 0.0060
Validation Loss: 0.0116
Epoch [26/50], Class Loss: 0.0085, CORAL Loss: 0.0053
Validation Loss: 0.0124
Epoch [27/50], Class Loss: 0.0084, CORAL Loss: 0.0055
Validation Loss: 0.0117
Epoch [28/50], Class Loss: 0.0084, CORAL Loss: 0.0052
Validation Loss: 0.0120
Epoch [29/50], Class Loss: 0.0084, CORAL Loss: 0.0057
Validation Loss: 0.0117
Epoch [30/50], Class Loss: 0.0082, CORAL Loss: 0.0060
Validation Loss: 0.0115
Epoch [31/50], Class Loss: 0.0079, CORAL Loss: 0.0055
Validation Loss: 0.0117
Epoch [32/50], Class Loss: 0.0081, CORAL Loss: 0.0055
Validation Loss: 0.0116
Epoch [33/50], Class Loss: 0.0079, CORAL Loss: 0.0054
Validation Loss: 0.0114
Epoch [34/50], Class Loss: 0.0080, CORAL Loss: 0.0058
Validation Loss: 0.0115
Epoch [35/50], Class Loss: 0.0081, CORAL Loss: 0.0050
Validation Loss: 0.0115
Epoch [36/50], Class Loss: 0.0083, CORAL Loss: 0.0050
Validation Loss: 0.0115
Epoch [37/50], Class Loss: 0.0082, CORAL Loss: 0.0054
Validation Loss: 0.0115
Epoch [38/50], Class Loss: 0.0081, CORAL Loss: 0.0061
Validation Loss: 0.0115
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.86%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 59.42%, Precision: 59.85%, Recall: 59.98%, F1 Score: 46.56%

Source performance: 89.65% 87.18% 89.84% 87.78%
Target performance: 52.79% 42.73% 53.24% 39.94%

Per-Class Accuracy on Target Domain:
bpsk: 79.91%
qpsk: 10.01%
4qam: 10.04%
16qam: 89.97%
apsk: 76.27%

Run 1/10
Epoch [1/50], Class Loss: 1.4709, JMMD Loss: 0.1848
Validation Loss: 0.8042
Epoch [2/50], Class Loss: 0.6390, JMMD Loss: 0.3588
Validation Loss: 0.3492
Epoch [3/50], Class Loss: 0.3509, JMMD Loss: 0.3532
Validation Loss: 0.2688
Epoch [4/50], Class Loss: 0.2668, JMMD Loss: 0.3357
Validation Loss: 0.1559
Epoch [5/50], Class Loss: 0.2872, JMMD Loss: 0.3345
Validation Loss: 0.0767
Epoch [6/50], Class Loss: 0.2148, JMMD Loss: 0.3137
Validation Loss: 0.1536
Epoch [7/50], Class Loss: 0.1296, JMMD Loss: 0.2926
Validation Loss: 0.0214
Epoch [8/50], Class Loss: 0.1363, JMMD Loss: 0.2873
Validation Loss: 0.1265
Epoch [9/50], Class Loss: 0.0241, JMMD Loss: 0.2986
Validation Loss: 0.0163
Epoch [10/50], Class Loss: 0.1035, JMMD Loss: 0.2799
Validation Loss: 0.9162
Epoch [11/50], Class Loss: 0.0479, JMMD Loss: 0.2525
Validation Loss: 0.0222
Epoch [12/50], Class Loss: 0.0164, JMMD Loss: 0.2470
Validation Loss: 0.0170
Epoch [13/50], Class Loss: 0.0128, JMMD Loss: 0.2439
Validation Loss: 0.0143
Epoch [14/50], Class Loss: 0.0105, JMMD Loss: 0.2379
Validation Loss: 0.0132
Epoch [15/50], Class Loss: 0.0095, JMMD Loss: 0.2388
Validation Loss: 0.0123
Epoch [16/50], Class Loss: 0.0090, JMMD Loss: 0.2335
Validation Loss: 0.0119
Epoch [17/50], Class Loss: 0.0085, JMMD Loss: 0.2338
Validation Loss: 0.0118
Epoch [18/50], Class Loss: 0.0085, JMMD Loss: 0.2243
Validation Loss: 0.0112
Epoch [19/50], Class Loss: 0.0082, JMMD Loss: 0.2269
Validation Loss: 0.0112
Epoch [20/50], Class Loss: 0.0082, JMMD Loss: 0.2208
Validation Loss: 0.0109
Epoch [21/50], Class Loss: 0.0079, JMMD Loss: 0.2218
Validation Loss: 0.0109
Epoch [22/50], Class Loss: 0.0080, JMMD Loss: 0.2235
Validation Loss: 0.0109
Epoch [23/50], Class Loss: 0.0079, JMMD Loss: 0.2165
Validation Loss: 0.0109
Epoch [24/50], Class Loss: 0.0079, JMMD Loss: 0.2196
Validation Loss: 0.0107
Epoch [25/50], Class Loss: 0.0080, JMMD Loss: 0.2176
Validation Loss: 0.0106
Epoch [26/50], Class Loss: 0.0079, JMMD Loss: 0.2172
Validation Loss: 0.0109
Epoch [27/50], Class Loss: 0.0077, JMMD Loss: 0.2132
Validation Loss: 0.0110
Epoch [28/50], Class Loss: 0.0078, JMMD Loss: 0.2211
Validation Loss: 0.0105
Epoch [29/50], Class Loss: 0.0077, JMMD Loss: 0.2188
Validation Loss: 0.0104
Epoch [30/50], Class Loss: 0.0078, JMMD Loss: 0.2114
Validation Loss: 0.0105
Epoch [31/50], Class Loss: 0.0075, JMMD Loss: 0.2151
Validation Loss: 0.0103
Epoch [32/50], Class Loss: 0.0074, JMMD Loss: 0.2171
Validation Loss: 0.0104
Epoch [33/50], Class Loss: 0.0076, JMMD Loss: 0.2131
Validation Loss: 0.0104
Epoch [34/50], Class Loss: 0.0075, JMMD Loss: 0.2102
Validation Loss: 0.0104
Epoch [35/50], Class Loss: 0.0076, JMMD Loss: 0.2096
Validation Loss: 0.0103
Epoch [36/50], Class Loss: 0.0076, JMMD Loss: 0.2137
Validation Loss: 0.0103
Epoch [37/50], Class Loss: 0.0077, JMMD Loss: 0.2180
Validation Loss: 0.0105
Epoch [38/50], Class Loss: 0.0075, JMMD Loss: 0.2182
Validation Loss: 0.0103
Epoch [39/50], Class Loss: 0.0075, JMMD Loss: 0.2180
Validation Loss: 0.0104
Epoch [40/50], Class Loss: 0.0074, JMMD Loss: 0.2136
Validation Loss: 0.0103
Epoch [41/50], Class Loss: 0.0075, JMMD Loss: 0.2106
Validation Loss: 0.0103
Epoch [42/50], Class Loss: 0.0075, JMMD Loss: 0.2188
Validation Loss: 0.0103
Epoch [43/50], Class Loss: 0.0075, JMMD Loss: 0.2088
Validation Loss: 0.0103
Epoch [44/50], Class Loss: 0.0075, JMMD Loss: 0.2129
Validation Loss: 0.0103
Epoch [45/50], Class Loss: 0.0075, JMMD Loss: 0.2123
Validation Loss: 0.0103
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 59.40%, Precision: 46.51%, Recall: 59.95%, F1 Score: 46.55%

Run 2/10
Epoch [1/50], Class Loss: 1.3013, JMMD Loss: 0.2192
Validation Loss: 0.5468
Epoch [2/50], Class Loss: 0.5841, JMMD Loss: 0.3565
Validation Loss: 0.2683
Epoch [3/50], Class Loss: 0.3650, JMMD Loss: 0.3571
Validation Loss: 0.4632
Epoch [4/50], Class Loss: 0.2247, JMMD Loss: 0.3485
Validation Loss: 0.5467
Epoch [5/50], Class Loss: 0.2268, JMMD Loss: 0.3367
Validation Loss: 0.1043
Epoch [6/50], Class Loss: 0.2082, JMMD Loss: 0.3315
Validation Loss: 0.0747
Epoch [7/50], Class Loss: 0.0182, JMMD Loss: 0.2886
Validation Loss: 0.0110
Epoch [8/50], Class Loss: 0.2024, JMMD Loss: 0.3262
Validation Loss: 0.0227
Epoch [9/50], Class Loss: 0.1005, JMMD Loss: 0.2762
Validation Loss: 0.0125
Epoch [10/50], Class Loss: 0.0100, JMMD Loss: 0.2352
Validation Loss: 0.0105
Epoch [11/50], Class Loss: 0.0080, JMMD Loss: 0.2170
Validation Loss: 0.0101
Epoch [12/50], Class Loss: 0.0084, JMMD Loss: 0.2094
Validation Loss: 0.0103
Epoch [13/50], Class Loss: 0.0083, JMMD Loss: 0.2174
Validation Loss: 0.0099
Epoch [14/50], Class Loss: 0.0080, JMMD Loss: 0.2124
Validation Loss: 0.0100
Epoch [15/50], Class Loss: 0.0081, JMMD Loss: 0.2006
Validation Loss: 0.0097
Epoch [16/50], Class Loss: 0.0074, JMMD Loss: 0.2016
Validation Loss: 0.0093
Epoch [17/50], Class Loss: 0.0077, JMMD Loss: 0.1989
Validation Loss: 0.0093
Epoch [18/50], Class Loss: 0.0073, JMMD Loss: 0.1895
Validation Loss: 0.0093
Epoch [19/50], Class Loss: 0.0074, JMMD Loss: 0.1834
Validation Loss: 0.0096
Epoch [20/50], Class Loss: 0.0071, JMMD Loss: 0.1812
Validation Loss: 0.0092
Epoch [21/50], Class Loss: 0.0065, JMMD Loss: 0.1801
Validation Loss: 0.0088
Epoch [22/50], Class Loss: 0.0066, JMMD Loss: 0.1776
Validation Loss: 0.0088
Epoch [23/50], Class Loss: 0.0066, JMMD Loss: 0.1754
Validation Loss: 0.0088
Epoch [24/50], Class Loss: 0.0066, JMMD Loss: 0.1740
Validation Loss: 0.0089
Epoch [25/50], Class Loss: 0.0066, JMMD Loss: 0.1710
Validation Loss: 0.0090
Epoch [26/50], Class Loss: 0.0066, JMMD Loss: 0.1792
Validation Loss: 0.0088
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 59.40%, Precision: 46.51%, Recall: 59.95%, F1 Score: 46.55%

Run 3/10
Epoch [1/50], Class Loss: 1.3499, JMMD Loss: 0.2148
Validation Loss: 0.5514
Epoch [2/50], Class Loss: 0.5123, JMMD Loss: 0.3639
Validation Loss: 0.2992
Epoch [3/50], Class Loss: 0.3150, JMMD Loss: 0.3522
Validation Loss: 0.1122
Epoch [4/50], Class Loss: 0.3014, JMMD Loss: 0.3373
Validation Loss: 0.3006
Epoch [5/50], Class Loss: 0.1910, JMMD Loss: 0.3210
Validation Loss: 0.0453
Epoch [6/50], Class Loss: 0.2013, JMMD Loss: 0.3204
Validation Loss: 0.0780
Epoch [7/50], Class Loss: 0.0757, JMMD Loss: 0.3030
Validation Loss: 0.0164
Epoch [8/50], Class Loss: 0.1125, JMMD Loss: 0.2719
Validation Loss: 0.0123
Epoch [9/50], Class Loss: 0.0099, JMMD Loss: 0.2428
Validation Loss: 0.0120
Epoch [10/50], Class Loss: 0.0089, JMMD Loss: 0.2155
Validation Loss: 0.0090
Epoch [11/50], Class Loss: 0.0070, JMMD Loss: 0.2077
Validation Loss: 0.0089
Epoch [12/50], Class Loss: 0.0071, JMMD Loss: 0.2140
Validation Loss: 0.0089
Epoch [13/50], Class Loss: 0.0070, JMMD Loss: 0.2035
Validation Loss: 0.0090
Epoch [14/50], Class Loss: 0.0071, JMMD Loss: 0.1947
Validation Loss: 0.0089
Epoch [15/50], Class Loss: 0.0070, JMMD Loss: 0.1939
Validation Loss: 0.0089
Epoch [16/50], Class Loss: 0.0067, JMMD Loss: 0.1939
Validation Loss: 0.0086
Epoch [17/50], Class Loss: 0.0066, JMMD Loss: 0.1809
Validation Loss: 0.0082
Epoch [18/50], Class Loss: 0.0064, JMMD Loss: 0.1741
Validation Loss: 0.0083
Epoch [19/50], Class Loss: 0.0059, JMMD Loss: 0.1676
Validation Loss: 0.0083
Epoch [20/50], Class Loss: 0.0059, JMMD Loss: 0.1546
Validation Loss: 0.0079
Epoch [21/50], Class Loss: 0.0055, JMMD Loss: 0.1544
Validation Loss: 0.0079
Epoch [22/50], Class Loss: 0.0052, JMMD Loss: 0.1532
Validation Loss: 0.0079
Epoch [23/50], Class Loss: 0.0054, JMMD Loss: 0.1501
Validation Loss: 0.0080
Epoch [24/50], Class Loss: 0.0053, JMMD Loss: 0.1488
Validation Loss: 0.0079
Epoch [25/50], Class Loss: 0.0052, JMMD Loss: 0.1571
Validation Loss: 0.0079
Epoch [26/50], Class Loss: 0.0052, JMMD Loss: 0.1520
Validation Loss: 0.0078
Epoch [27/50], Class Loss: 0.0052, JMMD Loss: 0.1477
Validation Loss: 0.0079
Epoch [28/50], Class Loss: 0.0052, JMMD Loss: 0.1491
Validation Loss: 0.0078
Epoch [29/50], Class Loss: 0.0052, JMMD Loss: 0.1508
Validation Loss: 0.0078
Epoch [30/50], Class Loss: 0.0051, JMMD Loss: 0.1485
Validation Loss: 0.0078
Epoch [31/50], Class Loss: 0.0052, JMMD Loss: 0.1491
Validation Loss: 0.0078
Epoch [32/50], Class Loss: 0.0051, JMMD Loss: 0.1429
Validation Loss: 0.0078
Epoch [33/50], Class Loss: 0.0050, JMMD Loss: 0.1447
Validation Loss: 0.0078
Epoch [34/50], Class Loss: 0.0054, JMMD Loss: 0.1468
Validation Loss: 0.0078
Epoch [35/50], Class Loss: 0.0051, JMMD Loss: 0.1474
Validation Loss: 0.0078
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 59.33%, Precision: 49.10%, Recall: 59.87%, F1 Score: 46.71%

Run 4/10
Epoch [1/50], Class Loss: 1.4914, JMMD Loss: 0.1812
Validation Loss: 0.7063
Epoch [2/50], Class Loss: 0.4870, JMMD Loss: 0.3630
Validation Loss: 0.1725
Epoch [3/50], Class Loss: 0.2345, JMMD Loss: 0.3479
Validation Loss: 0.2434
Epoch [4/50], Class Loss: 0.1994, JMMD Loss: 0.3333
Validation Loss: 0.0462
Epoch [5/50], Class Loss: 0.1882, JMMD Loss: 0.2699
Validation Loss: 0.0381
Epoch [6/50], Class Loss: 0.1475, JMMD Loss: 0.2763
Validation Loss: 0.0212
Epoch [7/50], Class Loss: 0.0103, JMMD Loss: 0.2516
Validation Loss: 0.0115
Epoch [8/50], Class Loss: 0.0086, JMMD Loss: 0.2408
Validation Loss: 0.0113
Epoch [9/50], Class Loss: 0.1664, JMMD Loss: 0.3209
Validation Loss: 0.0186
Epoch [10/50], Class Loss: 0.1482, JMMD Loss: 0.3395
Validation Loss: 0.0193
Epoch [11/50], Class Loss: 0.0124, JMMD Loss: 0.3194
Validation Loss: 0.0178
Epoch [12/50], Class Loss: 0.0116, JMMD Loss: 0.3113
Validation Loss: 0.0164
Epoch [13/50], Class Loss: 0.0113, JMMD Loss: 0.3114
Validation Loss: 0.0172
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.81%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 52.29%, Precision: 58.34%, Recall: 52.64%, F1 Score: 40.64%

Run 5/10
Epoch [1/50], Class Loss: 1.5405, JMMD Loss: 0.1567
Validation Loss: 4.5510
Epoch [2/50], Class Loss: 0.6200, JMMD Loss: 0.3642
Validation Loss: 0.2389
Epoch [3/50], Class Loss: 0.4597, JMMD Loss: 0.3622
Validation Loss: 0.2202
Epoch [4/50], Class Loss: 0.2832, JMMD Loss: 0.3581
Validation Loss: 0.1329
Epoch [5/50], Class Loss: 0.2951, JMMD Loss: 0.3486
Validation Loss: 0.0599
Epoch [6/50], Class Loss: 0.1592, JMMD Loss: 0.3385
Validation Loss: 0.0255
Epoch [7/50], Class Loss: 0.0117, JMMD Loss: 0.3226
Validation Loss: 0.0135
Epoch [8/50], Class Loss: 0.2816, JMMD Loss: 0.3405
Validation Loss: 0.0892
Epoch [9/50], Class Loss: 0.0229, JMMD Loss: 0.3113
Validation Loss: 0.0713
Epoch [10/50], Class Loss: 0.3669, JMMD Loss: 0.3345
Validation Loss: 0.0307
Epoch [11/50], Class Loss: 0.0183, JMMD Loss: 0.3106
Validation Loss: 0.0205
Epoch [12/50], Class Loss: 0.0153, JMMD Loss: 0.3055
Validation Loss: 0.0187
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 47.92%, Precision: 57.62%, Recall: 48.14%, F1 Score: 36.01%

Run 6/10
Epoch [1/50], Class Loss: 1.4382, JMMD Loss: 0.2149
Validation Loss: 1.0353
Epoch [2/50], Class Loss: 0.8489, JMMD Loss: 0.3602
Validation Loss: 0.2776
Epoch [3/50], Class Loss: 0.3121, JMMD Loss: 0.3584
Validation Loss: 0.1523
Epoch [4/50], Class Loss: 0.2397, JMMD Loss: 0.3538
Validation Loss: 0.1650
Epoch [5/50], Class Loss: 0.3344, JMMD Loss: 0.3391
Validation Loss: 0.7240
Epoch [6/50], Class Loss: 0.2238, JMMD Loss: 0.3482
Validation Loss: 0.1071
Epoch [7/50], Class Loss: 0.0517, JMMD Loss: 0.3269
Validation Loss: 0.0179
Epoch [8/50], Class Loss: 0.2868, JMMD Loss: 0.3287
Validation Loss: 0.1148
Epoch [9/50], Class Loss: 0.0224, JMMD Loss: 0.3038
Validation Loss: 0.0124
Epoch [10/50], Class Loss: 0.0089, JMMD Loss: 0.2775
Validation Loss: 0.0103
Epoch [11/50], Class Loss: 0.0074, JMMD Loss: 0.2526
Validation Loss: 0.0102
Epoch [12/50], Class Loss: 0.0081, JMMD Loss: 0.2422
Validation Loss: 0.0100
Epoch [13/50], Class Loss: 0.0080, JMMD Loss: 0.2461
Validation Loss: 0.0098
Epoch [14/50], Class Loss: 0.0079, JMMD Loss: 0.2463
Validation Loss: 0.0098
Epoch [15/50], Class Loss: 0.0082, JMMD Loss: 0.2462
Validation Loss: 0.0096
Epoch [16/50], Class Loss: 0.0081, JMMD Loss: 0.2486
Validation Loss: 0.0103
Epoch [17/50], Class Loss: 0.0082, JMMD Loss: 0.2414
Validation Loss: 0.0096
Epoch [18/50], Class Loss: 0.0080, JMMD Loss: 0.2393
Validation Loss: 0.0096
Epoch [19/50], Class Loss: 0.0081, JMMD Loss: 0.2315
Validation Loss: 0.0098
Epoch [20/50], Class Loss: 0.0079, JMMD Loss: 0.2333
Validation Loss: 0.0099
Epoch [21/50], Class Loss: 0.0077, JMMD Loss: 0.2263
Validation Loss: 0.0095
Epoch [22/50], Class Loss: 0.0080, JMMD Loss: 0.2386
Validation Loss: 0.0097
Epoch [23/50], Class Loss: 0.0078, JMMD Loss: 0.2270
Validation Loss: 0.0097
Epoch [24/50], Class Loss: 0.0080, JMMD Loss: 0.2296
Validation Loss: 0.0098
Epoch [25/50], Class Loss: 0.0080, JMMD Loss: 0.2278
Validation Loss: 0.0098
Epoch [26/50], Class Loss: 0.0079, JMMD Loss: 0.2296
Validation Loss: 0.0097
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 59.40%, Precision: 46.51%, Recall: 59.95%, F1 Score: 46.55%

Run 7/10
Epoch [1/50], Class Loss: 1.3643, JMMD Loss: 0.2362
Validation Loss: 0.5046
Epoch [2/50], Class Loss: 0.6974, JMMD Loss: 0.3609
Validation Loss: 0.2703
Epoch [3/50], Class Loss: 0.4052, JMMD Loss: 0.3577
Validation Loss: 0.4969
Epoch [4/50], Class Loss: 0.2494, JMMD Loss: 0.3404
Validation Loss: 0.2402
Epoch [5/50], Class Loss: 0.0742, JMMD Loss: 0.3207
Validation Loss: 0.0384
Epoch [6/50], Class Loss: 0.3680, JMMD Loss: 0.3444
Validation Loss: 0.0817
Epoch [7/50], Class Loss: 0.1092, JMMD Loss: 0.3087
Validation Loss: 0.3989
Epoch [8/50], Class Loss: 0.0668, JMMD Loss: 0.3013
Validation Loss: 0.0171
Epoch [9/50], Class Loss: 0.1084, JMMD Loss: 0.2627
Validation Loss: 0.2731
Epoch [10/50], Class Loss: 0.0822, JMMD Loss: 0.3409
Validation Loss: 0.0163
Epoch [11/50], Class Loss: 0.0105, JMMD Loss: 0.2971
Validation Loss: 0.0160
Epoch [12/50], Class Loss: 0.0101, JMMD Loss: 0.2958
Validation Loss: 0.0155
Epoch [13/50], Class Loss: 0.0097, JMMD Loss: 0.2838
Validation Loss: 0.0142
Epoch [14/50], Class Loss: 0.0093, JMMD Loss: 0.2855
Validation Loss: 0.0137
Epoch [15/50], Class Loss: 0.0089, JMMD Loss: 0.2795
Validation Loss: 0.0139
Epoch [16/50], Class Loss: 0.0092, JMMD Loss: 0.2681
Validation Loss: 0.0132
Epoch [17/50], Class Loss: 0.0090, JMMD Loss: 0.2571
Validation Loss: 0.0130
Epoch [18/50], Class Loss: 0.0087, JMMD Loss: 0.2508
Validation Loss: 0.0128
Epoch [19/50], Class Loss: 0.0087, JMMD Loss: 0.2432
Validation Loss: 0.0125
Epoch [20/50], Class Loss: 0.0081, JMMD Loss: 0.2419
Validation Loss: 0.0124
Epoch [21/50], Class Loss: 0.0079, JMMD Loss: 0.2403
Validation Loss: 0.0123
Epoch [22/50], Class Loss: 0.0078, JMMD Loss: 0.2374
Validation Loss: 0.0123
Epoch [23/50], Class Loss: 0.0079, JMMD Loss: 0.2410
Validation Loss: 0.0123
Epoch [24/50], Class Loss: 0.0077, JMMD Loss: 0.2298
Validation Loss: 0.0125
Epoch [25/50], Class Loss: 0.0078, JMMD Loss: 0.2351
Validation Loss: 0.0123
Epoch [26/50], Class Loss: 0.0079, JMMD Loss: 0.2378
Validation Loss: 0.0122
Epoch [27/50], Class Loss: 0.0078, JMMD Loss: 0.2324
Validation Loss: 0.0121
Epoch [28/50], Class Loss: 0.0079, JMMD Loss: 0.2345
Validation Loss: 0.0121
Epoch [29/50], Class Loss: 0.0079, JMMD Loss: 0.2394
Validation Loss: 0.0122
Epoch [30/50], Class Loss: 0.0075, JMMD Loss: 0.2374
Validation Loss: 0.0120
Epoch [31/50], Class Loss: 0.0076, JMMD Loss: 0.2309
Validation Loss: 0.0120
Epoch [32/50], Class Loss: 0.0076, JMMD Loss: 0.2297
Validation Loss: 0.0120
Epoch [33/50], Class Loss: 0.0075, JMMD Loss: 0.2429
Validation Loss: 0.0120
Epoch [34/50], Class Loss: 0.0076, JMMD Loss: 0.2391
Validation Loss: 0.0119
Epoch [35/50], Class Loss: 0.0076, JMMD Loss: 0.2365
Validation Loss: 0.0120
Epoch [36/50], Class Loss: 0.0075, JMMD Loss: 0.2353
Validation Loss: 0.0119
Epoch [37/50], Class Loss: 0.0076, JMMD Loss: 0.2386
Validation Loss: 0.0120
Epoch [38/50], Class Loss: 0.0075, JMMD Loss: 0.2312
Validation Loss: 0.0119
Epoch [39/50], Class Loss: 0.0075, JMMD Loss: 0.2360
Validation Loss: 0.0119
Epoch [40/50], Class Loss: 0.0075, JMMD Loss: 0.2414
Validation Loss: 0.0120
Epoch [41/50], Class Loss: 0.0077, JMMD Loss: 0.2371
Validation Loss: 0.0119
Epoch [42/50], Class Loss: 0.0075, JMMD Loss: 0.2332
Validation Loss: 0.0119
Epoch [43/50], Class Loss: 0.0074, JMMD Loss: 0.2463
Validation Loss: 0.0119
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 59.40%, Precision: 46.51%, Recall: 59.95%, F1 Score: 46.55%

Run 8/10
Epoch [1/50], Class Loss: 1.4675, JMMD Loss: 0.1742
Validation Loss: 0.9621
Epoch [2/50], Class Loss: 0.5711, JMMD Loss: 0.3722
Validation Loss: 0.9744
Epoch [3/50], Class Loss: 0.3031, JMMD Loss: 0.3517
Validation Loss: 0.0984
Epoch [4/50], Class Loss: 0.2704, JMMD Loss: 0.3496
Validation Loss: 0.1784
Epoch [5/50], Class Loss: 0.2272, JMMD Loss: 0.3234
Validation Loss: 0.0892
Epoch [6/50], Class Loss: 0.2405, JMMD Loss: 0.3346
Validation Loss: 0.0854
Epoch [7/50], Class Loss: 0.0898, JMMD Loss: 0.2928
Validation Loss: 0.0106
Epoch [8/50], Class Loss: 0.0090, JMMD Loss: 0.2453
Validation Loss: 0.0125
Epoch [9/50], Class Loss: 0.2293, JMMD Loss: 0.2120
Validation Loss: 0.3916
Epoch [10/50], Class Loss: 0.2120, JMMD Loss: 0.3459
Validation Loss: 0.2245
Epoch [11/50], Class Loss: 0.1047, JMMD Loss: 0.3082
Validation Loss: 0.0759
Epoch [12/50], Class Loss: 0.0532, JMMD Loss: 0.3012
Validation Loss: 0.0388
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 56.64%, Precision: 39.21%, Recall: 57.11%, F1 Score: 44.39%

Run 9/10
Epoch [1/50], Class Loss: 1.3707, JMMD Loss: 0.1952
Validation Loss: 0.4794
Epoch [2/50], Class Loss: 0.4434, JMMD Loss: 0.3538
Validation Loss: 0.2252
Epoch [3/50], Class Loss: 0.2795, JMMD Loss: 0.3326
Validation Loss: 0.7533
Epoch [4/50], Class Loss: 0.1802, JMMD Loss: 0.3307
Validation Loss: 0.0169
Epoch [5/50], Class Loss: 0.5362, JMMD Loss: 0.3213
Validation Loss: 0.1760
Epoch [6/50], Class Loss: 0.2669, JMMD Loss: 0.3453
Validation Loss: 0.1538
Epoch [7/50], Class Loss: 0.1248, JMMD Loss: 0.3238
Validation Loss: 0.0673
Epoch [8/50], Class Loss: 0.1128, JMMD Loss: 0.2960
Validation Loss: 0.0171
Epoch [9/50], Class Loss: 0.1358, JMMD Loss: 0.2872
Validation Loss: 0.0269
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 59.40%, Precision: 49.84%, Recall: 59.95%, F1 Score: 46.54%

Run 10/10
Epoch [1/50], Class Loss: 1.3732, JMMD Loss: 0.2243
Validation Loss: 0.6089
Epoch [2/50], Class Loss: 0.6911, JMMD Loss: 0.3610
Validation Loss: 0.2451
Epoch [3/50], Class Loss: 0.3373, JMMD Loss: 0.3532
Validation Loss: 0.8152
Epoch [4/50], Class Loss: 0.2750, JMMD Loss: 0.3533
Validation Loss: 0.1645
Epoch [5/50], Class Loss: 0.1719, JMMD Loss: 0.3256
Validation Loss: 0.1063
Epoch [6/50], Class Loss: 0.1831, JMMD Loss: 0.2986
Validation Loss: 0.2660
Epoch [7/50], Class Loss: 0.1801, JMMD Loss: 0.3262
Validation Loss: 0.0473
Epoch [8/50], Class Loss: 0.0277, JMMD Loss: 0.3012
Validation Loss: 0.0168
Epoch [9/50], Class Loss: 0.1659, JMMD Loss: 0.3241
Validation Loss: 0.1011
Epoch [10/50], Class Loss: 0.1556, JMMD Loss: 0.2978
Validation Loss: 0.1044
Epoch [11/50], Class Loss: 0.0633, JMMD Loss: 0.2812
Validation Loss: 0.0481
Epoch [12/50], Class Loss: 0.0356, JMMD Loss: 0.2889
Validation Loss: 0.0300
Epoch [13/50], Class Loss: 0.0221, JMMD Loss: 0.2841
Validation Loss: 0.0210
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 57.74%, Precision: 39.45%, Recall: 58.24%, F1 Score: 45.25%

Source performance: 99.86% 99.86% 99.86% 99.86%
Target performance: 57.09% 47.96% 57.58% 44.57%

Per-Class Accuracy on Target Domain (Mean over runs):
  Class 0: 99.88%
  Class 1: 0.13%
  Class 2: 0.02%
  Class 3: 99.91%
  Class 4: 87.93%

Run 1/10
Epoch 1/50, Train Loss: 1.3031, Train Acc: 0.4022, Val Loss: 0.8247, Val Acc: 0.5959
Epoch 2/50, Train Loss: 0.8220, Train Acc: 0.5574, Val Loss: 0.3578, Val Acc: 0.7942
Epoch 3/50, Train Loss: 0.6401, Train Acc: 0.6724, Val Loss: 1.9775, Val Acc: 0.4617
Epoch 4/50, Train Loss: 0.7806, Train Acc: 0.7097, Val Loss: 0.1975, Val Acc: 0.8350
Epoch 5/50, Train Loss: 0.4170, Train Acc: 0.8571, Val Loss: 0.1891, Val Acc: 0.8989
Epoch 6/50, Train Loss: 0.8590, Train Acc: 0.7985, Val Loss: 5.6727, Val Acc: 0.4004
Epoch 7/50, Train Loss: 0.4366, Train Acc: 0.8923, Val Loss: 0.0404, Val Acc: 0.9973
Epoch 8/50, Train Loss: 0.3016, Train Acc: 0.9243, Val Loss: 0.0767, Val Acc: 0.9712
Epoch 9/50, Train Loss: 0.8203, Train Acc: 0.8582, Val Loss: 0.5658, Val Acc: 0.7886
Epoch 10/50, Train Loss: 0.3288, Train Acc: 0.8984, Val Loss: 0.6170, Val Acc: 0.7605
Epoch 11/50, Train Loss: 0.0338, Train Acc: 0.9913, Val Loss: 0.0162, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0054, Train Acc: 0.9995, Val Loss: 0.0135, Val Acc: 0.9993
Epoch 13/50, Train Loss: 0.0038, Train Acc: 0.9996, Val Loss: 0.0119, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0029, Train Acc: 0.9995, Val Loss: 0.0105, Val Acc: 0.9990
Epoch 15/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0106, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0083, Val Acc: 0.9990
Epoch 17/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0068, Val Acc: 0.9990
Epoch 18/50, Train Loss: 0.0019, Train Acc: 0.9998, Val Loss: 0.0064, Val Acc: 0.9990
Epoch 19/50, Train Loss: 0.0018, Train Acc: 0.9995, Val Loss: 0.0064, Val Acc: 0.9993
Epoch 20/50, Train Loss: 0.0018, Train Acc: 0.9997, Val Loss: 0.0067, Val Acc: 0.9993
Epoch 21/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0067, Val Acc: 0.9993
Epoch 22/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0070, Val Acc: 0.9993
Epoch 23/50, Train Loss: 0.0010, Train Acc: 0.9998, Val Loss: 0.0066, Val Acc: 0.9990
Epoch 24/50, Train Loss: 0.0010, Train Acc: 0.9998, Val Loss: 0.0066, Val Acc: 0.9990
Early stopping!

Run 2/10
Epoch 1/50, Train Loss: 1.3872, Train Acc: 0.3805, Val Loss: 1.3822, Val Acc: 0.4128
Epoch 2/50, Train Loss: 0.7993, Train Acc: 0.6968, Val Loss: 0.3483, Val Acc: 0.7927
Epoch 3/50, Train Loss: 0.9338, Train Acc: 0.6919, Val Loss: 2.4728, Val Acc: 0.3411
Epoch 4/50, Train Loss: 0.6246, Train Acc: 0.7958, Val Loss: 0.9728, Val Acc: 0.6882
Epoch 5/50, Train Loss: 0.9249, Train Acc: 0.7339, Val Loss: 0.5421, Val Acc: 0.7356
Epoch 6/50, Train Loss: 0.6329, Train Acc: 0.7943, Val Loss: 0.4312, Val Acc: 0.7957
Epoch 7/50, Train Loss: 0.4896, Train Acc: 0.8105, Val Loss: 0.3941, Val Acc: 0.8035
Early stopping!

Run 3/10
Epoch 1/50, Train Loss: 1.3856, Train Acc: 0.4048, Val Loss: 0.3426, Val Acc: 0.9761
Epoch 2/50, Train Loss: 0.5837, Train Acc: 0.6865, Val Loss: 0.7359, Val Acc: 0.5427
Epoch 3/50, Train Loss: 0.9454, Train Acc: 0.7205, Val Loss: 0.6528, Val Acc: 0.6475
Epoch 4/50, Train Loss: 0.6387, Train Acc: 0.7935, Val Loss: 0.1079, Val Acc: 0.9985
Epoch 5/50, Train Loss: 0.9834, Train Acc: 0.7694, Val Loss: 0.4147, Val Acc: 0.8013
Epoch 6/50, Train Loss: 0.8028, Train Acc: 0.8162, Val Loss: 1.3410, Val Acc: 0.6104
Epoch 7/50, Train Loss: 0.5378, Train Acc: 0.8402, Val Loss: 0.8243, Val Acc: 0.8037
Epoch 8/50, Train Loss: 0.3868, Train Acc: 0.8995, Val Loss: 0.0752, Val Acc: 0.9888
Epoch 9/50, Train Loss: 0.2060, Train Acc: 0.9056, Val Loss: 0.4760, Val Acc: 0.8037
Epoch 10/50, Train Loss: 0.1860, Train Acc: 0.9084, Val Loss: 0.0491, Val Acc: 0.9954
Epoch 11/50, Train Loss: 0.0031, Train Acc: 0.9995, Val Loss: 0.0075, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0100, Val Acc: 0.9988
Epoch 13/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0073, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0070, Val Acc: 0.9990
Epoch 15/50, Train Loss: 0.0017, Train Acc: 0.9998, Val Loss: 0.0075, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0141, Val Acc: 0.9993
Epoch 17/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0093, Val Acc: 0.9990
Epoch 18/50, Train Loss: 0.0014, Train Acc: 0.9997, Val Loss: 0.0090, Val Acc: 0.9988
Epoch 19/50, Train Loss: 0.0020, Train Acc: 0.9993, Val Loss: 0.0081, Val Acc: 0.9985
Early stopping!

Run 4/10
Epoch 1/50, Train Loss: 1.3733, Train Acc: 0.3729, Val Loss: 0.9529, Val Acc: 0.4089
Epoch 2/50, Train Loss: 0.6616, Train Acc: 0.6052, Val Loss: 0.4471, Val Acc: 0.7209
Epoch 3/50, Train Loss: 0.5493, Train Acc: 0.7355, Val Loss: 0.2179, Val Acc: 0.9668
Epoch 4/50, Train Loss: 1.1880, Train Acc: 0.6835, Val Loss: 0.5391, Val Acc: 0.7405
Epoch 5/50, Train Loss: 1.0282, Train Acc: 0.6953, Val Loss: 0.3986, Val Acc: 0.7930
Epoch 6/50, Train Loss: 0.4537, Train Acc: 0.8390, Val Loss: 0.1345, Val Acc: 0.9985
Epoch 7/50, Train Loss: 0.2145, Train Acc: 0.8543, Val Loss: 0.2657, Val Acc: 0.8020
Epoch 8/50, Train Loss: 0.4491, Train Acc: 0.8825, Val Loss: 0.0393, Val Acc: 0.9937
Epoch 9/50, Train Loss: 0.5611, Train Acc: 0.8307, Val Loss: 0.1436, Val Acc: 0.9985
Epoch 10/50, Train Loss: 0.3809, Train Acc: 0.9127, Val Loss: 0.7193, Val Acc: 0.7942
Epoch 11/50, Train Loss: 0.0254, Train Acc: 0.9940, Val Loss: 0.0099, Val Acc: 0.9990
Epoch 12/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0091, Val Acc: 0.9988
Epoch 13/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0071, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0018, Train Acc: 0.9998, Val Loss: 0.0073, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0017, Train Acc: 0.9998, Val Loss: 0.0081, Val Acc: 0.9993
Epoch 16/50, Train Loss: 0.0017, Train Acc: 0.9998, Val Loss: 0.0086, Val Acc: 0.9993
Epoch 17/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0085, Val Acc: 0.9993
Epoch 18/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0087, Val Acc: 0.9993
Early stopping!

Run 5/10
Epoch 1/50, Train Loss: 1.2795, Train Acc: 0.4188, Val Loss: 0.8219, Val Acc: 0.5955
Epoch 2/50, Train Loss: 1.1544, Train Acc: 0.6407, Val Loss: 0.7706, Val Acc: 0.5728
Epoch 3/50, Train Loss: 0.6373, Train Acc: 0.7776, Val Loss: 0.1981, Val Acc: 0.8792
Epoch 4/50, Train Loss: 0.4827, Train Acc: 0.8272, Val Loss: 0.1519, Val Acc: 0.9978
Epoch 5/50, Train Loss: 0.8525, Train Acc: 0.8138, Val Loss: 0.1908, Val Acc: 0.8750
Epoch 6/50, Train Loss: 0.3998, Train Acc: 0.8642, Val Loss: 0.4029, Val Acc: 0.7703
Epoch 7/50, Train Loss: 0.3265, Train Acc: 0.9224, Val Loss: 3.8396, Val Acc: 0.7998
Epoch 8/50, Train Loss: 0.3071, Train Acc: 0.8942, Val Loss: 0.0160, Val Acc: 0.9993
Epoch 9/50, Train Loss: 0.7850, Train Acc: 0.8246, Val Loss: 0.3803, Val Acc: 0.8035
Epoch 10/50, Train Loss: 0.3182, Train Acc: 0.9288, Val Loss: 0.3622, Val Acc: 0.8442
Epoch 11/50, Train Loss: 0.0101, Train Acc: 0.9971, Val Loss: 0.0108, Val Acc: 0.9988
Epoch 12/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0100, Val Acc: 0.9988
Epoch 13/50, Train Loss: 0.0037, Train Acc: 0.9995, Val Loss: 0.0105, Val Acc: 0.9988
Epoch 14/50, Train Loss: 0.0033, Train Acc: 0.9996, Val Loss: 0.0087, Val Acc: 0.9985
Epoch 15/50, Train Loss: 0.0029, Train Acc: 0.9995, Val Loss: 0.0099, Val Acc: 0.9988
Epoch 16/50, Train Loss: 0.0027, Train Acc: 0.9995, Val Loss: 0.0093, Val Acc: 0.9983
Epoch 17/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0098, Val Acc: 0.9988
Epoch 18/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0091, Val Acc: 0.9988
Epoch 19/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0098, Val Acc: 0.9988
Early stopping!

Run 6/10
Epoch 1/50, Train Loss: 1.5013, Train Acc: 0.3570, Val Loss: 0.9277, Val Acc: 0.4006
Epoch 2/50, Train Loss: 0.5780, Train Acc: 0.6860, Val Loss: 0.3168, Val Acc: 0.7559
Epoch 3/50, Train Loss: 0.4819, Train Acc: 0.8068, Val Loss: 0.4070, Val Acc: 0.7332
Epoch 4/50, Train Loss: 1.0736, Train Acc: 0.7143, Val Loss: 1.2035, Val Acc: 0.4177
Epoch 5/50, Train Loss: 1.0836, Train Acc: 0.6684, Val Loss: 2.6155, Val Acc: 0.4517
Epoch 6/50, Train Loss: 0.4738, Train Acc: 0.8389, Val Loss: 0.2559, Val Acc: 0.8284
Epoch 7/50, Train Loss: 0.1025, Train Acc: 0.9594, Val Loss: 0.0274, Val Acc: 0.9990
Epoch 8/50, Train Loss: 0.5347, Train Acc: 0.8665, Val Loss: 0.0647, Val Acc: 0.9985
Epoch 9/50, Train Loss: 0.6236, Train Acc: 0.8417, Val Loss: 0.0209, Val Acc: 0.9978
Epoch 10/50, Train Loss: 0.5158, Train Acc: 0.8484, Val Loss: 0.0313, Val Acc: 0.9990
Epoch 11/50, Train Loss: 0.0049, Train Acc: 0.9995, Val Loss: 0.0095, Val Acc: 0.9988
Epoch 12/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0074, Val Acc: 0.9988
Epoch 13/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0069, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0069, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0067, Val Acc: 0.9993
Epoch 16/50, Train Loss: 0.0021, Train Acc: 0.9997, Val Loss: 0.0060, Val Acc: 0.9990
Epoch 17/50, Train Loss: 0.0021, Train Acc: 0.9997, Val Loss: 0.0076, Val Acc: 0.9993
Epoch 18/50, Train Loss: 0.0046, Train Acc: 0.9990, Val Loss: 0.0063, Val Acc: 0.9988
Epoch 19/50, Train Loss: 0.0226, Train Acc: 0.9965, Val Loss: 0.0071, Val Acc: 0.9993
Epoch 20/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0069, Val Acc: 0.9990
Epoch 21/50, Train Loss: 0.0018, Train Acc: 0.9998, Val Loss: 0.0069, Val Acc: 0.9990
Early stopping!

Run 7/10
Epoch 1/50, Train Loss: 1.3466, Train Acc: 0.4063, Val Loss: 0.6106, Val Acc: 0.7056
Epoch 2/50, Train Loss: 0.6523, Train Acc: 0.6804, Val Loss: 0.2600, Val Acc: 0.9924
Epoch 3/50, Train Loss: 0.6401, Train Acc: 0.7392, Val Loss: 0.3075, Val Acc: 0.8794
Epoch 4/50, Train Loss: 0.3278, Train Acc: 0.8389, Val Loss: 0.0670, Val Acc: 0.9968
Epoch 5/50, Train Loss: 0.5139, Train Acc: 0.8697, Val Loss: 2.9391, Val Acc: 0.5784
Epoch 6/50, Train Loss: 0.6093, Train Acc: 0.8851, Val Loss: 0.7272, Val Acc: 0.7998
Epoch 7/50, Train Loss: 0.3064, Train Acc: 0.9302, Val Loss: 2.7551, Val Acc: 0.7983
Epoch 8/50, Train Loss: 0.9041, Train Acc: 0.8168, Val Loss: 0.0558, Val Acc: 0.9978
Epoch 9/50, Train Loss: 0.4711, Train Acc: 0.8860, Val Loss: 0.2999, Val Acc: 0.8372
Epoch 10/50, Train Loss: 0.4537, Train Acc: 0.9163, Val Loss: 0.0383, Val Acc: 0.9980
Epoch 11/50, Train Loss: 0.0070, Train Acc: 0.9994, Val Loss: 0.0164, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0048, Train Acc: 0.9995, Val Loss: 0.0173, Val Acc: 0.9993
Epoch 13/50, Train Loss: 0.0038, Train Acc: 0.9997, Val Loss: 0.0156, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0034, Train Acc: 0.9997, Val Loss: 0.0141, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0029, Train Acc: 0.9998, Val Loss: 0.0118, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0028, Train Acc: 0.9997, Val Loss: 0.0106, Val Acc: 0.9990
Epoch 17/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0102, Val Acc: 0.9990
Epoch 18/50, Train Loss: 0.0018, Train Acc: 0.9998, Val Loss: 0.0075, Val Acc: 0.9993
Epoch 19/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0079, Val Acc: 0.9990
Epoch 20/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0090, Val Acc: 0.9988
Epoch 21/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0089, Val Acc: 0.9988
Epoch 22/50, Train Loss: 0.0014, Train Acc: 0.9998, Val Loss: 0.0089, Val Acc: 0.9988
Epoch 23/50, Train Loss: 0.0013, Train Acc: 0.9998, Val Loss: 0.0090, Val Acc: 0.9988
Early stopping!

Run 8/10
Epoch 1/50, Train Loss: 1.2373, Train Acc: 0.4227, Val Loss: 0.9238, Val Acc: 0.4363
Epoch 2/50, Train Loss: 1.1261, Train Acc: 0.6062, Val Loss: 1.4485, Val Acc: 0.4006
Epoch 3/50, Train Loss: 0.7780, Train Acc: 0.6300, Val Loss: 0.3389, Val Acc: 0.8005
Epoch 4/50, Train Loss: 0.4657, Train Acc: 0.8023, Val Loss: 0.8191, Val Acc: 0.7820
Epoch 5/50, Train Loss: 0.5982, Train Acc: 0.7963, Val Loss: 0.0462, Val Acc: 0.9983
Epoch 6/50, Train Loss: 0.7363, Train Acc: 0.8148, Val Loss: 0.2161, Val Acc: 0.8005
Epoch 7/50, Train Loss: 0.5303, Train Acc: 0.8515, Val Loss: 0.6108, Val Acc: 0.7937
Epoch 8/50, Train Loss: 0.4211, Train Acc: 0.8947, Val Loss: 0.1470, Val Acc: 0.9971
Epoch 9/50, Train Loss: 0.3043, Train Acc: 0.9343, Val Loss: 0.0280, Val Acc: 0.9988
Epoch 10/50, Train Loss: 0.3031, Train Acc: 0.9385, Val Loss: 0.0109, Val Acc: 0.9993
Epoch 11/50, Train Loss: 0.0069, Train Acc: 0.9993, Val Loss: 0.0091, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0054, Train Acc: 0.9994, Val Loss: 0.0070, Val Acc: 0.9993
Epoch 13/50, Train Loss: 0.0047, Train Acc: 0.9994, Val Loss: 0.0054, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0040, Train Acc: 0.9995, Val Loss: 0.0054, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0055, Val Acc: 0.9993
Epoch 16/50, Train Loss: 0.0074, Train Acc: 0.9974, Val Loss: 0.0113, Val Acc: 0.9988
Epoch 17/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0058, Val Acc: 0.9990
Epoch 18/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0055, Val Acc: 0.9993
Epoch 19/50, Train Loss: 0.0022, Train Acc: 0.9997, Val Loss: 0.0058, Val Acc: 0.9990
Early stopping!

Run 9/10
Epoch 1/50, Train Loss: 1.2839, Train Acc: 0.3792, Val Loss: 0.5952, Val Acc: 0.6511
Epoch 2/50, Train Loss: 0.5405, Train Acc: 0.6909, Val Loss: 0.6069, Val Acc: 0.6909
Epoch 3/50, Train Loss: 1.0435, Train Acc: 0.6840, Val Loss: 3.6498, Val Acc: 0.4246
Epoch 4/50, Train Loss: 0.8722, Train Acc: 0.7378, Val Loss: 0.6086, Val Acc: 0.8005
Epoch 5/50, Train Loss: 0.9094, Train Acc: 0.7802, Val Loss: 0.0205, Val Acc: 0.9988
Epoch 6/50, Train Loss: 0.6775, Train Acc: 0.8275, Val Loss: 0.0655, Val Acc: 0.9988
Epoch 7/50, Train Loss: 0.5471, Train Acc: 0.8460, Val Loss: 2.4158, Val Acc: 0.4150
Epoch 8/50, Train Loss: 0.5197, Train Acc: 0.8936, Val Loss: 0.0233, Val Acc: 0.9988
Epoch 9/50, Train Loss: 0.3546, Train Acc: 0.9324, Val Loss: 0.0116, Val Acc: 0.9990
Epoch 10/50, Train Loss: 0.3695, Train Acc: 0.9349, Val Loss: 0.0324, Val Acc: 0.9985
Epoch 11/50, Train Loss: 0.0084, Train Acc: 0.9995, Val Loss: 0.0113, Val Acc: 0.9990
Epoch 12/50, Train Loss: 0.0068, Train Acc: 0.9995, Val Loss: 0.0078, Val Acc: 0.9990
Epoch 13/50, Train Loss: 0.0053, Train Acc: 0.9995, Val Loss: 0.0066, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0044, Train Acc: 0.9996, Val Loss: 0.0073, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0039, Train Acc: 0.9996, Val Loss: 0.0075, Val Acc: 0.9993
Epoch 16/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0078, Val Acc: 0.9993
Epoch 17/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0078, Val Acc: 0.9993
Epoch 18/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0080, Val Acc: 0.9993
Early stopping!

Run 10/10
Epoch 1/50, Train Loss: 1.3920, Train Acc: 0.3937, Val Loss: 5.3599, Val Acc: 0.3999
Epoch 2/50, Train Loss: 1.1979, Train Acc: 0.5139, Val Loss: 0.6701, Val Acc: 0.5908
Epoch 3/50, Train Loss: 1.0184, Train Acc: 0.6533, Val Loss: 0.8484, Val Acc: 0.4692
Epoch 4/50, Train Loss: 0.6474, Train Acc: 0.6968, Val Loss: 0.6109, Val Acc: 0.7861
Epoch 5/50, Train Loss: 0.8004, Train Acc: 0.7590, Val Loss: 0.5438, Val Acc: 0.7634
Epoch 6/50, Train Loss: 0.6597, Train Acc: 0.7789, Val Loss: 0.0960, Val Acc: 0.9988
Epoch 7/50, Train Loss: 0.6987, Train Acc: 0.8226, Val Loss: 0.1509, Val Acc: 0.9138
Epoch 8/50, Train Loss: 0.4386, Train Acc: 0.8790, Val Loss: 0.0085, Val Acc: 0.9990
Epoch 9/50, Train Loss: 0.5057, Train Acc: 0.9064, Val Loss: 0.2067, Val Acc: 0.8540
Epoch 10/50, Train Loss: 0.3966, Train Acc: 0.9260, Val Loss: 2.4621, Val Acc: 0.6104
Epoch 11/50, Train Loss: 0.0937, Train Acc: 0.9808, Val Loss: 0.0071, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0076, Val Acc: 0.9990
Epoch 13/50, Train Loss: 0.0021, Train Acc: 0.9997, Val Loss: 0.0081, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0019, Train Acc: 0.9997, Val Loss: 0.0090, Val Acc: 0.9988
Epoch 15/50, Train Loss: 0.0022, Train Acc: 0.9997, Val Loss: 0.0075, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0085, Val Acc: 0.9990
Early stopping!

Source performance: 97.94 98.84 97.92 97.36
Target performance: 66.21 62.92 65.54 58.51

bpsk: 99.88
qpsk: 0.39
4qam: 83.70
16qam: 43.80
apsk: 99.93
Epoch 1/25, Loss: 3.1316, Domain Loss: 1.4301, Class Loss: 1.7015
Epoch 2/25, Loss: 3.0176, Domain Loss: 1.3863, Class Loss: 1.6313
Epoch 3/25, Loss: 2.7617, Domain Loss: 1.3915, Class Loss: 1.3702
Epoch 4/25, Loss: 2.4279, Domain Loss: 1.3990, Class Loss: 1.0289
Epoch 5/25, Loss: 2.4298, Domain Loss: 1.3879, Class Loss: 1.0419
Epoch 6/25, Loss: 1.9063, Domain Loss: 1.3709, Class Loss: 0.5355
Epoch 7/25, Loss: 1.9101, Domain Loss: 1.2650, Class Loss: 0.6451
Epoch 8/25, Loss: 2.9183, Domain Loss: 1.4883, Class Loss: 1.4299
Epoch 9/25, Loss: 1.8099, Domain Loss: 1.2433, Class Loss: 0.5666
Epoch 10/25, Loss: 1.5545, Domain Loss: 1.1885, Class Loss: 0.3660
Epoch 11/25, Loss: 1.4289, Domain Loss: 1.1473, Class Loss: 0.2817
Epoch 12/25, Loss: 1.3825, Domain Loss: 1.1028, Class Loss: 0.2796
Epoch 13/25, Loss: 1.6669, Domain Loss: 1.0479, Class Loss: 0.6191
Epoch 14/25, Loss: 1.5011, Domain Loss: 1.1255, Class Loss: 0.3756
Epoch 15/25, Loss: 4.7082, Domain Loss: 2.8846, Class Loss: 1.8236
Epoch 16/25, Loss: 2.4463, Domain Loss: 1.7578, Class Loss: 0.6884
Epoch 17/25, Loss: 3.8455, Domain Loss: 1.9164, Class Loss: 1.9291
Epoch 18/25, Loss: 1.9796, Domain Loss: 1.5133, Class Loss: 0.4663
Epoch 19/25, Loss: 1.5917, Domain Loss: 1.3685, Class Loss: 0.2232
Epoch 20/25, Loss: 2.6995, Domain Loss: 2.0025, Class Loss: 0.6969
Epoch 21/25, Loss: 4.8792, Domain Loss: 2.8467, Class Loss: 2.0325
Epoch 22/25, Loss: 2.4424, Domain Loss: 1.3094, Class Loss: 1.1330
Epoch 23/25, Loss: 2.0715, Domain Loss: 1.1971, Class Loss: 0.8744
Epoch 24/25, Loss: 1.8480, Domain Loss: 1.1902, Class Loss: 0.6578
Epoch 25/25, Loss: 1.4834, Domain Loss: 1.1380, Class Loss: 0.3454
79.05


Epoch 1/25, Loss: 3.0715, Domain Loss: 1.4107, Class Loss: 1.6608
Epoch 2/25, Loss: 2.5946, Domain Loss: 1.3887, Class Loss: 1.2059
Epoch 3/25, Loss: 2.3716, Domain Loss: 1.3726, Class Loss: 0.9990
Epoch 4/25, Loss: 3.2707, Domain Loss: 1.4155, Class Loss: 1.8552
Epoch 5/25, Loss: 2.4581, Domain Loss: 1.3735, Class Loss: 1.0845
Epoch 6/25, Loss: 2.1779, Domain Loss: 1.3539, Class Loss: 0.8240
Epoch 7/25, Loss: 1.7278, Domain Loss: 1.2511, Class Loss: 0.4767
Epoch 8/25, Loss: 1.5229, Domain Loss: 1.2012, Class Loss: 0.3216
Epoch 9/25, Loss: 2.1540, Domain Loss: 1.3056, Class Loss: 0.8484
Epoch 10/25, Loss: 1.9453, Domain Loss: 1.3585, Class Loss: 0.5868
Epoch 11/25, Loss: 1.8567, Domain Loss: 1.3195, Class Loss: 0.5372
Epoch 12/25, Loss: 2.5494, Domain Loss: 1.6628, Class Loss: 0.8866
Epoch 13/25, Loss: 1.8251, Domain Loss: 1.3117, Class Loss: 0.5134
Epoch 14/25, Loss: 1.4621, Domain Loss: 1.2282, Class Loss: 0.2339
Epoch 15/25, Loss: 3.2950, Domain Loss: 1.6804, Class Loss: 1.6145
Epoch 16/25, Loss: 1.8346, Domain Loss: 1.4330, Class Loss: 0.4016
Epoch 17/25, Loss: 1.7186, Domain Loss: 1.4875, Class Loss: 0.2310
Epoch 18/25, Loss: 1.9058, Domain Loss: 1.5442, Class Loss: 0.3616
Epoch 19/25, Loss: 1.4697, Domain Loss: 1.1978, Class Loss: 0.2719
Epoch 20/25, Loss: 8.0627, Domain Loss: 5.2088, Class Loss: 2.8538
Epoch 21/25, Loss: 5.4131, Domain Loss: 4.7474, Class Loss: 0.6657
Epoch 22/25, Loss: 2.6585, Domain Loss: 2.2549, Class Loss: 0.4036
Epoch 23/25, Loss: 5.5715, Domain Loss: 3.7321, Class Loss: 1.8394
Epoch 24/25, Loss: 6.6602, Domain Loss: 5.0547, Class Loss: 1.6055
Epoch 25/25, Loss: 12.6187, Domain Loss: 11.1558, Class Loss: 1.4629
39.62


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1033, Domain Loss: 1.4068, Class Loss: 1.6965
Epoch 2/25, Loss: 2.7762, Domain Loss: 1.3885, Class Loss: 1.3877
Epoch 3/25, Loss: 2.3180, Domain Loss: 1.3457, Class Loss: 0.9724
Epoch 4/25, Loss: 2.8459, Domain Loss: 1.4751, Class Loss: 1.3708
Epoch 5/25, Loss: 2.2896, Domain Loss: 1.4544, Class Loss: 0.8351
Epoch 6/25, Loss: 1.9151, Domain Loss: 1.3361, Class Loss: 0.5789
Epoch 7/25, Loss: 1.6840, Domain Loss: 1.2774, Class Loss: 0.4066
Epoch 8/25, Loss: 1.4891, Domain Loss: 1.2643, Class Loss: 0.2248
Epoch 9/25, Loss: 1.5376, Domain Loss: 1.2390, Class Loss: 0.2986
Epoch 10/25, Loss: 3.8733, Domain Loss: 1.8819, Class Loss: 1.9914
Epoch 11/25, Loss: 2.3572, Domain Loss: 1.5657, Class Loss: 0.7915
Epoch 12/25, Loss: 1.7371, Domain Loss: 1.3717, Class Loss: 0.3655
Epoch 13/25, Loss: 2.1302, Domain Loss: 1.5532, Class Loss: 0.5770
Epoch 14/25, Loss: 1.8237, Domain Loss: 1.4092, Class Loss: 0.4144
Epoch 15/25, Loss: 1.5427, Domain Loss: 1.2316, Class Loss: 0.3111
Epoch 16/25, Loss: 1.3989, Domain Loss: 1.1995, Class Loss: 0.1994
Epoch 17/25, Loss: 1.3311, Domain Loss: 1.1798, Class Loss: 0.1513
Epoch 18/25, Loss: 1.4906, Domain Loss: 1.3181, Class Loss: 0.1725
Epoch 19/25, Loss: 1.3134, Domain Loss: 1.1362, Class Loss: 0.1772
Epoch 20/25, Loss: 1.1931, Domain Loss: 1.1066, Class Loss: 0.0865
Epoch 21/25, Loss: 1.4352, Domain Loss: 1.1886, Class Loss: 0.2465
Epoch 22/25, Loss: 1.5779, Domain Loss: 1.2434, Class Loss: 0.3345
Epoch 23/25, Loss: 1.6477, Domain Loss: 1.2514, Class Loss: 0.3963
Epoch 24/25, Loss: 1.7146, Domain Loss: 1.3248, Class Loss: 0.3898
Epoch 25/25, Loss: 1.5440, Domain Loss: 1.2367, Class Loss: 0.3073
34.77


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1407, Domain Loss: 1.4220, Class Loss: 1.7186
Epoch 2/25, Loss: 2.8615, Domain Loss: 1.3867, Class Loss: 1.4749
Epoch 3/25, Loss: 2.2336, Domain Loss: 1.3742, Class Loss: 0.8594
Epoch 4/25, Loss: 2.2357, Domain Loss: 1.3827, Class Loss: 0.8530
Epoch 5/25, Loss: 1.9960, Domain Loss: 1.3482, Class Loss: 0.6477
Epoch 6/25, Loss: 1.4862, Domain Loss: 1.1522, Class Loss: 0.3340
Epoch 7/25, Loss: 2.9077, Domain Loss: 1.5458, Class Loss: 1.3619
Epoch 8/25, Loss: 3.8870, Domain Loss: 1.9547, Class Loss: 1.9323
Epoch 9/25, Loss: 2.4265, Domain Loss: 1.4035, Class Loss: 1.0230
Epoch 10/25, Loss: 2.0928, Domain Loss: 1.3863, Class Loss: 0.7066
Epoch 11/25, Loss: 2.2542, Domain Loss: 1.3851, Class Loss: 0.8691
Epoch 12/25, Loss: 1.7804, Domain Loss: 1.3832, Class Loss: 0.3972
Epoch 13/25, Loss: 1.8932, Domain Loss: 1.3812, Class Loss: 0.5120
Epoch 14/25, Loss: 1.7236, Domain Loss: 1.3766, Class Loss: 0.3471
Epoch 15/25, Loss: 1.7991, Domain Loss: 1.3664, Class Loss: 0.4327
Epoch 16/25, Loss: 1.5503, Domain Loss: 1.3432, Class Loss: 0.2071
Epoch 17/25, Loss: 1.5713, Domain Loss: 1.3335, Class Loss: 0.2377
Epoch 18/25, Loss: 1.5348, Domain Loss: 1.2971, Class Loss: 0.2377
Epoch 19/25, Loss: 1.5226, Domain Loss: 1.2384, Class Loss: 0.2842
Epoch 20/25, Loss: 1.5468, Domain Loss: 1.2194, Class Loss: 0.3274
Epoch 21/25, Loss: 1.8522, Domain Loss: 1.3179, Class Loss: 0.5343
Epoch 22/25, Loss: 1.5157, Domain Loss: 1.2644, Class Loss: 0.2513
Epoch 23/25, Loss: 1.8817, Domain Loss: 1.3357, Class Loss: 0.5460
Epoch 24/25, Loss: 1.5765, Domain Loss: 1.2152, Class Loss: 0.3613
Epoch 25/25, Loss: 1.3654, Domain Loss: 1.1463, Class Loss: 0.2191
68.29


Epoch 1/25, Loss: 3.1193, Domain Loss: 1.4224, Class Loss: 1.6970
Epoch 2/25, Loss: 2.9345, Domain Loss: 1.3924, Class Loss: 1.5420
Epoch 3/25, Loss: 2.1718, Domain Loss: 1.3419, Class Loss: 0.8299
Epoch 4/25, Loss: 2.4319, Domain Loss: 1.3963, Class Loss: 1.0356
Epoch 5/25, Loss: 1.7431, Domain Loss: 1.3131, Class Loss: 0.4300
Epoch 6/25, Loss: 1.9920, Domain Loss: 1.2248, Class Loss: 0.7673
Epoch 7/25, Loss: 1.6088, Domain Loss: 1.2356, Class Loss: 0.3732
Epoch 8/25, Loss: 2.6855, Domain Loss: 1.3344, Class Loss: 1.3512
Epoch 9/25, Loss: 1.7538, Domain Loss: 1.3000, Class Loss: 0.4538
Epoch 10/25, Loss: 1.7109, Domain Loss: 1.1933, Class Loss: 0.5175
Epoch 11/25, Loss: 3.4702, Domain Loss: 1.9758, Class Loss: 1.4944
Epoch 12/25, Loss: 1.7480, Domain Loss: 1.4464, Class Loss: 0.3016
Epoch 13/25, Loss: 1.4989, Domain Loss: 1.3215, Class Loss: 0.1773
Epoch 14/25, Loss: 1.4810, Domain Loss: 1.3414, Class Loss: 0.1395
Epoch 15/25, Loss: 1.5415, Domain Loss: 1.2964, Class Loss: 0.2451
Epoch 16/25, Loss: 1.4612, Domain Loss: 1.3659, Class Loss: 0.0953
Epoch 17/25, Loss: 4.6381, Domain Loss: 2.5601, Class Loss: 2.0780
Epoch 18/25, Loss: 2.4833, Domain Loss: 1.8459, Class Loss: 0.6374
Epoch 19/25, Loss: 1.4532, Domain Loss: 1.2116, Class Loss: 0.2416
Epoch 20/25, Loss: 1.7101, Domain Loss: 1.2710, Class Loss: 0.4391
Epoch 21/25, Loss: 1.7214, Domain Loss: 1.3553, Class Loss: 0.3661
Epoch 22/25, Loss: 1.8075, Domain Loss: 1.5920, Class Loss: 0.2155
Epoch 23/25, Loss: 1.9744, Domain Loss: 1.4453, Class Loss: 0.5291
Epoch 24/25, Loss: 2.1381, Domain Loss: 1.4572, Class Loss: 0.6809
Epoch 25/25, Loss: 1.7762, Domain Loss: 1.4410, Class Loss: 0.3352
75.34


Epoch 1/25, Loss: 3.1341, Domain Loss: 1.4202, Class Loss: 1.7140
Epoch 2/25, Loss: 2.9120, Domain Loss: 1.3900, Class Loss: 1.5220
Epoch 3/25, Loss: 2.7123, Domain Loss: 1.4190, Class Loss: 1.2933
Epoch 4/25, Loss: 3.3050, Domain Loss: 1.8924, Class Loss: 1.4126
Epoch 5/25, Loss: 3.4024, Domain Loss: 2.0194, Class Loss: 1.3830
Epoch 6/25, Loss: 2.9895, Domain Loss: 1.7791, Class Loss: 1.2104
Epoch 7/25, Loss: 3.3369, Domain Loss: 1.7363, Class Loss: 1.6006
Epoch 8/25, Loss: 3.0096, Domain Loss: 1.4142, Class Loss: 1.5954
Epoch 9/25, Loss: 2.9933, Domain Loss: 1.3865, Class Loss: 1.6068
Epoch 10/25, Loss: 2.9964, Domain Loss: 1.3864, Class Loss: 1.6100
Epoch 11/25, Loss: 2.9664, Domain Loss: 1.3864, Class Loss: 1.5800
Epoch 12/25, Loss: 2.9694, Domain Loss: 1.4078, Class Loss: 1.5615
Epoch 13/25, Loss: 3.0441, Domain Loss: 1.4065, Class Loss: 1.6376
Epoch 14/25, Loss: 2.9788, Domain Loss: 1.3868, Class Loss: 1.5920
Epoch 15/25, Loss: 3.0481, Domain Loss: 1.5022, Class Loss: 1.5458
Epoch 16/25, Loss: 2.9496, Domain Loss: 1.4224, Class Loss: 1.5272
Epoch 17/25, Loss: 2.9051, Domain Loss: 1.3880, Class Loss: 1.5172
Epoch 18/25, Loss: 2.7892, Domain Loss: 1.3987, Class Loss: 1.3906
Epoch 19/25, Loss: 3.0131, Domain Loss: 1.7707, Class Loss: 1.2423
Epoch 20/25, Loss: 2.6378, Domain Loss: 1.4324, Class Loss: 1.2054
Epoch 21/25, Loss: 2.3991, Domain Loss: 1.3873, Class Loss: 1.0118
Epoch 22/25, Loss: 2.2984, Domain Loss: 1.3863, Class Loss: 0.9121
Epoch 23/25, Loss: 2.1844, Domain Loss: 1.3870, Class Loss: 0.7974
Epoch 24/25, Loss: 2.0879, Domain Loss: 1.3882, Class Loss: 0.6997
Epoch 25/25, Loss: 2.0341, Domain Loss: 1.3861, Class Loss: 0.6480
59.77


Epoch 1/25, Loss: 3.1316, Domain Loss: 1.4378, Class Loss: 1.6938
Epoch 2/25, Loss: 2.8938, Domain Loss: 1.3903, Class Loss: 1.5035
Epoch 3/25, Loss: 2.2460, Domain Loss: 1.3450, Class Loss: 0.9010
Epoch 4/25, Loss: 1.7655, Domain Loss: 1.2520, Class Loss: 0.5135
Epoch 5/25, Loss: 4.3837, Domain Loss: 1.4576, Class Loss: 2.9262
Epoch 6/25, Loss: 2.3542, Domain Loss: 1.2758, Class Loss: 1.0784
Epoch 7/25, Loss: 1.9599, Domain Loss: 1.2006, Class Loss: 0.7593
Epoch 8/25, Loss: 1.6624, Domain Loss: 1.1687, Class Loss: 0.4937
Epoch 9/25, Loss: 1.6028, Domain Loss: 1.1471, Class Loss: 0.4557
Epoch 10/25, Loss: 1.3522, Domain Loss: 1.0680, Class Loss: 0.2841
Epoch 11/25, Loss: 1.2326, Domain Loss: 1.0137, Class Loss: 0.2189
Epoch 12/25, Loss: 1.7249, Domain Loss: 1.2686, Class Loss: 0.4563
Epoch 13/25, Loss: 1.6495, Domain Loss: 1.2503, Class Loss: 0.3992
Epoch 14/25, Loss: 1.8314, Domain Loss: 1.1917, Class Loss: 0.6397
Epoch 15/25, Loss: 1.5134, Domain Loss: 1.2029, Class Loss: 0.3105
Epoch 16/25, Loss: 1.6896, Domain Loss: 1.2629, Class Loss: 0.4267
Epoch 17/25, Loss: 2.2872, Domain Loss: 1.3788, Class Loss: 0.9084
Epoch 18/25, Loss: 1.6958, Domain Loss: 1.2964, Class Loss: 0.3994
Epoch 19/25, Loss: 1.6657, Domain Loss: 1.2662, Class Loss: 0.3994
Epoch 20/25, Loss: 1.4862, Domain Loss: 1.2345, Class Loss: 0.2516
Epoch 21/25, Loss: 1.6700, Domain Loss: 1.2273, Class Loss: 0.4427
Epoch 22/25, Loss: 1.4146, Domain Loss: 1.2167, Class Loss: 0.1979
Epoch 23/25, Loss: 2.2160, Domain Loss: 1.3052, Class Loss: 0.9109
Epoch 24/25, Loss: 1.6841, Domain Loss: 1.3859, Class Loss: 0.2982
Epoch 25/25, Loss: 1.5995, Domain Loss: 1.3657, Class Loss: 0.2338
69.92


Epoch 1/25, Loss: 3.1299, Domain Loss: 1.4198, Class Loss: 1.7101
Epoch 2/25, Loss: 2.8663, Domain Loss: 1.3869, Class Loss: 1.4794
Epoch 3/25, Loss: 2.6810, Domain Loss: 1.3723, Class Loss: 1.3087
Epoch 4/25, Loss: 3.4195, Domain Loss: 1.4481, Class Loss: 1.9714
Epoch 5/25, Loss: 2.9002, Domain Loss: 1.3862, Class Loss: 1.5139
Epoch 6/25, Loss: 2.5970, Domain Loss: 1.3862, Class Loss: 1.2109
Epoch 7/25, Loss: 2.2078, Domain Loss: 1.3863, Class Loss: 0.8215
Epoch 8/25, Loss: 2.2325, Domain Loss: 1.3860, Class Loss: 0.8465
Epoch 9/25, Loss: 1.8218, Domain Loss: 1.3859, Class Loss: 0.4359
Epoch 10/25, Loss: 2.3449, Domain Loss: 1.3859, Class Loss: 0.9590
Epoch 11/25, Loss: 1.8369, Domain Loss: 1.3868, Class Loss: 0.4501
Epoch 12/25, Loss: 1.6571, Domain Loss: 1.3865, Class Loss: 0.2706
Epoch 13/25, Loss: 1.6817, Domain Loss: 1.3863, Class Loss: 0.2953
Epoch 14/25, Loss: 1.9854, Domain Loss: 1.3863, Class Loss: 0.5991
Epoch 15/25, Loss: 1.6476, Domain Loss: 1.3850, Class Loss: 0.2625
Epoch 16/25, Loss: 1.5634, Domain Loss: 1.3717, Class Loss: 0.1917
Epoch 17/25, Loss: 1.5052, Domain Loss: 1.3360, Class Loss: 0.1692
Epoch 18/25, Loss: 1.6958, Domain Loss: 1.3009, Class Loss: 0.3949
Epoch 19/25, Loss: 1.5389, Domain Loss: 1.2900, Class Loss: 0.2489
Epoch 20/25, Loss: 1.4521, Domain Loss: 1.2729, Class Loss: 0.1792
Epoch 21/25, Loss: 1.4333, Domain Loss: 1.2780, Class Loss: 0.1553
Epoch 22/25, Loss: 1.4667, Domain Loss: 1.2696, Class Loss: 0.1971
Epoch 23/25, Loss: 1.5579, Domain Loss: 1.2746, Class Loss: 0.2833
Epoch 24/25, Loss: 1.3497, Domain Loss: 1.2122, Class Loss: 0.1375
Epoch 25/25, Loss: 1.1926, Domain Loss: 1.0816, Class Loss: 0.1111
76.12


Epoch 1/25, Loss: 3.1240, Domain Loss: 1.4141, Class Loss: 1.7099
Epoch 2/25, Loss: 2.9091, Domain Loss: 1.3880, Class Loss: 1.5211
Epoch 3/25, Loss: 2.5073, Domain Loss: 1.3830, Class Loss: 1.1243
Epoch 4/25, Loss: 2.2195, Domain Loss: 1.3163, Class Loss: 0.9032
Epoch 5/25, Loss: 3.0195, Domain Loss: 1.5494, Class Loss: 1.4702
Epoch 6/25, Loss: 3.5358, Domain Loss: 1.3923, Class Loss: 2.1435
Epoch 7/25, Loss: 2.3258, Domain Loss: 1.3896, Class Loss: 0.9362
Epoch 8/25, Loss: 2.4350, Domain Loss: 1.3861, Class Loss: 1.0489
Epoch 9/25, Loss: 2.0567, Domain Loss: 1.3851, Class Loss: 0.6716
Epoch 10/25, Loss: 1.8020, Domain Loss: 1.3853, Class Loss: 0.4167
Epoch 11/25, Loss: 1.9488, Domain Loss: 1.3843, Class Loss: 0.5644
Epoch 12/25, Loss: 1.7216, Domain Loss: 1.3843, Class Loss: 0.3372
Epoch 13/25, Loss: 1.5999, Domain Loss: 1.3819, Class Loss: 0.2179
Epoch 14/25, Loss: 1.6051, Domain Loss: 1.3822, Class Loss: 0.2230
Epoch 15/25, Loss: 1.6009, Domain Loss: 1.3786, Class Loss: 0.2223
Epoch 16/25, Loss: 1.6199, Domain Loss: 1.3793, Class Loss: 0.2407
Epoch 17/25, Loss: 2.1774, Domain Loss: 1.3823, Class Loss: 0.7951
Epoch 18/25, Loss: 1.6220, Domain Loss: 1.3728, Class Loss: 0.2492
Epoch 19/25, Loss: 1.6649, Domain Loss: 1.3757, Class Loss: 0.2892
Epoch 20/25, Loss: 1.6705, Domain Loss: 1.3756, Class Loss: 0.2949
Epoch 21/25, Loss: 1.5352, Domain Loss: 1.3702, Class Loss: 0.1650
Epoch 22/25, Loss: 1.4568, Domain Loss: 1.3747, Class Loss: 0.0821
Epoch 23/25, Loss: 1.4067, Domain Loss: 1.3716, Class Loss: 0.0352
Epoch 24/25, Loss: 2.5264, Domain Loss: 1.3828, Class Loss: 1.1435
Epoch 25/25, Loss: 1.7568, Domain Loss: 1.3657, Class Loss: 0.3912
79.47


Epoch 1/25, Loss: 3.1166, Domain Loss: 1.4243, Class Loss: 1.6923
Epoch 2/25, Loss: 3.0454, Domain Loss: 1.3889, Class Loss: 1.6566
Epoch 3/25, Loss: 2.5567, Domain Loss: 1.3815, Class Loss: 1.1752
Epoch 4/25, Loss: 2.2238, Domain Loss: 1.3702, Class Loss: 0.8536
Epoch 5/25, Loss: 2.6647, Domain Loss: 1.3641, Class Loss: 1.3006
Epoch 6/25, Loss: 2.0103, Domain Loss: 1.3397, Class Loss: 0.6706
Epoch 7/25, Loss: 1.6645, Domain Loss: 1.3087, Class Loss: 0.3558
Epoch 8/25, Loss: 2.6222, Domain Loss: 1.3436, Class Loss: 1.2786
Epoch 9/25, Loss: 1.8062, Domain Loss: 1.2972, Class Loss: 0.5090
Epoch 10/25, Loss: 1.7139, Domain Loss: 1.3500, Class Loss: 0.3640
Epoch 11/25, Loss: 1.5031, Domain Loss: 1.3124, Class Loss: 0.1907
Epoch 12/25, Loss: 1.7664, Domain Loss: 1.3335, Class Loss: 0.4328
Epoch 13/25, Loss: 2.7834, Domain Loss: 1.6277, Class Loss: 1.1557
Epoch 14/25, Loss: 2.8617, Domain Loss: 1.4027, Class Loss: 1.4591
Epoch 15/25, Loss: 1.9153, Domain Loss: 1.3510, Class Loss: 0.5643
Epoch 16/25, Loss: 1.8255, Domain Loss: 1.2449, Class Loss: 0.5807
Epoch 17/25, Loss: 5.0320, Domain Loss: 3.4923, Class Loss: 1.5397
Epoch 18/25, Loss: 18.3608, Domain Loss: 13.0578, Class Loss: 5.3029
Epoch 19/25, Loss: 4.5712, Domain Loss: 2.7031, Class Loss: 1.8681
Epoch 20/25, Loss: 2.8981, Domain Loss: 1.4289, Class Loss: 1.4692
Epoch 21/25, Loss: 2.5126, Domain Loss: 1.4022, Class Loss: 1.1103
Epoch 22/25, Loss: 2.2766, Domain Loss: 1.4058, Class Loss: 0.8708
Epoch 23/25, Loss: 2.0838, Domain Loss: 1.4304, Class Loss: 0.6533
Epoch 24/25, Loss: 1.7680, Domain Loss: 1.3851, Class Loss: 0.3829
Epoch 25/25, Loss: 1.7135, Domain Loss: 1.3873, Class Loss: 0.3262
43.21


Source performance:
80.41 77.82 80.36 76.36 
Target performance:
62.56 56.78 62.39 54.98 

Per-class target performance: 89.95 1.22 62.05 70.43 88.29 
Run 1/10
Epoch [1/50], Class Loss: 3.9264, Discrepancy Loss: 0.1188
Epoch [2/50], Class Loss: 0.7342, Discrepancy Loss: 0.1311
Epoch [3/50], Class Loss: 0.5206, Discrepancy Loss: 0.1121
Epoch [4/50], Class Loss: 0.4675, Discrepancy Loss: 0.1077
Epoch [5/50], Class Loss: 0.7696, Discrepancy Loss: 0.1160
Epoch [6/50], Class Loss: 0.3556, Discrepancy Loss: 0.1043
Epoch [7/50], Class Loss: 0.2174, Discrepancy Loss: 0.0855
Epoch [8/50], Class Loss: 0.1757, Discrepancy Loss: 0.0842
Epoch [9/50], Class Loss: 0.2023, Discrepancy Loss: 0.0841
Epoch [10/50], Class Loss: 0.1788, Discrepancy Loss: 0.0872
Epoch [11/50], Class Loss: 0.0611, Discrepancy Loss: 0.0665
Epoch [12/50], Class Loss: 0.0370, Discrepancy Loss: 0.0671
Epoch [13/50], Class Loss: 0.0550, Discrepancy Loss: 0.0662
Epoch [14/50], Class Loss: 0.0532, Discrepancy Loss: 0.0625
Epoch [15/50], Class Loss: 0.0301, Discrepancy Loss: 0.0782
Epoch [16/50], Class Loss: 0.0406, Discrepancy Loss: 0.0708
Epoch [17/50], Class Loss: 0.0350, Discrepancy Loss: 0.0736
Epoch [18/50], Class Loss: 0.0430, Discrepancy Loss: 0.0696
Epoch [19/50], Class Loss: 0.0266, Discrepancy Loss: 0.0725
Epoch [20/50], Class Loss: 0.0260, Discrepancy Loss: 0.0656
Epoch [21/50], Class Loss: 0.0139, Discrepancy Loss: 0.0527
Epoch [22/50], Class Loss: 0.0196, Discrepancy Loss: 0.0540
Epoch [23/50], Class Loss: 0.0146, Discrepancy Loss: 0.0550
Epoch [24/50], Class Loss: 0.0207, Discrepancy Loss: 0.0568
Epoch [25/50], Class Loss: 0.0187, Discrepancy Loss: 0.0607
Epoch [26/50], Class Loss: 0.0204, Discrepancy Loss: 0.0712
Epoch [27/50], Class Loss: 0.0228, Discrepancy Loss: 0.0686
Epoch [28/50], Class Loss: 0.0232, Discrepancy Loss: 0.0690
Epoch [29/50], Class Loss: 0.0281, Discrepancy Loss: 0.0706
Epoch [30/50], Class Loss: 0.0374, Discrepancy Loss: 0.0714
Epoch [31/50], Class Loss: 0.0325, Discrepancy Loss: 0.0736
Epoch [32/50], Class Loss: 0.0352, Discrepancy Loss: 0.0676
Epoch [33/50], Class Loss: 0.0278, Discrepancy Loss: 0.0738
Epoch [34/50], Class Loss: 0.0312, Discrepancy Loss: 0.0736
Epoch [35/50], Class Loss: 0.0322, Discrepancy Loss: 0.0728
Epoch [36/50], Class Loss: 0.0352, Discrepancy Loss: 0.0693
Epoch [37/50], Class Loss: 0.0424, Discrepancy Loss: 0.0759
Epoch [38/50], Class Loss: 0.0236, Discrepancy Loss: 0.0758
Epoch [39/50], Class Loss: 0.0441, Discrepancy Loss: 0.0762
Epoch [40/50], Class Loss: 0.0293, Discrepancy Loss: 0.0774
Epoch [41/50], Class Loss: 0.0357, Discrepancy Loss: 0.0719
Epoch [42/50], Class Loss: 0.0293, Discrepancy Loss: 0.0792
Epoch [43/50], Class Loss: 0.0282, Discrepancy Loss: 0.0734
Epoch [44/50], Class Loss: 0.0321, Discrepancy Loss: 0.0768
Epoch [45/50], Class Loss: 0.0358, Discrepancy Loss: 0.0812
Epoch [46/50], Class Loss: 0.0261, Discrepancy Loss: 0.0776
Epoch [47/50], Class Loss: 0.0356, Discrepancy Loss: 0.0815
Epoch [48/50], Class Loss: 0.0310, Discrepancy Loss: 0.0769
Epoch [49/50], Class Loss: 0.0411, Discrepancy Loss: 0.0765
Epoch [50/50], Class Loss: 0.0353, Discrepancy Loss: 0.0728
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 64.55%, Precision: 62.89%, Recall: 64.44%, F1 Score: 63.08%

Run 2/10
Epoch [1/50], Class Loss: 4.2035, Discrepancy Loss: 0.1058
Epoch [2/50], Class Loss: 1.3319, Discrepancy Loss: 0.1223
Epoch [3/50], Class Loss: 0.6534, Discrepancy Loss: 0.1268
Epoch [4/50], Class Loss: 0.4304, Discrepancy Loss: 0.1068
Epoch [5/50], Class Loss: 0.3736, Discrepancy Loss: 0.0899
Epoch [6/50], Class Loss: 0.3733, Discrepancy Loss: 0.0937
Epoch [7/50], Class Loss: 0.3073, Discrepancy Loss: 0.0832
Epoch [8/50], Class Loss: 0.2181, Discrepancy Loss: 0.0893
Epoch [9/50], Class Loss: 0.1830, Discrepancy Loss: 0.0849
Epoch [10/50], Class Loss: 0.1401, Discrepancy Loss: 0.0772
Epoch [11/50], Class Loss: 0.0662, Discrepancy Loss: 0.0626
Epoch [12/50], Class Loss: 0.0590, Discrepancy Loss: 0.0766
Epoch [13/50], Class Loss: 0.0531, Discrepancy Loss: 0.0734
Epoch [14/50], Class Loss: 0.0559, Discrepancy Loss: 0.0821
Epoch [15/50], Class Loss: 0.0699, Discrepancy Loss: 0.0828
Epoch [16/50], Class Loss: 0.0285, Discrepancy Loss: 0.0655
Epoch [17/50], Class Loss: 0.0784, Discrepancy Loss: 0.0716
Epoch [18/50], Class Loss: 0.0588, Discrepancy Loss: 0.0721
Epoch [19/50], Class Loss: 0.0604, Discrepancy Loss: 0.0877
Epoch [20/50], Class Loss: 0.0248, Discrepancy Loss: 0.0873
Epoch [21/50], Class Loss: 0.0212, Discrepancy Loss: 0.0796
Epoch [22/50], Class Loss: 0.0167, Discrepancy Loss: 0.0795
Epoch [23/50], Class Loss: 0.0150, Discrepancy Loss: 0.0799
Epoch [24/50], Class Loss: 0.0214, Discrepancy Loss: 0.0816
Epoch [25/50], Class Loss: 0.0151, Discrepancy Loss: 0.0866
Epoch [26/50], Class Loss: 0.0213, Discrepancy Loss: 0.0937
Epoch [27/50], Class Loss: 0.0224, Discrepancy Loss: 0.0909
Epoch [28/50], Class Loss: 0.0221, Discrepancy Loss: 0.0982
Epoch [29/50], Class Loss: 0.0232, Discrepancy Loss: 0.0914
Epoch [30/50], Class Loss: 0.0178, Discrepancy Loss: 0.0989
Epoch [31/50], Class Loss: 0.0245, Discrepancy Loss: 0.0991
Epoch [32/50], Class Loss: 0.0229, Discrepancy Loss: 0.0995
Epoch [33/50], Class Loss: 0.0275, Discrepancy Loss: 0.0965
Epoch [34/50], Class Loss: 0.0185, Discrepancy Loss: 0.0939
Epoch [35/50], Class Loss: 0.0241, Discrepancy Loss: 0.1005
Epoch [36/50], Class Loss: 0.0244, Discrepancy Loss: 0.1042
Epoch [37/50], Class Loss: 0.0257, Discrepancy Loss: 0.1035
Epoch [38/50], Class Loss: 0.0201, Discrepancy Loss: 0.0971
Epoch [39/50], Class Loss: 0.0249, Discrepancy Loss: 0.0949
Epoch [40/50], Class Loss: 0.0251, Discrepancy Loss: 0.1017
Epoch [41/50], Class Loss: 0.0197, Discrepancy Loss: 0.1010
Epoch [42/50], Class Loss: 0.0220, Discrepancy Loss: 0.0970
Epoch [43/50], Class Loss: 0.0196, Discrepancy Loss: 0.0978
Epoch [44/50], Class Loss: 0.0200, Discrepancy Loss: 0.1018
Epoch [45/50], Class Loss: 0.0206, Discrepancy Loss: 0.0987
Epoch [46/50], Class Loss: 0.0177, Discrepancy Loss: 0.1002
Epoch [47/50], Class Loss: 0.0200, Discrepancy Loss: 0.1089
Epoch [48/50], Class Loss: 0.0241, Discrepancy Loss: 0.0992
Epoch [49/50], Class Loss: 0.0231, Discrepancy Loss: 0.0999
Epoch [50/50], Class Loss: 0.0228, Discrepancy Loss: 0.0994
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 65.48%, Precision: 62.28%, Recall: 64.66%, F1 Score: 58.10%

Run 3/10
Epoch [1/50], Class Loss: 4.6530, Discrepancy Loss: 0.1197
Epoch [2/50], Class Loss: 0.9227, Discrepancy Loss: 0.1483
Epoch [3/50], Class Loss: 0.4845, Discrepancy Loss: 0.1150
Epoch [4/50], Class Loss: 0.4888, Discrepancy Loss: 0.0970
Epoch [5/50], Class Loss: 0.4580, Discrepancy Loss: 0.1036
Epoch [6/50], Class Loss: 0.4211, Discrepancy Loss: 0.1044
Epoch [7/50], Class Loss: 0.3226, Discrepancy Loss: 0.0879
Epoch [8/50], Class Loss: 0.3292, Discrepancy Loss: 0.0919
Epoch [9/50], Class Loss: 0.2647, Discrepancy Loss: 0.0903
Epoch [10/50], Class Loss: 0.2934, Discrepancy Loss: 0.0866
Epoch [11/50], Class Loss: 0.0641, Discrepancy Loss: 0.0635
Epoch [12/50], Class Loss: 0.0437, Discrepancy Loss: 0.0613
Epoch [13/50], Class Loss: 0.0437, Discrepancy Loss: 0.0646
Epoch [14/50], Class Loss: 0.0461, Discrepancy Loss: 0.0660
Epoch [15/50], Class Loss: 0.0487, Discrepancy Loss: 0.0533
Epoch [16/50], Class Loss: 0.0457, Discrepancy Loss: 0.0439
Epoch [17/50], Class Loss: 0.0271, Discrepancy Loss: 0.0481
Epoch [18/50], Class Loss: 0.0427, Discrepancy Loss: 0.0421
Epoch [19/50], Class Loss: 0.2286, Discrepancy Loss: 0.0719
Epoch [20/50], Class Loss: 0.2000, Discrepancy Loss: 0.0948
Epoch [21/50], Class Loss: 0.0581, Discrepancy Loss: 0.0812
Epoch [22/50], Class Loss: 0.0357, Discrepancy Loss: 0.0715
Epoch [23/50], Class Loss: 0.0242, Discrepancy Loss: 0.0772
Epoch [24/50], Class Loss: 0.0234, Discrepancy Loss: 0.0756
Epoch [25/50], Class Loss: 0.0191, Discrepancy Loss: 0.0604
Epoch [26/50], Class Loss: 0.0229, Discrepancy Loss: 0.0737
Epoch [27/50], Class Loss: 0.0260, Discrepancy Loss: 0.0774
Epoch [28/50], Class Loss: 0.0226, Discrepancy Loss: 0.0807
Epoch [29/50], Class Loss: 0.0180, Discrepancy Loss: 0.0885
Epoch [30/50], Class Loss: 0.0207, Discrepancy Loss: 0.0917
Epoch [31/50], Class Loss: 0.0148, Discrepancy Loss: 0.0952
Epoch [32/50], Class Loss: 0.0147, Discrepancy Loss: 0.0973
Epoch [33/50], Class Loss: 0.0153, Discrepancy Loss: 0.0986
Epoch [34/50], Class Loss: 0.0163, Discrepancy Loss: 0.0987
Epoch [35/50], Class Loss: 0.0125, Discrepancy Loss: 0.0990
Epoch [36/50], Class Loss: 0.0139, Discrepancy Loss: 0.0945
Epoch [37/50], Class Loss: 0.0156, Discrepancy Loss: 0.0977
Epoch [38/50], Class Loss: 0.0121, Discrepancy Loss: 0.0994
Epoch [39/50], Class Loss: 0.0121, Discrepancy Loss: 0.1069
Epoch [40/50], Class Loss: 0.0141, Discrepancy Loss: 0.0955
Epoch [41/50], Class Loss: 0.0141, Discrepancy Loss: 0.1061
Epoch [42/50], Class Loss: 0.0143, Discrepancy Loss: 0.0991
Epoch [43/50], Class Loss: 0.0103, Discrepancy Loss: 0.0971
Epoch [44/50], Class Loss: 0.0133, Discrepancy Loss: 0.1008
Epoch [45/50], Class Loss: 0.0143, Discrepancy Loss: 0.0922
Epoch [46/50], Class Loss: 0.0131, Discrepancy Loss: 0.0959
Epoch [47/50], Class Loss: 0.0153, Discrepancy Loss: 0.0945
Epoch [48/50], Class Loss: 0.0145, Discrepancy Loss: 0.0927
Epoch [49/50], Class Loss: 0.0113, Discrepancy Loss: 0.0965
Epoch [50/50], Class Loss: 0.0115, Discrepancy Loss: 0.0976
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.80%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 60.18%, Precision: 59.10%, Recall: 59.16%, F1 Score: 51.37%

Run 4/10
Epoch [1/50], Class Loss: 3.6051, Discrepancy Loss: 0.1123
Epoch [2/50], Class Loss: 0.8085, Discrepancy Loss: 0.1234
Epoch [3/50], Class Loss: 0.8667, Discrepancy Loss: 0.1081
Epoch [4/50], Class Loss: 0.4875, Discrepancy Loss: 0.1121
Epoch [5/50], Class Loss: 0.4223, Discrepancy Loss: 0.1014
Epoch [6/50], Class Loss: 0.4400, Discrepancy Loss: 0.0918
Epoch [7/50], Class Loss: 0.4205, Discrepancy Loss: 0.0981
Epoch [8/50], Class Loss: 0.3041, Discrepancy Loss: 0.0806
Epoch [9/50], Class Loss: 0.2639, Discrepancy Loss: 0.0770
Epoch [10/50], Class Loss: 0.2500, Discrepancy Loss: 0.0737
Epoch [11/50], Class Loss: 0.0824, Discrepancy Loss: 0.0679
Epoch [12/50], Class Loss: 0.0530, Discrepancy Loss: 0.0677
Epoch [13/50], Class Loss: 0.0433, Discrepancy Loss: 0.0664
Epoch [14/50], Class Loss: 0.0546, Discrepancy Loss: 0.0694
Epoch [15/50], Class Loss: 0.0297, Discrepancy Loss: 0.0671
Epoch [16/50], Class Loss: 0.0241, Discrepancy Loss: 0.0562
Epoch [17/50], Class Loss: 0.0564, Discrepancy Loss: 0.0735
Epoch [18/50], Class Loss: 0.0521, Discrepancy Loss: 0.0808
Epoch [19/50], Class Loss: 0.0369, Discrepancy Loss: 0.0679
Epoch [20/50], Class Loss: 0.0505, Discrepancy Loss: 0.0939
Epoch [21/50], Class Loss: 0.0187, Discrepancy Loss: 0.0975
Epoch [22/50], Class Loss: 0.0171, Discrepancy Loss: 0.1113
Epoch [23/50], Class Loss: 0.0207, Discrepancy Loss: 0.1121
Epoch [24/50], Class Loss: 0.0250, Discrepancy Loss: 0.1110
Epoch [25/50], Class Loss: 0.0172, Discrepancy Loss: 0.1008
Epoch [26/50], Class Loss: 0.0175, Discrepancy Loss: 0.0972
Epoch [27/50], Class Loss: 0.0222, Discrepancy Loss: 0.0841
Epoch [28/50], Class Loss: 0.0225, Discrepancy Loss: 0.0779
Epoch [29/50], Class Loss: 0.0285, Discrepancy Loss: 0.0862
Epoch [30/50], Class Loss: 0.0327, Discrepancy Loss: 0.0894
Epoch [31/50], Class Loss: 0.0249, Discrepancy Loss: 0.0899
Epoch [32/50], Class Loss: 0.0245, Discrepancy Loss: 0.0903
Epoch [33/50], Class Loss: 0.0293, Discrepancy Loss: 0.0928
Epoch [34/50], Class Loss: 0.0303, Discrepancy Loss: 0.0901
Epoch [35/50], Class Loss: 0.0279, Discrepancy Loss: 0.0924
Epoch [36/50], Class Loss: 0.0296, Discrepancy Loss: 0.0906
Epoch [37/50], Class Loss: 0.0286, Discrepancy Loss: 0.0933
Epoch [38/50], Class Loss: 0.0234, Discrepancy Loss: 0.0970
Epoch [39/50], Class Loss: 0.0288, Discrepancy Loss: 0.0945
Epoch [40/50], Class Loss: 0.0372, Discrepancy Loss: 0.0941
Epoch [41/50], Class Loss: 0.0333, Discrepancy Loss: 0.0906
Epoch [42/50], Class Loss: 0.0269, Discrepancy Loss: 0.0889
Epoch [43/50], Class Loss: 0.0264, Discrepancy Loss: 0.0950
Epoch [44/50], Class Loss: 0.0396, Discrepancy Loss: 0.0953
Epoch [45/50], Class Loss: 0.0250, Discrepancy Loss: 0.0899
Epoch [46/50], Class Loss: 0.0310, Discrepancy Loss: 0.0940
Epoch [47/50], Class Loss: 0.0310, Discrepancy Loss: 0.0968
Epoch [48/50], Class Loss: 0.0390, Discrepancy Loss: 0.0909
Epoch [49/50], Class Loss: 0.0324, Discrepancy Loss: 0.0921
Epoch [50/50], Class Loss: 0.0257, Discrepancy Loss: 0.0936
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 47.39%, Precision: 52.54%, Recall: 46.78%, F1 Score: 45.45%

Run 5/10
Epoch [1/50], Class Loss: 4.0752, Discrepancy Loss: 0.1119
Epoch [2/50], Class Loss: 1.2612, Discrepancy Loss: 0.1285
Epoch [3/50], Class Loss: 0.8150, Discrepancy Loss: 0.1265
Epoch [4/50], Class Loss: 0.5236, Discrepancy Loss: 0.1237
Epoch [5/50], Class Loss: 0.4144, Discrepancy Loss: 0.0919
Epoch [6/50], Class Loss: 0.4180, Discrepancy Loss: 0.0954
Epoch [7/50], Class Loss: 0.3639, Discrepancy Loss: 0.0880
Epoch [8/50], Class Loss: 0.1506, Discrepancy Loss: 0.0753
Epoch [9/50], Class Loss: 0.2025, Discrepancy Loss: 0.0853
Epoch [10/50], Class Loss: 0.1460, Discrepancy Loss: 0.0812
Epoch [11/50], Class Loss: 0.0652, Discrepancy Loss: 0.0695
Epoch [12/50], Class Loss: 0.0535, Discrepancy Loss: 0.0657
Epoch [13/50], Class Loss: 0.0371, Discrepancy Loss: 0.0566
Epoch [14/50], Class Loss: 0.0286, Discrepancy Loss: 0.0547
Epoch [15/50], Class Loss: 0.0429, Discrepancy Loss: 0.0592
Epoch [16/50], Class Loss: 0.0414, Discrepancy Loss: 0.0560
Epoch [17/50], Class Loss: 0.0413, Discrepancy Loss: 0.0599
Epoch [18/50], Class Loss: 0.0229, Discrepancy Loss: 0.0625
Epoch [19/50], Class Loss: 0.0430, Discrepancy Loss: 0.0642
Epoch [20/50], Class Loss: 0.0377, Discrepancy Loss: 0.0696
Epoch [21/50], Class Loss: 0.0220, Discrepancy Loss: 0.0693
Epoch [22/50], Class Loss: 0.0253, Discrepancy Loss: 0.0720
Epoch [23/50], Class Loss: 0.0240, Discrepancy Loss: 0.0714
Epoch [24/50], Class Loss: 0.0193, Discrepancy Loss: 0.0674
Epoch [25/50], Class Loss: 0.0241, Discrepancy Loss: 0.0696
Epoch [26/50], Class Loss: 0.0143, Discrepancy Loss: 0.0697
Epoch [27/50], Class Loss: 0.0154, Discrepancy Loss: 0.0752
Epoch [28/50], Class Loss: 0.0159, Discrepancy Loss: 0.0713
Epoch [29/50], Class Loss: 0.0159, Discrepancy Loss: 0.0693
Epoch [30/50], Class Loss: 0.0184, Discrepancy Loss: 0.0735
Epoch [31/50], Class Loss: 0.0118, Discrepancy Loss: 0.0711
Epoch [32/50], Class Loss: 0.0137, Discrepancy Loss: 0.0757
Epoch [33/50], Class Loss: 0.0127, Discrepancy Loss: 0.0707
Epoch [34/50], Class Loss: 0.0148, Discrepancy Loss: 0.0744
Epoch [35/50], Class Loss: 0.0134, Discrepancy Loss: 0.0763
Epoch [36/50], Class Loss: 0.0159, Discrepancy Loss: 0.0732
Epoch [37/50], Class Loss: 0.0141, Discrepancy Loss: 0.0757
Epoch [38/50], Class Loss: 0.0157, Discrepancy Loss: 0.0732
Epoch [39/50], Class Loss: 0.0120, Discrepancy Loss: 0.0732
Epoch [40/50], Class Loss: 0.0101, Discrepancy Loss: 0.0750
Epoch [41/50], Class Loss: 0.0129, Discrepancy Loss: 0.0753
Epoch [42/50], Class Loss: 0.0143, Discrepancy Loss: 0.0748
Epoch [43/50], Class Loss: 0.0144, Discrepancy Loss: 0.0805
Epoch [44/50], Class Loss: 0.0188, Discrepancy Loss: 0.0776
Epoch [45/50], Class Loss: 0.0163, Discrepancy Loss: 0.0769
Epoch [46/50], Class Loss: 0.0116, Discrepancy Loss: 0.0749
Epoch [47/50], Class Loss: 0.0175, Discrepancy Loss: 0.0729
Epoch [48/50], Class Loss: 0.0119, Discrepancy Loss: 0.0721
Epoch [49/50], Class Loss: 0.0131, Discrepancy Loss: 0.0798
Epoch [50/50], Class Loss: 0.0104, Discrepancy Loss: 0.0764
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 60.57%, Precision: 60.27%, Recall: 59.88%, F1 Score: 56.02%

Run 6/10
Epoch [1/50], Class Loss: 3.8447, Discrepancy Loss: 0.1046
Epoch [2/50], Class Loss: 0.8617, Discrepancy Loss: 0.1384
Epoch [3/50], Class Loss: 0.5758, Discrepancy Loss: 0.1170
Epoch [4/50], Class Loss: 0.4701, Discrepancy Loss: 0.1074
Epoch [5/50], Class Loss: 0.3918, Discrepancy Loss: 0.1031
Epoch [6/50], Class Loss: 0.5356, Discrepancy Loss: 0.1095
Epoch [7/50], Class Loss: 0.3770, Discrepancy Loss: 0.1063
Epoch [8/50], Class Loss: 0.3182, Discrepancy Loss: 0.1017
Epoch [9/50], Class Loss: 0.2883, Discrepancy Loss: 0.0839
Epoch [10/50], Class Loss: 0.2730, Discrepancy Loss: 0.0950
Epoch [11/50], Class Loss: 0.0641, Discrepancy Loss: 0.0632
Epoch [12/50], Class Loss: 0.0444, Discrepancy Loss: 0.0543
Epoch [13/50], Class Loss: 0.0354, Discrepancy Loss: 0.0551
Epoch [14/50], Class Loss: 0.0257, Discrepancy Loss: 0.0574
Epoch [15/50], Class Loss: 0.0600, Discrepancy Loss: 0.0511
Epoch [16/50], Class Loss: 0.0386, Discrepancy Loss: 0.0581
Epoch [17/50], Class Loss: 0.0205, Discrepancy Loss: 0.0568
Epoch [18/50], Class Loss: 0.0292, Discrepancy Loss: 0.0554
Epoch [19/50], Class Loss: 0.0581, Discrepancy Loss: 0.0664
Epoch [20/50], Class Loss: 0.0319, Discrepancy Loss: 0.0679
Epoch [21/50], Class Loss: 0.0211, Discrepancy Loss: 0.0832
Epoch [22/50], Class Loss: 0.0201, Discrepancy Loss: 0.0805
Epoch [23/50], Class Loss: 0.0216, Discrepancy Loss: 0.0842
Epoch [24/50], Class Loss: 0.0156, Discrepancy Loss: 0.0889
Epoch [25/50], Class Loss: 0.0386, Discrepancy Loss: 0.0929
Epoch [26/50], Class Loss: 0.0176, Discrepancy Loss: 0.1024
Epoch [27/50], Class Loss: 0.0235, Discrepancy Loss: 0.0982
Epoch [28/50], Class Loss: 0.0296, Discrepancy Loss: 0.1033
Epoch [29/50], Class Loss: 0.0212, Discrepancy Loss: 0.1043
Epoch [30/50], Class Loss: 0.0373, Discrepancy Loss: 0.1117
Epoch [31/50], Class Loss: 0.0203, Discrepancy Loss: 0.1136
Epoch [32/50], Class Loss: 0.0203, Discrepancy Loss: 0.1151
Epoch [33/50], Class Loss: 0.0210, Discrepancy Loss: 0.1194
Epoch [34/50], Class Loss: 0.0229, Discrepancy Loss: 0.1201
Epoch [35/50], Class Loss: 0.0199, Discrepancy Loss: 0.1168
Epoch [36/50], Class Loss: 0.0207, Discrepancy Loss: 0.1174
Epoch [37/50], Class Loss: 0.0190, Discrepancy Loss: 0.1222
Epoch [38/50], Class Loss: 0.0176, Discrepancy Loss: 0.1194
Epoch [39/50], Class Loss: 0.0197, Discrepancy Loss: 0.1187
Epoch [40/50], Class Loss: 0.0258, Discrepancy Loss: 0.1232
Epoch [41/50], Class Loss: 0.0239, Discrepancy Loss: 0.1238
Epoch [42/50], Class Loss: 0.0178, Discrepancy Loss: 0.1200
Epoch [43/50], Class Loss: 0.0221, Discrepancy Loss: 0.1236
Epoch [44/50], Class Loss: 0.0211, Discrepancy Loss: 0.1208
Epoch [45/50], Class Loss: 0.0210, Discrepancy Loss: 0.1231
Epoch [46/50], Class Loss: 0.0222, Discrepancy Loss: 0.1221
Epoch [47/50], Class Loss: 0.0287, Discrepancy Loss: 0.1249
Epoch [48/50], Class Loss: 0.0242, Discrepancy Loss: 0.1267
Epoch [49/50], Class Loss: 0.0189, Discrepancy Loss: 0.1206
Epoch [50/50], Class Loss: 0.0197, Discrepancy Loss: 0.1204
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 55.74%, Precision: 58.70%, Recall: 54.77%, F1 Score: 49.04%

Run 7/10
Epoch [1/50], Class Loss: 3.7185, Discrepancy Loss: 0.1250
Epoch [2/50], Class Loss: 1.1220, Discrepancy Loss: 0.1307
Epoch [3/50], Class Loss: 0.7519, Discrepancy Loss: 0.1240
Epoch [4/50], Class Loss: 0.4317, Discrepancy Loss: 0.1115
Epoch [5/50], Class Loss: 0.3858, Discrepancy Loss: 0.0950
Epoch [6/50], Class Loss: 0.2678, Discrepancy Loss: 0.0724
Epoch [7/50], Class Loss: 0.2149, Discrepancy Loss: 0.0829
Epoch [8/50], Class Loss: 0.2371, Discrepancy Loss: 0.0826
Epoch [9/50], Class Loss: 0.2144, Discrepancy Loss: 0.0794
Epoch [10/50], Class Loss: 0.1277, Discrepancy Loss: 0.0744
Epoch [11/50], Class Loss: 0.0331, Discrepancy Loss: 0.0467
Epoch [12/50], Class Loss: 0.0250, Discrepancy Loss: 0.0623
Epoch [13/50], Class Loss: 0.0452, Discrepancy Loss: 0.0607
Epoch [14/50], Class Loss: 0.0355, Discrepancy Loss: 0.0543
Epoch [15/50], Class Loss: 0.0378, Discrepancy Loss: 0.0585
Epoch [16/50], Class Loss: 0.0320, Discrepancy Loss: 0.0536
Epoch [17/50], Class Loss: 0.0916, Discrepancy Loss: 0.0695
Epoch [18/50], Class Loss: 0.0468, Discrepancy Loss: 0.0738
Epoch [19/50], Class Loss: 0.0305, Discrepancy Loss: 0.0858
Epoch [20/50], Class Loss: 0.0184, Discrepancy Loss: 0.0622
Epoch [21/50], Class Loss: 0.0161, Discrepancy Loss: 0.0602
Epoch [22/50], Class Loss: 0.0147, Discrepancy Loss: 0.0586
Epoch [23/50], Class Loss: 0.0141, Discrepancy Loss: 0.0613
Epoch [24/50], Class Loss: 0.0257, Discrepancy Loss: 0.0679
Epoch [25/50], Class Loss: 0.0233, Discrepancy Loss: 0.0774
Epoch [26/50], Class Loss: 0.0221, Discrepancy Loss: 0.0771
Epoch [27/50], Class Loss: 0.0247, Discrepancy Loss: 0.0842
Epoch [28/50], Class Loss: 0.0239, Discrepancy Loss: 0.0782
Epoch [29/50], Class Loss: 0.0222, Discrepancy Loss: 0.0868
Epoch [30/50], Class Loss: 0.0250, Discrepancy Loss: 0.0855
Epoch [31/50], Class Loss: 0.0225, Discrepancy Loss: 0.0830
Epoch [32/50], Class Loss: 0.0200, Discrepancy Loss: 0.0834
Epoch [33/50], Class Loss: 0.0195, Discrepancy Loss: 0.0930
Epoch [34/50], Class Loss: 0.0258, Discrepancy Loss: 0.0884
Epoch [35/50], Class Loss: 0.0203, Discrepancy Loss: 0.0907
Epoch [36/50], Class Loss: 0.0208, Discrepancy Loss: 0.0864
Epoch [37/50], Class Loss: 0.0205, Discrepancy Loss: 0.0890
Epoch [38/50], Class Loss: 0.0259, Discrepancy Loss: 0.0928
Epoch [39/50], Class Loss: 0.0209, Discrepancy Loss: 0.0943
Epoch [40/50], Class Loss: 0.0298, Discrepancy Loss: 0.0936
Epoch [41/50], Class Loss: 0.0183, Discrepancy Loss: 0.0881
Epoch [42/50], Class Loss: 0.0203, Discrepancy Loss: 0.0896
Epoch [43/50], Class Loss: 0.0271, Discrepancy Loss: 0.0923
Epoch [44/50], Class Loss: 0.0235, Discrepancy Loss: 0.0838
Epoch [45/50], Class Loss: 0.0194, Discrepancy Loss: 0.0915
Epoch [46/50], Class Loss: 0.0211, Discrepancy Loss: 0.0920
Epoch [47/50], Class Loss: 0.0185, Discrepancy Loss: 0.0918
Epoch [48/50], Class Loss: 0.0174, Discrepancy Loss: 0.0886
Epoch [49/50], Class Loss: 0.0277, Discrepancy Loss: 0.0923
Epoch [50/50], Class Loss: 0.0210, Discrepancy Loss: 0.0918
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.80%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 55.30%, Precision: 50.08%, Recall: 55.20%, F1 Score: 51.33%

Run 8/10
Epoch [1/50], Class Loss: 3.8455, Discrepancy Loss: 0.1201
Epoch [2/50], Class Loss: 0.9544, Discrepancy Loss: 0.1338
Epoch [3/50], Class Loss: 0.8302, Discrepancy Loss: 0.1357
Epoch [4/50], Class Loss: 0.6432, Discrepancy Loss: 0.1198
Epoch [5/50], Class Loss: 0.6765, Discrepancy Loss: 0.1219
Epoch [6/50], Class Loss: 0.6032, Discrepancy Loss: 0.1048
Epoch [7/50], Class Loss: 0.3623, Discrepancy Loss: 0.0996
Epoch [8/50], Class Loss: 0.3391, Discrepancy Loss: 0.0780
Epoch [9/50], Class Loss: 0.3115, Discrepancy Loss: 0.0909
Epoch [10/50], Class Loss: 0.2741, Discrepancy Loss: 0.0860
Epoch [11/50], Class Loss: 0.1768, Discrepancy Loss: 0.0806
Epoch [12/50], Class Loss: 0.0999, Discrepancy Loss: 0.0688
Epoch [13/50], Class Loss: 0.0570, Discrepancy Loss: 0.0580
Epoch [14/50], Class Loss: 0.0556, Discrepancy Loss: 0.0586
Epoch [15/50], Class Loss: 0.0508, Discrepancy Loss: 0.0627
Epoch [16/50], Class Loss: 0.0349, Discrepancy Loss: 0.0737
Epoch [17/50], Class Loss: 0.0244, Discrepancy Loss: 0.0791
Epoch [18/50], Class Loss: 0.0553, Discrepancy Loss: 0.0872
Epoch [19/50], Class Loss: 0.0505, Discrepancy Loss: 0.0803
Epoch [20/50], Class Loss: 0.0268, Discrepancy Loss: 0.0976
Epoch [21/50], Class Loss: 0.0241, Discrepancy Loss: 0.0902
Epoch [22/50], Class Loss: 0.0171, Discrepancy Loss: 0.0919
Epoch [23/50], Class Loss: 0.0225, Discrepancy Loss: 0.0877
Epoch [24/50], Class Loss: 0.0204, Discrepancy Loss: 0.0918
Epoch [25/50], Class Loss: 0.0216, Discrepancy Loss: 0.0871
Epoch [26/50], Class Loss: 0.0198, Discrepancy Loss: 0.0916
Epoch [27/50], Class Loss: 0.0165, Discrepancy Loss: 0.0935
Epoch [28/50], Class Loss: 0.0212, Discrepancy Loss: 0.0952
Epoch [29/50], Class Loss: 0.0228, Discrepancy Loss: 0.0944
Epoch [30/50], Class Loss: 0.0302, Discrepancy Loss: 0.0929
Epoch [31/50], Class Loss: 0.0230, Discrepancy Loss: 0.0996
Epoch [32/50], Class Loss: 0.0173, Discrepancy Loss: 0.0934
Epoch [33/50], Class Loss: 0.0197, Discrepancy Loss: 0.0955
Epoch [34/50], Class Loss: 0.0196, Discrepancy Loss: 0.0995
Epoch [35/50], Class Loss: 0.0169, Discrepancy Loss: 0.0932
Epoch [36/50], Class Loss: 0.0188, Discrepancy Loss: 0.0948
Epoch [37/50], Class Loss: 0.0151, Discrepancy Loss: 0.0937
Epoch [38/50], Class Loss: 0.0171, Discrepancy Loss: 0.0910
Epoch [39/50], Class Loss: 0.0180, Discrepancy Loss: 0.0996
Epoch [40/50], Class Loss: 0.0192, Discrepancy Loss: 0.0964
Epoch [41/50], Class Loss: 0.0142, Discrepancy Loss: 0.0960
Epoch [42/50], Class Loss: 0.0171, Discrepancy Loss: 0.1001
Epoch [43/50], Class Loss: 0.0190, Discrepancy Loss: 0.0949
Epoch [44/50], Class Loss: 0.0174, Discrepancy Loss: 0.0995
Epoch [45/50], Class Loss: 0.0221, Discrepancy Loss: 0.0949
Epoch [46/50], Class Loss: 0.0202, Discrepancy Loss: 0.0960
Epoch [47/50], Class Loss: 0.0218, Discrepancy Loss: 0.0944
Epoch [48/50], Class Loss: 0.0210, Discrepancy Loss: 0.0956
Epoch [49/50], Class Loss: 0.0151, Discrepancy Loss: 0.0938
Epoch [50/50], Class Loss: 0.0186, Discrepancy Loss: 0.0998
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 64.26%, Precision: 61.49%, Recall: 63.46%, F1 Score: 57.23%

Run 9/10
Epoch [1/50], Class Loss: 4.5127, Discrepancy Loss: 0.1159
Epoch [2/50], Class Loss: 0.6235, Discrepancy Loss: 0.1282
Epoch [3/50], Class Loss: 0.5171, Discrepancy Loss: 0.1207
Epoch [4/50], Class Loss: 0.4527, Discrepancy Loss: 0.1077
Epoch [5/50], Class Loss: 0.4176, Discrepancy Loss: 0.0991
Epoch [6/50], Class Loss: 0.3061, Discrepancy Loss: 0.0928
Epoch [7/50], Class Loss: 0.2481, Discrepancy Loss: 0.0888
Epoch [8/50], Class Loss: 0.3978, Discrepancy Loss: 0.0953
Epoch [9/50], Class Loss: 0.2237, Discrepancy Loss: 0.0972
Epoch [10/50], Class Loss: 0.2721, Discrepancy Loss: 0.0849
Epoch [11/50], Class Loss: 0.1219, Discrepancy Loss: 0.0744
Epoch [12/50], Class Loss: 0.0783, Discrepancy Loss: 0.0637
Epoch [13/50], Class Loss: 0.0457, Discrepancy Loss: 0.0580
Epoch [14/50], Class Loss: 0.0417, Discrepancy Loss: 0.0596
Epoch [15/50], Class Loss: 0.0460, Discrepancy Loss: 0.0595
Epoch [16/50], Class Loss: 0.0379, Discrepancy Loss: 0.0671
Epoch [17/50], Class Loss: 0.0234, Discrepancy Loss: 0.0652
Epoch [18/50], Class Loss: 0.0473, Discrepancy Loss: 0.0738
Epoch [19/50], Class Loss: 0.0339, Discrepancy Loss: 0.0659
Epoch [20/50], Class Loss: 0.0445, Discrepancy Loss: 0.0701
Epoch [21/50], Class Loss: 0.0167, Discrepancy Loss: 0.0693
Epoch [22/50], Class Loss: 0.0181, Discrepancy Loss: 0.0625
Epoch [23/50], Class Loss: 0.0144, Discrepancy Loss: 0.0644
Epoch [24/50], Class Loss: 0.0146, Discrepancy Loss: 0.0675
Epoch [25/50], Class Loss: 0.0163, Discrepancy Loss: 0.0668
Epoch [26/50], Class Loss: 0.0197, Discrepancy Loss: 0.0673
Epoch [27/50], Class Loss: 0.0140, Discrepancy Loss: 0.0677
Epoch [28/50], Class Loss: 0.0186, Discrepancy Loss: 0.0669
Epoch [29/50], Class Loss: 0.0172, Discrepancy Loss: 0.0742
Epoch [30/50], Class Loss: 0.0192, Discrepancy Loss: 0.0677
Epoch [31/50], Class Loss: 0.0116, Discrepancy Loss: 0.0697
Epoch [32/50], Class Loss: 0.0089, Discrepancy Loss: 0.0652
Epoch [33/50], Class Loss: 0.0131, Discrepancy Loss: 0.0650
Epoch [34/50], Class Loss: 0.0150, Discrepancy Loss: 0.0658
Epoch [35/50], Class Loss: 0.0156, Discrepancy Loss: 0.0587
Epoch [36/50], Class Loss: 0.0160, Discrepancy Loss: 0.0699
Epoch [37/50], Class Loss: 0.0175, Discrepancy Loss: 0.0670
Epoch [38/50], Class Loss: 0.0144, Discrepancy Loss: 0.0676
Epoch [39/50], Class Loss: 0.0143, Discrepancy Loss: 0.0636
Epoch [40/50], Class Loss: 0.0161, Discrepancy Loss: 0.0696
Epoch [41/50], Class Loss: 0.0140, Discrepancy Loss: 0.0666
Epoch [42/50], Class Loss: 0.0150, Discrepancy Loss: 0.0703
Epoch [43/50], Class Loss: 0.0160, Discrepancy Loss: 0.0667
Epoch [44/50], Class Loss: 0.0185, Discrepancy Loss: 0.0683
Epoch [45/50], Class Loss: 0.0167, Discrepancy Loss: 0.0677
Epoch [46/50], Class Loss: 0.0161, Discrepancy Loss: 0.0631
Epoch [47/50], Class Loss: 0.0136, Discrepancy Loss: 0.0676
Epoch [48/50], Class Loss: 0.0160, Discrepancy Loss: 0.0700
Epoch [49/50], Class Loss: 0.0139, Discrepancy Loss: 0.0688
Epoch [50/50], Class Loss: 0.0149, Discrepancy Loss: 0.0653
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 66.58%, Precision: 64.40%, Recall: 66.62%, F1 Score: 65.22%

Run 10/10
Epoch [1/50], Class Loss: 3.8688, Discrepancy Loss: 0.1103
Epoch [2/50], Class Loss: 0.6901, Discrepancy Loss: 0.1346
Epoch [3/50], Class Loss: 1.6710, Discrepancy Loss: 0.1120
Epoch [4/50], Class Loss: 0.6741, Discrepancy Loss: 0.1192
Epoch [5/50], Class Loss: 0.3951, Discrepancy Loss: 0.1033
Epoch [6/50], Class Loss: 0.3623, Discrepancy Loss: 0.0956
Epoch [7/50], Class Loss: 0.4903, Discrepancy Loss: 0.0866
Epoch [8/50], Class Loss: 0.2845, Discrepancy Loss: 0.0878
Epoch [9/50], Class Loss: 0.5455, Discrepancy Loss: 0.0817
Epoch [10/50], Class Loss: 0.1347, Discrepancy Loss: 0.0633
Epoch [11/50], Class Loss: 0.0200, Discrepancy Loss: 0.0620
Epoch [12/50], Class Loss: 0.0139, Discrepancy Loss: 0.0607
Epoch [13/50], Class Loss: 0.0145, Discrepancy Loss: 0.0583
Epoch [14/50], Class Loss: 0.0132, Discrepancy Loss: 0.0533
Epoch [15/50], Class Loss: 0.0200, Discrepancy Loss: 0.0366
Epoch [16/50], Class Loss: 0.0421, Discrepancy Loss: 0.0436
Epoch [17/50], Class Loss: 0.0232, Discrepancy Loss: 0.0489
Epoch [18/50], Class Loss: 0.0206, Discrepancy Loss: 0.0381
Epoch [19/50], Class Loss: 0.0139, Discrepancy Loss: 0.0304
Epoch [20/50], Class Loss: 0.0337, Discrepancy Loss: 0.0344
Epoch [21/50], Class Loss: 0.0066, Discrepancy Loss: 0.0359
Epoch [22/50], Class Loss: 0.0085, Discrepancy Loss: 0.0365
Epoch [23/50], Class Loss: 0.0078, Discrepancy Loss: 0.0423
Epoch [24/50], Class Loss: 0.0272, Discrepancy Loss: 0.0447
Epoch [25/50], Class Loss: 0.0292, Discrepancy Loss: 0.0487
Epoch [26/50], Class Loss: 0.0122, Discrepancy Loss: 0.0604
Epoch [27/50], Class Loss: 0.0194, Discrepancy Loss: 0.0511
Epoch [28/50], Class Loss: 0.0193, Discrepancy Loss: 0.0581
Epoch [29/50], Class Loss: 0.0152, Discrepancy Loss: 0.0588
Epoch [30/50], Class Loss: 0.0186, Discrepancy Loss: 0.0549
Epoch [31/50], Class Loss: 0.0170, Discrepancy Loss: 0.0628
Epoch [32/50], Class Loss: 0.0178, Discrepancy Loss: 0.0593
Epoch [33/50], Class Loss: 0.0191, Discrepancy Loss: 0.0557
Epoch [34/50], Class Loss: 0.0179, Discrepancy Loss: 0.0554
Epoch [35/50], Class Loss: 0.0203, Discrepancy Loss: 0.0561
Epoch [36/50], Class Loss: 0.0175, Discrepancy Loss: 0.0546
Epoch [37/50], Class Loss: 0.0150, Discrepancy Loss: 0.0517
Epoch [38/50], Class Loss: 0.0193, Discrepancy Loss: 0.0552
Epoch [39/50], Class Loss: 0.0172, Discrepancy Loss: 0.0534
Epoch [40/50], Class Loss: 0.0138, Discrepancy Loss: 0.0532
Epoch [41/50], Class Loss: 0.0183, Discrepancy Loss: 0.0530
Epoch [42/50], Class Loss: 0.0181, Discrepancy Loss: 0.0525
Epoch [43/50], Class Loss: 0.0178, Discrepancy Loss: 0.0545
Epoch [44/50], Class Loss: 0.0187, Discrepancy Loss: 0.0513
Epoch [45/50], Class Loss: 0.0145, Discrepancy Loss: 0.0541
Epoch [46/50], Class Loss: 0.0162, Discrepancy Loss: 0.0541
Epoch [47/50], Class Loss: 0.0212, Discrepancy Loss: 0.0561
Epoch [48/50], Class Loss: 0.0172, Discrepancy Loss: 0.0546
Epoch [49/50], Class Loss: 0.0153, Discrepancy Loss: 0.0541
Epoch [50/50], Class Loss: 0.0147, Discrepancy Loss: 0.0545
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 54.42%, Precision: 56.73%, Recall: 54.17%, F1 Score: 54.24%

Source performance: 99.87% 99.86% 99.86% 99.86%
Target performance: 59.45% 58.85% 58.91% 55.11%

Per-Class Accuracy on Target Domain:
bpsk: 99.88%
qpsk: 0.01%
4qam: 47.25%
16qam: 47.74%
apsk: 99.68%

Run 1/10
Epoch [1/50], Class Loss: 2.9584, Discrepancy Loss: 0.0333
Validation Loss: 1.3822
Epoch [2/50], Class Loss: 1.2168, Discrepancy Loss: 0.0158
Validation Loss: 0.7652
Epoch [3/50], Class Loss: 1.3583, Discrepancy Loss: 0.0278
Validation Loss: 0.4868
Epoch [4/50], Class Loss: 0.4313, Discrepancy Loss: 0.0132
Validation Loss: 0.4271
Epoch [5/50], Class Loss: 0.4014, Discrepancy Loss: 0.0193
Validation Loss: 0.4868
Epoch [6/50], Class Loss: 1.1234, Discrepancy Loss: 0.0319
Validation Loss: 0.8007
Epoch [7/50], Class Loss: 1.1412, Discrepancy Loss: 0.0407
Validation Loss: 0.8217
Epoch [8/50], Class Loss: 0.5027, Discrepancy Loss: 0.0154
Validation Loss: 0.3899
Epoch [9/50], Class Loss: 0.7147, Discrepancy Loss: 0.0193
Validation Loss: 3.7475
Epoch [10/50], Class Loss: 1.3231, Discrepancy Loss: 0.0478
Validation Loss: 7.9076
Epoch [11/50], Class Loss: 0.4911, Discrepancy Loss: 0.0102
Validation Loss: 0.0417
Epoch [12/50], Class Loss: 0.0654, Discrepancy Loss: 0.0059
Validation Loss: 0.0501
Epoch [13/50], Class Loss: 0.0473, Discrepancy Loss: 0.0054
Validation Loss: 0.0396
Epoch [14/50], Class Loss: 0.0803, Discrepancy Loss: 0.0067
Validation Loss: 0.0564
Epoch [15/50], Class Loss: 0.0825, Discrepancy Loss: 0.0081
Validation Loss: 0.7568
Epoch [16/50], Class Loss: 0.0814, Discrepancy Loss: 0.0125
Validation Loss: 0.0345
Epoch [17/50], Class Loss: 0.0762, Discrepancy Loss: 0.0106
Validation Loss: 0.0346
Epoch [18/50], Class Loss: 0.0639, Discrepancy Loss: 0.0116
Validation Loss: 0.0410
Epoch [19/50], Class Loss: 0.0969, Discrepancy Loss: 0.0113
Validation Loss: 0.0596
Epoch [20/50], Class Loss: 0.0934, Discrepancy Loss: 0.0123
Validation Loss: 0.0308
Epoch [21/50], Class Loss: 0.0345, Discrepancy Loss: 0.0085
Validation Loss: 0.0283
Epoch [22/50], Class Loss: 0.0352, Discrepancy Loss: 0.0092
Validation Loss: 0.0285
Epoch [23/50], Class Loss: 0.0339, Discrepancy Loss: 0.0092
Validation Loss: 0.0272
Epoch [24/50], Class Loss: 0.0365, Discrepancy Loss: 0.0098
Validation Loss: 0.0270
Epoch [25/50], Class Loss: 0.0417, Discrepancy Loss: 0.0092
Validation Loss: 0.0274
Epoch [26/50], Class Loss: 0.0341, Discrepancy Loss: 0.0091
Validation Loss: 0.0280
Epoch [27/50], Class Loss: 0.0377, Discrepancy Loss: 0.0096
Validation Loss: 0.0260
Epoch [28/50], Class Loss: 0.0376, Discrepancy Loss: 0.0091
Validation Loss: 0.0294
Epoch [29/50], Class Loss: 0.0408, Discrepancy Loss: 0.0089
Validation Loss: 0.0280
Epoch [30/50], Class Loss: 0.0395, Discrepancy Loss: 0.0093
Validation Loss: 0.0267
Epoch [31/50], Class Loss: 0.0353, Discrepancy Loss: 0.0093
Validation Loss: 0.0254
Epoch [32/50], Class Loss: 0.0347, Discrepancy Loss: 0.0088
Validation Loss: 0.0256
Epoch [33/50], Class Loss: 0.0328, Discrepancy Loss: 0.0090
Validation Loss: 0.0258
Epoch [34/50], Class Loss: 0.0307, Discrepancy Loss: 0.0088
Validation Loss: 0.0256
Epoch [35/50], Class Loss: 0.0348, Discrepancy Loss: 0.0092
Validation Loss: 0.0261
Epoch [36/50], Class Loss: 0.0329, Discrepancy Loss: 0.0092
Validation Loss: 0.0261
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 63.82%, Precision: 61.21%, Recall: 62.80%, F1 Score: 53.92%

Run 2/10
Epoch [1/50], Class Loss: 2.7934, Discrepancy Loss: 0.0345
Validation Loss: 1.9777
Epoch [2/50], Class Loss: 1.6498, Discrepancy Loss: 0.0500
Validation Loss: 0.9682
Epoch [3/50], Class Loss: 1.3930, Discrepancy Loss: 0.0556
Validation Loss: 1.5263
Epoch [4/50], Class Loss: 1.0255, Discrepancy Loss: 0.0394
Validation Loss: 0.4448
Epoch [5/50], Class Loss: 1.9822, Discrepancy Loss: 0.0669
Validation Loss: 0.9506
Epoch [6/50], Class Loss: 1.0966, Discrepancy Loss: 0.0340
Validation Loss: 1.0716
Epoch [7/50], Class Loss: 1.1196, Discrepancy Loss: 0.0488
Validation Loss: 0.3121
Epoch [8/50], Class Loss: 0.3778, Discrepancy Loss: 0.0135
Validation Loss: 1.5795
Epoch [9/50], Class Loss: 0.7219, Discrepancy Loss: 0.0308
Validation Loss: 0.0908
Epoch [10/50], Class Loss: 0.8474, Discrepancy Loss: 0.0493
Validation Loss: 0.7058
Epoch [11/50], Class Loss: 0.0938, Discrepancy Loss: 0.0181
Validation Loss: 0.0365
Epoch [12/50], Class Loss: 0.0638, Discrepancy Loss: 0.0109
Validation Loss: 0.0340
Epoch [13/50], Class Loss: 0.1045, Discrepancy Loss: 0.0086
Validation Loss: 0.0675
Epoch [14/50], Class Loss: 0.1866, Discrepancy Loss: 0.0093
Validation Loss: 0.0475
Epoch [15/50], Class Loss: 0.1466, Discrepancy Loss: 0.0077
Validation Loss: 0.0423
Epoch [16/50], Class Loss: 0.1264, Discrepancy Loss: 0.0100
Validation Loss: 0.0378
Epoch [17/50], Class Loss: 0.1080, Discrepancy Loss: 0.0125
Validation Loss: 0.0379
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 60.91%, Precision: 60.32%, Recall: 59.67%, F1 Score: 47.64%

Run 3/10
Epoch [1/50], Class Loss: 2.9938, Discrepancy Loss: 0.0406
Validation Loss: 1.0820
Epoch [2/50], Class Loss: 1.9814, Discrepancy Loss: 0.0421
Validation Loss: 1.0427
Epoch [3/50], Class Loss: 1.9640, Discrepancy Loss: 0.0551
Validation Loss: 1.0474
Epoch [4/50], Class Loss: 1.5376, Discrepancy Loss: 0.0488
Validation Loss: 4.5613
Epoch [5/50], Class Loss: 1.5996, Discrepancy Loss: 0.0479
Validation Loss: 3.4057
Epoch [6/50], Class Loss: 1.2885, Discrepancy Loss: 0.0575
Validation Loss: 0.4575
Epoch [7/50], Class Loss: 0.4167, Discrepancy Loss: 0.0153
Validation Loss: 0.4489
Epoch [8/50], Class Loss: 0.3637, Discrepancy Loss: 0.0070
Validation Loss: 0.2418
Epoch [9/50], Class Loss: 0.3355, Discrepancy Loss: 0.0063
Validation Loss: 0.2910
Epoch [10/50], Class Loss: 0.3861, Discrepancy Loss: 0.0124
Validation Loss: 0.0769
Epoch [11/50], Class Loss: 0.0343, Discrepancy Loss: 0.0046
Validation Loss: 0.0344
Epoch [12/50], Class Loss: 0.0177, Discrepancy Loss: 0.0114
Validation Loss: 0.0186
Epoch [13/50], Class Loss: 0.0252, Discrepancy Loss: 0.0105
Validation Loss: 0.0176
Epoch [14/50], Class Loss: 0.0321, Discrepancy Loss: 0.0103
Validation Loss: 0.0326
Epoch [15/50], Class Loss: 0.0873, Discrepancy Loss: 0.0128
Validation Loss: 0.0576
Epoch [16/50], Class Loss: 0.5581, Discrepancy Loss: 0.0181
Validation Loss: 0.0265
Epoch [17/50], Class Loss: 0.0756, Discrepancy Loss: 0.0138
Validation Loss: 0.0332
Epoch [18/50], Class Loss: 0.0800, Discrepancy Loss: 0.0153
Validation Loss: 0.0206
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 47.19%, Precision: 53.16%, Recall: 46.46%, F1 Score: 44.26%

Run 4/10
Epoch [1/50], Class Loss: 2.9503, Discrepancy Loss: 0.0402
Validation Loss: 2.8611
Epoch [2/50], Class Loss: 1.5338, Discrepancy Loss: 0.0388
Validation Loss: 2.0951
Epoch [3/50], Class Loss: 1.5844, Discrepancy Loss: 0.0283
Validation Loss: 1.1805
Epoch [4/50], Class Loss: 2.0186, Discrepancy Loss: 0.0462
Validation Loss: 1.0134
Epoch [5/50], Class Loss: 0.7982, Discrepancy Loss: 0.0296
Validation Loss: 0.1919
Epoch [6/50], Class Loss: 0.3543, Discrepancy Loss: 0.0095
Validation Loss: 0.4548
Epoch [7/50], Class Loss: 0.3715, Discrepancy Loss: 0.0233
Validation Loss: 0.1381
Epoch [8/50], Class Loss: 0.3486, Discrepancy Loss: 0.0206
Validation Loss: 0.4026
Epoch [9/50], Class Loss: 0.2973, Discrepancy Loss: 0.0304
Validation Loss: 0.0967
Epoch [10/50], Class Loss: 1.5462, Discrepancy Loss: 0.0476
Validation Loss: 0.1866
Epoch [11/50], Class Loss: 0.0596, Discrepancy Loss: 0.0088
Validation Loss: 0.0431
Epoch [12/50], Class Loss: 0.1256, Discrepancy Loss: 0.0119
Validation Loss: 0.0363
Epoch [13/50], Class Loss: 0.0525, Discrepancy Loss: 0.0098
Validation Loss: 0.0809
Epoch [14/50], Class Loss: 0.0511, Discrepancy Loss: 0.0100
Validation Loss: 0.0318
Epoch [15/50], Class Loss: 0.1542, Discrepancy Loss: 0.0109
Validation Loss: 0.0323
Epoch [16/50], Class Loss: 0.0437, Discrepancy Loss: 0.0107
Validation Loss: 0.0814
Epoch [17/50], Class Loss: 0.0838, Discrepancy Loss: 0.0111
Validation Loss: 0.0287
Epoch [18/50], Class Loss: 0.2062, Discrepancy Loss: 0.0139
Validation Loss: 0.0336
Epoch [19/50], Class Loss: 0.1384, Discrepancy Loss: 0.0150
Validation Loss: 0.0256
Epoch [20/50], Class Loss: 0.2303, Discrepancy Loss: 0.0137
Validation Loss: 0.0236
Epoch [21/50], Class Loss: 0.0200, Discrepancy Loss: 0.0099
Validation Loss: 0.0238
Epoch [22/50], Class Loss: 0.0196, Discrepancy Loss: 0.0095
Validation Loss: 0.0237
Epoch [23/50], Class Loss: 0.0194, Discrepancy Loss: 0.0091
Validation Loss: 0.0230
Epoch [24/50], Class Loss: 0.0207, Discrepancy Loss: 0.0092
Validation Loss: 0.0226
Epoch [25/50], Class Loss: 0.0200, Discrepancy Loss: 0.0094
Validation Loss: 0.0224
Epoch [26/50], Class Loss: 0.0196, Discrepancy Loss: 0.0090
Validation Loss: 0.0223
Epoch [27/50], Class Loss: 0.0192, Discrepancy Loss: 0.0092
Validation Loss: 0.0220
Epoch [28/50], Class Loss: 0.0177, Discrepancy Loss: 0.0091
Validation Loss: 0.0226
Epoch [29/50], Class Loss: 0.0177, Discrepancy Loss: 0.0092
Validation Loss: 0.0215
Epoch [30/50], Class Loss: 0.0163, Discrepancy Loss: 0.0091
Validation Loss: 0.0211
Epoch [31/50], Class Loss: 0.0176, Discrepancy Loss: 0.0092
Validation Loss: 0.0209
Epoch [32/50], Class Loss: 0.0170, Discrepancy Loss: 0.0093
Validation Loss: 0.0209
Epoch [33/50], Class Loss: 0.0159, Discrepancy Loss: 0.0092
Validation Loss: 0.0211
Epoch [34/50], Class Loss: 0.0169, Discrepancy Loss: 0.0090
Validation Loss: 0.0209
Epoch [35/50], Class Loss: 0.0166, Discrepancy Loss: 0.0092
Validation Loss: 0.0207
Epoch [36/50], Class Loss: 0.0173, Discrepancy Loss: 0.0091
Validation Loss: 0.0207
Epoch [37/50], Class Loss: 0.0165, Discrepancy Loss: 0.0091
Validation Loss: 0.0206
Epoch [38/50], Class Loss: 0.0168, Discrepancy Loss: 0.0093
Validation Loss: 0.0209
Epoch [39/50], Class Loss: 0.0158, Discrepancy Loss: 0.0091
Validation Loss: 0.0207
Epoch [40/50], Class Loss: 0.0171, Discrepancy Loss: 0.0091
Validation Loss: 0.0204
Epoch [41/50], Class Loss: 0.0178, Discrepancy Loss: 0.0088
Validation Loss: 0.0204
Epoch [42/50], Class Loss: 0.0170, Discrepancy Loss: 0.0092
Validation Loss: 0.0205
Epoch [43/50], Class Loss: 0.0155, Discrepancy Loss: 0.0091
Validation Loss: 0.0205
Epoch [44/50], Class Loss: 0.0165, Discrepancy Loss: 0.0091
Validation Loss: 0.0205
Epoch [45/50], Class Loss: 0.0178, Discrepancy Loss: 0.0090
Validation Loss: 0.0205
Epoch [46/50], Class Loss: 0.0168, Discrepancy Loss: 0.0091
Validation Loss: 0.0205
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 57.69%, Precision: 59.24%, Recall: 56.86%, F1 Score: 52.28%

Run 5/10
Epoch [1/50], Class Loss: 3.1271, Discrepancy Loss: 0.0362
Validation Loss: 3.3461
Epoch [2/50], Class Loss: 1.5803, Discrepancy Loss: 0.0369
Validation Loss: 1.3211
Epoch [3/50], Class Loss: 1.3658, Discrepancy Loss: 0.0240
Validation Loss: 0.4498
Epoch [4/50], Class Loss: 1.7972, Discrepancy Loss: 0.0568
Validation Loss: 0.9389
Epoch [5/50], Class Loss: 1.3327, Discrepancy Loss: 0.0467
Validation Loss: 0.7511
Epoch [6/50], Class Loss: 0.9105, Discrepancy Loss: 0.0267
Validation Loss: 0.0474
Epoch [7/50], Class Loss: 0.3263, Discrepancy Loss: 0.0235
Validation Loss: 0.6142
Epoch [8/50], Class Loss: 1.8189, Discrepancy Loss: 0.0534
Validation Loss: 0.1859
Epoch [9/50], Class Loss: 0.9056, Discrepancy Loss: 0.0436
Validation Loss: 0.4229
Epoch [10/50], Class Loss: 1.0288, Discrepancy Loss: 0.0450
Validation Loss: 0.3364
Epoch [11/50], Class Loss: 0.0743, Discrepancy Loss: 0.0082
Validation Loss: 0.0856
Early stopping!
Source Domain Performance - Accuracy: 99.07%, Precision: 99.11%, Recall: 99.07%, F1 Score: 99.08%
Target Domain Performance - Accuracy: 61.47%, Precision: 59.69%, Recall: 60.21%, F1 Score: 47.34%

Run 6/10
Epoch [1/50], Class Loss: 2.9795, Discrepancy Loss: 0.0439
Validation Loss: 2.4771
Epoch [2/50], Class Loss: 0.7617, Discrepancy Loss: 0.0251
Validation Loss: 0.3491
Epoch [3/50], Class Loss: 0.3033, Discrepancy Loss: 0.0062
Validation Loss: 0.3514
Epoch [4/50], Class Loss: 0.2393, Discrepancy Loss: 0.0148
Validation Loss: 0.1805
Epoch [5/50], Class Loss: 0.1928, Discrepancy Loss: 0.0187
Validation Loss: 0.0402
Epoch [6/50], Class Loss: 0.1098, Discrepancy Loss: 0.0214
Validation Loss: 0.0710
Epoch [7/50], Class Loss: 2.4272, Discrepancy Loss: 0.0427
Validation Loss: 6.7503
Epoch [8/50], Class Loss: 0.5892, Discrepancy Loss: 0.0157
Validation Loss: 0.2495
Epoch [9/50], Class Loss: 0.2640, Discrepancy Loss: 0.0093
Validation Loss: 0.2669
Epoch [10/50], Class Loss: 0.2040, Discrepancy Loss: 0.0124
Validation Loss: 0.2338
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 41.09%, Precision: 50.42%, Recall: 40.05%, F1 Score: 33.75%

Run 7/10
Epoch [1/50], Class Loss: 3.0314, Discrepancy Loss: 0.0394
Validation Loss: 4.9428
Epoch [2/50], Class Loss: 2.3008, Discrepancy Loss: 0.0601
Validation Loss: 0.7807
Epoch [3/50], Class Loss: 1.0812, Discrepancy Loss: 0.0242
Validation Loss: 6.2435
Epoch [4/50], Class Loss: 1.7322, Discrepancy Loss: 0.0408
Validation Loss: 2.1988
Epoch [5/50], Class Loss: 1.8059, Discrepancy Loss: 0.0518
Validation Loss: 7.0393
Epoch [6/50], Class Loss: 2.0079, Discrepancy Loss: 0.0622
Validation Loss: 0.3782
Epoch [7/50], Class Loss: 0.3420, Discrepancy Loss: 0.0214
Validation Loss: 0.5145
Epoch [8/50], Class Loss: 0.3085, Discrepancy Loss: 0.0231
Validation Loss: 0.2928
Epoch [9/50], Class Loss: 0.3251, Discrepancy Loss: 0.0358
Validation Loss: 0.1662
Epoch [10/50], Class Loss: 1.0774, Discrepancy Loss: 0.0524
Validation Loss: 4.8530
Epoch [11/50], Class Loss: 0.1541, Discrepancy Loss: 0.0144
Validation Loss: 0.0471
Epoch [12/50], Class Loss: 0.0317, Discrepancy Loss: 0.0104
Validation Loss: 0.2088
Epoch [13/50], Class Loss: 0.0836, Discrepancy Loss: 0.0160
Validation Loss: 0.0297
Epoch [14/50], Class Loss: 0.0700, Discrepancy Loss: 0.0135
Validation Loss: 0.0357
Epoch [15/50], Class Loss: 0.0986, Discrepancy Loss: 0.0128
Validation Loss: 0.0242
Epoch [16/50], Class Loss: 0.1864, Discrepancy Loss: 0.0154
Validation Loss: 0.1302
Epoch [17/50], Class Loss: 0.3086, Discrepancy Loss: 0.0160
Validation Loss: 0.1061
Epoch [18/50], Class Loss: 0.2700, Discrepancy Loss: 0.0193
Validation Loss: 0.0525
Epoch [19/50], Class Loss: 0.1756, Discrepancy Loss: 0.0178
Validation Loss: 0.1376
Epoch [20/50], Class Loss: 0.1627, Discrepancy Loss: 0.0150
Validation Loss: 0.1980
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 53.64%, Precision: 57.27%, Recall: 52.92%, F1 Score: 50.38%

Run 8/10
Epoch [1/50], Class Loss: 2.5309, Discrepancy Loss: 0.0370
Validation Loss: 2.6821
Epoch [2/50], Class Loss: 2.3799, Discrepancy Loss: 0.0523
Validation Loss: 1.4188
Epoch [3/50], Class Loss: 1.1865, Discrepancy Loss: 0.0317
Validation Loss: 0.2329
Epoch [4/50], Class Loss: 0.6378, Discrepancy Loss: 0.0172
Validation Loss: 5.2374
Epoch [5/50], Class Loss: 2.0213, Discrepancy Loss: 0.0368
Validation Loss: 2.3502
Epoch [6/50], Class Loss: 1.9735, Discrepancy Loss: 0.0388
Validation Loss: 0.7371
Epoch [7/50], Class Loss: 1.4764, Discrepancy Loss: 0.0338
Validation Loss: 0.1138
Epoch [8/50], Class Loss: 0.5458, Discrepancy Loss: 0.0328
Validation Loss: 0.3258
Epoch [9/50], Class Loss: 0.3109, Discrepancy Loss: 0.0308
Validation Loss: 0.2682
Epoch [10/50], Class Loss: 0.7169, Discrepancy Loss: 0.0413
Validation Loss: 0.4418
Epoch [11/50], Class Loss: 0.0844, Discrepancy Loss: 0.0102
Validation Loss: 0.0473
Epoch [12/50], Class Loss: 0.0390, Discrepancy Loss: 0.0106
Validation Loss: 0.0338
Epoch [13/50], Class Loss: 0.1065, Discrepancy Loss: 0.0143
Validation Loss: 0.0309
Epoch [14/50], Class Loss: 0.0898, Discrepancy Loss: 0.0118
Validation Loss: 0.1010
Epoch [15/50], Class Loss: 0.0709, Discrepancy Loss: 0.0132
Validation Loss: 0.0211
Epoch [16/50], Class Loss: 0.1862, Discrepancy Loss: 0.0125
Validation Loss: 0.7611
Epoch [17/50], Class Loss: 0.1792, Discrepancy Loss: 0.0137
Validation Loss: 0.2049
Epoch [18/50], Class Loss: 0.1602, Discrepancy Loss: 0.0137
Validation Loss: 0.0468
Epoch [19/50], Class Loss: 0.4273, Discrepancy Loss: 0.0143
Validation Loss: 0.0244
Epoch [20/50], Class Loss: 0.1468, Discrepancy Loss: 0.0174
Validation Loss: 0.0364
Early stopping!
Source Domain Performance - Accuracy: 99.68%, Precision: 99.69%, Recall: 99.68%, F1 Score: 99.68%
Target Domain Performance - Accuracy: 64.09%, Precision: 61.93%, Recall: 63.72%, F1 Score: 61.17%

Run 9/10
Epoch [1/50], Class Loss: 2.7596, Discrepancy Loss: 0.0355
Validation Loss: 0.7548
Epoch [2/50], Class Loss: 1.5963, Discrepancy Loss: 0.0310
Validation Loss: 0.8554
Epoch [3/50], Class Loss: 1.2741, Discrepancy Loss: 0.0437
Validation Loss: 0.4651
Epoch [4/50], Class Loss: 1.7897, Discrepancy Loss: 0.0387
Validation Loss: 4.2295
Epoch [5/50], Class Loss: 1.0749, Discrepancy Loss: 0.0283
Validation Loss: 1.6888
Epoch [6/50], Class Loss: 2.0926, Discrepancy Loss: 0.0472
Validation Loss: 0.7615
Epoch [7/50], Class Loss: 0.9512, Discrepancy Loss: 0.0394
Validation Loss: 0.3643
Epoch [8/50], Class Loss: 0.5336, Discrepancy Loss: 0.0290
Validation Loss: 0.5964
Epoch [9/50], Class Loss: 1.4598, Discrepancy Loss: 0.0486
Validation Loss: 1.1607
Epoch [10/50], Class Loss: 1.3030, Discrepancy Loss: 0.0323
Validation Loss: 0.9490
Epoch [11/50], Class Loss: 0.0605, Discrepancy Loss: 0.0092
Validation Loss: 0.0320
Epoch [12/50], Class Loss: 0.0547, Discrepancy Loss: 0.0062
Validation Loss: 0.0323
Epoch [13/50], Class Loss: 0.1762, Discrepancy Loss: 0.0039
Validation Loss: 0.0317
Epoch [14/50], Class Loss: 0.1288, Discrepancy Loss: 0.0041
Validation Loss: 0.0239
Epoch [15/50], Class Loss: 0.0999, Discrepancy Loss: 0.0046
Validation Loss: 0.0580
Epoch [16/50], Class Loss: 0.1346, Discrepancy Loss: 0.0093
Validation Loss: 0.0263
Epoch [17/50], Class Loss: 0.1561, Discrepancy Loss: 0.0093
Validation Loss: 0.2112
Epoch [18/50], Class Loss: 0.1931, Discrepancy Loss: 0.0114
Validation Loss: 0.0225
Epoch [19/50], Class Loss: 0.2017, Discrepancy Loss: 0.0144
Validation Loss: 0.0423
Epoch [20/50], Class Loss: 0.1735, Discrepancy Loss: 0.0172
Validation Loss: 0.0305
Epoch [21/50], Class Loss: 0.0586, Discrepancy Loss: 0.0108
Validation Loss: 0.0202
Epoch [22/50], Class Loss: 0.0563, Discrepancy Loss: 0.0102
Validation Loss: 0.0212
Epoch [23/50], Class Loss: 0.0546, Discrepancy Loss: 0.0110
Validation Loss: 0.0186
Epoch [24/50], Class Loss: 0.0570, Discrepancy Loss: 0.0113
Validation Loss: 0.0261
Epoch [25/50], Class Loss: 0.0585, Discrepancy Loss: 0.0112
Validation Loss: 0.0367
Epoch [26/50], Class Loss: 0.0539, Discrepancy Loss: 0.0115
Validation Loss: 0.0215
Epoch [27/50], Class Loss: 0.0466, Discrepancy Loss: 0.0108
Validation Loss: 0.0269
Epoch [28/50], Class Loss: 0.0456, Discrepancy Loss: 0.0113
Validation Loss: 0.0265
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 67.48%, Precision: 62.65%, Recall: 66.79%, F1 Score: 60.46%

Run 10/10
Epoch [1/50], Class Loss: 3.0491, Discrepancy Loss: 0.0549
Validation Loss: 2.3821
Epoch [2/50], Class Loss: 1.6116, Discrepancy Loss: 0.0352
Validation Loss: 0.9909
Epoch [3/50], Class Loss: 2.2263, Discrepancy Loss: 0.0380
Validation Loss: 2.0409
Epoch [4/50], Class Loss: 1.2178, Discrepancy Loss: 0.0255
Validation Loss: 0.4468
Epoch [5/50], Class Loss: 1.1877, Discrepancy Loss: 0.0311
Validation Loss: 0.2510
Epoch [6/50], Class Loss: 0.2587, Discrepancy Loss: 0.0177
Validation Loss: 0.2946
Epoch [7/50], Class Loss: 0.2673, Discrepancy Loss: 0.0194
Validation Loss: 0.1815
Epoch [8/50], Class Loss: 0.3647, Discrepancy Loss: 0.0240
Validation Loss: 1.0265
Epoch [9/50], Class Loss: 1.3142, Discrepancy Loss: 0.0490
Validation Loss: 0.7786
Epoch [10/50], Class Loss: 1.8486, Discrepancy Loss: 0.0553
Validation Loss: 1.1495
Epoch [11/50], Class Loss: 0.0817, Discrepancy Loss: 0.0078
Validation Loss: 0.0378
Epoch [12/50], Class Loss: 0.0280, Discrepancy Loss: 0.0032
Validation Loss: 0.0312
Epoch [13/50], Class Loss: 0.0454, Discrepancy Loss: 0.0096
Validation Loss: 0.0305
Epoch [14/50], Class Loss: 0.0253, Discrepancy Loss: 0.0104
Validation Loss: 0.0200
Epoch [15/50], Class Loss: 0.0879, Discrepancy Loss: 0.0136
Validation Loss: 0.0161
Epoch [16/50], Class Loss: 0.0927, Discrepancy Loss: 0.0126
Validation Loss: 0.0216
Epoch [17/50], Class Loss: 0.3277, Discrepancy Loss: 0.0177
Validation Loss: 0.0327
Epoch [18/50], Class Loss: 0.1000, Discrepancy Loss: 0.0141
Validation Loss: 0.0294
Epoch [19/50], Class Loss: 0.5022, Discrepancy Loss: 0.0172
Validation Loss: 0.0165
Epoch [20/50], Class Loss: 0.2879, Discrepancy Loss: 0.0165
Validation Loss: 0.0195
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 51.37%, Precision: 57.13%, Recall: 50.22%, F1 Score: 42.11%

Source performance: 99.78% 99.79% 99.78% 99.78%
Target performance: 56.88% 58.30% 55.97% 49.33%

Per-Class Accuracy on Target Domain:
bpsk: 99.93%
qpsk: 0.00%
4qam: 58.69%
16qam: 21.25%
apsk: 99.99%

Run 1/10
Epoch [1/50], Class Loss: 1.3502, CORAL Loss: 0.0043
Validation Loss: 1.0219
Epoch [2/50], Class Loss: 0.7313, CORAL Loss: 0.0141
Validation Loss: 0.2250
Epoch [3/50], Class Loss: 0.2321, CORAL Loss: 0.0168
Validation Loss: 0.1257
Epoch [4/50], Class Loss: 0.2578, CORAL Loss: 0.0088
Validation Loss: 0.0821
Epoch [5/50], Class Loss: 0.2473, CORAL Loss: 0.0096
Validation Loss: 0.0718
Epoch [6/50], Class Loss: 0.1759, CORAL Loss: 0.0112
Validation Loss: 0.1081
Epoch [7/50], Class Loss: 0.3732, CORAL Loss: 6.4455
Validation Loss: 1.3977
Epoch [8/50], Class Loss: 0.8666, CORAL Loss: 0.0070
Validation Loss: 0.7907
Epoch [9/50], Class Loss: 0.5706, CORAL Loss: 0.0162
Validation Loss: 0.2890
Epoch [10/50], Class Loss: 0.1776, CORAL Loss: 0.0163
Validation Loss: 0.4205
Early stopping!
Source Domain Performance - Accuracy: 79.22%, Precision: 69.49%, Recall: 79.60%, F1 Score: 72.85%
Target Domain Performance - Accuracy: 24.05%, Precision: 31.57%, Recall: 24.19%, F1 Score: 21.34%

Run 2/10
Epoch [1/50], Class Loss: 1.1835, CORAL Loss: 0.0056
Validation Loss: 0.5875
Epoch [2/50], Class Loss: 0.4643, CORAL Loss: 0.0160
Validation Loss: 0.1858
Epoch [3/50], Class Loss: 0.3811, CORAL Loss: 0.0158
Validation Loss: 0.3671
Epoch [4/50], Class Loss: 1.0968, CORAL Loss: 1.9548
Validation Loss: 1.1159
Epoch [5/50], Class Loss: 0.7779, CORAL Loss: 0.0035
Validation Loss: 0.3855
Epoch [6/50], Class Loss: 0.4360, CORAL Loss: 0.0232
Validation Loss: 0.2709
Epoch [7/50], Class Loss: 0.4176, CORAL Loss: 0.0218
Validation Loss: 0.3060
Early stopping!
Source Domain Performance - Accuracy: 99.00%, Precision: 99.01%, Recall: 98.98%, F1 Score: 98.98%
Target Domain Performance - Accuracy: 42.50%, Precision: 50.46%, Recall: 41.57%, F1 Score: 36.94%

Run 3/10
Epoch [1/50], Class Loss: 1.3620, CORAL Loss: 0.0034
Validation Loss: 0.5761
Epoch [2/50], Class Loss: 0.5563, CORAL Loss: 0.0148
Validation Loss: 2.0092
Epoch [3/50], Class Loss: 0.4433, CORAL Loss: 0.0096
Validation Loss: 0.6452
Epoch [4/50], Class Loss: 0.2587, CORAL Loss: 0.0070
Validation Loss: 0.0834
Epoch [5/50], Class Loss: 0.3221, CORAL Loss: 0.0091
Validation Loss: 0.1630
Epoch [6/50], Class Loss: 0.1461, CORAL Loss: 0.0132
Validation Loss: 2.3358
Epoch [7/50], Class Loss: 0.2035, CORAL Loss: 0.0057
Validation Loss: 0.0364
Epoch [8/50], Class Loss: 0.0612, CORAL Loss: 0.0078
Validation Loss: 0.0351
Epoch [9/50], Class Loss: 0.1189, CORAL Loss: 0.0058
Validation Loss: 0.0130
Epoch [10/50], Class Loss: 0.0067, CORAL Loss: 0.0059
Validation Loss: 0.0080
Epoch [11/50], Class Loss: 0.0037, CORAL Loss: 0.0042
Validation Loss: 0.0078
Epoch [12/50], Class Loss: 0.0036, CORAL Loss: 0.0036
Validation Loss: 0.0077
Epoch [13/50], Class Loss: 0.0035, CORAL Loss: 0.0032
Validation Loss: 0.0077
Epoch [14/50], Class Loss: 0.0034, CORAL Loss: 0.0031
Validation Loss: 0.0070
Epoch [15/50], Class Loss: 0.0033, CORAL Loss: 0.0028
Validation Loss: 0.0073
Epoch [16/50], Class Loss: 0.0031, CORAL Loss: 0.0027
Validation Loss: 0.0071
Epoch [17/50], Class Loss: 0.0028, CORAL Loss: 0.0024
Validation Loss: 0.0072
Epoch [18/50], Class Loss: 0.0032, CORAL Loss: 0.0023
Validation Loss: 0.0072
Epoch [19/50], Class Loss: 0.0030, CORAL Loss: 0.0022
Validation Loss: 0.0072
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 73.34%, Precision: 67.97%, Recall: 73.42%, F1 Score: 70.00%

Run 4/10
Epoch [1/50], Class Loss: 1.2806, CORAL Loss: 0.0069
Validation Loss: 0.3671
Epoch [2/50], Class Loss: 0.8043, CORAL Loss: 0.0137
Validation Loss: 0.3894
Epoch [3/50], Class Loss: 0.3829, CORAL Loss: 0.0178
Validation Loss: 0.1684
Epoch [4/50], Class Loss: 0.3179, CORAL Loss: 0.0100
Validation Loss: 0.1206
Epoch [5/50], Class Loss: 0.2091, CORAL Loss: 0.0088
Validation Loss: 0.1423
Epoch [6/50], Class Loss: 0.1514, CORAL Loss: 0.0117
Validation Loss: 0.0247
Epoch [7/50], Class Loss: 0.1729, CORAL Loss: 0.0066
Validation Loss: 0.3889
Epoch [8/50], Class Loss: 0.2909, CORAL Loss: 0.0110
Validation Loss: 0.0913
Epoch [9/50], Class Loss: 0.0962, CORAL Loss: 0.0141
Validation Loss: 0.0493
Epoch [10/50], Class Loss: 0.2898, CORAL Loss: 0.0100
Validation Loss: 0.0322
Epoch [11/50], Class Loss: 0.0221, CORAL Loss: 0.0112
Validation Loss: 0.0256
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 78.08%, Precision: 69.47%, Recall: 78.11%, F1 Score: 72.45%

Run 5/10
Epoch [1/50], Class Loss: 1.1961, CORAL Loss: 0.0074
Validation Loss: 0.6793
Epoch [2/50], Class Loss: 0.4836, CORAL Loss: 0.0210
Validation Loss: 0.2269
Epoch [3/50], Class Loss: 0.2443, CORAL Loss: 0.0176
Validation Loss: 0.1355
Epoch [4/50], Class Loss: 0.3320, CORAL Loss: 0.0119
Validation Loss: 0.2150
Epoch [5/50], Class Loss: 0.1362, CORAL Loss: 0.0158
Validation Loss: 0.0245
Epoch [6/50], Class Loss: 0.3797, CORAL Loss: 0.0091
Validation Loss: 0.0530
Epoch [7/50], Class Loss: 0.1227, CORAL Loss: 0.0126
Validation Loss: 0.0295
Epoch [8/50], Class Loss: 0.1394, CORAL Loss: 0.0083
Validation Loss: 0.1588
Epoch [9/50], Class Loss: 0.0480, CORAL Loss: 0.0084
Validation Loss: 0.0133
Epoch [10/50], Class Loss: 0.0080, CORAL Loss: 0.0055
Validation Loss: 0.0080
Epoch [11/50], Class Loss: 0.0052, CORAL Loss: 0.0040
Validation Loss: 0.0085
Epoch [12/50], Class Loss: 0.0053, CORAL Loss: 0.0037
Validation Loss: 0.0078
Epoch [13/50], Class Loss: 0.0053, CORAL Loss: 0.0034
Validation Loss: 0.0079
Epoch [14/50], Class Loss: 0.0050, CORAL Loss: 0.0033
Validation Loss: 0.0079
Epoch [15/50], Class Loss: 0.0051, CORAL Loss: 0.0030
Validation Loss: 0.0075
Epoch [16/50], Class Loss: 0.0049, CORAL Loss: 0.0029
Validation Loss: 0.0072
Epoch [17/50], Class Loss: 0.0048, CORAL Loss: 0.0028
Validation Loss: 0.0075
Epoch [18/50], Class Loss: 0.0047, CORAL Loss: 0.0026
Validation Loss: 0.0069
Epoch [19/50], Class Loss: 0.0047, CORAL Loss: 0.0024
Validation Loss: 0.0066
Epoch [20/50], Class Loss: 0.0044, CORAL Loss: 0.0024
Validation Loss: 0.0065
Epoch [21/50], Class Loss: 0.0040, CORAL Loss: 0.0023
Validation Loss: 0.0066
Epoch [22/50], Class Loss: 0.0041, CORAL Loss: 0.0022
Validation Loss: 0.0066
Epoch [23/50], Class Loss: 0.0039, CORAL Loss: 0.0021
Validation Loss: 0.0065
Epoch [24/50], Class Loss: 0.0040, CORAL Loss: 0.0023
Validation Loss: 0.0066
Epoch [25/50], Class Loss: 0.0038, CORAL Loss: 0.0022
Validation Loss: 0.0065
Epoch [26/50], Class Loss: 0.0039, CORAL Loss: 0.0022
Validation Loss: 0.0065
Epoch [27/50], Class Loss: 0.0039, CORAL Loss: 0.0022
Validation Loss: 0.0065
Epoch [28/50], Class Loss: 0.0039, CORAL Loss: 0.0022
Validation Loss: 0.0065
Epoch [29/50], Class Loss: 0.0038, CORAL Loss: 0.0021
Validation Loss: 0.0065
Epoch [30/50], Class Loss: 0.0038, CORAL Loss: 0.0022
Validation Loss: 0.0066
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 69.31%, Precision: 66.19%, Recall: 69.42%, F1 Score: 67.47%

Run 6/10
Epoch [1/50], Class Loss: 1.4536, CORAL Loss: 0.0007
Validation Loss: 0.6261
Epoch [2/50], Class Loss: 0.6911, CORAL Loss: 0.0143
Validation Loss: 0.2123
Epoch [3/50], Class Loss: 0.3633, CORAL Loss: 0.0128
Validation Loss: 0.4760
Epoch [4/50], Class Loss: 0.2003, CORAL Loss: 0.0103
Validation Loss: 0.0658
Epoch [5/50], Class Loss: 0.1985, CORAL Loss: 0.0094
Validation Loss: 0.0535
Epoch [6/50], Class Loss: 0.1333, CORAL Loss: 0.0108
Validation Loss: 0.9544
Epoch [7/50], Class Loss: 0.3181, CORAL Loss: 0.0077
Validation Loss: 0.2802
Epoch [8/50], Class Loss: 0.1162, CORAL Loss: 0.0106
Validation Loss: 0.1640
Epoch [9/50], Class Loss: 0.1618, CORAL Loss: 0.0083
Validation Loss: 0.1096
Epoch [10/50], Class Loss: 0.0311, CORAL Loss: 0.0099
Validation Loss: 0.0379
Epoch [11/50], Class Loss: 0.0065, CORAL Loss: 0.0059
Validation Loss: 0.0096
Epoch [12/50], Class Loss: 0.0050, CORAL Loss: 0.0052
Validation Loss: 0.0089
Epoch [13/50], Class Loss: 0.0045, CORAL Loss: 0.0045
Validation Loss: 0.0102
Epoch [14/50], Class Loss: 0.0045, CORAL Loss: 0.0038
Validation Loss: 0.0086
Epoch [15/50], Class Loss: 0.0042, CORAL Loss: 0.0034
Validation Loss: 0.0078
Epoch [16/50], Class Loss: 0.0037, CORAL Loss: 0.0031
Validation Loss: 0.0082
Epoch [17/50], Class Loss: 0.0035, CORAL Loss: 0.0027
Validation Loss: 0.0079
Epoch [18/50], Class Loss: 0.0034, CORAL Loss: 0.0025
Validation Loss: 0.0084
Epoch [19/50], Class Loss: 0.0036, CORAL Loss: 0.0022
Validation Loss: 0.0078
Epoch [20/50], Class Loss: 0.0031, CORAL Loss: 0.0022
Validation Loss: 0.0071
Epoch [21/50], Class Loss: 0.0027, CORAL Loss: 0.0021
Validation Loss: 0.0072
Epoch [22/50], Class Loss: 0.0026, CORAL Loss: 0.0020
Validation Loss: 0.0073
Epoch [23/50], Class Loss: 0.0028, CORAL Loss: 0.0019
Validation Loss: 0.0074
Epoch [24/50], Class Loss: 0.0027, CORAL Loss: 0.0019
Validation Loss: 0.0074
Epoch [25/50], Class Loss: 0.0026, CORAL Loss: 0.0020
Validation Loss: 0.0074
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 76.20%, Precision: 68.84%, Recall: 76.24%, F1 Score: 71.46%

Run 7/10
Epoch [1/50], Class Loss: 1.5830, CORAL Loss: 0.0003
Validation Loss: 1.5757
Epoch [2/50], Class Loss: 0.9199, CORAL Loss: 0.0115
Validation Loss: 0.5739
Epoch [3/50], Class Loss: 0.4151, CORAL Loss: 0.0267
Validation Loss: 0.2917
Epoch [4/50], Class Loss: 0.3772, CORAL Loss: 0.0128
Validation Loss: 0.2003
Epoch [5/50], Class Loss: 0.2739, CORAL Loss: 0.0158
Validation Loss: 0.6018
Epoch [6/50], Class Loss: 0.1728, CORAL Loss: 0.0145
Validation Loss: 0.0903
Epoch [7/50], Class Loss: 0.1089, CORAL Loss: 0.0109
Validation Loss: 0.0156
Epoch [8/50], Class Loss: 0.9153, CORAL Loss: 0.2687
Validation Loss: 1.2725
Epoch [9/50], Class Loss: 0.7537, CORAL Loss: 0.0207
Validation Loss: 1.1634
Epoch [10/50], Class Loss: 0.3345, CORAL Loss: 0.0191
Validation Loss: 0.2247
Epoch [11/50], Class Loss: 0.0910, CORAL Loss: 0.0240
Validation Loss: 0.0332
Epoch [12/50], Class Loss: 0.0998, CORAL Loss: 0.0191
Validation Loss: 0.0931
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 62.13%, Precision: 60.64%, Recall: 60.92%, F1 Score: 49.11%

Run 8/10
Epoch [1/50], Class Loss: 1.3268, CORAL Loss: 0.0072
Validation Loss: 0.4030
Epoch [2/50], Class Loss: 0.4313, CORAL Loss: 0.0194
Validation Loss: 0.2248
Epoch [3/50], Class Loss: 14.9890, CORAL Loss: 164.8124
Validation Loss: 4.3170
Epoch [4/50], Class Loss: 1.6916, CORAL Loss: 0.1707
Validation Loss: 1.6102
Epoch [5/50], Class Loss: 1.6101, CORAL Loss: 0.1631
Validation Loss: 1.6099
Epoch [6/50], Class Loss: 1.6097, CORAL Loss: 0.1408
Validation Loss: 1.6097
Epoch [7/50], Class Loss: 1.6097, CORAL Loss: 0.1298
Validation Loss: 1.6096
Early stopping!
Source Domain Performance - Accuracy: 19.73%, Precision: 3.95%, Recall: 20.00%, F1 Score: 6.59%
Target Domain Performance - Accuracy: 18.70%, Precision: 3.74%, Recall: 20.00%, F1 Score: 6.30%

Run 9/10
Epoch [1/50], Class Loss: 1.2654, CORAL Loss: 0.0022
Validation Loss: 1.3609
Epoch [2/50], Class Loss: 0.5006, CORAL Loss: 0.0171
Validation Loss: 0.1788
Epoch [3/50], Class Loss: 0.4185, CORAL Loss: 0.0126
Validation Loss: 0.3513
Epoch [4/50], Class Loss: 0.2584, CORAL Loss: 0.0096
Validation Loss: 0.2492
Epoch [5/50], Class Loss: 0.1666, CORAL Loss: 0.0111
Validation Loss: 0.1618
Epoch [6/50], Class Loss: 0.7400, CORAL Loss: 0.0686
Validation Loss: 1.1203
Epoch [7/50], Class Loss: 0.5741, CORAL Loss: 0.0210
Validation Loss: 0.2246
Epoch [8/50], Class Loss: 0.2973, CORAL Loss: 0.0251
Validation Loss: 0.1728
Epoch [9/50], Class Loss: 0.1070, CORAL Loss: 0.0171
Validation Loss: 0.0144
Epoch [10/50], Class Loss: 0.1701, CORAL Loss: 0.0088
Validation Loss: 0.1895
Epoch [11/50], Class Loss: 0.1639, CORAL Loss: 0.0126
Validation Loss: 0.1321
Epoch [12/50], Class Loss: 0.1155, CORAL Loss: 0.0195
Validation Loss: 0.0883
Epoch [13/50], Class Loss: 0.0770, CORAL Loss: 0.0248
Validation Loss: 0.0567
Epoch [14/50], Class Loss: 0.0517, CORAL Loss: 0.0267
Validation Loss: 0.0377
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 59.50%, Precision: 59.94%, Recall: 58.25%, F1 Score: 46.40%

Run 10/10
Epoch [1/50], Class Loss: 1.4718, CORAL Loss: 0.0044
Validation Loss: 0.6667
Epoch [2/50], Class Loss: 0.6740, CORAL Loss: 0.0179
Validation Loss: 0.3375
Epoch [3/50], Class Loss: 0.3521, CORAL Loss: 0.0123
Validation Loss: 0.2977
Epoch [4/50], Class Loss: 0.2394, CORAL Loss: 0.0090
Validation Loss: 0.1309
Epoch [5/50], Class Loss: 0.2450, CORAL Loss: 0.0077
Validation Loss: 0.1326
Epoch [6/50], Class Loss: 0.1435, CORAL Loss: 0.0099
Validation Loss: 0.0237
Epoch [7/50], Class Loss: 0.2515, CORAL Loss: 0.0074
Validation Loss: 0.0616
Epoch [8/50], Class Loss: 0.0423, CORAL Loss: 0.0149
Validation Loss: 0.0146
Epoch [9/50], Class Loss: 0.0087, CORAL Loss: 0.0064
Validation Loss: 0.0098
Epoch [10/50], Class Loss: 0.1997, CORAL Loss: 0.0063
Validation Loss: 0.0272
Epoch [11/50], Class Loss: 0.0156, CORAL Loss: 0.0145
Validation Loss: 0.0194
Epoch [12/50], Class Loss: 0.0134, CORAL Loss: 0.0126
Validation Loss: 0.0163
Epoch [13/50], Class Loss: 0.0118, CORAL Loss: 0.0106
Validation Loss: 0.0141
Epoch [14/50], Class Loss: 0.0101, CORAL Loss: 0.0093
Validation Loss: 0.0124
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 73.71%, Precision: 68.14%, Recall: 73.79%, F1 Score: 70.24%

Source performance: 89.71% 87.16% 89.77% 87.76%
Target performance: 57.75% 54.69% 57.59% 51.17%

Per-Class Accuracy on Target Domain:
bpsk: 79.92%
qpsk: 0.00%
4qam: 55.33%
16qam: 62.77%
apsk: 89.94%

Run 1/10
Epoch [1/50], Class Loss: 1.3980, JMMD Loss: 0.1944
Validation Loss: 1.0708
Epoch [2/50], Class Loss: 0.7026, JMMD Loss: 0.3109
Validation Loss: 0.3651
Epoch [3/50], Class Loss: 0.3714, JMMD Loss: 0.3091
Validation Loss: 0.3509
Epoch [4/50], Class Loss: 0.1807, JMMD Loss: 0.2829
Validation Loss: 0.0236
Epoch [5/50], Class Loss: 1.4601, JMMD Loss: 0.2892
Validation Loss: 0.3209
Epoch [6/50], Class Loss: 0.2823, JMMD Loss: 0.3151
Validation Loss: 0.1528
Epoch [7/50], Class Loss: 0.2116, JMMD Loss: 0.3147
Validation Loss: 0.1667
Epoch [8/50], Class Loss: 0.1928, JMMD Loss: 0.3006
Validation Loss: 0.1602
Epoch [9/50], Class Loss: 0.1233, JMMD Loss: 0.2845
Validation Loss: 0.0643
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 77.47%, Precision: 68.56%, Recall: 77.42%, F1 Score: 71.52%

Run 2/10
Epoch [1/50], Class Loss: 1.4021, JMMD Loss: 0.1751
Validation Loss: 1.2252
Epoch [2/50], Class Loss: 0.5969, JMMD Loss: 0.3227
Validation Loss: 0.2608
Epoch [3/50], Class Loss: 0.2179, JMMD Loss: 0.3023
Validation Loss: 0.1992
Epoch [4/50], Class Loss: 0.2362, JMMD Loss: 0.2892
Validation Loss: 0.0723
Epoch [5/50], Class Loss: 0.3336, JMMD Loss: 0.2660
Validation Loss: 0.2701
Epoch [6/50], Class Loss: 0.1924, JMMD Loss: 0.3015
Validation Loss: 0.3551
Epoch [7/50], Class Loss: 0.0795, JMMD Loss: 0.2713
Validation Loss: 0.0251
Epoch [8/50], Class Loss: 0.1064, JMMD Loss: 0.2614
Validation Loss: 0.0170
Epoch [9/50], Class Loss: 0.2904, JMMD Loss: 0.2306
Validation Loss: 0.2489
Epoch [10/50], Class Loss: 0.2269, JMMD Loss: 0.3072
Validation Loss: 0.1965
Epoch [11/50], Class Loss: 0.0572, JMMD Loss: 0.2942
Validation Loss: 0.0460
Epoch [12/50], Class Loss: 0.0416, JMMD Loss: 0.2911
Validation Loss: 0.0362
Epoch [13/50], Class Loss: 0.0340, JMMD Loss: 0.2845
Validation Loss: 0.0295
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.80%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 75.59%, Precision: 68.23%, Recall: 75.65%, F1 Score: 70.86%

Run 3/10
Epoch [1/50], Class Loss: 1.5299, JMMD Loss: 0.1360
Validation Loss: 0.9553
Epoch [2/50], Class Loss: 0.6506, JMMD Loss: 0.3111
Validation Loss: 0.2374
Epoch [3/50], Class Loss: 0.3377, JMMD Loss: 0.3150
Validation Loss: 0.2773
Epoch [4/50], Class Loss: 0.2365, JMMD Loss: 0.3115
Validation Loss: 0.0893
Epoch [5/50], Class Loss: 0.2794, JMMD Loss: 0.2966
Validation Loss: 0.0676
Epoch [6/50], Class Loss: 0.1241, JMMD Loss: 0.2755
Validation Loss: 0.0361
Epoch [7/50], Class Loss: 0.0132, JMMD Loss: 0.2396
Validation Loss: 0.0161
Epoch [8/50], Class Loss: 0.2551, JMMD Loss: 0.2894
Validation Loss: 0.0246
Epoch [9/50], Class Loss: 0.0311, JMMD Loss: 0.2428
Validation Loss: 0.0219
Epoch [10/50], Class Loss: 0.2083, JMMD Loss: 0.2858
Validation Loss: 0.0158
Epoch [11/50], Class Loss: 0.0101, JMMD Loss: 0.2344
Validation Loss: 0.0154
Epoch [12/50], Class Loss: 0.0095, JMMD Loss: 0.2264
Validation Loss: 0.0145
Epoch [13/50], Class Loss: 0.0088, JMMD Loss: 0.2250
Validation Loss: 0.0134
Epoch [14/50], Class Loss: 0.0092, JMMD Loss: 0.2194
Validation Loss: 0.0124
Epoch [15/50], Class Loss: 0.0088, JMMD Loss: 0.2012
Validation Loss: 0.0125
Epoch [16/50], Class Loss: 0.0085, JMMD Loss: 0.1915
Validation Loss: 0.0110
Epoch [17/50], Class Loss: 0.0079, JMMD Loss: 0.1794
Validation Loss: 0.0105
Epoch [18/50], Class Loss: 0.0076, JMMD Loss: 0.1720
Validation Loss: 0.0101
Epoch [19/50], Class Loss: 0.0073, JMMD Loss: 0.1677
Validation Loss: 0.0100
Epoch [20/50], Class Loss: 0.0071, JMMD Loss: 0.1683
Validation Loss: 0.0104
Epoch [21/50], Class Loss: 0.0066, JMMD Loss: 0.1625
Validation Loss: 0.0097
Epoch [22/50], Class Loss: 0.0064, JMMD Loss: 0.1635
Validation Loss: 0.0097
Epoch [23/50], Class Loss: 0.0065, JMMD Loss: 0.1630
Validation Loss: 0.0096
Epoch [24/50], Class Loss: 0.0064, JMMD Loss: 0.1646
Validation Loss: 0.0097
Epoch [25/50], Class Loss: 0.0065, JMMD Loss: 0.1559
Validation Loss: 0.0094
Epoch [26/50], Class Loss: 0.0065, JMMD Loss: 0.1597
Validation Loss: 0.0096
Epoch [27/50], Class Loss: 0.0063, JMMD Loss: 0.1634
Validation Loss: 0.0095
Epoch [28/50], Class Loss: 0.0063, JMMD Loss: 0.1608
Validation Loss: 0.0096
Epoch [29/50], Class Loss: 0.0064, JMMD Loss: 0.1618
Validation Loss: 0.0094
Epoch [30/50], Class Loss: 0.0062, JMMD Loss: 0.1613
Validation Loss: 0.0095
Epoch [31/50], Class Loss: 0.0063, JMMD Loss: 0.1605
Validation Loss: 0.0095
Epoch [32/50], Class Loss: 0.0063, JMMD Loss: 0.1575
Validation Loss: 0.0095
Epoch [33/50], Class Loss: 0.0061, JMMD Loss: 0.1653
Validation Loss: 0.0095
Epoch [34/50], Class Loss: 0.0061, JMMD Loss: 0.1563
Validation Loss: 0.0094
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 60.08%, Precision: 60.34%, Recall: 60.29%, F1 Score: 60.31%

Run 4/10
Epoch [1/50], Class Loss: 1.4675, JMMD Loss: 0.1517
Validation Loss: 1.8906
Epoch [2/50], Class Loss: 0.8325, JMMD Loss: 0.3200
Validation Loss: 0.2384
Epoch [3/50], Class Loss: 0.3304, JMMD Loss: 0.3231
Validation Loss: 0.1933
Epoch [4/50], Class Loss: 0.2451, JMMD Loss: 0.3153
Validation Loss: 0.8392
Epoch [5/50], Class Loss: 0.3019, JMMD Loss: 0.3148
Validation Loss: 0.1244
Epoch [6/50], Class Loss: 0.1971, JMMD Loss: 0.2896
Validation Loss: 0.1945
Epoch [7/50], Class Loss: 0.1259, JMMD Loss: 0.2789
Validation Loss: 0.0443
Epoch [8/50], Class Loss: 0.1631, JMMD Loss: 0.2466
Validation Loss: 0.1323
Epoch [9/50], Class Loss: 0.0557, JMMD Loss: 0.2470
Validation Loss: 0.0172
Epoch [10/50], Class Loss: 0.0562, JMMD Loss: 0.2151
Validation Loss: 0.0144
Epoch [11/50], Class Loss: 0.0090, JMMD Loss: 0.1882
Validation Loss: 0.0140
Epoch [12/50], Class Loss: 0.0084, JMMD Loss: 0.1820
Validation Loss: 0.0126
Epoch [13/50], Class Loss: 0.0085, JMMD Loss: 0.1740
Validation Loss: 0.0127
Epoch [14/50], Class Loss: 0.0084, JMMD Loss: 0.1712
Validation Loss: 0.0126
Epoch [15/50], Class Loss: 0.0086, JMMD Loss: 0.1662
Validation Loss: 0.0122
Epoch [16/50], Class Loss: 0.0085, JMMD Loss: 0.1658
Validation Loss: 0.0118
Epoch [17/50], Class Loss: 0.0081, JMMD Loss: 0.1648
Validation Loss: 0.0124
Epoch [18/50], Class Loss: 0.0081, JMMD Loss: 0.1597
Validation Loss: 0.0115
Epoch [19/50], Class Loss: 0.0080, JMMD Loss: 0.1609
Validation Loss: 0.0118
Epoch [20/50], Class Loss: 0.0074, JMMD Loss: 0.1562
Validation Loss: 0.0113
Epoch [21/50], Class Loss: 0.0075, JMMD Loss: 0.1629
Validation Loss: 0.0113
Epoch [22/50], Class Loss: 0.0074, JMMD Loss: 0.1574
Validation Loss: 0.0114
Epoch [23/50], Class Loss: 0.0074, JMMD Loss: 0.1521
Validation Loss: 0.0112
Epoch [24/50], Class Loss: 0.0070, JMMD Loss: 0.1536
Validation Loss: 0.0116
Epoch [25/50], Class Loss: 0.0075, JMMD Loss: 0.1585
Validation Loss: 0.0115
Epoch [26/50], Class Loss: 0.0074, JMMD Loss: 0.1558
Validation Loss: 0.0112
Epoch [27/50], Class Loss: 0.0074, JMMD Loss: 0.1562
Validation Loss: 0.0117
Epoch [28/50], Class Loss: 0.0075, JMMD Loss: 0.1588
Validation Loss: 0.0125
Epoch [29/50], Class Loss: 0.0074, JMMD Loss: 0.1523
Validation Loss: 0.0118
Epoch [30/50], Class Loss: 0.0072, JMMD Loss: 0.1546
Validation Loss: 0.0116
Epoch [31/50], Class Loss: 0.0073, JMMD Loss: 0.1520
Validation Loss: 0.0115
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.80%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 59.38%, Precision: 59.66%, Recall: 59.61%, F1 Score: 59.63%

Run 5/10
Epoch [1/50], Class Loss: 1.1727, JMMD Loss: 0.2185
Validation Loss: 0.4552
Epoch [2/50], Class Loss: 0.5094, JMMD Loss: 0.3067
Validation Loss: 0.2524
Epoch [3/50], Class Loss: 0.2398, JMMD Loss: 0.2969
Validation Loss: 0.1693
Epoch [4/50], Class Loss: 0.3520, JMMD Loss: 0.2603
Validation Loss: 0.1182
Epoch [5/50], Class Loss: 0.2757, JMMD Loss: 0.2821
Validation Loss: 0.2098
Epoch [6/50], Class Loss: 0.2004, JMMD Loss: 0.2987
Validation Loss: 0.4615
Epoch [7/50], Class Loss: 0.1224, JMMD Loss: 0.2758
Validation Loss: 0.0118
Epoch [8/50], Class Loss: 0.3062, JMMD Loss: 0.2901
Validation Loss: 0.0671
Epoch [9/50], Class Loss: 0.0249, JMMD Loss: 0.2658
Validation Loss: 0.0157
Epoch [10/50], Class Loss: 0.1410, JMMD Loss: 0.2366
Validation Loss: 0.0483
Epoch [11/50], Class Loss: 0.0320, JMMD Loss: 0.2689
Validation Loss: 0.0242
Epoch [12/50], Class Loss: 0.0186, JMMD Loss: 0.2578
Validation Loss: 0.0183
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.80%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 66.70%, Precision: 65.08%, Recall: 66.87%, F1 Score: 65.84%

Run 6/10
Epoch [1/50], Class Loss: 1.4533, JMMD Loss: 0.1875
Validation Loss: 1.6184
Epoch [2/50], Class Loss: 0.6055, JMMD Loss: 0.3173
Validation Loss: 0.2217
Epoch [3/50], Class Loss: 0.4622, JMMD Loss: 0.3178
Validation Loss: 0.6117
Epoch [4/50], Class Loss: 0.2792, JMMD Loss: 0.3049
Validation Loss: 0.2499
Epoch [5/50], Class Loss: 0.2808, JMMD Loss: 0.2998
Validation Loss: 0.0734
Epoch [6/50], Class Loss: 0.1527, JMMD Loss: 0.2648
Validation Loss: 0.0143
Epoch [7/50], Class Loss: 0.4216, JMMD Loss: 0.2866
Validation Loss: 0.1092
Epoch [8/50], Class Loss: 0.2090, JMMD Loss: 0.2915
Validation Loss: 0.2027
Epoch [9/50], Class Loss: 0.1427, JMMD Loss: 0.2706
Validation Loss: 0.0751
Epoch [10/50], Class Loss: 0.2033, JMMD Loss: 0.2680
Validation Loss: 0.0250
Epoch [11/50], Class Loss: 0.0169, JMMD Loss: 0.2389
Validation Loss: 0.0200
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 65.53%, Precision: 63.70%, Recall: 65.70%, F1 Score: 64.46%

Run 7/10
Epoch [1/50], Class Loss: 1.5391, JMMD Loss: 0.1426
Validation Loss: 0.8796
Epoch [2/50], Class Loss: 0.8992, JMMD Loss: 0.3012
Validation Loss: 1.3011
Epoch [3/50], Class Loss: 0.3399, JMMD Loss: 0.3120
Validation Loss: 0.2534
Epoch [4/50], Class Loss: 0.2147, JMMD Loss: 0.3051
Validation Loss: 0.1878
Epoch [5/50], Class Loss: 0.3038, JMMD Loss: 0.3042
Validation Loss: 0.2372
Epoch [6/50], Class Loss: 0.2867, JMMD Loss: 0.3089
Validation Loss: 0.1284
Epoch [7/50], Class Loss: 0.1824, JMMD Loss: 0.2893
Validation Loss: 0.0511
Epoch [8/50], Class Loss: 0.0153, JMMD Loss: 0.2470
Validation Loss: 0.0117
Epoch [9/50], Class Loss: 0.0080, JMMD Loss: 0.1783
Validation Loss: 0.0079
Epoch [10/50], Class Loss: 0.0603, JMMD Loss: 0.1806
Validation Loss: 0.2839
Epoch [11/50], Class Loss: 0.0800, JMMD Loss: 0.2181
Validation Loss: 0.0286
Epoch [12/50], Class Loss: 0.0203, JMMD Loss: 0.1779
Validation Loss: 0.0157
Epoch [13/50], Class Loss: 0.0120, JMMD Loss: 0.1662
Validation Loss: 0.0120
Epoch [14/50], Class Loss: 0.0095, JMMD Loss: 0.1686
Validation Loss: 0.0101
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 68.82%, Precision: 63.67%, Recall: 68.40%, F1 Score: 63.75%

Run 8/10
Epoch [1/50], Class Loss: 1.4128, JMMD Loss: 0.2130
Validation Loss: 0.9092
Epoch [2/50], Class Loss: 0.5914, JMMD Loss: 0.3263
Validation Loss: 0.1839
Epoch [3/50], Class Loss: 0.2859, JMMD Loss: 0.3120
Validation Loss: 0.3966
Epoch [4/50], Class Loss: 0.2593, JMMD Loss: 0.2932
Validation Loss: 0.2432
Epoch [5/50], Class Loss: 0.1306, JMMD Loss: 0.2493
Validation Loss: 0.0163
Epoch [6/50], Class Loss: 1.7461, JMMD Loss: 0.2106
Validation Loss: 0.3259
Epoch [7/50], Class Loss: 0.3945, JMMD Loss: 0.2908
Validation Loss: 0.1528
Epoch [8/50], Class Loss: 0.2901, JMMD Loss: 0.2699
Validation Loss: 0.1039
Epoch [9/50], Class Loss: 0.2757, JMMD Loss: 0.2545
Validation Loss: 0.1972
Epoch [10/50], Class Loss: 0.1290, JMMD Loss: 0.2856
Validation Loss: 0.0237
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.80%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 77.78%, Precision: 68.86%, Recall: 77.76%, F1 Score: 71.87%

Run 9/10
Epoch [1/50], Class Loss: 1.3488, JMMD Loss: 0.2140
Validation Loss: 0.6814
Epoch [2/50], Class Loss: 0.6516, JMMD Loss: 0.3203
Validation Loss: 0.3559
Epoch [3/50], Class Loss: 0.2453, JMMD Loss: 0.3167
Validation Loss: 0.1567
Epoch [4/50], Class Loss: 0.2932, JMMD Loss: 0.3079
Validation Loss: 0.2016
Epoch [5/50], Class Loss: 0.1961, JMMD Loss: 0.2799
Validation Loss: 0.3805
Epoch [6/50], Class Loss: 0.1930, JMMD Loss: 0.2754
Validation Loss: 0.0413
Epoch [7/50], Class Loss: 0.1171, JMMD Loss: 0.2716
Validation Loss: 0.0243
Epoch [8/50], Class Loss: 0.0105, JMMD Loss: 0.1959
Validation Loss: 0.0106
Epoch [9/50], Class Loss: 0.2104, JMMD Loss: 0.2509
Validation Loss: 0.2171
Epoch [10/50], Class Loss: 0.0244, JMMD Loss: 0.2139
Validation Loss: 0.0108
Epoch [11/50], Class Loss: 0.0074, JMMD Loss: 0.1784
Validation Loss: 0.0098
Epoch [12/50], Class Loss: 0.0075, JMMD Loss: 0.1725
Validation Loss: 0.0103
Epoch [13/50], Class Loss: 0.0075, JMMD Loss: 0.1663
Validation Loss: 0.0094
Epoch [14/50], Class Loss: 0.0070, JMMD Loss: 0.1680
Validation Loss: 0.0095
Epoch [15/50], Class Loss: 0.0069, JMMD Loss: 0.1631
Validation Loss: 0.0089
Epoch [16/50], Class Loss: 0.0067, JMMD Loss: 0.1560
Validation Loss: 0.0087
Epoch [17/50], Class Loss: 0.0067, JMMD Loss: 0.1534
Validation Loss: 0.0086
Epoch [18/50], Class Loss: 0.0066, JMMD Loss: 0.1574
Validation Loss: 0.0087
Epoch [19/50], Class Loss: 0.0062, JMMD Loss: 0.1538
Validation Loss: 0.0083
Epoch [20/50], Class Loss: 0.0063, JMMD Loss: 0.1413
Validation Loss: 0.0089
Epoch [21/50], Class Loss: 0.0054, JMMD Loss: 0.1444
Validation Loss: 0.0083
Epoch [22/50], Class Loss: 0.0059, JMMD Loss: 0.1412
Validation Loss: 0.0081
Epoch [23/50], Class Loss: 0.0058, JMMD Loss: 0.1392
Validation Loss: 0.0082
Epoch [24/50], Class Loss: 0.0059, JMMD Loss: 0.1424
Validation Loss: 0.0082
Epoch [25/50], Class Loss: 0.0056, JMMD Loss: 0.1431
Validation Loss: 0.0082
Epoch [26/50], Class Loss: 0.0056, JMMD Loss: 0.1392
Validation Loss: 0.0087
Epoch [27/50], Class Loss: 0.0054, JMMD Loss: 0.1394
Validation Loss: 0.0085
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 58.84%, Precision: 59.16%, Recall: 59.03%, F1 Score: 59.08%

Run 10/10
Epoch [1/50], Class Loss: 1.3658, JMMD Loss: 0.1808
Validation Loss: 0.6322
Epoch [2/50], Class Loss: 0.5880, JMMD Loss: 0.3155
Validation Loss: 0.3449
Epoch [3/50], Class Loss: 0.2465, JMMD Loss: 0.3153
Validation Loss: 0.1740
Epoch [4/50], Class Loss: 0.2214, JMMD Loss: 0.3152
Validation Loss: 0.1074
Epoch [5/50], Class Loss: 0.4793, JMMD Loss: 0.3116
Validation Loss: 0.3710
Epoch [6/50], Class Loss: 0.2056, JMMD Loss: 0.3082
Validation Loss: 0.3227
Epoch [7/50], Class Loss: 0.2239, JMMD Loss: 0.3045
Validation Loss: 1.0264
Epoch [8/50], Class Loss: 0.1521, JMMD Loss: 0.2866
Validation Loss: 0.0171
Epoch [9/50], Class Loss: 0.0121, JMMD Loss: 0.2267
Validation Loss: 0.0145
Epoch [10/50], Class Loss: 0.1720, JMMD Loss: 0.2258
Validation Loss: 0.0762
Epoch [11/50], Class Loss: 0.0426, JMMD Loss: 0.2937
Validation Loss: 0.0357
Epoch [12/50], Class Loss: 0.0228, JMMD Loss: 0.2802
Validation Loss: 0.0246
Epoch [13/50], Class Loss: 0.0157, JMMD Loss: 0.2704
Validation Loss: 0.0209
Epoch [14/50], Class Loss: 0.0126, JMMD Loss: 0.2544
Validation Loss: 0.0182
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 63.75%, Precision: 62.88%, Recall: 63.95%, F1 Score: 63.32%

Source performance: 99.84% 99.84% 99.84% 99.84%
Target performance: 67.39% 64.01% 67.47% 65.06%

Per-Class Accuracy on Target Domain (Mean over runs):
  Class 0: 99.88%
  Class 1: 0.00%
  Class 2: 45.48%
  Class 3: 93.97%
  Class 4: 98.01%

Run 1/10
Epoch 1/50, Train Loss: 1.2252, Train Acc: 0.3925, Val Loss: 0.7008, Val Acc: 0.5422
Epoch 2/50, Train Loss: 0.6163, Train Acc: 0.6502, Val Loss: 1.0373, Val Acc: 0.4807
Epoch 3/50, Train Loss: 1.0778, Train Acc: 0.6400, Val Loss: 0.7399, Val Acc: 0.5391
Epoch 4/50, Train Loss: 0.7418, Train Acc: 0.7593, Val Loss: 0.0314, Val Acc: 0.9990
Epoch 5/50, Train Loss: 0.7348, Train Acc: 0.8090, Val Loss: 0.7046, Val Acc: 0.8015
Epoch 6/50, Train Loss: 0.8435, Train Acc: 0.7751, Val Loss: 0.1314, Val Acc: 0.9917
Epoch 7/50, Train Loss: 0.4516, Train Acc: 0.9038, Val Loss: 0.0105, Val Acc: 0.9993
Epoch 8/50, Train Loss: 0.6470, Train Acc: 0.8952, Val Loss: 0.0130, Val Acc: 0.9993
Epoch 9/50, Train Loss: 0.5263, Train Acc: 0.8730, Val Loss: 0.2716, Val Acc: 0.8259
Epoch 10/50, Train Loss: 0.4476, Train Acc: 0.9055, Val Loss: 0.0041, Val Acc: 0.9995
Epoch 11/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0036, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0032, Train Acc: 0.9994, Val Loss: 0.0026, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0032, Train Acc: 0.9996, Val Loss: 0.0037, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0023, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0033, Train Acc: 0.9996, Val Loss: 0.0017, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0020, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0023, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0032, Train Acc: 0.9996, Val Loss: 0.0022, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0023, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0023, Val Acc: 0.9995
Early stopping!

Run 2/10
Epoch 1/50, Train Loss: 1.4512, Train Acc: 0.3641, Val Loss: 1.2500, Val Acc: 0.3987
Epoch 2/50, Train Loss: 1.0216, Train Acc: 0.6252, Val Loss: 0.4763, Val Acc: 0.7229
Epoch 3/50, Train Loss: 0.5786, Train Acc: 0.7086, Val Loss: 0.2166, Val Acc: 0.9961
Epoch 4/50, Train Loss: 0.7476, Train Acc: 0.7664, Val Loss: 0.1710, Val Acc: 0.9929
Epoch 5/50, Train Loss: 0.6997, Train Acc: 0.7875, Val Loss: 0.6343, Val Acc: 0.7905
Epoch 6/50, Train Loss: 0.2981, Train Acc: 0.8784, Val Loss: 0.0496, Val Acc: 0.9988
Epoch 7/50, Train Loss: 1.3156, Train Acc: 0.8231, Val Loss: 0.0661, Val Acc: 0.9980
Epoch 8/50, Train Loss: 0.4716, Train Acc: 0.8979, Val Loss: 0.0103, Val Acc: 0.9995
Epoch 9/50, Train Loss: 0.4267, Train Acc: 0.9137, Val Loss: 0.4432, Val Acc: 0.8489
Epoch 10/50, Train Loss: 0.7179, Train Acc: 0.8727, Val Loss: 1.4133, Val Acc: 0.7996
Epoch 11/50, Train Loss: 0.0454, Train Acc: 0.9921, Val Loss: 0.0191, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0048, Train Acc: 0.9996, Val Loss: 0.0179, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0049, Train Acc: 0.9995, Val Loss: 0.0179, Val Acc: 0.9995
Early stopping!

Run 3/10
Epoch 1/50, Train Loss: 1.3023, Train Acc: 0.4331, Val Loss: 2.0267, Val Acc: 0.5859
Epoch 2/50, Train Loss: 0.8420, Train Acc: 0.6080, Val Loss: 0.8737, Val Acc: 0.5156
Epoch 3/50, Train Loss: 0.7695, Train Acc: 0.6943, Val Loss: 0.3285, Val Acc: 0.7920
Epoch 4/50, Train Loss: 0.7040, Train Acc: 0.7217, Val Loss: 0.6551, Val Acc: 0.7283
Epoch 5/50, Train Loss: 0.9301, Train Acc: 0.5948, Val Loss: 0.2559, Val Acc: 0.9983
Epoch 6/50, Train Loss: 0.5675, Train Acc: 0.7496, Val Loss: 0.1953, Val Acc: 0.8042
Epoch 7/50, Train Loss: 0.5243, Train Acc: 0.7836, Val Loss: 0.1791, Val Acc: 0.9927
Epoch 8/50, Train Loss: 0.5491, Train Acc: 0.8548, Val Loss: 0.0307, Val Acc: 0.9927
Epoch 9/50, Train Loss: 0.3331, Train Acc: 0.9308, Val Loss: 0.0627, Val Acc: 0.9978
Epoch 10/50, Train Loss: 0.2167, Train Acc: 0.9547, Val Loss: 0.0335, Val Acc: 0.9929
Epoch 11/50, Train Loss: 0.0068, Train Acc: 0.9986, Val Loss: 0.0093, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0034, Train Acc: 0.9995, Val Loss: 0.0094, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0037, Train Acc: 0.9996, Val Loss: 0.0077, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0058, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0031, Train Acc: 0.9995, Val Loss: 0.0042, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0024, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0027, Train Acc: 0.9995, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0111, Train Acc: 0.9968, Val Loss: 0.0020, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0048, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0021, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0024, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0031, Val Acc: 0.9998
Early stopping!

Run 4/10
Epoch 1/50, Train Loss: 1.5060, Train Acc: 0.3655, Val Loss: 1.0304, Val Acc: 0.3933
Epoch 2/50, Train Loss: 0.7820, Train Acc: 0.5548, Val Loss: 0.9423, Val Acc: 0.4565
Epoch 3/50, Train Loss: 0.5124, Train Acc: 0.7054, Val Loss: 0.3594, Val Acc: 0.7896
Epoch 4/50, Train Loss: 0.4453, Train Acc: 0.8284, Val Loss: 0.2074, Val Acc: 0.9917
Epoch 5/50, Train Loss: 0.8142, Train Acc: 0.7298, Val Loss: 0.2630, Val Acc: 0.7991
Epoch 6/50, Train Loss: 0.4303, Train Acc: 0.8344, Val Loss: 2.4174, Val Acc: 0.4536
Epoch 7/50, Train Loss: 0.5345, Train Acc: 0.8434, Val Loss: 0.3878, Val Acc: 0.8010
Epoch 8/50, Train Loss: 0.5538, Train Acc: 0.8783, Val Loss: 0.5626, Val Acc: 0.7944
Epoch 9/50, Train Loss: 0.6364, Train Acc: 0.8643, Val Loss: 0.1552, Val Acc: 0.9033
Epoch 10/50, Train Loss: 0.3120, Train Acc: 0.9286, Val Loss: 0.0739, Val Acc: 0.9983
Epoch 11/50, Train Loss: 0.0073, Train Acc: 0.9989, Val Loss: 0.0103, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0036, Train Acc: 0.9996, Val Loss: 0.0081, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0032, Train Acc: 0.9996, Val Loss: 0.0056, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0030, Train Acc: 0.9996, Val Loss: 0.0043, Val Acc: 0.9990
Epoch 15/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0031, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0039, Val Acc: 0.9993
Epoch 18/50, Train Loss: 0.0023, Train Acc: 0.9997, Val Loss: 0.0029, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0035, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0024, Train Acc: 0.9998, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0025, Train Acc: 0.9998, Val Loss: 0.0024, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0025, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0025, Train Acc: 0.9998, Val Loss: 0.0026, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0026, Val Acc: 0.9998
Epoch 25/50, Train Loss: 0.0025, Train Acc: 0.9998, Val Loss: 0.0029, Val Acc: 0.9998
Early stopping!

Run 5/10
Epoch 1/50, Train Loss: 1.2541, Train Acc: 0.4139, Val Loss: 0.3141, Val Acc: 0.8035
Epoch 2/50, Train Loss: 0.7531, Train Acc: 0.6626, Val Loss: 0.4029, Val Acc: 0.7571
Epoch 3/50, Train Loss: 0.5166, Train Acc: 0.7587, Val Loss: 1.8320, Val Acc: 0.3958
Epoch 4/50, Train Loss: 0.8907, Train Acc: 0.6818, Val Loss: 0.4876, Val Acc: 0.7898
Epoch 5/50, Train Loss: 0.5914, Train Acc: 0.7678, Val Loss: 0.1748, Val Acc: 0.9990
Epoch 6/50, Train Loss: 0.7027, Train Acc: 0.8209, Val Loss: 0.2218, Val Acc: 0.8040
Epoch 7/50, Train Loss: 0.2027, Train Acc: 0.9409, Val Loss: 0.0117, Val Acc: 0.9990
Epoch 8/50, Train Loss: 0.5242, Train Acc: 0.8959, Val Loss: 0.3629, Val Acc: 0.8184
Epoch 9/50, Train Loss: 0.6819, Train Acc: 0.8691, Val Loss: 1.9600, Val Acc: 0.7703
Epoch 10/50, Train Loss: 0.3419, Train Acc: 0.9225, Val Loss: 0.0432, Val Acc: 0.9988
Epoch 11/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0038, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0019, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0029, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0020, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0046, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0033, Train Acc: 0.9995, Val Loss: 0.0022, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9998
Early stopping!

Run 6/10
Epoch 1/50, Train Loss: 1.3259, Train Acc: 0.4161, Val Loss: 0.4032, Val Acc: 0.9756
Epoch 2/50, Train Loss: 1.0807, Train Acc: 0.6316, Val Loss: 0.4108, Val Acc: 0.9956
Epoch 3/50, Train Loss: 0.6417, Train Acc: 0.6202, Val Loss: 0.4021, Val Acc: 0.7961
Epoch 4/50, Train Loss: 0.7658, Train Acc: 0.7108, Val Loss: 0.3445, Val Acc: 0.8040
Epoch 5/50, Train Loss: 0.6041, Train Acc: 0.8195, Val Loss: 0.1299, Val Acc: 0.9907
Epoch 6/50, Train Loss: 0.5822, Train Acc: 0.8264, Val Loss: 0.3535, Val Acc: 0.8037
Epoch 7/50, Train Loss: 0.6355, Train Acc: 0.8727, Val Loss: 1.1707, Val Acc: 0.7786
Epoch 8/50, Train Loss: 1.0451, Train Acc: 0.8249, Val Loss: 0.6840, Val Acc: 0.7854
Epoch 9/50, Train Loss: 0.4128, Train Acc: 0.8837, Val Loss: 0.0914, Val Acc: 0.9619
Epoch 10/50, Train Loss: 0.5024, Train Acc: 0.8893, Val Loss: 0.5246, Val Acc: 0.7947
Epoch 11/50, Train Loss: 0.0152, Train Acc: 0.9956, Val Loss: 0.0074, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0037, Train Acc: 0.9995, Val Loss: 0.0052, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0041, Train Acc: 0.9995, Val Loss: 0.0043, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0031, Train Acc: 0.9995, Val Loss: 0.0050, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0036, Train Acc: 0.9995, Val Loss: 0.0041, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0051, Val Acc: 0.9993
Epoch 17/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0073, Val Acc: 0.9988
Epoch 18/50, Train Loss: 0.0032, Train Acc: 0.9996, Val Loss: 0.0035, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0039, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0064, Val Acc: 0.9995
Epoch 21/50, Train Loss: 0.0030, Train Acc: 0.9997, Val Loss: 0.0063, Val Acc: 0.9993
Epoch 22/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0054, Val Acc: 0.9995
Epoch 23/50, Train Loss: 0.0027, Train Acc: 0.9997, Val Loss: 0.0050, Val Acc: 0.9995
Early stopping!

Run 7/10
Epoch 1/50, Train Loss: 1.3319, Train Acc: 0.3924, Val Loss: 0.7228, Val Acc: 0.4280
Epoch 2/50, Train Loss: 0.5206, Train Acc: 0.7200, Val Loss: 5.6403, Val Acc: 0.3923
Epoch 3/50, Train Loss: 0.5949, Train Acc: 0.7446, Val Loss: 0.3183, Val Acc: 0.8000
Epoch 4/50, Train Loss: 0.6674, Train Acc: 0.7808, Val Loss: 0.0838, Val Acc: 0.9990
Epoch 5/50, Train Loss: 0.6955, Train Acc: 0.7917, Val Loss: 0.3069, Val Acc: 0.7947
Epoch 6/50, Train Loss: 0.2321, Train Acc: 0.8751, Val Loss: 0.0188, Val Acc: 0.9988
Epoch 7/50, Train Loss: 0.6528, Train Acc: 0.8896, Val Loss: 0.0196, Val Acc: 0.9993
Epoch 8/50, Train Loss: 0.5326, Train Acc: 0.8909, Val Loss: 0.1187, Val Acc: 0.9978
Epoch 9/50, Train Loss: 0.3618, Train Acc: 0.9138, Val Loss: 1.4898, Val Acc: 0.7383
Epoch 10/50, Train Loss: 0.6971, Train Acc: 0.8838, Val Loss: 1.6959, Val Acc: 0.8013
Epoch 11/50, Train Loss: 0.0597, Train Acc: 0.9907, Val Loss: 0.0119, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0045, Train Acc: 0.9996, Val Loss: 0.0070, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0038, Train Acc: 0.9996, Val Loss: 0.0043, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0023, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0059, Val Acc: 0.9988
Epoch 16/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0020, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0030, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0024, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0019, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0020, Val Acc: 0.9995
Epoch 21/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0019, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0023, Val Acc: 0.9998
Epoch 23/50, Train Loss: 0.0012, Train Acc: 0.9997, Val Loss: 0.0020, Val Acc: 0.9998
Epoch 24/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0020, Val Acc: 0.9998
Early stopping!

Run 8/10
Epoch 1/50, Train Loss: 1.3540, Train Acc: 0.3699, Val Loss: 0.8014, Val Acc: 0.4456
Epoch 2/50, Train Loss: 0.8159, Train Acc: 0.6862, Val Loss: 0.2636, Val Acc: 0.7988
Epoch 3/50, Train Loss: 0.8580, Train Acc: 0.7375, Val Loss: 4.0084, Val Acc: 0.5896
Epoch 4/50, Train Loss: 1.3433, Train Acc: 0.7302, Val Loss: 0.2456, Val Acc: 0.8157
Epoch 5/50, Train Loss: 0.5228, Train Acc: 0.8286, Val Loss: 1.9225, Val Acc: 0.5156
Epoch 6/50, Train Loss: 0.1902, Train Acc: 0.9695, Val Loss: 1.8547, Val Acc: 0.7913
Epoch 7/50, Train Loss: 0.5419, Train Acc: 0.8552, Val Loss: 0.2660, Val Acc: 0.8037
Epoch 8/50, Train Loss: 0.1885, Train Acc: 0.8915, Val Loss: 0.4394, Val Acc: 0.8010
Epoch 9/50, Train Loss: 0.1508, Train Acc: 0.9255, Val Loss: 0.0178, Val Acc: 0.9978
Epoch 10/50, Train Loss: 0.4771, Train Acc: 0.8766, Val Loss: 0.2689, Val Acc: 0.8960
Epoch 11/50, Train Loss: 0.0162, Train Acc: 0.9976, Val Loss: 0.0297, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0073, Train Acc: 0.9995, Val Loss: 0.0276, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0070, Train Acc: 0.9996, Val Loss: 0.0253, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0067, Train Acc: 0.9996, Val Loss: 0.0224, Val Acc: 0.9995
Early stopping!

Run 9/10
Epoch 1/50, Train Loss: 1.3522, Train Acc: 0.4349, Val Loss: 0.3626, Val Acc: 0.7986
Epoch 2/50, Train Loss: 0.8510, Train Acc: 0.7741, Val Loss: 0.6060, Val Acc: 0.6179
Epoch 3/50, Train Loss: 0.8943, Train Acc: 0.6921, Val Loss: 0.3941, Val Acc: 0.7893
Epoch 4/50, Train Loss: 0.4156, Train Acc: 0.8109, Val Loss: 0.1349, Val Acc: 0.9983
Epoch 5/50, Train Loss: 0.2115, Train Acc: 0.8896, Val Loss: 0.0917, Val Acc: 0.9990
Epoch 6/50, Train Loss: 0.2062, Train Acc: 0.8960, Val Loss: 0.1870, Val Acc: 0.8494
Epoch 7/50, Train Loss: 0.1761, Train Acc: 0.9079, Val Loss: 0.5215, Val Acc: 0.7939
Epoch 8/50, Train Loss: 0.5632, Train Acc: 0.7765, Val Loss: 0.1858, Val Acc: 0.8049
Epoch 9/50, Train Loss: 0.7410, Train Acc: 0.8282, Val Loss: 4.6025, Val Acc: 0.6826
Epoch 10/50, Train Loss: 0.7314, Train Acc: 0.8459, Val Loss: 0.0171, Val Acc: 0.9985
Epoch 11/50, Train Loss: 0.0110, Train Acc: 0.9986, Val Loss: 0.0090, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0048, Train Acc: 0.9993, Val Loss: 0.0070, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0047, Train Acc: 0.9994, Val Loss: 0.0062, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0041, Train Acc: 0.9994, Val Loss: 0.0041, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0037, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0037, Train Acc: 0.9994, Val Loss: 0.0048, Val Acc: 0.9993
Epoch 17/50, Train Loss: 0.0035, Train Acc: 0.9996, Val Loss: 0.0031, Val Acc: 0.9993
Epoch 18/50, Train Loss: 0.0037, Train Acc: 0.9996, Val Loss: 0.0036, Val Acc: 0.9993
Epoch 19/50, Train Loss: 0.0033, Train Acc: 0.9995, Val Loss: 0.0034, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0034, Train Acc: 0.9995, Val Loss: 0.0080, Val Acc: 0.9988
Epoch 21/50, Train Loss: 0.0031, Train Acc: 0.9996, Val Loss: 0.0036, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0031, Train Acc: 0.9996, Val Loss: 0.0034, Val Acc: 0.9995
Early stopping!

Run 10/10
Epoch 1/50, Train Loss: 1.2316, Train Acc: 0.4092, Val Loss: 0.6807, Val Acc: 0.4421
Epoch 2/50, Train Loss: 0.9044, Train Acc: 0.6320, Val Loss: 0.4862, Val Acc: 0.7986
Epoch 3/50, Train Loss: 0.6324, Train Acc: 0.6334, Val Loss: 0.7089, Val Acc: 0.6792
Epoch 4/50, Train Loss: 0.6991, Train Acc: 0.7632, Val Loss: 0.8677, Val Acc: 0.7019
Epoch 5/50, Train Loss: 0.6428, Train Acc: 0.8409, Val Loss: 0.5846, Val Acc: 0.7898
Epoch 6/50, Train Loss: 0.4647, Train Acc: 0.8165, Val Loss: 0.2334, Val Acc: 0.8164
Epoch 7/50, Train Loss: 0.6958, Train Acc: 0.8404, Val Loss: 0.0657, Val Acc: 0.9973
Epoch 8/50, Train Loss: 0.5308, Train Acc: 0.8670, Val Loss: 0.2578, Val Acc: 0.8022
Epoch 9/50, Train Loss: 0.4435, Train Acc: 0.8793, Val Loss: 0.0094, Val Acc: 0.9995
Epoch 10/50, Train Loss: 0.2616, Train Acc: 0.9241, Val Loss: 0.0089, Val Acc: 0.9995
Epoch 11/50, Train Loss: 0.0040, Train Acc: 0.9995, Val Loss: 0.0071, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0037, Train Acc: 0.9995, Val Loss: 0.0045, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0031, Train Acc: 0.9995, Val Loss: 0.0047, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0030, Train Acc: 0.9996, Val Loss: 0.0039, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0038, Train Acc: 0.9991, Val Loss: 0.0008, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0030, Train Acc: 0.9996, Val Loss: 0.0031, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0017, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0027, Train Acc: 0.9997, Val Loss: 0.0011, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0021, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0021, Val Acc: 0.9998
Early stopping!

Source performance: 99.96 99.96 99.97 99.96
Target performance: 90.00 93.71 90.07 88.78

bpsk: 99.90
qpsk: 99.74
4qam: 50.95
16qam: 99.78
apsk: 100.00
Epoch 1/25, Loss: 3.1265, Domain Loss: 1.4266, Class Loss: 1.6999
Epoch 2/25, Loss: 2.7787, Domain Loss: 1.3690, Class Loss: 1.4097
Epoch 3/25, Loss: 2.5587, Domain Loss: 1.3571, Class Loss: 1.2016
Epoch 4/25, Loss: 2.0041, Domain Loss: 1.2654, Class Loss: 0.7387
Epoch 5/25, Loss: 2.4366, Domain Loss: 1.3049, Class Loss: 1.1317
Epoch 6/25, Loss: 1.9096, Domain Loss: 1.4215, Class Loss: 0.4881
Epoch 7/25, Loss: 1.8025, Domain Loss: 1.4282, Class Loss: 0.3743
Epoch 8/25, Loss: 1.5978, Domain Loss: 1.3745, Class Loss: 0.2233
Epoch 9/25, Loss: 1.6861, Domain Loss: 1.3733, Class Loss: 0.3128
Epoch 10/25, Loss: 1.5975, Domain Loss: 1.3593, Class Loss: 0.2382
Epoch 11/25, Loss: 1.5694, Domain Loss: 1.3452, Class Loss: 0.2242
Epoch 12/25, Loss: 1.5266, Domain Loss: 1.3356, Class Loss: 0.1910
Epoch 13/25, Loss: 1.4847, Domain Loss: 1.3306, Class Loss: 0.1541
Epoch 14/25, Loss: 1.5370, Domain Loss: 1.3309, Class Loss: 0.2060
Epoch 15/25, Loss: 1.6098, Domain Loss: 1.3816, Class Loss: 0.2282
Epoch 16/25, Loss: 2.3289, Domain Loss: 1.3819, Class Loss: 0.9469
Epoch 17/25, Loss: 1.6013, Domain Loss: 1.3157, Class Loss: 0.2856
Epoch 18/25, Loss: 1.5885, Domain Loss: 1.3960, Class Loss: 0.1926
Epoch 19/25, Loss: 2.4256, Domain Loss: 1.5194, Class Loss: 0.9061
Epoch 20/25, Loss: 1.7286, Domain Loss: 1.4213, Class Loss: 0.3073
Epoch 21/25, Loss: 1.6113, Domain Loss: 1.3756, Class Loss: 0.2357
Epoch 22/25, Loss: 1.6344, Domain Loss: 1.3531, Class Loss: 0.2813
Epoch 23/25, Loss: 1.6274, Domain Loss: 1.3472, Class Loss: 0.2802
Epoch 24/25, Loss: 3.4139, Domain Loss: 2.0951, Class Loss: 1.3188
Epoch 25/25, Loss: 7.1573, Domain Loss: 5.5566, Class Loss: 1.6007
31.81


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1331, Domain Loss: 1.4334, Class Loss: 1.6996
Epoch 2/25, Loss: 3.0242, Domain Loss: 1.3972, Class Loss: 1.6270
Epoch 3/25, Loss: 2.8966, Domain Loss: 1.4180, Class Loss: 1.4786
Epoch 4/25, Loss: 2.9866, Domain Loss: 1.4270, Class Loss: 1.5596
Epoch 5/25, Loss: 2.1572, Domain Loss: 1.3750, Class Loss: 0.7822
Epoch 6/25, Loss: 2.1831, Domain Loss: 1.3636, Class Loss: 0.8195
Epoch 7/25, Loss: 1.7012, Domain Loss: 1.3299, Class Loss: 0.3713
Epoch 8/25, Loss: 1.5293, Domain Loss: 1.2551, Class Loss: 0.2741
Epoch 9/25, Loss: 2.5769, Domain Loss: 1.3433, Class Loss: 1.2336
Epoch 10/25, Loss: 1.8875, Domain Loss: 1.3840, Class Loss: 0.5036
Epoch 11/25, Loss: 1.5626, Domain Loss: 1.2802, Class Loss: 0.2825
Epoch 12/25, Loss: 1.3657, Domain Loss: 1.1830, Class Loss: 0.1826
Epoch 13/25, Loss: 1.3924, Domain Loss: 1.1614, Class Loss: 0.2310
Epoch 14/25, Loss: 1.3657, Domain Loss: 1.1659, Class Loss: 0.1998
Epoch 15/25, Loss: 1.3442, Domain Loss: 1.1653, Class Loss: 0.1789
Epoch 16/25, Loss: 1.2803, Domain Loss: 1.1588, Class Loss: 0.1215
Epoch 17/25, Loss: 1.2944, Domain Loss: 1.1661, Class Loss: 0.1283
Epoch 18/25, Loss: 1.2244, Domain Loss: 1.1627, Class Loss: 0.0617
Epoch 19/25, Loss: 1.7719, Domain Loss: 1.1891, Class Loss: 0.5829
Epoch 20/25, Loss: 38.7454, Domain Loss: 34.3995, Class Loss: 4.3459
Epoch 21/25, Loss: 11.4403, Domain Loss: 9.8091, Class Loss: 1.6312
Epoch 22/25, Loss: 12.2648, Domain Loss: 10.6831, Class Loss: 1.5817
Epoch 23/25, Loss: 17.4675, Domain Loss: 16.0705, Class Loss: 1.3970
Epoch 24/25, Loss: 9.8980, Domain Loss: 8.2294, Class Loss: 1.6686
Epoch 25/25, Loss: 8.3675, Domain Loss: 6.7693, Class Loss: 1.5981
19.90


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1218, Domain Loss: 1.4312, Class Loss: 1.6906
Epoch 2/25, Loss: 2.7727, Domain Loss: 1.3839, Class Loss: 1.3888
Epoch 3/25, Loss: 2.6587, Domain Loss: 1.4196, Class Loss: 1.2391
Epoch 4/25, Loss: 2.9066, Domain Loss: 1.3827, Class Loss: 1.5239
Epoch 5/25, Loss: 2.2708, Domain Loss: 1.3584, Class Loss: 0.9124
Epoch 6/25, Loss: 2.0887, Domain Loss: 1.2298, Class Loss: 0.8589
Epoch 7/25, Loss: 13.9941, Domain Loss: 9.5000, Class Loss: 4.4941
Epoch 8/25, Loss: 3.5556, Domain Loss: 1.9231, Class Loss: 1.6325
Epoch 9/25, Loss: 3.0435, Domain Loss: 1.4150, Class Loss: 1.6285
Epoch 10/25, Loss: 3.0346, Domain Loss: 1.4174, Class Loss: 1.6172
Epoch 11/25, Loss: 3.0436, Domain Loss: 1.4243, Class Loss: 1.6193
Epoch 12/25, Loss: 3.0552, Domain Loss: 1.4362, Class Loss: 1.6190
Epoch 13/25, Loss: 3.0634, Domain Loss: 1.4491, Class Loss: 1.6142
Epoch 14/25, Loss: 3.0909, Domain Loss: 1.4779, Class Loss: 1.6130
Epoch 15/25, Loss: 3.1392, Domain Loss: 1.5258, Class Loss: 1.6134
Epoch 16/25, Loss: 3.2922, Domain Loss: 1.6798, Class Loss: 1.6124
Epoch 17/25, Loss: 3.3023, Domain Loss: 1.6914, Class Loss: 1.6109
Epoch 18/25, Loss: 3.1917, Domain Loss: 1.5919, Class Loss: 1.5998
Epoch 19/25, Loss: 3.3695, Domain Loss: 1.8110, Class Loss: 1.5586
Epoch 20/25, Loss: 3.1284, Domain Loss: 1.5046, Class Loss: 1.6238
Epoch 21/25, Loss: 3.0287, Domain Loss: 1.4395, Class Loss: 1.5893
Epoch 22/25, Loss: 2.9698, Domain Loss: 1.4207, Class Loss: 1.5491
Epoch 23/25, Loss: 2.7724, Domain Loss: 1.3961, Class Loss: 1.3763
Epoch 24/25, Loss: 2.6481, Domain Loss: 1.4004, Class Loss: 1.2477
Epoch 25/25, Loss: 2.7805, Domain Loss: 1.4784, Class Loss: 1.3021
39.60


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1069, Domain Loss: 1.4029, Class Loss: 1.7039
Epoch 2/25, Loss: 2.9765, Domain Loss: 1.3851, Class Loss: 1.5914
Epoch 3/25, Loss: 2.8472, Domain Loss: 1.3711, Class Loss: 1.4761
Epoch 4/25, Loss: 2.1272, Domain Loss: 1.2769, Class Loss: 0.8503
Epoch 5/25, Loss: 3.0011, Domain Loss: 1.5559, Class Loss: 1.4452
Epoch 6/25, Loss: 2.8838, Domain Loss: 1.3941, Class Loss: 1.4897
Epoch 7/25, Loss: 2.4946, Domain Loss: 1.3919, Class Loss: 1.1027
Epoch 8/25, Loss: 2.2059, Domain Loss: 1.3604, Class Loss: 0.8454
Epoch 9/25, Loss: 2.0479, Domain Loss: 1.3266, Class Loss: 0.7213
Epoch 10/25, Loss: 1.8478, Domain Loss: 1.2942, Class Loss: 0.5537
Epoch 11/25, Loss: 2.7474, Domain Loss: 1.2781, Class Loss: 1.4693
Epoch 12/25, Loss: 2.1185, Domain Loss: 1.2359, Class Loss: 0.8826
Epoch 13/25, Loss: 1.7994, Domain Loss: 1.2074, Class Loss: 0.5920
Epoch 14/25, Loss: 1.5964, Domain Loss: 1.2163, Class Loss: 0.3801
Epoch 15/25, Loss: 2.0198, Domain Loss: 1.2247, Class Loss: 0.7951
Epoch 16/25, Loss: 1.5090, Domain Loss: 1.1843, Class Loss: 0.3247
Epoch 17/25, Loss: 1.4429, Domain Loss: 1.1809, Class Loss: 0.2620
Epoch 18/25, Loss: 2.5594, Domain Loss: 1.2633, Class Loss: 1.2961
Epoch 19/25, Loss: 1.8314, Domain Loss: 1.1794, Class Loss: 0.6520
Epoch 20/25, Loss: 1.4905, Domain Loss: 1.1454, Class Loss: 0.3451
Epoch 21/25, Loss: 1.3607, Domain Loss: 1.1439, Class Loss: 0.2169
Epoch 22/25, Loss: 1.3237, Domain Loss: 1.1323, Class Loss: 0.1914
Epoch 23/25, Loss: 1.2470, Domain Loss: 1.1100, Class Loss: 0.1369
Epoch 24/25, Loss: 1.3179, Domain Loss: 1.1157, Class Loss: 0.2022
Epoch 25/25, Loss: 1.1839, Domain Loss: 1.1020, Class Loss: 0.0819
93.65


Epoch 1/25, Loss: 3.0972, Domain Loss: 1.4075, Class Loss: 1.6897
Epoch 2/25, Loss: 3.0187, Domain Loss: 1.3967, Class Loss: 1.6221
Epoch 3/25, Loss: 2.3448, Domain Loss: 1.3240, Class Loss: 1.0208
Epoch 4/25, Loss: 2.0029, Domain Loss: 1.2256, Class Loss: 0.7773
Epoch 5/25, Loss: 1.9670, Domain Loss: 1.2442, Class Loss: 0.7228
Epoch 6/25, Loss: 2.1067, Domain Loss: 1.3726, Class Loss: 0.7341
Epoch 7/25, Loss: 1.6857, Domain Loss: 1.2494, Class Loss: 0.4363
Epoch 8/25, Loss: 2.8039, Domain Loss: 1.6339, Class Loss: 1.1700
Epoch 9/25, Loss: 1.8399, Domain Loss: 1.2775, Class Loss: 0.5623
Epoch 10/25, Loss: 1.4766, Domain Loss: 1.1828, Class Loss: 0.2938
Epoch 11/25, Loss: 1.3729, Domain Loss: 1.1784, Class Loss: 0.1945
Epoch 12/25, Loss: 1.3325, Domain Loss: 1.1720, Class Loss: 0.1605
Epoch 13/25, Loss: 1.5579, Domain Loss: 1.2012, Class Loss: 0.3567
Epoch 14/25, Loss: 1.5767, Domain Loss: 1.3731, Class Loss: 0.2037
Epoch 15/25, Loss: 1.4449, Domain Loss: 1.2423, Class Loss: 0.2026
Epoch 16/25, Loss: 1.7573, Domain Loss: 1.2809, Class Loss: 0.4764
Epoch 17/25, Loss: 2.1318, Domain Loss: 1.5503, Class Loss: 0.5815
Epoch 18/25, Loss: 1.4554, Domain Loss: 1.2780, Class Loss: 0.1774
Epoch 19/25, Loss: 1.4857, Domain Loss: 1.3379, Class Loss: 0.1479
Epoch 20/25, Loss: 4.5237, Domain Loss: 2.1560, Class Loss: 2.3677
Epoch 21/25, Loss: 1.3917, Domain Loss: 1.1524, Class Loss: 0.2394
Epoch 22/25, Loss: 1.2718, Domain Loss: 1.1086, Class Loss: 0.1632
Epoch 23/25, Loss: 1.1540, Domain Loss: 1.0692, Class Loss: 0.0849
Epoch 24/25, Loss: 1.1066, Domain Loss: 1.0284, Class Loss: 0.0782
Epoch 25/25, Loss: 1.7938, Domain Loss: 1.3116, Class Loss: 0.4822
95.41


Epoch 1/25, Loss: 3.1148, Domain Loss: 1.4197, Class Loss: 1.6952
Epoch 2/25, Loss: 2.7627, Domain Loss: 1.3914, Class Loss: 1.3712
Epoch 3/25, Loss: 3.0392, Domain Loss: 1.4233, Class Loss: 1.6159
Epoch 4/25, Loss: 2.5158, Domain Loss: 1.3802, Class Loss: 1.1356
Epoch 5/25, Loss: 2.4027, Domain Loss: 1.3792, Class Loss: 1.0235
Epoch 6/25, Loss: 2.1790, Domain Loss: 1.3779, Class Loss: 0.8012
Epoch 7/25, Loss: 2.2678, Domain Loss: 1.3776, Class Loss: 0.8902
Epoch 8/25, Loss: 1.8898, Domain Loss: 1.3730, Class Loss: 0.5169
Epoch 9/25, Loss: 2.0567, Domain Loss: 1.3693, Class Loss: 0.6875
Epoch 10/25, Loss: 1.6854, Domain Loss: 1.3666, Class Loss: 0.3188
Epoch 11/25, Loss: 2.1463, Domain Loss: 1.3586, Class Loss: 0.7877
Epoch 12/25, Loss: 1.6703, Domain Loss: 1.3502, Class Loss: 0.3200
Epoch 13/25, Loss: 1.9964, Domain Loss: 1.3609, Class Loss: 0.6355
Epoch 14/25, Loss: 1.6119, Domain Loss: 1.3177, Class Loss: 0.2942
Epoch 15/25, Loss: 1.5409, Domain Loss: 1.3045, Class Loss: 0.2364
Epoch 16/25, Loss: 1.7254, Domain Loss: 1.2892, Class Loss: 0.4362
Epoch 17/25, Loss: 1.4691, Domain Loss: 1.2620, Class Loss: 0.2070
Epoch 18/25, Loss: 1.5071, Domain Loss: 1.2561, Class Loss: 0.2510
Epoch 19/25, Loss: 2.1643, Domain Loss: 1.3649, Class Loss: 0.7994
Epoch 20/25, Loss: 1.8009, Domain Loss: 1.3848, Class Loss: 0.4161
Epoch 21/25, Loss: 1.4520, Domain Loss: 1.2368, Class Loss: 0.2153
Epoch 22/25, Loss: 1.3469, Domain Loss: 1.1935, Class Loss: 0.1534
Epoch 23/25, Loss: 1.2470, Domain Loss: 1.1850, Class Loss: 0.0620
Epoch 24/25, Loss: 1.3401, Domain Loss: 1.1701, Class Loss: 0.1699
Epoch 25/25, Loss: 2.0910, Domain Loss: 1.1868, Class Loss: 0.9042
60.11


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1393, Domain Loss: 1.4258, Class Loss: 1.7135
Epoch 2/25, Loss: 2.9727, Domain Loss: 1.3864, Class Loss: 1.5862
Epoch 3/25, Loss: 2.4610, Domain Loss: 1.3454, Class Loss: 1.1156
Epoch 4/25, Loss: 3.2917, Domain Loss: 1.6182, Class Loss: 1.6735
Epoch 5/25, Loss: 2.8214, Domain Loss: 1.3351, Class Loss: 1.4863
Epoch 6/25, Loss: 1.9860, Domain Loss: 1.1971, Class Loss: 0.7889
Epoch 7/25, Loss: 1.6417, Domain Loss: 1.1653, Class Loss: 0.4763
Epoch 8/25, Loss: 1.6886, Domain Loss: 1.1657, Class Loss: 0.5229
Epoch 9/25, Loss: 1.4289, Domain Loss: 1.1568, Class Loss: 0.2721
Epoch 10/25, Loss: 1.5016, Domain Loss: 1.1498, Class Loss: 0.3518
Epoch 11/25, Loss: 2.2168, Domain Loss: 1.1473, Class Loss: 1.0695
Epoch 12/25, Loss: 1.4667, Domain Loss: 1.1204, Class Loss: 0.3463
Epoch 13/25, Loss: 1.3068, Domain Loss: 1.1118, Class Loss: 0.1950
Epoch 14/25, Loss: 1.2671, Domain Loss: 1.1249, Class Loss: 0.1422
Epoch 15/25, Loss: 1.4043, Domain Loss: 1.1133, Class Loss: 0.2910
Epoch 16/25, Loss: 1.2572, Domain Loss: 1.1207, Class Loss: 0.1366
Epoch 17/25, Loss: 1.2567, Domain Loss: 1.1165, Class Loss: 0.1402
Epoch 18/25, Loss: 1.1849, Domain Loss: 1.1047, Class Loss: 0.0802
Epoch 19/25, Loss: 1.1522, Domain Loss: 1.1101, Class Loss: 0.0421
Epoch 20/25, Loss: 1.1218, Domain Loss: 1.1142, Class Loss: 0.0076
Epoch 21/25, Loss: 2.1105, Domain Loss: 1.1240, Class Loss: 0.9865
Epoch 22/25, Loss: 1.6002, Domain Loss: 1.1170, Class Loss: 0.4832
Epoch 23/25, Loss: 1.3271, Domain Loss: 1.1141, Class Loss: 0.2130
Epoch 24/25, Loss: 1.2414, Domain Loss: 1.1115, Class Loss: 0.1299
Epoch 25/25, Loss: 1.1734, Domain Loss: 1.0897, Class Loss: 0.0837
97.29


Epoch 1/25, Loss: 3.1271, Domain Loss: 1.4127, Class Loss: 1.7144
Epoch 2/25, Loss: 2.9520, Domain Loss: 1.3833, Class Loss: 1.5687
Epoch 3/25, Loss: 3.3632, Domain Loss: 1.4807, Class Loss: 1.8825
Epoch 4/25, Loss: 2.8656, Domain Loss: 1.3846, Class Loss: 1.4810
Epoch 5/25, Loss: 2.5761, Domain Loss: 1.3865, Class Loss: 1.1896
Epoch 6/25, Loss: 2.3290, Domain Loss: 1.3736, Class Loss: 0.9554
Epoch 7/25, Loss: 2.1939, Domain Loss: 1.3589, Class Loss: 0.8350
Epoch 8/25, Loss: 1.9129, Domain Loss: 1.2692, Class Loss: 0.6436
Epoch 9/25, Loss: 2.1022, Domain Loss: 1.2632, Class Loss: 0.8390
Epoch 10/25, Loss: 1.7763, Domain Loss: 1.1922, Class Loss: 0.5842
Epoch 11/25, Loss: 2.2773, Domain Loss: 1.2451, Class Loss: 1.0322
Epoch 12/25, Loss: 2.3727, Domain Loss: 1.3675, Class Loss: 1.0052
Epoch 13/25, Loss: 1.6872, Domain Loss: 1.2168, Class Loss: 0.4703
Epoch 14/25, Loss: 1.4319, Domain Loss: 1.1672, Class Loss: 0.2647
Epoch 15/25, Loss: 3.2723, Domain Loss: 1.3703, Class Loss: 1.9020
Epoch 16/25, Loss: 8.6172, Domain Loss: 3.7781, Class Loss: 4.8391
Epoch 17/25, Loss: 2.4817, Domain Loss: 1.4059, Class Loss: 1.0757
Epoch 18/25, Loss: 2.1939, Domain Loss: 1.3937, Class Loss: 0.8002
Epoch 19/25, Loss: 1.9228, Domain Loss: 1.3903, Class Loss: 0.5325
Epoch 20/25, Loss: 1.7112, Domain Loss: 1.3880, Class Loss: 0.3231
Epoch 21/25, Loss: 1.8435, Domain Loss: 1.3846, Class Loss: 0.4590
Epoch 22/25, Loss: 1.5866, Domain Loss: 1.3801, Class Loss: 0.2065
Epoch 23/25, Loss: 1.5944, Domain Loss: 1.3775, Class Loss: 0.2169
Epoch 24/25, Loss: 1.6323, Domain Loss: 1.3706, Class Loss: 0.2617
Epoch 25/25, Loss: 1.5080, Domain Loss: 1.3625, Class Loss: 0.1455
95.43


Epoch 1/25, Loss: 3.1417, Domain Loss: 1.4355, Class Loss: 1.7063
Epoch 2/25, Loss: 3.1731, Domain Loss: 1.5213, Class Loss: 1.6518
Epoch 3/25, Loss: 3.5054, Domain Loss: 1.8547, Class Loss: 1.6506
Epoch 4/25, Loss: 2.7260, Domain Loss: 1.5551, Class Loss: 1.1709
Epoch 5/25, Loss: 2.4866, Domain Loss: 1.4281, Class Loss: 1.0585
Epoch 6/25, Loss: 2.4930, Domain Loss: 1.3506, Class Loss: 1.1425
Epoch 7/25, Loss: 1.9844, Domain Loss: 1.2986, Class Loss: 0.6857
Epoch 8/25, Loss: 1.5486, Domain Loss: 1.2421, Class Loss: 0.3064
Epoch 9/25, Loss: 2.5384, Domain Loss: 1.3240, Class Loss: 1.2144
Epoch 10/25, Loss: 1.7200, Domain Loss: 1.2372, Class Loss: 0.4829
Epoch 11/25, Loss: 1.4011, Domain Loss: 1.1706, Class Loss: 0.2305
Epoch 12/25, Loss: 1.3269, Domain Loss: 1.1560, Class Loss: 0.1710
Epoch 13/25, Loss: 2.2899, Domain Loss: 1.4046, Class Loss: 0.8853
Epoch 14/25, Loss: 1.5759, Domain Loss: 1.3277, Class Loss: 0.2482
Epoch 15/25, Loss: 5.0445, Domain Loss: 1.9575, Class Loss: 3.0869
Epoch 16/25, Loss: 2.4284, Domain Loss: 1.3043, Class Loss: 1.1241
Epoch 17/25, Loss: 1.7559, Domain Loss: 1.2313, Class Loss: 0.5246
Epoch 18/25, Loss: 1.4480, Domain Loss: 1.1491, Class Loss: 0.2988
Epoch 19/25, Loss: 1.3816, Domain Loss: 1.1488, Class Loss: 0.2328
Epoch 20/25, Loss: 1.3317, Domain Loss: 1.0701, Class Loss: 0.2616
Epoch 21/25, Loss: 1.1902, Domain Loss: 1.0931, Class Loss: 0.0971
Epoch 22/25, Loss: 2.3273, Domain Loss: 1.1282, Class Loss: 1.1992
Epoch 23/25, Loss: 1.6324, Domain Loss: 1.1443, Class Loss: 0.4880
Epoch 24/25, Loss: 1.3530, Domain Loss: 1.0954, Class Loss: 0.2576
Epoch 25/25, Loss: 1.2016, Domain Loss: 1.0350, Class Loss: 0.1665
97.27


Epoch 1/25, Loss: 3.1273, Domain Loss: 1.4153, Class Loss: 1.7120
Epoch 2/25, Loss: 2.8019, Domain Loss: 1.3784, Class Loss: 1.4235
Epoch 3/25, Loss: 2.6097, Domain Loss: 1.3659, Class Loss: 1.2438
Epoch 4/25, Loss: 2.4625, Domain Loss: 1.3318, Class Loss: 1.1307
Epoch 5/25, Loss: 2.1261, Domain Loss: 1.2580, Class Loss: 0.8681
Epoch 6/25, Loss: 3.9113, Domain Loss: 1.4088, Class Loss: 2.5025
Epoch 7/25, Loss: 1.9522, Domain Loss: 1.1926, Class Loss: 0.7596
Epoch 8/25, Loss: 1.7942, Domain Loss: 1.1779, Class Loss: 0.6163
Epoch 9/25, Loss: 2.5815, Domain Loss: 1.8565, Class Loss: 0.7250
Epoch 10/25, Loss: 21.4906, Domain Loss: 19.8599, Class Loss: 1.6307
Epoch 11/25, Loss: 16.1436, Domain Loss: 14.8250, Class Loss: 1.3185
Epoch 12/25, Loss: 34.8875, Domain Loss: 33.3576, Class Loss: 1.5299
Epoch 13/25, Loss: 29.4993, Domain Loss: 28.0640, Class Loss: 1.4353
Epoch 14/25, Loss: 48.1422, Domain Loss: 46.6355, Class Loss: 1.5068
Epoch 15/25, Loss: 29.1340, Domain Loss: 27.7852, Class Loss: 1.3488
Epoch 16/25, Loss: 47.7249, Domain Loss: 45.2078, Class Loss: 2.5171
Epoch 17/25, Loss: 33.9429, Domain Loss: 32.5774, Class Loss: 1.3656
Epoch 18/25, Loss: 17.6327, Domain Loss: 16.5655, Class Loss: 1.0672
Epoch 19/25, Loss: 7.8730, Domain Loss: 7.1685, Class Loss: 0.7045
Epoch 20/25, Loss: 17.3116, Domain Loss: 15.8933, Class Loss: 1.4184
Epoch 21/25, Loss: 13.7835, Domain Loss: 12.9778, Class Loss: 0.8058
Epoch 22/25, Loss: 11.9111, Domain Loss: 11.0724, Class Loss: 0.8387
Epoch 23/25, Loss: 10.4932, Domain Loss: 9.7116, Class Loss: 0.7816
Epoch 24/25, Loss: 9.5657, Domain Loss: 8.7898, Class Loss: 0.7759
Epoch 25/25, Loss: 8.7362, Domain Loss: 8.2034, Class Loss: 0.5327
91.33


Source performance:
71.77 68.45 72.03 66.73 
Target performance:
72.18 68.91 72.31 67.80 

Per-class target performance: 69.93 68.67 63.08 69.88 90.00 
Run 1/10
Epoch [1/50], Class Loss: 3.5111, Discrepancy Loss: 0.1114
Epoch [2/50], Class Loss: 0.6930, Discrepancy Loss: 0.0984
Epoch [3/50], Class Loss: 0.5234, Discrepancy Loss: 0.0835
Epoch [4/50], Class Loss: 0.4547, Discrepancy Loss: 0.0661
Epoch [5/50], Class Loss: 0.2921, Discrepancy Loss: 0.0547
Epoch [6/50], Class Loss: 0.3912, Discrepancy Loss: 0.0654
Epoch [7/50], Class Loss: 0.3303, Discrepancy Loss: 0.0562
Epoch [8/50], Class Loss: 0.2211, Discrepancy Loss: 0.0492
Epoch [9/50], Class Loss: 0.1383, Discrepancy Loss: 0.0449
Epoch [10/50], Class Loss: 0.0819, Discrepancy Loss: 0.0382
Epoch [11/50], Class Loss: 0.0366, Discrepancy Loss: 0.0371
Epoch [12/50], Class Loss: 0.0179, Discrepancy Loss: 0.0304
Epoch [13/50], Class Loss: 0.0124, Discrepancy Loss: 0.0337
Epoch [14/50], Class Loss: 0.0115, Discrepancy Loss: 0.0367
Epoch [15/50], Class Loss: 0.0120, Discrepancy Loss: 0.0401
Epoch [16/50], Class Loss: 0.0251, Discrepancy Loss: 0.0380
Epoch [17/50], Class Loss: 0.0234, Discrepancy Loss: 0.0388
Epoch [18/50], Class Loss: 0.0159, Discrepancy Loss: 0.0399
Epoch [19/50], Class Loss: 0.0201, Discrepancy Loss: 0.0373
Epoch [20/50], Class Loss: 0.0118, Discrepancy Loss: 0.0420
Epoch [21/50], Class Loss: 0.0071, Discrepancy Loss: 0.0431
Epoch [22/50], Class Loss: 0.0081, Discrepancy Loss: 0.0390
Epoch [23/50], Class Loss: 0.0069, Discrepancy Loss: 0.0395
Epoch [24/50], Class Loss: 0.0062, Discrepancy Loss: 0.0433
Epoch [25/50], Class Loss: 0.0106, Discrepancy Loss: 0.0426
Epoch [26/50], Class Loss: 0.0096, Discrepancy Loss: 0.0401
Epoch [27/50], Class Loss: 0.0099, Discrepancy Loss: 0.0439
Epoch [28/50], Class Loss: 0.0092, Discrepancy Loss: 0.0414
Epoch [29/50], Class Loss: 0.0083, Discrepancy Loss: 0.0392
Epoch [30/50], Class Loss: 0.0101, Discrepancy Loss: 0.0425
Epoch [31/50], Class Loss: 0.0098, Discrepancy Loss: 0.0439
Epoch [32/50], Class Loss: 0.0095, Discrepancy Loss: 0.0468
Epoch [33/50], Class Loss: 0.0076, Discrepancy Loss: 0.0458
Epoch [34/50], Class Loss: 0.0081, Discrepancy Loss: 0.0453
Epoch [35/50], Class Loss: 0.0091, Discrepancy Loss: 0.0518
Epoch [36/50], Class Loss: 0.0076, Discrepancy Loss: 0.0466
Epoch [37/50], Class Loss: 0.0107, Discrepancy Loss: 0.0461
Epoch [38/50], Class Loss: 0.0093, Discrepancy Loss: 0.0500
Epoch [39/50], Class Loss: 0.0109, Discrepancy Loss: 0.0421
Epoch [40/50], Class Loss: 0.0113, Discrepancy Loss: 0.0416
Epoch [41/50], Class Loss: 0.0117, Discrepancy Loss: 0.0444
Epoch [42/50], Class Loss: 0.0082, Discrepancy Loss: 0.0448
Epoch [43/50], Class Loss: 0.0104, Discrepancy Loss: 0.0472
Epoch [44/50], Class Loss: 0.0105, Discrepancy Loss: 0.0498
Epoch [45/50], Class Loss: 0.0107, Discrepancy Loss: 0.0515
Epoch [46/50], Class Loss: 0.0094, Discrepancy Loss: 0.0455
Epoch [47/50], Class Loss: 0.0078, Discrepancy Loss: 0.0465
Epoch [48/50], Class Loss: 0.0084, Discrepancy Loss: 0.0518
Epoch [49/50], Class Loss: 0.0113, Discrepancy Loss: 0.0443
Epoch [50/50], Class Loss: 0.0105, Discrepancy Loss: 0.0467
Source Domain Performance - Accuracy: 99.71%, Precision: 99.71%, Recall: 99.71%, F1 Score: 99.71%
Target Domain Performance - Accuracy: 97.66%, Precision: 97.92%, Recall: 97.67%, F1 Score: 97.69%

Run 2/10
Epoch [1/50], Class Loss: 3.5506, Discrepancy Loss: 0.1165
Epoch [2/50], Class Loss: 0.7468, Discrepancy Loss: 0.0967
Epoch [3/50], Class Loss: 0.4141, Discrepancy Loss: 0.0804
Epoch [4/50], Class Loss: 0.3849, Discrepancy Loss: 0.0620
Epoch [5/50], Class Loss: 0.4226, Discrepancy Loss: 0.0630
Epoch [6/50], Class Loss: 0.2892, Discrepancy Loss: 0.0545
Epoch [7/50], Class Loss: 0.2223, Discrepancy Loss: 0.0489
Epoch [8/50], Class Loss: 0.1617, Discrepancy Loss: 0.0464
Epoch [9/50], Class Loss: 0.1901, Discrepancy Loss: 0.0427
Epoch [10/50], Class Loss: 0.2307, Discrepancy Loss: 0.0495
Epoch [11/50], Class Loss: 0.2313, Discrepancy Loss: 0.0465
Epoch [12/50], Class Loss: 0.0792, Discrepancy Loss: 0.0424
Epoch [13/50], Class Loss: 0.0517, Discrepancy Loss: 0.0436
Epoch [14/50], Class Loss: 0.0458, Discrepancy Loss: 0.0417
Epoch [15/50], Class Loss: 0.0298, Discrepancy Loss: 0.0466
Epoch [16/50], Class Loss: 0.0360, Discrepancy Loss: 0.0452
Epoch [17/50], Class Loss: 0.0356, Discrepancy Loss: 0.0384
Epoch [18/50], Class Loss: 0.0193, Discrepancy Loss: 0.0438
Epoch [19/50], Class Loss: 0.0415, Discrepancy Loss: 0.0395
Epoch [20/50], Class Loss: 0.0423, Discrepancy Loss: 0.0457
Epoch [21/50], Class Loss: 0.0147, Discrepancy Loss: 0.0489
Epoch [22/50], Class Loss: 0.0134, Discrepancy Loss: 0.0480
Epoch [23/50], Class Loss: 0.0130, Discrepancy Loss: 0.0439
Epoch [24/50], Class Loss: 0.0118, Discrepancy Loss: 0.0531
Epoch [25/50], Class Loss: 0.0109, Discrepancy Loss: 0.0430
Epoch [26/50], Class Loss: 0.0108, Discrepancy Loss: 0.0480
Epoch [27/50], Class Loss: 0.0163, Discrepancy Loss: 0.0487
Epoch [28/50], Class Loss: 0.0152, Discrepancy Loss: 0.0462
Epoch [29/50], Class Loss: 0.0099, Discrepancy Loss: 0.0484
Epoch [30/50], Class Loss: 0.0158, Discrepancy Loss: 0.0487
Epoch [31/50], Class Loss: 0.0115, Discrepancy Loss: 0.0408
Epoch [32/50], Class Loss: 0.0128, Discrepancy Loss: 0.0464
Epoch [33/50], Class Loss: 0.0108, Discrepancy Loss: 0.0433
Epoch [34/50], Class Loss: 0.0112, Discrepancy Loss: 0.0467
Epoch [35/50], Class Loss: 0.0086, Discrepancy Loss: 0.0498
Epoch [36/50], Class Loss: 0.0110, Discrepancy Loss: 0.0439
Epoch [37/50], Class Loss: 0.0119, Discrepancy Loss: 0.0461
Epoch [38/50], Class Loss: 0.0107, Discrepancy Loss: 0.0469
Epoch [39/50], Class Loss: 0.0107, Discrepancy Loss: 0.0507
Epoch [40/50], Class Loss: 0.0088, Discrepancy Loss: 0.0443
Epoch [41/50], Class Loss: 0.0086, Discrepancy Loss: 0.0504
Epoch [42/50], Class Loss: 0.0085, Discrepancy Loss: 0.0493
Epoch [43/50], Class Loss: 0.0096, Discrepancy Loss: 0.0481
Epoch [44/50], Class Loss: 0.0095, Discrepancy Loss: 0.0476
Epoch [45/50], Class Loss: 0.0092, Discrepancy Loss: 0.0457
Epoch [46/50], Class Loss: 0.0071, Discrepancy Loss: 0.0475
Epoch [47/50], Class Loss: 0.0096, Discrepancy Loss: 0.0476
Epoch [48/50], Class Loss: 0.0082, Discrepancy Loss: 0.0493
Epoch [49/50], Class Loss: 0.0094, Discrepancy Loss: 0.0432
Epoch [50/50], Class Loss: 0.0086, Discrepancy Loss: 0.0447
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 90.67%, Precision: 93.66%, Recall: 90.74%, F1 Score: 90.29%

Run 3/10
Epoch [1/50], Class Loss: 3.5170, Discrepancy Loss: 0.1099
Epoch [2/50], Class Loss: 0.8037, Discrepancy Loss: 0.1042
Epoch [3/50], Class Loss: 0.5242, Discrepancy Loss: 0.0848
Epoch [4/50], Class Loss: 0.4647, Discrepancy Loss: 0.0748
Epoch [5/50], Class Loss: 0.4738, Discrepancy Loss: 0.0728
Epoch [6/50], Class Loss: 0.5454, Discrepancy Loss: 0.0753
Epoch [7/50], Class Loss: 0.3236, Discrepancy Loss: 0.0590
Epoch [8/50], Class Loss: 0.2850, Discrepancy Loss: 0.0547
Epoch [9/50], Class Loss: 0.1546, Discrepancy Loss: 0.0473
Epoch [10/50], Class Loss: 0.1301, Discrepancy Loss: 0.0462
Epoch [11/50], Class Loss: 0.0324, Discrepancy Loss: 0.0367
Epoch [12/50], Class Loss: 0.0290, Discrepancy Loss: 0.0400
Epoch [13/50], Class Loss: 0.0314, Discrepancy Loss: 0.0396
Epoch [14/50], Class Loss: 0.0236, Discrepancy Loss: 0.0420
Epoch [15/50], Class Loss: 0.0280, Discrepancy Loss: 0.0424
Epoch [16/50], Class Loss: 0.0241, Discrepancy Loss: 0.0396
Epoch [17/50], Class Loss: 0.0213, Discrepancy Loss: 0.0412
Epoch [18/50], Class Loss: 0.0240, Discrepancy Loss: 0.0357
Epoch [19/50], Class Loss: 0.0302, Discrepancy Loss: 0.0371
Epoch [20/50], Class Loss: 0.0130, Discrepancy Loss: 0.0412
Epoch [21/50], Class Loss: 0.0095, Discrepancy Loss: 0.0462
Epoch [22/50], Class Loss: 0.0099, Discrepancy Loss: 0.0395
Epoch [23/50], Class Loss: 0.0087, Discrepancy Loss: 0.0408
Epoch [24/50], Class Loss: 0.0095, Discrepancy Loss: 0.0408
Epoch [25/50], Class Loss: 0.0086, Discrepancy Loss: 0.0399
Epoch [26/50], Class Loss: 0.0090, Discrepancy Loss: 0.0412
Epoch [27/50], Class Loss: 0.0080, Discrepancy Loss: 0.0418
Epoch [28/50], Class Loss: 0.0094, Discrepancy Loss: 0.0451
Epoch [29/50], Class Loss: 0.0088, Discrepancy Loss: 0.0478
Epoch [30/50], Class Loss: 0.0088, Discrepancy Loss: 0.0458
Epoch [31/50], Class Loss: 0.0075, Discrepancy Loss: 0.0512
Epoch [32/50], Class Loss: 0.0060, Discrepancy Loss: 0.0487
Epoch [33/50], Class Loss: 0.0106, Discrepancy Loss: 0.0497
Epoch [34/50], Class Loss: 0.0066, Discrepancy Loss: 0.0494
Epoch [35/50], Class Loss: 0.0098, Discrepancy Loss: 0.0540
Epoch [36/50], Class Loss: 0.0084, Discrepancy Loss: 0.0486
Epoch [37/50], Class Loss: 0.0080, Discrepancy Loss: 0.0457
Epoch [38/50], Class Loss: 0.0105, Discrepancy Loss: 0.0493
Epoch [39/50], Class Loss: 0.0072, Discrepancy Loss: 0.0489
Epoch [40/50], Class Loss: 0.0090, Discrepancy Loss: 0.0486
Epoch [41/50], Class Loss: 0.0095, Discrepancy Loss: 0.0486
Epoch [42/50], Class Loss: 0.0106, Discrepancy Loss: 0.0515
Epoch [43/50], Class Loss: 0.0078, Discrepancy Loss: 0.0498
Epoch [44/50], Class Loss: 0.0076, Discrepancy Loss: 0.0479
Epoch [45/50], Class Loss: 0.0071, Discrepancy Loss: 0.0478
Epoch [46/50], Class Loss: 0.0091, Discrepancy Loss: 0.0492
Epoch [47/50], Class Loss: 0.0085, Discrepancy Loss: 0.0518
Epoch [48/50], Class Loss: 0.0099, Discrepancy Loss: 0.0526
Epoch [49/50], Class Loss: 0.0102, Discrepancy Loss: 0.0485
Epoch [50/50], Class Loss: 0.0101, Discrepancy Loss: 0.0458
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.86%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 97.07%, Precision: 97.44%, Recall: 97.09%, F1 Score: 97.11%

Run 4/10
Epoch [1/50], Class Loss: 3.4690, Discrepancy Loss: 0.1157
Epoch [2/50], Class Loss: 0.8923, Discrepancy Loss: 0.1067
Epoch [3/50], Class Loss: 0.6371, Discrepancy Loss: 0.1090
Epoch [4/50], Class Loss: 0.4466, Discrepancy Loss: 0.0780
Epoch [5/50], Class Loss: 0.4996, Discrepancy Loss: 0.0700
Epoch [6/50], Class Loss: 0.5761, Discrepancy Loss: 0.0740
Epoch [7/50], Class Loss: 0.4617, Discrepancy Loss: 0.0756
Epoch [8/50], Class Loss: 0.2507, Discrepancy Loss: 0.0550
Epoch [9/50], Class Loss: 0.4291, Discrepancy Loss: 0.0531
Epoch [10/50], Class Loss: 0.1666, Discrepancy Loss: 0.0417
Epoch [11/50], Class Loss: 0.1251, Discrepancy Loss: 0.0385
Epoch [12/50], Class Loss: 0.0247, Discrepancy Loss: 0.0289
Epoch [13/50], Class Loss: 0.0262, Discrepancy Loss: 0.0341
Epoch [14/50], Class Loss: 0.0220, Discrepancy Loss: 0.0334
Epoch [15/50], Class Loss: 0.0325, Discrepancy Loss: 0.0356
Epoch [16/50], Class Loss: 0.0181, Discrepancy Loss: 0.0340
Epoch [17/50], Class Loss: 0.0270, Discrepancy Loss: 0.0329
Epoch [18/50], Class Loss: 0.0305, Discrepancy Loss: 0.0373
Epoch [19/50], Class Loss: 0.0311, Discrepancy Loss: 0.0353
Epoch [20/50], Class Loss: 0.0101, Discrepancy Loss: 0.0395
Epoch [21/50], Class Loss: 0.0077, Discrepancy Loss: 0.0419
Epoch [22/50], Class Loss: 0.0059, Discrepancy Loss: 0.0381
Epoch [23/50], Class Loss: 0.0084, Discrepancy Loss: 0.0400
Epoch [24/50], Class Loss: 0.0061, Discrepancy Loss: 0.0398
Epoch [25/50], Class Loss: 0.0087, Discrepancy Loss: 0.0411
Epoch [26/50], Class Loss: 0.0064, Discrepancy Loss: 0.0371
Epoch [27/50], Class Loss: 0.0076, Discrepancy Loss: 0.0404
Epoch [28/50], Class Loss: 0.0089, Discrepancy Loss: 0.0416
Epoch [29/50], Class Loss: 0.0078, Discrepancy Loss: 0.0407
Epoch [30/50], Class Loss: 0.0086, Discrepancy Loss: 0.0439
Epoch [31/50], Class Loss: 0.0076, Discrepancy Loss: 0.0413
Epoch [32/50], Class Loss: 0.0096, Discrepancy Loss: 0.0484
Epoch [33/50], Class Loss: 0.0106, Discrepancy Loss: 0.0421
Epoch [34/50], Class Loss: 0.0082, Discrepancy Loss: 0.0452
Epoch [35/50], Class Loss: 0.0074, Discrepancy Loss: 0.0447
Epoch [36/50], Class Loss: 0.0072, Discrepancy Loss: 0.0458
Epoch [37/50], Class Loss: 0.0069, Discrepancy Loss: 0.0409
Epoch [38/50], Class Loss: 0.0055, Discrepancy Loss: 0.0393
Epoch [39/50], Class Loss: 0.0059, Discrepancy Loss: 0.0412
Epoch [40/50], Class Loss: 0.0071, Discrepancy Loss: 0.0406
Epoch [41/50], Class Loss: 0.0092, Discrepancy Loss: 0.0435
Epoch [42/50], Class Loss: 0.0106, Discrepancy Loss: 0.0484
Epoch [43/50], Class Loss: 0.0069, Discrepancy Loss: 0.0444
Epoch [44/50], Class Loss: 0.0075, Discrepancy Loss: 0.0488
Epoch [45/50], Class Loss: 0.0083, Discrepancy Loss: 0.0441
Epoch [46/50], Class Loss: 0.0070, Discrepancy Loss: 0.0453
Epoch [47/50], Class Loss: 0.0071, Discrepancy Loss: 0.0437
Epoch [48/50], Class Loss: 0.0082, Discrepancy Loss: 0.0461
Epoch [49/50], Class Loss: 0.0079, Discrepancy Loss: 0.0435
Epoch [50/50], Class Loss: 0.0072, Discrepancy Loss: 0.0481
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 96.83%, Precision: 97.29%, Recall: 96.85%, F1 Score: 96.86%

Run 5/10
Epoch [1/50], Class Loss: 3.4006, Discrepancy Loss: 0.1191
Epoch [2/50], Class Loss: 1.4260, Discrepancy Loss: 0.0990
Epoch [3/50], Class Loss: 0.7524, Discrepancy Loss: 0.0906
Epoch [4/50], Class Loss: 0.4258, Discrepancy Loss: 0.0721
Epoch [5/50], Class Loss: 0.3534, Discrepancy Loss: 0.0645
Epoch [6/50], Class Loss: 0.7715, Discrepancy Loss: 0.0807
Epoch [7/50], Class Loss: 0.4809, Discrepancy Loss: 0.0836
Epoch [8/50], Class Loss: 0.3118, Discrepancy Loss: 0.0576
Epoch [9/50], Class Loss: 0.3992, Discrepancy Loss: 0.0643
Epoch [10/50], Class Loss: 0.2148, Discrepancy Loss: 0.0480
Epoch [11/50], Class Loss: 0.0431, Discrepancy Loss: 0.0281
Epoch [12/50], Class Loss: 0.0342, Discrepancy Loss: 0.0301
Epoch [13/50], Class Loss: 0.0643, Discrepancy Loss: 0.0380
Epoch [14/50], Class Loss: 0.0331, Discrepancy Loss: 0.0362
Epoch [15/50], Class Loss: 0.0555, Discrepancy Loss: 0.0380
Epoch [16/50], Class Loss: 0.0247, Discrepancy Loss: 0.0395
Epoch [17/50], Class Loss: 0.0407, Discrepancy Loss: 0.0376
Epoch [18/50], Class Loss: 0.0396, Discrepancy Loss: 0.0341
Epoch [19/50], Class Loss: 0.0382, Discrepancy Loss: 0.0412
Epoch [20/50], Class Loss: 0.0178, Discrepancy Loss: 0.0366
Epoch [21/50], Class Loss: 0.0175, Discrepancy Loss: 0.0401
Epoch [22/50], Class Loss: 0.0118, Discrepancy Loss: 0.0400
Epoch [23/50], Class Loss: 0.0149, Discrepancy Loss: 0.0394
Epoch [24/50], Class Loss: 0.0132, Discrepancy Loss: 0.0352
Epoch [25/50], Class Loss: 0.0148, Discrepancy Loss: 0.0396
Epoch [26/50], Class Loss: 0.0100, Discrepancy Loss: 0.0417
Epoch [27/50], Class Loss: 0.0115, Discrepancy Loss: 0.0410
Epoch [28/50], Class Loss: 0.0131, Discrepancy Loss: 0.0445
Epoch [29/50], Class Loss: 0.0126, Discrepancy Loss: 0.0460
Epoch [30/50], Class Loss: 0.0099, Discrepancy Loss: 0.0419
Epoch [31/50], Class Loss: 0.0084, Discrepancy Loss: 0.0463
Epoch [32/50], Class Loss: 0.0128, Discrepancy Loss: 0.0448
Epoch [33/50], Class Loss: 0.0090, Discrepancy Loss: 0.0413
Epoch [34/50], Class Loss: 0.0094, Discrepancy Loss: 0.0459
Epoch [35/50], Class Loss: 0.0073, Discrepancy Loss: 0.0440
Epoch [36/50], Class Loss: 0.0106, Discrepancy Loss: 0.0432
Epoch [37/50], Class Loss: 0.0087, Discrepancy Loss: 0.0512
Epoch [38/50], Class Loss: 0.0076, Discrepancy Loss: 0.0495
Epoch [39/50], Class Loss: 0.0106, Discrepancy Loss: 0.0505
Epoch [40/50], Class Loss: 0.0101, Discrepancy Loss: 0.0481
Epoch [41/50], Class Loss: 0.0075, Discrepancy Loss: 0.0498
Epoch [42/50], Class Loss: 0.0101, Discrepancy Loss: 0.0444
Epoch [43/50], Class Loss: 0.0096, Discrepancy Loss: 0.0491
Epoch [44/50], Class Loss: 0.0079, Discrepancy Loss: 0.0478
Epoch [45/50], Class Loss: 0.0082, Discrepancy Loss: 0.0465
Epoch [46/50], Class Loss: 0.0093, Discrepancy Loss: 0.0471
Epoch [47/50], Class Loss: 0.0090, Discrepancy Loss: 0.0503
Epoch [48/50], Class Loss: 0.0091, Discrepancy Loss: 0.0462
Epoch [49/50], Class Loss: 0.0072, Discrepancy Loss: 0.0462
Epoch [50/50], Class Loss: 0.0087, Discrepancy Loss: 0.0475
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.91%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 93.99%, Precision: 95.44%, Recall: 94.04%, F1 Score: 93.95%

Run 6/10
Epoch [1/50], Class Loss: 2.9866, Discrepancy Loss: 0.1212
Epoch [2/50], Class Loss: 1.0177, Discrepancy Loss: 0.1117
Epoch [3/50], Class Loss: 0.5173, Discrepancy Loss: 0.0941
Epoch [4/50], Class Loss: 0.7819, Discrepancy Loss: 0.0897
Epoch [5/50], Class Loss: 0.4998, Discrepancy Loss: 0.0873
Epoch [6/50], Class Loss: 0.3881, Discrepancy Loss: 0.0695
Epoch [7/50], Class Loss: 0.2827, Discrepancy Loss: 0.0532
Epoch [8/50], Class Loss: 0.2055, Discrepancy Loss: 0.0418
Epoch [9/50], Class Loss: 0.1177, Discrepancy Loss: 0.0371
Epoch [10/50], Class Loss: 0.1106, Discrepancy Loss: 0.0371
Epoch [11/50], Class Loss: 0.0367, Discrepancy Loss: 0.0270
Epoch [12/50], Class Loss: 0.0170, Discrepancy Loss: 0.0298
Epoch [13/50], Class Loss: 0.0127, Discrepancy Loss: 0.0335
Epoch [14/50], Class Loss: 0.0122, Discrepancy Loss: 0.0399
Epoch [15/50], Class Loss: 0.0188, Discrepancy Loss: 0.0354
Epoch [16/50], Class Loss: 0.0205, Discrepancy Loss: 0.0392
Epoch [17/50], Class Loss: 0.0164, Discrepancy Loss: 0.0403
Epoch [18/50], Class Loss: 0.0136, Discrepancy Loss: 0.0401
Epoch [19/50], Class Loss: 0.0147, Discrepancy Loss: 0.0410
Epoch [20/50], Class Loss: 0.0102, Discrepancy Loss: 0.0419
Epoch [21/50], Class Loss: 0.0067, Discrepancy Loss: 0.0424
Epoch [22/50], Class Loss: 0.0062, Discrepancy Loss: 0.0397
Epoch [23/50], Class Loss: 0.0095, Discrepancy Loss: 0.0460
Epoch [24/50], Class Loss: 0.0067, Discrepancy Loss: 0.0461
Epoch [25/50], Class Loss: 0.0077, Discrepancy Loss: 0.0474
Epoch [26/50], Class Loss: 0.0083, Discrepancy Loss: 0.0449
Epoch [27/50], Class Loss: 0.0052, Discrepancy Loss: 0.0461
Epoch [28/50], Class Loss: 0.0081, Discrepancy Loss: 0.0504
Epoch [29/50], Class Loss: 0.0084, Discrepancy Loss: 0.0476
Epoch [30/50], Class Loss: 0.0075, Discrepancy Loss: 0.0534
Epoch [31/50], Class Loss: 0.0081, Discrepancy Loss: 0.0476
Epoch [32/50], Class Loss: 0.0061, Discrepancy Loss: 0.0513
Epoch [33/50], Class Loss: 0.0086, Discrepancy Loss: 0.0571
Epoch [34/50], Class Loss: 0.0069, Discrepancy Loss: 0.0481
Epoch [35/50], Class Loss: 0.0057, Discrepancy Loss: 0.0505
Epoch [36/50], Class Loss: 0.0088, Discrepancy Loss: 0.0544
Epoch [37/50], Class Loss: 0.0064, Discrepancy Loss: 0.0503
Epoch [38/50], Class Loss: 0.0085, Discrepancy Loss: 0.0467
Epoch [39/50], Class Loss: 0.0070, Discrepancy Loss: 0.0519
Epoch [40/50], Class Loss: 0.0081, Discrepancy Loss: 0.0512
Epoch [41/50], Class Loss: 0.0071, Discrepancy Loss: 0.0511
Epoch [42/50], Class Loss: 0.0075, Discrepancy Loss: 0.0542
Epoch [43/50], Class Loss: 0.0077, Discrepancy Loss: 0.0553
Epoch [44/50], Class Loss: 0.0064, Discrepancy Loss: 0.0525
Epoch [45/50], Class Loss: 0.0064, Discrepancy Loss: 0.0506
Epoch [46/50], Class Loss: 0.0055, Discrepancy Loss: 0.0521
Epoch [47/50], Class Loss: 0.0063, Discrepancy Loss: 0.0493
Epoch [48/50], Class Loss: 0.0075, Discrepancy Loss: 0.0488
Epoch [49/50], Class Loss: 0.0075, Discrepancy Loss: 0.0522
Epoch [50/50], Class Loss: 0.0064, Discrepancy Loss: 0.0513
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 98.51%, Precision: 98.61%, Recall: 98.52%, F1 Score: 98.53%

Run 7/10
Epoch [1/50], Class Loss: 4.1086, Discrepancy Loss: 0.1128
Epoch [2/50], Class Loss: 0.6238, Discrepancy Loss: 0.0939
Epoch [3/50], Class Loss: 0.6745, Discrepancy Loss: 0.0807
Epoch [4/50], Class Loss: 0.4923, Discrepancy Loss: 0.0773
Epoch [5/50], Class Loss: 0.4264, Discrepancy Loss: 0.0646
Epoch [6/50], Class Loss: 0.4257, Discrepancy Loss: 0.0658
Epoch [7/50], Class Loss: 0.2381, Discrepancy Loss: 0.0509
Epoch [8/50], Class Loss: 0.2432, Discrepancy Loss: 0.0442
Epoch [9/50], Class Loss: 0.1988, Discrepancy Loss: 0.0425
Epoch [10/50], Class Loss: 0.1155, Discrepancy Loss: 0.0359
Epoch [11/50], Class Loss: 0.0288, Discrepancy Loss: 0.0337
Epoch [12/50], Class Loss: 0.0283, Discrepancy Loss: 0.0335
Epoch [13/50], Class Loss: 0.0201, Discrepancy Loss: 0.0305
Epoch [14/50], Class Loss: 0.0156, Discrepancy Loss: 0.0313
Epoch [15/50], Class Loss: 0.0156, Discrepancy Loss: 0.0353
Epoch [16/50], Class Loss: 0.0366, Discrepancy Loss: 0.0337
Epoch [17/50], Class Loss: 0.0216, Discrepancy Loss: 0.0337
Epoch [18/50], Class Loss: 0.0175, Discrepancy Loss: 0.0383
Epoch [19/50], Class Loss: 0.0335, Discrepancy Loss: 0.0363
Epoch [20/50], Class Loss: 0.0184, Discrepancy Loss: 0.0382
Epoch [21/50], Class Loss: 0.0109, Discrepancy Loss: 0.0345
Epoch [22/50], Class Loss: 0.0112, Discrepancy Loss: 0.0355
Epoch [23/50], Class Loss: 0.0119, Discrepancy Loss: 0.0343
Epoch [24/50], Class Loss: 0.0124, Discrepancy Loss: 0.0402
Epoch [25/50], Class Loss: 0.0140, Discrepancy Loss: 0.0373
Epoch [26/50], Class Loss: 0.0104, Discrepancy Loss: 0.0405
Epoch [27/50], Class Loss: 0.0102, Discrepancy Loss: 0.0373
Epoch [28/50], Class Loss: 0.0127, Discrepancy Loss: 0.0392
Epoch [29/50], Class Loss: 0.0123, Discrepancy Loss: 0.0400
Epoch [30/50], Class Loss: 0.0090, Discrepancy Loss: 0.0447
Epoch [31/50], Class Loss: 0.0091, Discrepancy Loss: 0.0406
Epoch [32/50], Class Loss: 0.0077, Discrepancy Loss: 0.0442
Epoch [33/50], Class Loss: 0.0084, Discrepancy Loss: 0.0458
Epoch [34/50], Class Loss: 0.0086, Discrepancy Loss: 0.0399
Epoch [35/50], Class Loss: 0.0086, Discrepancy Loss: 0.0431
Epoch [36/50], Class Loss: 0.0102, Discrepancy Loss: 0.0456
Epoch [37/50], Class Loss: 0.0094, Discrepancy Loss: 0.0481
Epoch [38/50], Class Loss: 0.0082, Discrepancy Loss: 0.0414
Epoch [39/50], Class Loss: 0.0093, Discrepancy Loss: 0.0462
Epoch [40/50], Class Loss: 0.0080, Discrepancy Loss: 0.0460
Epoch [41/50], Class Loss: 0.0077, Discrepancy Loss: 0.0428
Epoch [42/50], Class Loss: 0.0100, Discrepancy Loss: 0.0465
Epoch [43/50], Class Loss: 0.0074, Discrepancy Loss: 0.0442
Epoch [44/50], Class Loss: 0.0078, Discrepancy Loss: 0.0480
Epoch [45/50], Class Loss: 0.0097, Discrepancy Loss: 0.0457
Epoch [46/50], Class Loss: 0.0082, Discrepancy Loss: 0.0465
Epoch [47/50], Class Loss: 0.0078, Discrepancy Loss: 0.0450
Epoch [48/50], Class Loss: 0.0084, Discrepancy Loss: 0.0466
Epoch [49/50], Class Loss: 0.0066, Discrepancy Loss: 0.0493
Epoch [50/50], Class Loss: 0.0103, Discrepancy Loss: 0.0467
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.86%, F1 Score: 99.86%
Target Domain Performance - Accuracy: 96.36%, Precision: 96.95%, Recall: 96.39%, F1 Score: 96.39%

Run 8/10
Epoch [1/50], Class Loss: 3.5444, Discrepancy Loss: 0.1146
Epoch [2/50], Class Loss: 0.8348, Discrepancy Loss: 0.1070
Epoch [3/50], Class Loss: 0.4993, Discrepancy Loss: 0.0751
Epoch [4/50], Class Loss: 0.5207, Discrepancy Loss: 0.0759
Epoch [5/50], Class Loss: 0.4561, Discrepancy Loss: 0.0690
Epoch [6/50], Class Loss: 0.2863, Discrepancy Loss: 0.0524
Epoch [7/50], Class Loss: 0.4884, Discrepancy Loss: 0.0670
Epoch [8/50], Class Loss: 0.3116, Discrepancy Loss: 0.0561
Epoch [9/50], Class Loss: 0.2267, Discrepancy Loss: 0.0389
Epoch [10/50], Class Loss: 0.1767, Discrepancy Loss: 0.0377
Epoch [11/50], Class Loss: 0.0483, Discrepancy Loss: 0.0346
Epoch [12/50], Class Loss: 0.0353, Discrepancy Loss: 0.0353
Epoch [13/50], Class Loss: 0.0214, Discrepancy Loss: 0.0319
Epoch [14/50], Class Loss: 0.0249, Discrepancy Loss: 0.0360
Epoch [15/50], Class Loss: 0.0206, Discrepancy Loss: 0.0347
Epoch [16/50], Class Loss: 0.0162, Discrepancy Loss: 0.0357
Epoch [17/50], Class Loss: 0.0503, Discrepancy Loss: 0.0336
Epoch [18/50], Class Loss: 0.0275, Discrepancy Loss: 0.0356
Epoch [19/50], Class Loss: 0.0189, Discrepancy Loss: 0.0368
Epoch [20/50], Class Loss: 0.0196, Discrepancy Loss: 0.0381
Epoch [21/50], Class Loss: 0.0123, Discrepancy Loss: 0.0368
Epoch [22/50], Class Loss: 0.0125, Discrepancy Loss: 0.0426
Epoch [23/50], Class Loss: 0.0083, Discrepancy Loss: 0.0394
Epoch [24/50], Class Loss: 0.0090, Discrepancy Loss: 0.0417
Epoch [25/50], Class Loss: 0.0087, Discrepancy Loss: 0.0387
Epoch [26/50], Class Loss: 0.0106, Discrepancy Loss: 0.0375
Epoch [27/50], Class Loss: 0.0091, Discrepancy Loss: 0.0391
Epoch [28/50], Class Loss: 0.0123, Discrepancy Loss: 0.0442
Epoch [29/50], Class Loss: 0.0133, Discrepancy Loss: 0.0438
Epoch [30/50], Class Loss: 0.0115, Discrepancy Loss: 0.0420
Epoch [31/50], Class Loss: 0.0112, Discrepancy Loss: 0.0479
Epoch [32/50], Class Loss: 0.0100, Discrepancy Loss: 0.0462
Epoch [33/50], Class Loss: 0.0098, Discrepancy Loss: 0.0454
Epoch [34/50], Class Loss: 0.0148, Discrepancy Loss: 0.0461
Epoch [35/50], Class Loss: 0.0085, Discrepancy Loss: 0.0434
Epoch [36/50], Class Loss: 0.0106, Discrepancy Loss: 0.0402
Epoch [37/50], Class Loss: 0.0106, Discrepancy Loss: 0.0458
Epoch [38/50], Class Loss: 0.0080, Discrepancy Loss: 0.0443
Epoch [39/50], Class Loss: 0.0108, Discrepancy Loss: 0.0461
Epoch [40/50], Class Loss: 0.0081, Discrepancy Loss: 0.0412
Epoch [41/50], Class Loss: 0.0124, Discrepancy Loss: 0.0437
Epoch [42/50], Class Loss: 0.0096, Discrepancy Loss: 0.0462
Epoch [43/50], Class Loss: 0.0083, Discrepancy Loss: 0.0504
Epoch [44/50], Class Loss: 0.0096, Discrepancy Loss: 0.0413
Epoch [45/50], Class Loss: 0.0134, Discrepancy Loss: 0.0410
Epoch [46/50], Class Loss: 0.0077, Discrepancy Loss: 0.0434
Epoch [47/50], Class Loss: 0.0070, Discrepancy Loss: 0.0426
Epoch [48/50], Class Loss: 0.0098, Discrepancy Loss: 0.0442
Epoch [49/50], Class Loss: 0.0098, Discrepancy Loss: 0.0423
Epoch [50/50], Class Loss: 0.0085, Discrepancy Loss: 0.0435
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 94.70%, Precision: 95.85%, Recall: 94.74%, F1 Score: 94.69%

Run 9/10
Epoch [1/50], Class Loss: 4.0723, Discrepancy Loss: 0.1128
Epoch [2/50], Class Loss: 1.2698, Discrepancy Loss: 0.0968
Epoch [3/50], Class Loss: 0.5646, Discrepancy Loss: 0.0906
Epoch [4/50], Class Loss: 0.4130, Discrepancy Loss: 0.0850
Epoch [5/50], Class Loss: 0.4707, Discrepancy Loss: 0.0719
Epoch [6/50], Class Loss: 0.3668, Discrepancy Loss: 0.0727
Epoch [7/50], Class Loss: 0.2297, Discrepancy Loss: 0.0455
Epoch [8/50], Class Loss: 0.1599, Discrepancy Loss: 0.0420
Epoch [9/50], Class Loss: 0.1432, Discrepancy Loss: 0.0415
Epoch [10/50], Class Loss: 0.1863, Discrepancy Loss: 0.0439
Epoch [11/50], Class Loss: 0.1423, Discrepancy Loss: 0.0429
Epoch [12/50], Class Loss: 0.0686, Discrepancy Loss: 0.0364
Epoch [13/50], Class Loss: 0.0484, Discrepancy Loss: 0.0325
Epoch [14/50], Class Loss: 0.0271, Discrepancy Loss: 0.0342
Epoch [15/50], Class Loss: 0.0297, Discrepancy Loss: 0.0372
Epoch [16/50], Class Loss: 0.0214, Discrepancy Loss: 0.0382
Epoch [17/50], Class Loss: 0.0284, Discrepancy Loss: 0.0407
Epoch [18/50], Class Loss: 0.0260, Discrepancy Loss: 0.0371
Epoch [19/50], Class Loss: 0.0216, Discrepancy Loss: 0.0382
Epoch [20/50], Class Loss: 0.0254, Discrepancy Loss: 0.0407
Epoch [21/50], Class Loss: 0.0133, Discrepancy Loss: 0.0455
Epoch [22/50], Class Loss: 0.0100, Discrepancy Loss: 0.0443
Epoch [23/50], Class Loss: 0.0099, Discrepancy Loss: 0.0442
Epoch [24/50], Class Loss: 0.0114, Discrepancy Loss: 0.0462
Epoch [25/50], Class Loss: 0.0082, Discrepancy Loss: 0.0454
Epoch [26/50], Class Loss: 0.0086, Discrepancy Loss: 0.0422
Epoch [27/50], Class Loss: 0.0136, Discrepancy Loss: 0.0461
Epoch [28/50], Class Loss: 0.0123, Discrepancy Loss: 0.0490
Epoch [29/50], Class Loss: 0.0096, Discrepancy Loss: 0.0453
Epoch [30/50], Class Loss: 0.0116, Discrepancy Loss: 0.0442
Epoch [31/50], Class Loss: 0.0097, Discrepancy Loss: 0.0455
Epoch [32/50], Class Loss: 0.0066, Discrepancy Loss: 0.0446
Epoch [33/50], Class Loss: 0.0065, Discrepancy Loss: 0.0477
Epoch [34/50], Class Loss: 0.0087, Discrepancy Loss: 0.0503
Epoch [35/50], Class Loss: 0.0076, Discrepancy Loss: 0.0487
Epoch [36/50], Class Loss: 0.0062, Discrepancy Loss: 0.0471
Epoch [37/50], Class Loss: 0.0092, Discrepancy Loss: 0.0467
Epoch [38/50], Class Loss: 0.0070, Discrepancy Loss: 0.0470
Epoch [39/50], Class Loss: 0.0070, Discrepancy Loss: 0.0502
Epoch [40/50], Class Loss: 0.0113, Discrepancy Loss: 0.0482
Epoch [41/50], Class Loss: 0.0111, Discrepancy Loss: 0.0451
Epoch [42/50], Class Loss: 0.0060, Discrepancy Loss: 0.0468
Epoch [43/50], Class Loss: 0.0083, Discrepancy Loss: 0.0476
Epoch [44/50], Class Loss: 0.0067, Discrepancy Loss: 0.0486
Epoch [45/50], Class Loss: 0.0079, Discrepancy Loss: 0.0471
Epoch [46/50], Class Loss: 0.0093, Discrepancy Loss: 0.0473
Epoch [47/50], Class Loss: 0.0071, Discrepancy Loss: 0.0485
Epoch [48/50], Class Loss: 0.0074, Discrepancy Loss: 0.0493
Epoch [49/50], Class Loss: 0.0075, Discrepancy Loss: 0.0461
Epoch [50/50], Class Loss: 0.0080, Discrepancy Loss: 0.0438
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 98.10%, Precision: 98.25%, Recall: 98.11%, F1 Score: 98.12%

Run 10/10
Epoch [1/50], Class Loss: 4.5353, Discrepancy Loss: 0.1113
Epoch [2/50], Class Loss: 0.9983, Discrepancy Loss: 0.0992
Epoch [3/50], Class Loss: 0.5340, Discrepancy Loss: 0.0790
Epoch [4/50], Class Loss: 0.4883, Discrepancy Loss: 0.0717
Epoch [5/50], Class Loss: 0.3041, Discrepancy Loss: 0.0599
Epoch [6/50], Class Loss: 0.2097, Discrepancy Loss: 0.0455
Epoch [7/50], Class Loss: 0.4286, Discrepancy Loss: 0.0635
Epoch [8/50], Class Loss: 0.2743, Discrepancy Loss: 0.0500
Epoch [9/50], Class Loss: 1.1908, Discrepancy Loss: 0.0525
Epoch [10/50], Class Loss: 0.4135, Discrepancy Loss: 0.0546
Epoch [11/50], Class Loss: 0.2226, Discrepancy Loss: 0.0381
Epoch [12/50], Class Loss: 0.1367, Discrepancy Loss: 0.0356
Epoch [13/50], Class Loss: 0.1209, Discrepancy Loss: 0.0318
Epoch [14/50], Class Loss: 0.0583, Discrepancy Loss: 0.0280
Epoch [15/50], Class Loss: 0.0436, Discrepancy Loss: 0.0313
Epoch [16/50], Class Loss: 0.0478, Discrepancy Loss: 0.0307
Epoch [17/50], Class Loss: 0.0775, Discrepancy Loss: 0.0340
Epoch [18/50], Class Loss: 0.0351, Discrepancy Loss: 0.0294
Epoch [19/50], Class Loss: 0.0569, Discrepancy Loss: 0.0344
Epoch [20/50], Class Loss: 0.0491, Discrepancy Loss: 0.0293
Epoch [21/50], Class Loss: 0.0121, Discrepancy Loss: 0.0300
Epoch [22/50], Class Loss: 0.0146, Discrepancy Loss: 0.0296
Epoch [23/50], Class Loss: 0.0113, Discrepancy Loss: 0.0340
Epoch [24/50], Class Loss: 0.0144, Discrepancy Loss: 0.0333
Epoch [25/50], Class Loss: 0.0129, Discrepancy Loss: 0.0315
Epoch [26/50], Class Loss: 0.0116, Discrepancy Loss: 0.0345
Epoch [27/50], Class Loss: 0.0145, Discrepancy Loss: 0.0357
Epoch [28/50], Class Loss: 0.0112, Discrepancy Loss: 0.0320
Epoch [29/50], Class Loss: 0.0089, Discrepancy Loss: 0.0335
Epoch [30/50], Class Loss: 0.0123, Discrepancy Loss: 0.0369
Epoch [31/50], Class Loss: 0.0138, Discrepancy Loss: 0.0373
Epoch [32/50], Class Loss: 0.0094, Discrepancy Loss: 0.0341
Epoch [33/50], Class Loss: 0.0096, Discrepancy Loss: 0.0390
Epoch [34/50], Class Loss: 0.0099, Discrepancy Loss: 0.0347
Epoch [35/50], Class Loss: 0.0099, Discrepancy Loss: 0.0370
Epoch [36/50], Class Loss: 0.0108, Discrepancy Loss: 0.0336
Epoch [37/50], Class Loss: 0.0101, Discrepancy Loss: 0.0368
Epoch [38/50], Class Loss: 0.0100, Discrepancy Loss: 0.0358
Epoch [39/50], Class Loss: 0.0105, Discrepancy Loss: 0.0333
Epoch [40/50], Class Loss: 0.0108, Discrepancy Loss: 0.0352
Epoch [41/50], Class Loss: 0.0138, Discrepancy Loss: 0.0367
Epoch [42/50], Class Loss: 0.0112, Discrepancy Loss: 0.0367
Epoch [43/50], Class Loss: 0.0114, Discrepancy Loss: 0.0335
Epoch [44/50], Class Loss: 0.0106, Discrepancy Loss: 0.0374
Epoch [45/50], Class Loss: 0.0116, Discrepancy Loss: 0.0345
Epoch [46/50], Class Loss: 0.0102, Discrepancy Loss: 0.0352
Epoch [47/50], Class Loss: 0.0094, Discrepancy Loss: 0.0387
Epoch [48/50], Class Loss: 0.0095, Discrepancy Loss: 0.0364
Epoch [49/50], Class Loss: 0.0085, Discrepancy Loss: 0.0328
Epoch [50/50], Class Loss: 0.0113, Discrepancy Loss: 0.0372
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 97.44%, Precision: 97.73%, Recall: 97.46%, F1 Score: 97.47%

Source performance: 99.90% 99.90% 99.90% 99.90%
Target performance: 96.13% 96.91% 96.16% 96.11%

Per-Class Accuracy on Target Domain:
bpsk: 100.00%
qpsk: 99.61%
4qam: 81.35%
16qam: 99.85%
apsk: 100.00%

Run 1/10
Epoch [1/50], Class Loss: 2.8123, Discrepancy Loss: 0.0322
Validation Loss: 3.0551
Epoch [2/50], Class Loss: 1.4826, Discrepancy Loss: 0.0434
Validation Loss: 1.2096
Epoch [3/50], Class Loss: 1.1709, Discrepancy Loss: 0.0208
Validation Loss: 0.3985
Epoch [4/50], Class Loss: 0.4006, Discrepancy Loss: 0.0039
Validation Loss: 0.2360
Epoch [5/50], Class Loss: 1.7502, Discrepancy Loss: 0.0274
Validation Loss: 1.4310
Epoch [6/50], Class Loss: 1.8286, Discrepancy Loss: 0.0334
Validation Loss: 4.1397
Epoch [7/50], Class Loss: 0.6312, Discrepancy Loss: 0.0120
Validation Loss: 0.0980
Epoch [8/50], Class Loss: 1.4577, Discrepancy Loss: 0.0187
Validation Loss: 0.7166
Epoch [9/50], Class Loss: 1.0823, Discrepancy Loss: 0.0156
Validation Loss: 0.2350
Epoch [10/50], Class Loss: 0.4066, Discrepancy Loss: 0.0033
Validation Loss: 0.3129
Epoch [11/50], Class Loss: 0.0213, Discrepancy Loss: 0.0014
Validation Loss: 0.1857
Epoch [12/50], Class Loss: 0.0165, Discrepancy Loss: 0.0017
Validation Loss: 0.0119
Epoch [13/50], Class Loss: 0.0175, Discrepancy Loss: 0.0015
Validation Loss: 0.0184
Epoch [14/50], Class Loss: 0.0429, Discrepancy Loss: 0.0020
Validation Loss: 0.0073
Epoch [15/50], Class Loss: 0.0341, Discrepancy Loss: 0.0017
Validation Loss: 0.0106
Epoch [16/50], Class Loss: 0.2174, Discrepancy Loss: 0.0046
Validation Loss: 0.0104
Epoch [17/50], Class Loss: 0.0816, Discrepancy Loss: 0.0048
Validation Loss: 0.0129
Epoch [18/50], Class Loss: 0.1006, Discrepancy Loss: 0.0056
Validation Loss: 0.0550
Epoch [19/50], Class Loss: 0.4311, Discrepancy Loss: 0.0162
Validation Loss: 0.1467
Early stopping!
Source Domain Performance - Accuracy: 98.44%, Precision: 98.50%, Recall: 98.51%, F1 Score: 98.45%
Target Domain Performance - Accuracy: 84.20%, Precision: 91.23%, Recall: 84.32%, F1 Score: 81.56%

Run 2/10
Epoch [1/50], Class Loss: 2.6004, Discrepancy Loss: 0.0363
Validation Loss: 2.6878
Epoch [2/50], Class Loss: 3.2221, Discrepancy Loss: 0.0580
Validation Loss: 12.6528
Epoch [3/50], Class Loss: 1.9657, Discrepancy Loss: 0.0333
Validation Loss: 0.8233
Epoch [4/50], Class Loss: 0.4458, Discrepancy Loss: 0.0076
Validation Loss: 0.2852
Epoch [5/50], Class Loss: 2.2333, Discrepancy Loss: 0.0299
Validation Loss: 0.3115
Epoch [6/50], Class Loss: 0.3879, Discrepancy Loss: 0.0202
Validation Loss: 0.4214
Epoch [7/50], Class Loss: 1.6257, Discrepancy Loss: 0.0427
Validation Loss: 0.3220
Epoch [8/50], Class Loss: 1.3841, Discrepancy Loss: 0.0349
Validation Loss: 1.0610
Epoch [9/50], Class Loss: 2.2543, Discrepancy Loss: 0.0409
Validation Loss: 0.5055
Early stopping!
Source Domain Performance - Accuracy: 84.81%, Precision: 91.09%, Recall: 85.52%, F1 Score: 83.04%
Target Domain Performance - Accuracy: 95.14%, Precision: 96.02%, Recall: 95.18%, F1 Score: 95.15%

Run 3/10
Epoch [1/50], Class Loss: 3.6332, Discrepancy Loss: 0.0425
Validation Loss: 1.9985
Epoch [2/50], Class Loss: 2.0572, Discrepancy Loss: 0.0409
Validation Loss: 3.1981
Epoch [3/50], Class Loss: 1.8922, Discrepancy Loss: 0.0435
Validation Loss: 2.1382
Epoch [4/50], Class Loss: 2.0298, Discrepancy Loss: 0.0490
Validation Loss: 0.5917
Epoch [5/50], Class Loss: 2.0957, Discrepancy Loss: 0.0489
Validation Loss: 0.5548
Epoch [6/50], Class Loss: 1.0706, Discrepancy Loss: 0.0353
Validation Loss: 6.3017
Epoch [7/50], Class Loss: 1.3478, Discrepancy Loss: 0.0318
Validation Loss: 5.9434
Epoch [8/50], Class Loss: 1.2483, Discrepancy Loss: 0.0299
Validation Loss: 4.2672
Epoch [9/50], Class Loss: 1.2646, Discrepancy Loss: 0.0210
Validation Loss: 3.9962
Epoch [10/50], Class Loss: 0.7350, Discrepancy Loss: 0.0096
Validation Loss: 1.0700
Early stopping!
Source Domain Performance - Accuracy: 80.30%, Precision: 70.06%, Recall: 79.74%, F1 Score: 73.42%
Target Domain Performance - Accuracy: 59.91%, Precision: 50.05%, Recall: 59.95%, F1 Score: 53.37%

Run 4/10
Epoch [1/50], Class Loss: 4.0613, Discrepancy Loss: 0.0428
Validation Loss: 2.2270
Epoch [2/50], Class Loss: 2.3814, Discrepancy Loss: 0.0362
Validation Loss: 0.5024
Epoch [3/50], Class Loss: 1.6254, Discrepancy Loss: 0.0236
Validation Loss: 0.8750
Epoch [4/50], Class Loss: 1.5815, Discrepancy Loss: 0.0423
Validation Loss: 0.9862
Epoch [5/50], Class Loss: 1.4109, Discrepancy Loss: 0.0262
Validation Loss: 0.9658
Epoch [6/50], Class Loss: 1.6357, Discrepancy Loss: 0.0262
Validation Loss: 0.2911
Epoch [7/50], Class Loss: 0.6651, Discrepancy Loss: 0.0116
Validation Loss: 2.0916
Epoch [8/50], Class Loss: 0.5272, Discrepancy Loss: 0.0128
Validation Loss: 0.2764
Epoch [9/50], Class Loss: 0.3822, Discrepancy Loss: 0.0045
Validation Loss: 0.2362
Epoch [10/50], Class Loss: 0.3557, Discrepancy Loss: 0.0050
Validation Loss: 0.4808
Epoch [11/50], Class Loss: 0.0644, Discrepancy Loss: 0.0051
Validation Loss: 0.0374
Epoch [12/50], Class Loss: 0.0711, Discrepancy Loss: 0.0054
Validation Loss: 0.0433
Epoch [13/50], Class Loss: 0.1498, Discrepancy Loss: 0.0181
Validation Loss: 0.1006
Epoch [14/50], Class Loss: 0.0720, Discrepancy Loss: 0.0138
Validation Loss: 0.0605
Epoch [15/50], Class Loss: 0.1052, Discrepancy Loss: 0.0134
Validation Loss: 0.0828
Epoch [16/50], Class Loss: 0.0465, Discrepancy Loss: 0.0119
Validation Loss: 0.1094
Early stopping!
Source Domain Performance - Accuracy: 99.32%, Precision: 99.31%, Recall: 99.32%, F1 Score: 99.31%
Target Domain Performance - Accuracy: 83.42%, Precision: 88.88%, Recall: 83.51%, F1 Score: 82.11%

Run 5/10
Epoch [1/50], Class Loss: 3.2299, Discrepancy Loss: 0.0119
Validation Loss: 3.2188
Epoch [2/50], Class Loss: 3.2196, Discrepancy Loss: 0.0006
Validation Loss: 3.2187
Epoch [3/50], Class Loss: 3.2191, Discrepancy Loss: 0.0000
Validation Loss: 3.2190
Epoch [4/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2192
Epoch [5/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2193
Epoch [6/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2193
Epoch [7/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Early stopping!
Source Domain Performance - Accuracy: 19.17%, Precision: 3.83%, Recall: 20.00%, F1 Score: 6.43%
Target Domain Performance - Accuracy: 19.43%, Precision: 3.89%, Recall: 20.00%, F1 Score: 6.51%

Run 6/10
Epoch [1/50], Class Loss: 2.3812, Discrepancy Loss: 0.0221
Validation Loss: 1.1974
Epoch [2/50], Class Loss: 1.4252, Discrepancy Loss: 0.0173
Validation Loss: 1.6749
Epoch [3/50], Class Loss: 1.1411, Discrepancy Loss: 0.0142
Validation Loss: 0.6297
Epoch [4/50], Class Loss: 2.2733, Discrepancy Loss: 0.0375
Validation Loss: 0.6197
Epoch [5/50], Class Loss: 0.3629, Discrepancy Loss: 0.0100
Validation Loss: 0.5118
Epoch [6/50], Class Loss: 0.9211, Discrepancy Loss: 0.0152
Validation Loss: 0.2686
Epoch [7/50], Class Loss: 0.4242, Discrepancy Loss: 0.0176
Validation Loss: 0.5099
Epoch [8/50], Class Loss: 0.3306, Discrepancy Loss: 0.0080
Validation Loss: 0.2956
Epoch [9/50], Class Loss: 0.3239, Discrepancy Loss: 0.0124
Validation Loss: 0.1656
Epoch [10/50], Class Loss: 0.6507, Discrepancy Loss: 0.0229
Validation Loss: 0.1239
Epoch [11/50], Class Loss: 0.0241, Discrepancy Loss: 0.0020
Validation Loss: 0.0263
Epoch [12/50], Class Loss: 0.0316, Discrepancy Loss: 0.0031
Validation Loss: 0.0310
Epoch [13/50], Class Loss: 0.2661, Discrepancy Loss: 0.0098
Validation Loss: 0.0533
Epoch [14/50], Class Loss: 0.3928, Discrepancy Loss: 0.0165
Validation Loss: 0.0728
Epoch [15/50], Class Loss: 0.3161, Discrepancy Loss: 0.0127
Validation Loss: 0.1585
Epoch [16/50], Class Loss: 0.1571, Discrepancy Loss: 0.0098
Validation Loss: 0.0305
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.84%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 94.73%, Precision: 95.37%, Recall: 94.78%, F1 Score: 94.76%

Run 7/10
Epoch [1/50], Class Loss: 2.9897, Discrepancy Loss: 0.0325
Validation Loss: 0.9294
Epoch [2/50], Class Loss: 1.5403, Discrepancy Loss: 0.0184
Validation Loss: 2.3986
Epoch [3/50], Class Loss: 1.1773, Discrepancy Loss: 0.0204
Validation Loss: 0.2737
Epoch [4/50], Class Loss: 2.4504, Discrepancy Loss: 0.0642
Validation Loss: 0.4552
Epoch [5/50], Class Loss: 1.9219, Discrepancy Loss: 0.0348
Validation Loss: 3.4145
Epoch [6/50], Class Loss: 1.4448, Discrepancy Loss: 0.0250
Validation Loss: 0.2659
Epoch [7/50], Class Loss: 1.0331, Discrepancy Loss: 0.0303
Validation Loss: 1.5266
Epoch [8/50], Class Loss: 1.2620, Discrepancy Loss: 0.0193
Validation Loss: 0.6143
Epoch [9/50], Class Loss: 1.0154, Discrepancy Loss: 0.0251
Validation Loss: 0.3730
Epoch [10/50], Class Loss: 1.5075, Discrepancy Loss: 0.0353
Validation Loss: 6.0942
Epoch [11/50], Class Loss: 0.3400, Discrepancy Loss: 0.0109
Validation Loss: 0.0207
Epoch [12/50], Class Loss: 0.0735, Discrepancy Loss: 0.0038
Validation Loss: 0.0338
Epoch [13/50], Class Loss: 0.1142, Discrepancy Loss: 0.0034
Validation Loss: 0.0167
Epoch [14/50], Class Loss: 0.1686, Discrepancy Loss: 0.0047
Validation Loss: 0.0134
Epoch [15/50], Class Loss: 0.0363, Discrepancy Loss: 0.0051
Validation Loss: 0.0151
Epoch [16/50], Class Loss: 0.0743, Discrepancy Loss: 0.0085
Validation Loss: 0.0311
Epoch [17/50], Class Loss: 0.0308, Discrepancy Loss: 0.0037
Validation Loss: 0.0235
Epoch [18/50], Class Loss: 0.1158, Discrepancy Loss: 0.0075
Validation Loss: 0.0232
Epoch [19/50], Class Loss: 0.0429, Discrepancy Loss: 0.0041
Validation Loss: 0.0190
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.91%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 96.17%, Precision: 96.26%, Recall: 96.22%, F1 Score: 96.23%

Run 8/10
Epoch [1/50], Class Loss: 3.2676, Discrepancy Loss: 0.0411
Validation Loss: 0.9897
Epoch [2/50], Class Loss: 1.1998, Discrepancy Loss: 0.0113
Validation Loss: 1.1948
Epoch [3/50], Class Loss: 1.6938, Discrepancy Loss: 0.0256
Validation Loss: 1.4918
Epoch [4/50], Class Loss: 1.5905, Discrepancy Loss: 0.0268
Validation Loss: 1.7218
Epoch [5/50], Class Loss: 1.0695, Discrepancy Loss: 0.0212
Validation Loss: 0.3137
Epoch [6/50], Class Loss: 0.1885, Discrepancy Loss: 0.0140
Validation Loss: 0.0720
Epoch [7/50], Class Loss: 1.0071, Discrepancy Loss: 0.0192
Validation Loss: 5.7722
Epoch [8/50], Class Loss: 1.9000, Discrepancy Loss: 0.0512
Validation Loss: 1.5529
Epoch [9/50], Class Loss: 0.4991, Discrepancy Loss: 0.0278
Validation Loss: 0.0655
Epoch [10/50], Class Loss: 1.8485, Discrepancy Loss: 0.0407
Validation Loss: 1.4263
Epoch [11/50], Class Loss: 0.1391, Discrepancy Loss: 0.0141
Validation Loss: 0.0449
Epoch [12/50], Class Loss: 0.2521, Discrepancy Loss: 0.0115
Validation Loss: 0.6505
Epoch [13/50], Class Loss: 0.2847, Discrepancy Loss: 0.0142
Validation Loss: 0.1138
Epoch [14/50], Class Loss: 0.2165, Discrepancy Loss: 0.0116
Validation Loss: 0.0427
Epoch [15/50], Class Loss: 0.1100, Discrepancy Loss: 0.0102
Validation Loss: 0.6271
Epoch [16/50], Class Loss: 0.1954, Discrepancy Loss: 0.0123
Validation Loss: 0.0385
Epoch [17/50], Class Loss: 0.1286, Discrepancy Loss: 0.0102
Validation Loss: 0.0790
Epoch [18/50], Class Loss: 0.0715, Discrepancy Loss: 0.0103
Validation Loss: 2.1192
Epoch [19/50], Class Loss: 0.1005, Discrepancy Loss: 0.0103
Validation Loss: 0.0411
Epoch [20/50], Class Loss: 0.1492, Discrepancy Loss: 0.0130
Validation Loss: 0.0525
Epoch [21/50], Class Loss: 0.0204, Discrepancy Loss: 0.0073
Validation Loss: 0.0351
Epoch [22/50], Class Loss: 0.0214, Discrepancy Loss: 0.0072
Validation Loss: 0.0341
Epoch [23/50], Class Loss: 0.0183, Discrepancy Loss: 0.0070
Validation Loss: 0.0338
Epoch [24/50], Class Loss: 0.0175, Discrepancy Loss: 0.0070
Validation Loss: 0.0331
Epoch [25/50], Class Loss: 0.0177, Discrepancy Loss: 0.0068
Validation Loss: 0.0328
Epoch [26/50], Class Loss: 0.0150, Discrepancy Loss: 0.0065
Validation Loss: 0.0342
Epoch [27/50], Class Loss: 0.0154, Discrepancy Loss: 0.0064
Validation Loss: 0.0322
Epoch [28/50], Class Loss: 0.0164, Discrepancy Loss: 0.0063
Validation Loss: 0.0315
Epoch [29/50], Class Loss: 0.0175, Discrepancy Loss: 0.0061
Validation Loss: 0.0309
Epoch [30/50], Class Loss: 0.0150, Discrepancy Loss: 0.0058
Validation Loss: 0.0306
Epoch [31/50], Class Loss: 0.0127, Discrepancy Loss: 0.0056
Validation Loss: 0.0303
Epoch [32/50], Class Loss: 0.0133, Discrepancy Loss: 0.0056
Validation Loss: 0.0302
Epoch [33/50], Class Loss: 0.0125, Discrepancy Loss: 0.0056
Validation Loss: 0.0302
Epoch [34/50], Class Loss: 0.0117, Discrepancy Loss: 0.0056
Validation Loss: 0.0302
Epoch [35/50], Class Loss: 0.0126, Discrepancy Loss: 0.0055
Validation Loss: 0.0302
Epoch [36/50], Class Loss: 0.0129, Discrepancy Loss: 0.0056
Validation Loss: 0.0300
Epoch [37/50], Class Loss: 0.0130, Discrepancy Loss: 0.0056
Validation Loss: 0.0300
Epoch [38/50], Class Loss: 0.0125, Discrepancy Loss: 0.0056
Validation Loss: 0.0301
Epoch [39/50], Class Loss: 0.0127, Discrepancy Loss: 0.0054
Validation Loss: 0.0300
Epoch [40/50], Class Loss: 0.0126, Discrepancy Loss: 0.0054
Validation Loss: 0.0300
Epoch [41/50], Class Loss: 0.0131, Discrepancy Loss: 0.0055
Validation Loss: 0.0300
Epoch [42/50], Class Loss: 0.0116, Discrepancy Loss: 0.0055
Validation Loss: 0.0300
Epoch [43/50], Class Loss: 0.0132, Discrepancy Loss: 0.0054
Validation Loss: 0.0300
Epoch [44/50], Class Loss: 0.0116, Discrepancy Loss: 0.0055
Validation Loss: 0.0300
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 95.12%, Precision: 95.42%, Recall: 95.22%, F1 Score: 95.19%

Run 9/10
Epoch [1/50], Class Loss: 2.8224, Discrepancy Loss: 0.0346
Validation Loss: 1.0593
Epoch [2/50], Class Loss: 1.4231, Discrepancy Loss: 0.0132
Validation Loss: 1.1353
Epoch [3/50], Class Loss: 1.1247, Discrepancy Loss: 0.0138
Validation Loss: 0.5187
Epoch [4/50], Class Loss: 1.3861, Discrepancy Loss: 0.0202
Validation Loss: 0.6202
Epoch [5/50], Class Loss: 0.3658, Discrepancy Loss: 0.0024
Validation Loss: 0.5060
Epoch [6/50], Class Loss: 0.3836, Discrepancy Loss: 0.0028
Validation Loss: 0.0985
Epoch [7/50], Class Loss: 0.3691, Discrepancy Loss: 0.0054
Validation Loss: 0.1410
Epoch [8/50], Class Loss: 0.4270, Discrepancy Loss: 0.0093
Validation Loss: 0.4870
Epoch [9/50], Class Loss: 0.9670, Discrepancy Loss: 0.0152
Validation Loss: 0.1287
Epoch [10/50], Class Loss: 1.3918, Discrepancy Loss: 0.0222
Validation Loss: 0.3062
Epoch [11/50], Class Loss: 0.0303, Discrepancy Loss: 0.0017
Validation Loss: 0.0182
Epoch [12/50], Class Loss: 0.1091, Discrepancy Loss: 0.0025
Validation Loss: 0.0213
Epoch [13/50], Class Loss: 0.0948, Discrepancy Loss: 0.0026
Validation Loss: 0.0226
Epoch [14/50], Class Loss: 0.0786, Discrepancy Loss: 0.0026
Validation Loss: 0.0627
Epoch [15/50], Class Loss: 0.0657, Discrepancy Loss: 0.0027
Validation Loss: 0.0678
Epoch [16/50], Class Loss: 0.1118, Discrepancy Loss: 0.0029
Validation Loss: 0.0241
Early stopping!
Source Domain Performance - Accuracy: 99.66%, Precision: 99.65%, Recall: 99.67%, F1 Score: 99.66%
Target Domain Performance - Accuracy: 91.28%, Precision: 93.96%, Recall: 91.35%, F1 Score: 91.00%

Run 10/10
Epoch [1/50], Class Loss: 2.5974, Discrepancy Loss: 0.0413
Validation Loss: 0.7105
Epoch [2/50], Class Loss: 2.1166, Discrepancy Loss: 0.0447
Validation Loss: 1.7351
Epoch [3/50], Class Loss: 2.7367, Discrepancy Loss: 0.0641
Validation Loss: 18.3982
Epoch [4/50], Class Loss: 1.5264, Discrepancy Loss: 0.0335
Validation Loss: 5.8445
Epoch [5/50], Class Loss: 1.7292, Discrepancy Loss: 0.0611
Validation Loss: 7.1360
Epoch [6/50], Class Loss: 1.3375, Discrepancy Loss: 0.0283
Validation Loss: 0.2138
Epoch [7/50], Class Loss: 1.7455, Discrepancy Loss: 0.0258
Validation Loss: 0.2454
Epoch [8/50], Class Loss: 0.6941, Discrepancy Loss: 0.0172
Validation Loss: 0.6137
Epoch [9/50], Class Loss: 1.1350, Discrepancy Loss: 0.0182
Validation Loss: 0.6742
Epoch [10/50], Class Loss: 0.4947, Discrepancy Loss: 0.0128
Validation Loss: 0.0405
Epoch [11/50], Class Loss: 0.0187, Discrepancy Loss: 0.0036
Validation Loss: 0.0164
Epoch [12/50], Class Loss: 0.1569, Discrepancy Loss: 0.0040
Validation Loss: 0.0171
Epoch [13/50], Class Loss: 0.1080, Discrepancy Loss: 0.0049
Validation Loss: 0.0118
Epoch [14/50], Class Loss: 0.2332, Discrepancy Loss: 0.0061
Validation Loss: 0.0168
Epoch [15/50], Class Loss: 0.1615, Discrepancy Loss: 0.0101
Validation Loss: 0.0163
Epoch [16/50], Class Loss: 0.0982, Discrepancy Loss: 0.0106
Validation Loss: 0.0122
Epoch [17/50], Class Loss: 0.0713, Discrepancy Loss: 0.0091
Validation Loss: 0.5327
Epoch [18/50], Class Loss: 0.1205, Discrepancy Loss: 0.0108
Validation Loss: 1.2185
Early stopping!
Source Domain Performance - Accuracy: 90.97%, Precision: 93.56%, Recall: 91.38%, F1 Score: 90.73%
Target Domain Performance - Accuracy: 92.43%, Precision: 93.86%, Recall: 92.61%, F1 Score: 92.40%

Source performance: 87.23% 85.57% 87.38% 85.07%
Target performance: 81.18% 80.49% 81.31% 78.83%

Per-Class Accuracy on Target Domain:
bpsk: 79.95%
qpsk: 83.57%
4qam: 55.10%
16qam: 87.95%
apsk: 100.00%

Run 1/10
Epoch [1/50], Class Loss: 1.1757, CORAL Loss: 0.0150
Validation Loss: 0.4917
Epoch [2/50], Class Loss: 0.6460, CORAL Loss: 0.0243
Validation Loss: 0.3250
Epoch [3/50], Class Loss: 0.3022, CORAL Loss: 0.0071
Validation Loss: 0.1423
Epoch [4/50], Class Loss: 0.4293, CORAL Loss: 0.0204
Validation Loss: 0.3645
Epoch [5/50], Class Loss: 0.2724, CORAL Loss: 0.0068
Validation Loss: 0.4950
Epoch [6/50], Class Loss: 0.2671, CORAL Loss: 0.0045
Validation Loss: 0.1038
Epoch [7/50], Class Loss: 0.1015, CORAL Loss: 0.0054
Validation Loss: 0.5871
Epoch [8/50], Class Loss: 0.1022, CORAL Loss: 0.0030
Validation Loss: 0.0356
Epoch [9/50], Class Loss: 0.1364, CORAL Loss: 0.0031
Validation Loss: 0.0098
Epoch [10/50], Class Loss: 0.2004, CORAL Loss: 0.0031
Validation Loss: 0.1745
Epoch [11/50], Class Loss: 0.1155, CORAL Loss: 0.0089
Validation Loss: 0.0722
Epoch [12/50], Class Loss: 0.0576, CORAL Loss: 0.0091
Validation Loss: 0.0326
Epoch [13/50], Class Loss: 0.0317, CORAL Loss: 0.0079
Validation Loss: 0.0169
Epoch [14/50], Class Loss: 0.0200, CORAL Loss: 0.0078
Validation Loss: 0.0122
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 91.14%, Precision: 93.85%, Recall: 91.20%, F1 Score: 90.84%

Run 2/10
Epoch [1/50], Class Loss: 1.3717, CORAL Loss: 0.0089
Validation Loss: 0.8700
Epoch [2/50], Class Loss: 1.6855, CORAL Loss: 2.3165
Validation Loss: 0.7561
Epoch [3/50], Class Loss: 0.6845, CORAL Loss: 0.0285
Validation Loss: 1.0902
Epoch [4/50], Class Loss: 0.5029, CORAL Loss: 0.0357
Validation Loss: 0.3520
Epoch [5/50], Class Loss: 0.4466, CORAL Loss: 0.0315
Validation Loss: 0.3121
Epoch [6/50], Class Loss: 0.3187, CORAL Loss: 0.0262
Validation Loss: 0.2339
Epoch [7/50], Class Loss: 0.3720, CORAL Loss: 0.0129
Validation Loss: 0.2039
Epoch [8/50], Class Loss: 0.3502, CORAL Loss: 0.0111
Validation Loss: 0.1862
Epoch [9/50], Class Loss: 0.2242, CORAL Loss: 0.0078
Validation Loss: 0.2750
Epoch [10/50], Class Loss: 0.2372, CORAL Loss: 0.0045
Validation Loss: 0.6905
Epoch [11/50], Class Loss: 0.2249, CORAL Loss: 0.0039
Validation Loss: 0.2179
Epoch [12/50], Class Loss: 0.1653, CORAL Loss: 0.0064
Validation Loss: 0.1465
Epoch [13/50], Class Loss: 0.0864, CORAL Loss: 0.0129
Validation Loss: 0.0697
Epoch [14/50], Class Loss: 0.0396, CORAL Loss: 0.0220
Validation Loss: 0.0456
Epoch [15/50], Class Loss: 0.0274, CORAL Loss: 0.0182
Validation Loss: 0.0405
Epoch [16/50], Class Loss: 0.0228, CORAL Loss: 0.0168
Validation Loss: 0.0425
Epoch [17/50], Class Loss: 0.0212, CORAL Loss: 0.0136
Validation Loss: 0.0359
Epoch [18/50], Class Loss: 0.0184, CORAL Loss: 0.0119
Validation Loss: 0.0343
Epoch [19/50], Class Loss: 0.0173, CORAL Loss: 0.0106
Validation Loss: 0.0282
Epoch [20/50], Class Loss: 0.0164, CORAL Loss: 0.0101
Validation Loss: 0.0282
Epoch [21/50], Class Loss: 0.0145, CORAL Loss: 0.0091
Validation Loss: 0.0291
Epoch [22/50], Class Loss: 0.0143, CORAL Loss: 0.0086
Validation Loss: 0.0292
Epoch [23/50], Class Loss: 0.0146, CORAL Loss: 0.0099
Validation Loss: 0.0275
Epoch [24/50], Class Loss: 0.0140, CORAL Loss: 0.0080
Validation Loss: 0.0290
Epoch [25/50], Class Loss: 0.0146, CORAL Loss: 0.0081
Validation Loss: 0.0302
Epoch [26/50], Class Loss: 0.0142, CORAL Loss: 0.0082
Validation Loss: 0.0285
Epoch [27/50], Class Loss: 0.0143, CORAL Loss: 0.0085
Validation Loss: 0.0257
Epoch [28/50], Class Loss: 0.0139, CORAL Loss: 0.0083
Validation Loss: 0.0307
Epoch [29/50], Class Loss: 0.0137, CORAL Loss: 0.0090
Validation Loss: 0.0278
Epoch [30/50], Class Loss: 0.0135, CORAL Loss: 0.0076
Validation Loss: 0.0267
Epoch [31/50], Class Loss: 0.0136, CORAL Loss: 0.0091
Validation Loss: 0.0277
Epoch [32/50], Class Loss: 0.0140, CORAL Loss: 0.0074
Validation Loss: 0.0270
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 90.55%, Precision: 93.54%, Recall: 90.62%, F1 Score: 90.18%

Run 3/10
Epoch [1/50], Class Loss: 1.5403, CORAL Loss: 0.0027
Validation Loss: 1.0388
Epoch [2/50], Class Loss: 0.6399, CORAL Loss: 0.0316
Validation Loss: 0.2812
Epoch [3/50], Class Loss: 0.4872, CORAL Loss: 0.0184
Validation Loss: 0.1986
Epoch [4/50], Class Loss: 0.5145, CORAL Loss: 0.0106
Validation Loss: 0.2227
Epoch [5/50], Class Loss: 0.1430, CORAL Loss: 0.0106
Validation Loss: 0.0287
Epoch [6/50], Class Loss: 0.3477, CORAL Loss: 0.0073
Validation Loss: 0.0212
Epoch [7/50], Class Loss: 0.0552, CORAL Loss: 0.0051
Validation Loss: 0.0109
Epoch [8/50], Class Loss: 0.0821, CORAL Loss: 0.0030
Validation Loss: 0.0734
Epoch [9/50], Class Loss: 0.0273, CORAL Loss: 0.0069
Validation Loss: 0.0077
Epoch [10/50], Class Loss: 0.1720, CORAL Loss: 0.0027
Validation Loss: 0.1943
Epoch [11/50], Class Loss: 0.0737, CORAL Loss: 0.0042
Validation Loss: 0.0277
Epoch [12/50], Class Loss: 0.0213, CORAL Loss: 0.0052
Validation Loss: 0.0157
Epoch [13/50], Class Loss: 0.0133, CORAL Loss: 0.0053
Validation Loss: 0.0118
Epoch [14/50], Class Loss: 0.0101, CORAL Loss: 0.0051
Validation Loss: 0.0103
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 89.23%, Precision: 93.01%, Recall: 89.31%, F1 Score: 88.58%

Run 4/10
Epoch [1/50], Class Loss: 1.5971, CORAL Loss: 0.0013
Validation Loss: 2.3442
Epoch [2/50], Class Loss: 1.0143, CORAL Loss: 0.0278
Validation Loss: 0.6396
Epoch [3/50], Class Loss: 0.4804, CORAL Loss: 0.0230
Validation Loss: 0.4361
Epoch [4/50], Class Loss: 0.3709, CORAL Loss: 0.0064
Validation Loss: 0.3012
Epoch [5/50], Class Loss: 0.2307, CORAL Loss: 0.0152
Validation Loss: 0.2686
Epoch [6/50], Class Loss: 0.1828, CORAL Loss: 0.0101
Validation Loss: 0.0691
Epoch [7/50], Class Loss: 0.0377, CORAL Loss: 0.0107
Validation Loss: 0.0145
Epoch [8/50], Class Loss: 0.1403, CORAL Loss: 0.0077
Validation Loss: 0.0540
Epoch [9/50], Class Loss: 0.2133, CORAL Loss: 0.0096
Validation Loss: 0.1124
Epoch [10/50], Class Loss: 0.0245, CORAL Loss: 0.0085
Validation Loss: 0.0123
Epoch [11/50], Class Loss: 0.0088, CORAL Loss: 0.0059
Validation Loss: 0.0114
Epoch [12/50], Class Loss: 0.0086, CORAL Loss: 0.0059
Validation Loss: 0.0114
Epoch [13/50], Class Loss: 0.0081, CORAL Loss: 0.0048
Validation Loss: 0.0109
Epoch [14/50], Class Loss: 0.0078, CORAL Loss: 0.0053
Validation Loss: 0.0105
Epoch [15/50], Class Loss: 0.0075, CORAL Loss: 0.0047
Validation Loss: 0.0102
Epoch [16/50], Class Loss: 0.0074, CORAL Loss: 0.0044
Validation Loss: 0.0100
Epoch [17/50], Class Loss: 0.0073, CORAL Loss: 0.0046
Validation Loss: 0.0108
Epoch [18/50], Class Loss: 0.0068, CORAL Loss: 0.0046
Validation Loss: 0.0088
Epoch [19/50], Class Loss: 0.0068, CORAL Loss: 0.0045
Validation Loss: 0.0094
Epoch [20/50], Class Loss: 0.0065, CORAL Loss: 0.0039
Validation Loss: 0.0086
Epoch [21/50], Class Loss: 0.0061, CORAL Loss: 0.0042
Validation Loss: 0.0085
Epoch [22/50], Class Loss: 0.0058, CORAL Loss: 0.0043
Validation Loss: 0.0084
Epoch [23/50], Class Loss: 0.0062, CORAL Loss: 0.0037
Validation Loss: 0.0083
Epoch [24/50], Class Loss: 0.0058, CORAL Loss: 0.0038
Validation Loss: 0.0082
Epoch [25/50], Class Loss: 0.0061, CORAL Loss: 0.0037
Validation Loss: 0.0083
Epoch [26/50], Class Loss: 0.0058, CORAL Loss: 0.0042
Validation Loss: 0.0085
Epoch [27/50], Class Loss: 0.0061, CORAL Loss: 0.0038
Validation Loss: 0.0085
Epoch [28/50], Class Loss: 0.0057, CORAL Loss: 0.0035
Validation Loss: 0.0085
Epoch [29/50], Class Loss: 0.0056, CORAL Loss: 0.0038
Validation Loss: 0.0084
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 89.70%, Precision: 93.22%, Recall: 89.77%, F1 Score: 89.15%

Run 5/10
Epoch [1/50], Class Loss: 1.5190, CORAL Loss: 0.0046
Validation Loss: 1.0475
Epoch [2/50], Class Loss: 0.7250, CORAL Loss: 0.0267
Validation Loss: 0.3485
Epoch [3/50], Class Loss: 0.4813, CORAL Loss: 0.0165
Validation Loss: 0.1802
Epoch [4/50], Class Loss: 0.3862, CORAL Loss: 0.0116
Validation Loss: 0.2385
Epoch [5/50], Class Loss: 1.3732, CORAL Loss: 5.9243
Validation Loss: 0.8486
Epoch [6/50], Class Loss: 0.9181, CORAL Loss: 0.0046
Validation Loss: 0.9133
Epoch [7/50], Class Loss: 0.8353, CORAL Loss: 0.0102
Validation Loss: 0.5909
Epoch [8/50], Class Loss: 0.7962, CORAL Loss: 0.0132
Validation Loss: 0.5718
Early stopping!
Source Domain Performance - Accuracy: 79.13%, Precision: 89.59%, Recall: 80.09%, F1 Score: 73.21%
Target Domain Performance - Accuracy: 95.73%, Precision: 96.14%, Recall: 95.82%, F1 Score: 95.77%

Run 6/10
Epoch [1/50], Class Loss: 1.4379, CORAL Loss: 0.0042
Validation Loss: 0.7913
Epoch [2/50], Class Loss: 0.5568, CORAL Loss: 0.0234
Validation Loss: 0.2190
Epoch [3/50], Class Loss: 0.6115, CORAL Loss: 0.0195
Validation Loss: 0.4703
Epoch [4/50], Class Loss: 0.3326, CORAL Loss: 0.0094
Validation Loss: 0.3846
Epoch [5/50], Class Loss: 0.1600, CORAL Loss: 0.0064
Validation Loss: 0.0245
Epoch [6/50], Class Loss: 0.2338, CORAL Loss: 0.0081
Validation Loss: 0.1140
Epoch [7/50], Class Loss: 0.1862, CORAL Loss: 0.0038
Validation Loss: 0.0768
Epoch [8/50], Class Loss: 0.1038, CORAL Loss: 0.0048
Validation Loss: 0.0137
Epoch [9/50], Class Loss: 0.0099, CORAL Loss: 0.0053
Validation Loss: 0.0101
Epoch [10/50], Class Loss: 0.0986, CORAL Loss: 0.0037
Validation Loss: 0.0134
Epoch [11/50], Class Loss: 0.0098, CORAL Loss: 0.0044
Validation Loss: 0.0121
Epoch [12/50], Class Loss: 0.0084, CORAL Loss: 0.0046
Validation Loss: 0.0103
Epoch [13/50], Class Loss: 0.0076, CORAL Loss: 0.0036
Validation Loss: 0.0092
Epoch [14/50], Class Loss: 0.0069, CORAL Loss: 0.0035
Validation Loss: 0.0077
Epoch [15/50], Class Loss: 0.0063, CORAL Loss: 0.0032
Validation Loss: 0.0072
Epoch [16/50], Class Loss: 0.0058, CORAL Loss: 0.0029
Validation Loss: 0.0064
Epoch [17/50], Class Loss: 0.0056, CORAL Loss: 0.0030
Validation Loss: 0.0054
Epoch [18/50], Class Loss: 0.0046, CORAL Loss: 0.0025
Validation Loss: 0.0055
Epoch [19/50], Class Loss: 0.0048, CORAL Loss: 0.0021
Validation Loss: 0.0050
Epoch [20/50], Class Loss: 0.0046, CORAL Loss: 0.0022
Validation Loss: 0.0069
Epoch [21/50], Class Loss: 0.0040, CORAL Loss: 0.0023
Validation Loss: 0.0056
Epoch [22/50], Class Loss: 0.0038, CORAL Loss: 0.0021
Validation Loss: 0.0052
Epoch [23/50], Class Loss: 0.0037, CORAL Loss: 0.0020
Validation Loss: 0.0052
Epoch [24/50], Class Loss: 0.0041, CORAL Loss: 0.0020
Validation Loss: 0.0051
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 80.00%, Precision: 88.30%, Recall: 80.15%, F1 Score: 73.88%

Run 7/10
Epoch [1/50], Class Loss: 1.3185, CORAL Loss: 0.0110
Validation Loss: 0.5731
Epoch [2/50], Class Loss: 0.7291, CORAL Loss: 0.0217
Validation Loss: 0.3301
Epoch [3/50], Class Loss: 0.2757, CORAL Loss: 0.0075
Validation Loss: 0.0997
Epoch [4/50], Class Loss: 0.2246, CORAL Loss: 0.0083
Validation Loss: 0.0439
Epoch [5/50], Class Loss: 0.1976, CORAL Loss: 0.0134
Validation Loss: 0.0935
Epoch [6/50], Class Loss: 0.1752, CORAL Loss: 0.0096
Validation Loss: 0.4981
Epoch [7/50], Class Loss: 0.1643, CORAL Loss: 0.0111
Validation Loss: 0.3801
Epoch [8/50], Class Loss: 0.3255, CORAL Loss: 0.0105
Validation Loss: 0.1604
Epoch [9/50], Class Loss: 0.0747, CORAL Loss: 0.0100
Validation Loss: 0.0088
Epoch [10/50], Class Loss: 0.0067, CORAL Loss: 0.0046
Validation Loss: 0.0060
Epoch [11/50], Class Loss: 0.0050, CORAL Loss: 0.0026
Validation Loss: 0.0056
Epoch [12/50], Class Loss: 0.0046, CORAL Loss: 0.0027
Validation Loss: 0.0052
Epoch [13/50], Class Loss: 0.0047, CORAL Loss: 0.0024
Validation Loss: 0.0051
Epoch [14/50], Class Loss: 0.0049, CORAL Loss: 0.0021
Validation Loss: 0.0044
Epoch [15/50], Class Loss: 0.0043, CORAL Loss: 0.0020
Validation Loss: 0.0044
Epoch [16/50], Class Loss: 0.0039, CORAL Loss: 0.0019
Validation Loss: 0.0048
Epoch [17/50], Class Loss: 0.0043, CORAL Loss: 0.0019
Validation Loss: 0.0042
Epoch [18/50], Class Loss: 0.0040, CORAL Loss: 0.0017
Validation Loss: 0.0043
Epoch [19/50], Class Loss: 0.0041, CORAL Loss: 0.0017
Validation Loss: 0.0043
Epoch [20/50], Class Loss: 0.0039, CORAL Loss: 0.0017
Validation Loss: 0.0036
Epoch [21/50], Class Loss: 0.0034, CORAL Loss: 0.0015
Validation Loss: 0.0039
Epoch [22/50], Class Loss: 0.0037, CORAL Loss: 0.0015
Validation Loss: 0.0039
Epoch [23/50], Class Loss: 0.0033, CORAL Loss: 0.0017
Validation Loss: 0.0041
Epoch [24/50], Class Loss: 0.0034, CORAL Loss: 0.0016
Validation Loss: 0.0042
Epoch [25/50], Class Loss: 0.0034, CORAL Loss: 0.0016
Validation Loss: 0.0040
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 94.12%, Precision: 95.46%, Recall: 94.16%, F1 Score: 94.08%

Run 8/10
Epoch [1/50], Class Loss: 1.4179, CORAL Loss: 0.0045
Validation Loss: 3.7367
Epoch [2/50], Class Loss: 0.7584, CORAL Loss: 0.0223
Validation Loss: 0.2833
Epoch [3/50], Class Loss: 0.3831, CORAL Loss: 0.0201
Validation Loss: 0.1707
Epoch [4/50], Class Loss: 0.5491, CORAL Loss: 0.0181
Validation Loss: 0.2064
Epoch [5/50], Class Loss: 0.3560, CORAL Loss: 0.0079
Validation Loss: 0.1041
Epoch [6/50], Class Loss: 0.2865, CORAL Loss: 0.0081
Validation Loss: 0.0202
Epoch [7/50], Class Loss: 0.1476, CORAL Loss: 0.0051
Validation Loss: 0.0137
Epoch [8/50], Class Loss: 0.0087, CORAL Loss: 0.0037
Validation Loss: 0.0085
Epoch [9/50], Class Loss: 0.3664, CORAL Loss: 0.0037
Validation Loss: 0.2227
Epoch [10/50], Class Loss: 0.3300, CORAL Loss: 0.0114
Validation Loss: 0.2758
Epoch [11/50], Class Loss: 0.2027, CORAL Loss: 0.0057
Validation Loss: 0.1654
Epoch [12/50], Class Loss: 0.1117, CORAL Loss: 0.0056
Validation Loss: 0.0841
Epoch [13/50], Class Loss: 0.0537, CORAL Loss: 0.0072
Validation Loss: 0.0452
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 98.17%, Precision: 98.20%, Recall: 98.20%, F1 Score: 98.20%

Run 9/10
Epoch [1/50], Class Loss: 1.4260, CORAL Loss: 0.0050
Validation Loss: 0.8462
Epoch [2/50], Class Loss: 0.5220, CORAL Loss: 0.0258
Validation Loss: 0.2915
Epoch [3/50], Class Loss: 0.4259, CORAL Loss: 0.0095
Validation Loss: 0.1713
Epoch [4/50], Class Loss: 0.2855, CORAL Loss: 0.0101
Validation Loss: 0.0454
Epoch [5/50], Class Loss: 0.4901, CORAL Loss: 0.0117
Validation Loss: 0.1747
Epoch [6/50], Class Loss: 0.1552, CORAL Loss: 0.0063
Validation Loss: 0.0439
Epoch [7/50], Class Loss: 0.0139, CORAL Loss: 0.0045
Validation Loss: 0.0097
Epoch [8/50], Class Loss: 0.4898, CORAL Loss: 0.0084
Validation Loss: 0.2672
Epoch [9/50], Class Loss: 0.2305, CORAL Loss: 0.0089
Validation Loss: 0.1051
Epoch [10/50], Class Loss: 0.1604, CORAL Loss: 0.0041
Validation Loss: 0.0440
Epoch [11/50], Class Loss: 0.0290, CORAL Loss: 0.0041
Validation Loss: 0.0339
Epoch [12/50], Class Loss: 0.0210, CORAL Loss: 0.0039
Validation Loss: 0.0277
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 97.19%, Precision: 97.55%, Recall: 97.21%, F1 Score: 97.22%

Run 10/10
Epoch [1/50], Class Loss: 1.5754, CORAL Loss: 0.0035
Validation Loss: 1.0530
Epoch [2/50], Class Loss: 0.5908, CORAL Loss: 0.0203
Validation Loss: 0.2414
Epoch [3/50], Class Loss: 0.1956, CORAL Loss: 0.0103
Validation Loss: 0.1173
Epoch [4/50], Class Loss: 0.1649, CORAL Loss: 0.1073
Validation Loss: 3.0308
Epoch [5/50], Class Loss: 0.8462, CORAL Loss: 0.0193
Validation Loss: 0.4327
Epoch [6/50], Class Loss: 0.6706, CORAL Loss: 0.0234
Validation Loss: 0.2996
Epoch [7/50], Class Loss: 0.3229, CORAL Loss: 0.0169
Validation Loss: 0.2585
Epoch [8/50], Class Loss: 0.1908, CORAL Loss: 0.0127
Validation Loss: 0.1977
Early stopping!
Source Domain Performance - Accuracy: 80.40%, Precision: 70.19%, Recall: 79.83%, F1 Score: 73.50%
Target Domain Performance - Accuracy: 60.82%, Precision: 51.15%, Recall: 60.85%, F1 Score: 54.46%

Source performance: 95.90% 95.92% 95.94% 94.62%
Target performance: 88.66% 90.04% 88.73% 87.24%

Per-Class Accuracy on Target Domain:
bpsk: 89.89%
qpsk: 97.61%
4qam: 56.36%
16qam: 99.78%
apsk: 100.00%

Run 1/10
Epoch [1/50], Class Loss: 1.2995, JMMD Loss: 0.1302
Validation Loss: 0.4096
Epoch [2/50], Class Loss: 0.5969, JMMD Loss: 0.1650
Validation Loss: 0.2077
Epoch [3/50], Class Loss: 0.5081, JMMD Loss: 0.1531
Validation Loss: 0.1537
Epoch [4/50], Class Loss: 0.2777, JMMD Loss: 0.1296
Validation Loss: 0.1351
Epoch [5/50], Class Loss: 0.2163, JMMD Loss: 0.0936
Validation Loss: 0.2250
Epoch [6/50], Class Loss: 0.1354, JMMD Loss: 0.1368
Validation Loss: 0.0162
Epoch [7/50], Class Loss: 0.0098, JMMD Loss: 0.1728
Validation Loss: 0.0086
Epoch [8/50], Class Loss: 0.3245, JMMD Loss: 0.1414
Validation Loss: 0.1002
Epoch [9/50], Class Loss: 0.2974, JMMD Loss: 0.1195
Validation Loss: 0.0855
Epoch [10/50], Class Loss: 0.0152, JMMD Loss: 0.1279
Validation Loss: 0.0087
Epoch [11/50], Class Loss: 0.0064, JMMD Loss: 0.1162
Validation Loss: 0.0081
Epoch [12/50], Class Loss: 0.0064, JMMD Loss: 0.1122
Validation Loss: 0.0077
Epoch [13/50], Class Loss: 0.0064, JMMD Loss: 0.1172
Validation Loss: 0.0076
Epoch [14/50], Class Loss: 0.0063, JMMD Loss: 0.1156
Validation Loss: 0.0075
Epoch [15/50], Class Loss: 0.0065, JMMD Loss: 0.1174
Validation Loss: 0.0074
Epoch [16/50], Class Loss: 0.0066, JMMD Loss: 0.1188
Validation Loss: 0.0074
Epoch [17/50], Class Loss: 0.0065, JMMD Loss: 0.1188
Validation Loss: 0.0098
Epoch [18/50], Class Loss: 0.0066, JMMD Loss: 0.1216
Validation Loss: 0.0072
Epoch [19/50], Class Loss: 0.0066, JMMD Loss: 0.1313
Validation Loss: 0.0077
Epoch [20/50], Class Loss: 0.0068, JMMD Loss: 0.1259
Validation Loss: 0.0075
Epoch [21/50], Class Loss: 0.0064, JMMD Loss: 0.1294
Validation Loss: 0.0070
Epoch [22/50], Class Loss: 0.0063, JMMD Loss: 0.1279
Validation Loss: 0.0070
Epoch [23/50], Class Loss: 0.0065, JMMD Loss: 0.1294
Validation Loss: 0.0070
Epoch [24/50], Class Loss: 0.0064, JMMD Loss: 0.1320
Validation Loss: 0.0069
Epoch [25/50], Class Loss: 0.0063, JMMD Loss: 0.1221
Validation Loss: 0.0070
Epoch [26/50], Class Loss: 0.0067, JMMD Loss: 0.1232
Validation Loss: 0.0071
Epoch [27/50], Class Loss: 0.0066, JMMD Loss: 0.1281
Validation Loss: 0.0071
Epoch [28/50], Class Loss: 0.0065, JMMD Loss: 0.1361
Validation Loss: 0.0070
Epoch [29/50], Class Loss: 0.0066, JMMD Loss: 0.1267
Validation Loss: 0.0070
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 96.90%, Precision: 97.33%, Recall: 96.92%, F1 Score: 96.93%

Run 2/10
Epoch [1/50], Class Loss: 1.3586, JMMD Loss: 0.1344
Validation Loss: 0.8826
Epoch [2/50], Class Loss: 0.7228, JMMD Loss: 0.1785
Validation Loss: 0.6324
Epoch [3/50], Class Loss: 0.3171, JMMD Loss: 0.1655
Validation Loss: 0.4362
Epoch [4/50], Class Loss: 0.3208, JMMD Loss: 0.1403
Validation Loss: 0.1125
Epoch [5/50], Class Loss: 0.2727, JMMD Loss: 0.1335
Validation Loss: 0.0979
Epoch [6/50], Class Loss: 0.2930, JMMD Loss: 0.1085
Validation Loss: 0.2600
Epoch [7/50], Class Loss: 0.1397, JMMD Loss: 0.0799
Validation Loss: 0.0249
Epoch [8/50], Class Loss: 0.2757, JMMD Loss: 0.0969
Validation Loss: 0.0205
Epoch [9/50], Class Loss: 0.2101, JMMD Loss: 0.1168
Validation Loss: 0.0492
Epoch [10/50], Class Loss: 0.1287, JMMD Loss: 0.1241
Validation Loss: 0.0106
Epoch [11/50], Class Loss: 0.0068, JMMD Loss: 0.1366
Validation Loss: 0.0083
Epoch [12/50], Class Loss: 0.0066, JMMD Loss: 0.1325
Validation Loss: 0.0080
Epoch [13/50], Class Loss: 0.0068, JMMD Loss: 0.1362
Validation Loss: 0.0079
Epoch [14/50], Class Loss: 0.0069, JMMD Loss: 0.1345
Validation Loss: 0.0075
Epoch [15/50], Class Loss: 0.0067, JMMD Loss: 0.1298
Validation Loss: 0.0076
Epoch [16/50], Class Loss: 0.0066, JMMD Loss: 0.1304
Validation Loss: 0.0069
Epoch [17/50], Class Loss: 0.0067, JMMD Loss: 0.1271
Validation Loss: 0.0076
Epoch [18/50], Class Loss: 0.0066, JMMD Loss: 0.1269
Validation Loss: 0.0071
Epoch [19/50], Class Loss: 0.0063, JMMD Loss: 0.1234
Validation Loss: 0.0067
Epoch [20/50], Class Loss: 0.0064, JMMD Loss: 0.1257
Validation Loss: 0.0064
Epoch [21/50], Class Loss: 0.0059, JMMD Loss: 0.1384
Validation Loss: 0.0064
Epoch [22/50], Class Loss: 0.0060, JMMD Loss: 0.1317
Validation Loss: 0.0064
Epoch [23/50], Class Loss: 0.0061, JMMD Loss: 0.1253
Validation Loss: 0.0064
Epoch [24/50], Class Loss: 0.0060, JMMD Loss: 0.1250
Validation Loss: 0.0065
Epoch [25/50], Class Loss: 0.0061, JMMD Loss: 0.1319
Validation Loss: 0.0065
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 96.24%, Precision: 96.85%, Recall: 96.27%, F1 Score: 96.27%

Run 3/10
Epoch [1/50], Class Loss: 1.2462, JMMD Loss: 0.1317
Validation Loss: 0.3521
Epoch [2/50], Class Loss: 0.6239, JMMD Loss: 0.1542
Validation Loss: 0.2631
Epoch [3/50], Class Loss: 0.5770, JMMD Loss: 0.1519
Validation Loss: 0.1895
Epoch [4/50], Class Loss: 0.4541, JMMD Loss: 0.1441
Validation Loss: 0.1404
Epoch [5/50], Class Loss: 0.2270, JMMD Loss: 0.1248
Validation Loss: 0.1986
Epoch [6/50], Class Loss: 0.2048, JMMD Loss: 0.1088
Validation Loss: 0.1311
Epoch [7/50], Class Loss: 0.1771, JMMD Loss: 0.0916
Validation Loss: 1.7547
Epoch [8/50], Class Loss: 0.2907, JMMD Loss: 0.1334
Validation Loss: 0.2636
Epoch [9/50], Class Loss: 0.1115, JMMD Loss: 0.1123
Validation Loss: 0.0367
Epoch [10/50], Class Loss: 0.1211, JMMD Loss: 0.0982
Validation Loss: 0.0167
Epoch [11/50], Class Loss: 0.0092, JMMD Loss: 0.0932
Validation Loss: 0.0127
Epoch [12/50], Class Loss: 0.0081, JMMD Loss: 0.1028
Validation Loss: 0.0114
Epoch [13/50], Class Loss: 0.0073, JMMD Loss: 0.1091
Validation Loss: 0.0100
Epoch [14/50], Class Loss: 0.0069, JMMD Loss: 0.1063
Validation Loss: 0.0091
Epoch [15/50], Class Loss: 0.0067, JMMD Loss: 0.1125
Validation Loss: 0.0082
Epoch [16/50], Class Loss: 0.0065, JMMD Loss: 0.1148
Validation Loss: 0.0074
Epoch [17/50], Class Loss: 0.0062, JMMD Loss: 0.1228
Validation Loss: 0.0069
Epoch [18/50], Class Loss: 0.0062, JMMD Loss: 0.1269
Validation Loss: 0.0067
Epoch [19/50], Class Loss: 0.0058, JMMD Loss: 0.1306
Validation Loss: 0.0065
Epoch [20/50], Class Loss: 0.0063, JMMD Loss: 0.1382
Validation Loss: 0.0066
Epoch [21/50], Class Loss: 0.0064, JMMD Loss: 0.1411
Validation Loss: 0.0066
Epoch [22/50], Class Loss: 0.0061, JMMD Loss: 0.1448
Validation Loss: 0.0066
Epoch [23/50], Class Loss: 0.0063, JMMD Loss: 0.1397
Validation Loss: 0.0066
Epoch [24/50], Class Loss: 0.0062, JMMD Loss: 0.1438
Validation Loss: 0.0067
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 96.07%, Precision: 96.73%, Recall: 96.10%, F1 Score: 96.10%

Run 4/10
Epoch [1/50], Class Loss: 1.3496, JMMD Loss: 0.1307
Validation Loss: 0.7912
Epoch [2/50], Class Loss: 0.5977, JMMD Loss: 0.1813
Validation Loss: 0.9648
Epoch [3/50], Class Loss: 0.4309, JMMD Loss: 0.1633
Validation Loss: 0.1875
Epoch [4/50], Class Loss: 0.2003, JMMD Loss: 0.1250
Validation Loss: 0.3971
Epoch [5/50], Class Loss: 0.2916, JMMD Loss: 0.1210
Validation Loss: 0.1698
Epoch [6/50], Class Loss: 0.1522, JMMD Loss: 0.0982
Validation Loss: 0.0746
Epoch [7/50], Class Loss: 0.0189, JMMD Loss: 0.0896
Validation Loss: 0.0119
Epoch [8/50], Class Loss: 0.2179, JMMD Loss: 0.0990
Validation Loss: 0.0225
Epoch [9/50], Class Loss: 0.0110, JMMD Loss: 0.0877
Validation Loss: 0.0135
Epoch [10/50], Class Loss: 0.2132, JMMD Loss: 0.1252
Validation Loss: 0.1725
Epoch [11/50], Class Loss: 0.0650, JMMD Loss: 0.1129
Validation Loss: 0.0363
Epoch [12/50], Class Loss: 0.0284, JMMD Loss: 0.1102
Validation Loss: 0.0179
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 92.92%, Precision: 94.75%, Recall: 92.97%, F1 Score: 92.81%

Run 5/10
Epoch [1/50], Class Loss: 1.3969, JMMD Loss: 0.1068
Validation Loss: 0.6789
Epoch [2/50], Class Loss: 0.5037, JMMD Loss: 0.1248
Validation Loss: 0.8111
Epoch [3/50], Class Loss: 0.2228, JMMD Loss: 0.1065
Validation Loss: 0.1259
Epoch [4/50], Class Loss: 0.3992, JMMD Loss: 0.0978
Validation Loss: 0.3171
Epoch [5/50], Class Loss: 0.2275, JMMD Loss: 0.0823
Validation Loss: 0.1989
Epoch [6/50], Class Loss: 0.2826, JMMD Loss: 0.1244
Validation Loss: 0.1353
Epoch [7/50], Class Loss: 0.1459, JMMD Loss: 0.1379
Validation Loss: 0.0272
Epoch [8/50], Class Loss: 0.1732, JMMD Loss: 0.0994
Validation Loss: 0.0278
Epoch [9/50], Class Loss: 0.0114, JMMD Loss: 0.1176
Validation Loss: 0.0121
Epoch [10/50], Class Loss: 0.0064, JMMD Loss: 0.1272
Validation Loss: 0.0082
Epoch [11/50], Class Loss: 0.0056, JMMD Loss: 0.1410
Validation Loss: 0.0080
Epoch [12/50], Class Loss: 0.0059, JMMD Loss: 0.1403
Validation Loss: 0.0084
Epoch [13/50], Class Loss: 0.0060, JMMD Loss: 0.1424
Validation Loss: 0.0083
Epoch [14/50], Class Loss: 0.0060, JMMD Loss: 0.1369
Validation Loss: 0.0087
Epoch [15/50], Class Loss: 0.0061, JMMD Loss: 0.1388
Validation Loss: 0.0079
Epoch [16/50], Class Loss: 0.0060, JMMD Loss: 0.1424
Validation Loss: 0.0078
Epoch [17/50], Class Loss: 0.0060, JMMD Loss: 0.1393
Validation Loss: 0.0077
Epoch [18/50], Class Loss: 0.0060, JMMD Loss: 0.1412
Validation Loss: 0.0076
Epoch [19/50], Class Loss: 0.0062, JMMD Loss: 0.1368
Validation Loss: 0.0082
Epoch [20/50], Class Loss: 0.0058, JMMD Loss: 0.1351
Validation Loss: 0.0075
Epoch [21/50], Class Loss: 0.0054, JMMD Loss: 0.1336
Validation Loss: 0.0077
Epoch [22/50], Class Loss: 0.0056, JMMD Loss: 0.1373
Validation Loss: 0.0077
Epoch [23/50], Class Loss: 0.0057, JMMD Loss: 0.1316
Validation Loss: 0.0076
Epoch [24/50], Class Loss: 0.0056, JMMD Loss: 0.1407
Validation Loss: 0.0078
Epoch [25/50], Class Loss: 0.0055, JMMD Loss: 0.1372
Validation Loss: 0.0076
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 96.22%, Precision: 96.83%, Recall: 96.24%, F1 Score: 96.24%

Run 6/10
Epoch [1/50], Class Loss: 1.4428, JMMD Loss: 0.1304
Validation Loss: 0.7600
Epoch [2/50], Class Loss: 0.8297, JMMD Loss: 0.1894
Validation Loss: 0.2078
Epoch [3/50], Class Loss: 0.7222, JMMD Loss: 0.1741
Validation Loss: 1.0673
Epoch [4/50], Class Loss: 0.5658, JMMD Loss: 0.1733
Validation Loss: 0.9523
Epoch [5/50], Class Loss: 0.2910, JMMD Loss: 0.1628
Validation Loss: 0.2016
Epoch [6/50], Class Loss: 0.1318, JMMD Loss: 0.1249
Validation Loss: 0.0313
Epoch [7/50], Class Loss: 0.2624, JMMD Loss: 0.1064
Validation Loss: 0.6136
Epoch [8/50], Class Loss: 0.1705, JMMD Loss: 0.1071
Validation Loss: 0.0562
Epoch [9/50], Class Loss: 0.0185, JMMD Loss: 0.0875
Validation Loss: 0.0829
Epoch [10/50], Class Loss: 0.3004, JMMD Loss: 0.1004
Validation Loss: 0.0170
Epoch [11/50], Class Loss: 0.0123, JMMD Loss: 0.0882
Validation Loss: 0.0125
Epoch [12/50], Class Loss: 0.0105, JMMD Loss: 0.0835
Validation Loss: 0.0108
Epoch [13/50], Class Loss: 0.0094, JMMD Loss: 0.0869
Validation Loss: 0.0096
Epoch [14/50], Class Loss: 0.0082, JMMD Loss: 0.0843
Validation Loss: 0.0090
Epoch [15/50], Class Loss: 0.0080, JMMD Loss: 0.0808
Validation Loss: 0.0078
Epoch [16/50], Class Loss: 0.0074, JMMD Loss: 0.0873
Validation Loss: 0.0078
Epoch [17/50], Class Loss: 0.0071, JMMD Loss: 0.0840
Validation Loss: 0.0067
Epoch [18/50], Class Loss: 0.0068, JMMD Loss: 0.0848
Validation Loss: 0.0063
Epoch [19/50], Class Loss: 0.0065, JMMD Loss: 0.0842
Validation Loss: 0.0066
Epoch [20/50], Class Loss: 0.0059, JMMD Loss: 0.0816
Validation Loss: 0.0071
Epoch [21/50], Class Loss: 0.0057, JMMD Loss: 0.0883
Validation Loss: 0.0059
Epoch [22/50], Class Loss: 0.0050, JMMD Loss: 0.0821
Validation Loss: 0.0058
Epoch [23/50], Class Loss: 0.0053, JMMD Loss: 0.0809
Validation Loss: 0.0058
Epoch [24/50], Class Loss: 0.0052, JMMD Loss: 0.0879
Validation Loss: 0.0058
Epoch [25/50], Class Loss: 0.0055, JMMD Loss: 0.0913
Validation Loss: 0.0057
Epoch [26/50], Class Loss: 0.0053, JMMD Loss: 0.0848
Validation Loss: 0.0056
Epoch [27/50], Class Loss: 0.0052, JMMD Loss: 0.0898
Validation Loss: 0.0057
Epoch [28/50], Class Loss: 0.0055, JMMD Loss: 0.0914
Validation Loss: 0.0056
Epoch [29/50], Class Loss: 0.0052, JMMD Loss: 0.0828
Validation Loss: 0.0055
Epoch [30/50], Class Loss: 0.0055, JMMD Loss: 0.0886
Validation Loss: 0.0055
Epoch [31/50], Class Loss: 0.0052, JMMD Loss: 0.0813
Validation Loss: 0.0054
Epoch [32/50], Class Loss: 0.0051, JMMD Loss: 0.0874
Validation Loss: 0.0055
Epoch [33/50], Class Loss: 0.0052, JMMD Loss: 0.0874
Validation Loss: 0.0054
Epoch [34/50], Class Loss: 0.0051, JMMD Loss: 0.0873
Validation Loss: 0.0054
Epoch [35/50], Class Loss: 0.0052, JMMD Loss: 0.0844
Validation Loss: 0.0054
Epoch [36/50], Class Loss: 0.0052, JMMD Loss: 0.0896
Validation Loss: 0.0054
Epoch [37/50], Class Loss: 0.0051, JMMD Loss: 0.0810
Validation Loss: 0.0054
Epoch [38/50], Class Loss: 0.0051, JMMD Loss: 0.0825
Validation Loss: 0.0054
Epoch [39/50], Class Loss: 0.0052, JMMD Loss: 0.0896
Validation Loss: 0.0054
Epoch [40/50], Class Loss: 0.0051, JMMD Loss: 0.0851
Validation Loss: 0.0054
Epoch [41/50], Class Loss: 0.0049, JMMD Loss: 0.0821
Validation Loss: 0.0054
Epoch [42/50], Class Loss: 0.0050, JMMD Loss: 0.0872
Validation Loss: 0.0054
Epoch [43/50], Class Loss: 0.0053, JMMD Loss: 0.0889
Validation Loss: 0.0054
Epoch [44/50], Class Loss: 0.0051, JMMD Loss: 0.0860
Validation Loss: 0.0054
Epoch [45/50], Class Loss: 0.0050, JMMD Loss: 0.0952
Validation Loss: 0.0054
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 86.01%, Precision: 91.73%, Recall: 86.11%, F1 Score: 84.33%

Run 7/10
Epoch [1/50], Class Loss: 1.4125, JMMD Loss: 0.1229
Validation Loss: 1.5150
Epoch [2/50], Class Loss: 0.8441, JMMD Loss: 0.1746
Validation Loss: 0.2613
Epoch [3/50], Class Loss: 0.2656, JMMD Loss: 0.1558
Validation Loss: 0.0822
Epoch [4/50], Class Loss: 0.4707, JMMD Loss: 0.1489
Validation Loss: 2.0229
Epoch [5/50], Class Loss: 0.1840, JMMD Loss: 0.1347
Validation Loss: 0.0772
Epoch [6/50], Class Loss: 0.4419, JMMD Loss: 0.1349
Validation Loss: 0.0459
Epoch [7/50], Class Loss: 0.0236, JMMD Loss: 0.1066
Validation Loss: 0.0229
Epoch [8/50], Class Loss: 0.3732, JMMD Loss: 0.1373
Validation Loss: 0.0159
Epoch [9/50], Class Loss: 0.0145, JMMD Loss: 0.0969
Validation Loss: 0.0099
Epoch [10/50], Class Loss: 0.2772, JMMD Loss: 0.1047
Validation Loss: 0.3520
Epoch [11/50], Class Loss: 0.1191, JMMD Loss: 0.1369
Validation Loss: 0.0870
Epoch [12/50], Class Loss: 0.0682, JMMD Loss: 0.1233
Validation Loss: 0.0517
Epoch [13/50], Class Loss: 0.0399, JMMD Loss: 0.1128
Validation Loss: 0.0321
Epoch [14/50], Class Loss: 0.0248, JMMD Loss: 0.1082
Validation Loss: 0.0213
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 97.44%, Precision: 97.68%, Recall: 97.46%, F1 Score: 97.47%

Run 8/10
Epoch [1/50], Class Loss: 1.3126, JMMD Loss: 0.1390
Validation Loss: 0.7882
Epoch [2/50], Class Loss: 0.6611, JMMD Loss: 0.1696
Validation Loss: 0.2129
Epoch [3/50], Class Loss: 0.5034, JMMD Loss: 0.1485
Validation Loss: 0.2201
Epoch [4/50], Class Loss: 0.3273, JMMD Loss: 0.1306
Validation Loss: 0.1192
Epoch [5/50], Class Loss: 0.4569, JMMD Loss: 0.1187
Validation Loss: 0.2549
Epoch [6/50], Class Loss: 0.0888, JMMD Loss: 0.0957
Validation Loss: 0.0187
Epoch [7/50], Class Loss: 0.1903, JMMD Loss: 0.0979
Validation Loss: 0.0132
Epoch [8/50], Class Loss: 0.2894, JMMD Loss: 0.0958
Validation Loss: 0.1901
Epoch [9/50], Class Loss: 0.1298, JMMD Loss: 0.1118
Validation Loss: 0.0261
Epoch [10/50], Class Loss: 0.1002, JMMD Loss: 0.0956
Validation Loss: 0.3090
Epoch [11/50], Class Loss: 0.1789, JMMD Loss: 0.0987
Validation Loss: 0.1157
Epoch [12/50], Class Loss: 0.0680, JMMD Loss: 0.0894
Validation Loss: 0.0422
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.86%, F1 Score: 99.86%
Target Domain Performance - Accuracy: 79.83%, Precision: 90.07%, Recall: 79.98%, F1 Score: 73.47%

Run 9/10
Epoch [1/50], Class Loss: 1.4175, JMMD Loss: 0.1226
Validation Loss: 1.0314
Epoch [2/50], Class Loss: 1.0165, JMMD Loss: 0.1857
Validation Loss: 0.3104
Epoch [3/50], Class Loss: 0.6838, JMMD Loss: 0.2010
Validation Loss: 0.3928
Epoch [4/50], Class Loss: 0.2500, JMMD Loss: 0.1620
Validation Loss: 0.2331
Epoch [5/50], Class Loss: 0.2686, JMMD Loss: 0.1506
Validation Loss: 0.2224
Epoch [6/50], Class Loss: 0.4092, JMMD Loss: 0.1484
Validation Loss: 1.3286
Epoch [7/50], Class Loss: 0.2678, JMMD Loss: 0.1223
Validation Loss: 0.1509
Epoch [8/50], Class Loss: 0.2557, JMMD Loss: 0.1156
Validation Loss: 0.0960
Epoch [9/50], Class Loss: 0.1919, JMMD Loss: 0.1275
Validation Loss: 0.1622
Epoch [10/50], Class Loss: 0.0583, JMMD Loss: 0.1027
Validation Loss: 0.0091
Epoch [11/50], Class Loss: 0.0099, JMMD Loss: 0.1163
Validation Loss: 0.0076
Epoch [12/50], Class Loss: 0.0082, JMMD Loss: 0.1081
Validation Loss: 0.0066
Epoch [13/50], Class Loss: 0.0075, JMMD Loss: 0.1126
Validation Loss: 0.0065
Epoch [14/50], Class Loss: 0.0072, JMMD Loss: 0.1159
Validation Loss: 0.0064
Epoch [15/50], Class Loss: 0.0070, JMMD Loss: 0.1228
Validation Loss: 0.0062
Epoch [16/50], Class Loss: 0.0067, JMMD Loss: 0.1275
Validation Loss: 0.0062
Epoch [17/50], Class Loss: 0.0068, JMMD Loss: 0.1345
Validation Loss: 0.0067
Epoch [18/50], Class Loss: 0.0067, JMMD Loss: 0.1330
Validation Loss: 0.0067
Epoch [19/50], Class Loss: 0.0066, JMMD Loss: 0.1409
Validation Loss: 0.0071
Epoch [20/50], Class Loss: 0.0069, JMMD Loss: 0.1539
Validation Loss: 0.0078
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 93.09%, Precision: 94.87%, Recall: 93.14%, F1 Score: 93.00%

Run 10/10
Epoch [1/50], Class Loss: 1.4209, JMMD Loss: 0.1360
Validation Loss: 0.6382
Epoch [2/50], Class Loss: 0.6837, JMMD Loss: 0.1662
Validation Loss: 0.1867
Epoch [3/50], Class Loss: 0.2643, JMMD Loss: 0.1423
Validation Loss: 0.1840
Epoch [4/50], Class Loss: 0.3250, JMMD Loss: 0.1220
Validation Loss: 0.1906
Epoch [5/50], Class Loss: 0.1717, JMMD Loss: 0.1169
Validation Loss: 0.1190
Epoch [6/50], Class Loss: 0.0633, JMMD Loss: 0.1033
Validation Loss: 0.0106
Epoch [7/50], Class Loss: 0.3748, JMMD Loss: 0.1319
Validation Loss: 0.2248
Epoch [8/50], Class Loss: 0.0761, JMMD Loss: 0.1125
Validation Loss: 0.0262
Epoch [9/50], Class Loss: 0.0809, JMMD Loss: 0.0859
Validation Loss: 0.0248
Epoch [10/50], Class Loss: 0.0609, JMMD Loss: 0.0936
Validation Loss: 0.0424
Epoch [11/50], Class Loss: 0.0288, JMMD Loss: 0.1123
Validation Loss: 0.0296
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 93.41%, Precision: 95.05%, Recall: 93.46%, F1 Score: 93.34%

Source performance: 99.93% 99.93% 99.93% 99.93%
Target performance: 92.81% 95.19% 92.86% 92.00%

Per-Class Accuracy on Target Domain (Mean over runs):
  Class 0: 99.88%
  Class 1: 99.61%
  Class 2: 64.99%
  Class 3: 99.84%
  Class 4: 100.00%

Run 1/10
Epoch 1/50, Train Loss: 1.4937, Train Acc: 0.4020, Val Loss: 0.4342, Val Acc: 0.8040
Epoch 2/50, Train Loss: 0.9659, Train Acc: 0.6523, Val Loss: 0.4370, Val Acc: 0.7981
Epoch 3/50, Train Loss: 0.9538, Train Acc: 0.6969, Val Loss: 0.6312, Val Acc: 0.7993
Epoch 4/50, Train Loss: 1.1113, Train Acc: 0.6237, Val Loss: 0.2386, Val Acc: 0.9980
Epoch 5/50, Train Loss: 0.2163, Train Acc: 0.9009, Val Loss: 0.0113, Val Acc: 0.9983
Epoch 6/50, Train Loss: 0.9466, Train Acc: 0.7501, Val Loss: 0.1871, Val Acc: 0.8037
Epoch 7/50, Train Loss: 0.0831, Train Acc: 0.9637, Val Loss: 0.0441, Val Acc: 0.9868
Epoch 8/50, Train Loss: 0.3949, Train Acc: 0.8954, Val Loss: 0.0094, Val Acc: 0.9980
Epoch 9/50, Train Loss: 0.6217, Train Acc: 0.8560, Val Loss: 0.3259, Val Acc: 0.8032
Epoch 10/50, Train Loss: 0.4306, Train Acc: 0.8950, Val Loss: 0.0263, Val Acc: 0.9985
Epoch 11/50, Train Loss: 0.0100, Train Acc: 0.9993, Val Loss: 0.0131, Val Acc: 0.9990
Epoch 12/50, Train Loss: 0.0058, Train Acc: 0.9995, Val Loss: 0.0089, Val Acc: 0.9993
Epoch 13/50, Train Loss: 0.0049, Train Acc: 0.9995, Val Loss: 0.0080, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0047, Train Acc: 0.9996, Val Loss: 0.0067, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0116, Train Acc: 0.9968, Val Loss: 0.3238, Val Acc: 0.8042
Epoch 16/50, Train Loss: 0.0074, Train Acc: 0.9977, Val Loss: 0.0053, Val Acc: 0.9993
Epoch 17/50, Train Loss: 0.0033, Train Acc: 0.9996, Val Loss: 0.0028, Val Acc: 0.9990
Epoch 18/50, Train Loss: 0.0028, Train Acc: 0.9997, Val Loss: 0.0031, Val Acc: 0.9990
Epoch 19/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0037, Val Acc: 0.9990
Epoch 20/50, Train Loss: 0.0025, Train Acc: 0.9995, Val Loss: 0.0034, Val Acc: 0.9990
Epoch 21/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0031, Val Acc: 0.9993
Epoch 22/50, Train Loss: 0.0025, Train Acc: 0.9998, Val Loss: 0.0030, Val Acc: 0.9993
Early stopping!

Run 2/10
Epoch 1/50, Train Loss: 1.4630, Train Acc: 0.4027, Val Loss: 0.4778, Val Acc: 0.9817
Epoch 2/50, Train Loss: 0.4814, Train Acc: 0.8056, Val Loss: 3.0477, Val Acc: 0.3967
Epoch 3/50, Train Loss: 0.9815, Train Acc: 0.6356, Val Loss: 0.2451, Val Acc: 0.8037
Epoch 4/50, Train Loss: 1.0404, Train Acc: 0.6707, Val Loss: 0.3110, Val Acc: 0.8035
Epoch 5/50, Train Loss: 0.5102, Train Acc: 0.7549, Val Loss: 0.0375, Val Acc: 0.9983
Epoch 6/50, Train Loss: 0.6145, Train Acc: 0.8660, Val Loss: 0.1769, Val Acc: 0.8042
Epoch 7/50, Train Loss: 0.7585, Train Acc: 0.7848, Val Loss: 0.5535, Val Acc: 0.7778
Epoch 8/50, Train Loss: 0.5684, Train Acc: 0.8436, Val Loss: 0.0511, Val Acc: 0.9973
Epoch 9/50, Train Loss: 0.4249, Train Acc: 0.9020, Val Loss: 0.0317, Val Acc: 0.9983
Epoch 10/50, Train Loss: 0.3312, Train Acc: 0.9102, Val Loss: 0.5506, Val Acc: 0.8049
Epoch 11/50, Train Loss: 0.0144, Train Acc: 0.9957, Val Loss: 0.0070, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0046, Train Acc: 0.9995, Val Loss: 0.0054, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0038, Train Acc: 0.9996, Val Loss: 0.0048, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0044, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0038, Train Acc: 0.9995, Val Loss: 0.0025, Val Acc: 0.9993
Epoch 16/50, Train Loss: 0.0033, Train Acc: 0.9995, Val Loss: 0.0038, Val Acc: 0.9993
Epoch 17/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0039, Val Acc: 0.9993
Epoch 18/50, Train Loss: 0.0030, Train Acc: 0.9996, Val Loss: 0.0036, Val Acc: 0.9993
Epoch 19/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0051, Val Acc: 0.9993
Epoch 20/50, Train Loss: 0.0029, Train Acc: 0.9997, Val Loss: 0.0047, Val Acc: 0.9993
Early stopping!

Run 3/10
Epoch 1/50, Train Loss: 1.4047, Train Acc: 0.3542, Val Loss: 0.7612, Val Acc: 0.5508
Epoch 2/50, Train Loss: 0.7742, Train Acc: 0.6721, Val Loss: 0.4818, Val Acc: 0.7979
Epoch 3/50, Train Loss: 1.0805, Train Acc: 0.6356, Val Loss: 0.5940, Val Acc: 0.7522
Epoch 4/50, Train Loss: 0.4391, Train Acc: 0.8340, Val Loss: 0.3663, Val Acc: 0.8042
Epoch 5/50, Train Loss: 0.3941, Train Acc: 0.8306, Val Loss: 0.5884, Val Acc: 0.7961
Epoch 6/50, Train Loss: 0.3057, Train Acc: 0.8517, Val Loss: 0.0287, Val Acc: 0.9978
Epoch 7/50, Train Loss: 0.3577, Train Acc: 0.8866, Val Loss: 0.1386, Val Acc: 0.9976
Epoch 8/50, Train Loss: 0.3772, Train Acc: 0.8961, Val Loss: 0.0618, Val Acc: 0.9902
Epoch 9/50, Train Loss: 0.8835, Train Acc: 0.8365, Val Loss: 0.1268, Val Acc: 0.9963
Epoch 10/50, Train Loss: 0.1705, Train Acc: 0.9315, Val Loss: 0.2910, Val Acc: 0.8035
Epoch 11/50, Train Loss: 0.0122, Train Acc: 0.9965, Val Loss: 0.0108, Val Acc: 0.9988
Epoch 12/50, Train Loss: 0.0067, Train Acc: 0.9995, Val Loss: 0.0086, Val Acc: 0.9990
Epoch 13/50, Train Loss: 0.0061, Train Acc: 0.9994, Val Loss: 0.0097, Val Acc: 0.9988
Epoch 14/50, Train Loss: 0.0055, Train Acc: 0.9995, Val Loss: 0.0062, Val Acc: 0.9990
Epoch 15/50, Train Loss: 0.0051, Train Acc: 0.9993, Val Loss: 0.0055, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0046, Train Acc: 0.9993, Val Loss: 0.0039, Val Acc: 0.9990
Epoch 17/50, Train Loss: 0.0040, Train Acc: 0.9995, Val Loss: 0.0020, Val Acc: 0.9988
Epoch 18/50, Train Loss: 0.0045, Train Acc: 0.9995, Val Loss: 0.0029, Val Acc: 0.9990
Epoch 19/50, Train Loss: 0.0048, Train Acc: 0.9996, Val Loss: 0.0015, Val Acc: 0.9993
Epoch 20/50, Train Loss: 0.0208, Train Acc: 0.9947, Val Loss: 0.0039, Val Acc: 0.9993
Epoch 21/50, Train Loss: 0.0036, Train Acc: 0.9997, Val Loss: 0.0031, Val Acc: 0.9993
Epoch 22/50, Train Loss: 0.0036, Train Acc: 0.9996, Val Loss: 0.0031, Val Acc: 0.9993
Epoch 23/50, Train Loss: 0.0033, Train Acc: 0.9997, Val Loss: 0.0029, Val Acc: 0.9993
Epoch 24/50, Train Loss: 0.0035, Train Acc: 0.9996, Val Loss: 0.0029, Val Acc: 0.9993
Early stopping!

Run 4/10
Epoch 1/50, Train Loss: 1.1591, Train Acc: 0.4854, Val Loss: 0.6625, Val Acc: 0.7166
Epoch 2/50, Train Loss: 0.7482, Train Acc: 0.7332, Val Loss: 0.2500, Val Acc: 0.8035
Epoch 3/50, Train Loss: 0.6717, Train Acc: 0.7927, Val Loss: 0.2144, Val Acc: 0.8376
Epoch 4/50, Train Loss: 0.2212, Train Acc: 0.8335, Val Loss: 0.1686, Val Acc: 0.8040
Epoch 5/50, Train Loss: 0.2325, Train Acc: 0.8882, Val Loss: 0.4987, Val Acc: 0.8003
Epoch 6/50, Train Loss: 0.8426, Train Acc: 0.7786, Val Loss: 0.7920, Val Acc: 0.6021
Epoch 7/50, Train Loss: 0.6976, Train Acc: 0.8078, Val Loss: 1.8163, Val Acc: 0.7659
Epoch 8/50, Train Loss: 1.1932, Train Acc: 0.7847, Val Loss: 0.1789, Val Acc: 0.8518
Epoch 9/50, Train Loss: 0.2241, Train Acc: 0.9064, Val Loss: 0.6389, Val Acc: 0.8010
Early stopping!

Run 5/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.3175, Train Acc: 0.4148, Val Loss: 0.3892, Val Acc: 0.7944
Epoch 2/50, Train Loss: 0.9866, Train Acc: 0.6652, Val Loss: 1.2007, Val Acc: 0.5042
Epoch 3/50, Train Loss: 0.7008, Train Acc: 0.6981, Val Loss: 1.6050, Val Acc: 0.4431
Epoch 4/50, Train Loss: 0.6761, Train Acc: 0.7245, Val Loss: 0.2256, Val Acc: 0.8801
Epoch 5/50, Train Loss: 1.1021, Train Acc: 0.7698, Val Loss: 0.3521, Val Acc: 0.7988
Epoch 6/50, Train Loss: 0.5388, Train Acc: 0.8051, Val Loss: 0.0772, Val Acc: 0.9922
Epoch 7/50, Train Loss: 0.9735, Train Acc: 0.7964, Val Loss: 0.3775, Val Acc: 0.7969
Epoch 8/50, Train Loss: 0.5011, Train Acc: 0.8398, Val Loss: 0.3994, Val Acc: 0.8022
Epoch 9/50, Train Loss: 0.3416, Train Acc: 0.9149, Val Loss: 0.0337, Val Acc: 0.9963
Epoch 10/50, Train Loss: 0.2420, Train Acc: 0.9513, Val Loss: 0.0101, Val Acc: 0.9985
Epoch 11/50, Train Loss: 0.0039, Train Acc: 0.9996, Val Loss: 0.0057, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0036, Train Acc: 0.9996, Val Loss: 0.0047, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0031, Train Acc: 0.9996, Val Loss: 0.0041, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0026, Train Acc: 0.9995, Val Loss: 0.0036, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0026, Train Acc: 0.9995, Val Loss: 0.0040, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0021, Train Acc: 0.9997, Val Loss: 0.0029, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0019, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0023, Train Acc: 0.9997, Val Loss: 0.0021, Val Acc: 0.9993
Epoch 19/50, Train Loss: 0.0022, Train Acc: 0.9997, Val Loss: 0.0027, Val Acc: 0.9990
Epoch 20/50, Train Loss: 0.0019, Train Acc: 0.9997, Val Loss: 0.0021, Val Acc: 0.9993
Epoch 21/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0019, Val Acc: 0.9990
Epoch 22/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0019, Val Acc: 0.9990
Epoch 23/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0020, Val Acc: 0.9990
Epoch 24/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0022, Val Acc: 0.9993
Epoch 25/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0022, Val Acc: 0.9993
Epoch 26/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0017, Val Acc: 0.9990
Epoch 27/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9990
Epoch 28/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0016, Val Acc: 0.9990
Epoch 29/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9990
Epoch 30/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9990
Epoch 31/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9990
Epoch 32/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0016, Val Acc: 0.9990
Early stopping!

Run 6/10
Epoch 1/50, Train Loss: 1.4415, Train Acc: 0.3524, Val Loss: 0.8768, Val Acc: 0.3960
Epoch 2/50, Train Loss: 0.6683, Train Acc: 0.6075, Val Loss: 0.3536, Val Acc: 0.9949
Epoch 3/50, Train Loss: 0.3562, Train Acc: 0.7864, Val Loss: 0.2145, Val Acc: 0.8035
Epoch 4/50, Train Loss: 0.3134, Train Acc: 0.8503, Val Loss: 0.1357, Val Acc: 0.9956
Epoch 5/50, Train Loss: 0.2400, Train Acc: 0.8888, Val Loss: 0.1284, Val Acc: 0.9688
Epoch 6/50, Train Loss: 0.1755, Train Acc: 0.8740, Val Loss: 0.0833, Val Acc: 0.9978
Epoch 7/50, Train Loss: 0.6436, Train Acc: 0.8015, Val Loss: 0.0709, Val Acc: 0.9985
Epoch 8/50, Train Loss: 0.3147, Train Acc: 0.8411, Val Loss: 0.3043, Val Acc: 0.7993
Epoch 9/50, Train Loss: 0.2412, Train Acc: 0.8685, Val Loss: 0.1187, Val Acc: 0.9932
Epoch 10/50, Train Loss: 0.1846, Train Acc: 0.8940, Val Loss: 0.2987, Val Acc: 0.8066
Epoch 11/50, Train Loss: 0.0157, Train Acc: 0.9964, Val Loss: 0.0119, Val Acc: 0.9990
Epoch 12/50, Train Loss: 0.0061, Train Acc: 0.9992, Val Loss: 0.0092, Val Acc: 0.9985
Epoch 13/50, Train Loss: 0.0040, Train Acc: 0.9995, Val Loss: 0.0036, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0033, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0030, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0026, Val Acc: 0.9993
Epoch 17/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0045, Val Acc: 0.9990
Epoch 18/50, Train Loss: 0.0030, Train Acc: 0.9996, Val Loss: 0.0064, Val Acc: 0.9985
Epoch 19/50, Train Loss: 0.0042, Train Acc: 0.9991, Val Loss: 0.0044, Val Acc: 0.9988
Epoch 20/50, Train Loss: 0.0016, Train Acc: 0.9996, Val Loss: 0.0056, Val Acc: 0.9990
Early stopping!

Run 7/10
Epoch 1/50, Train Loss: 1.2382, Train Acc: 0.4302, Val Loss: 0.3288, Val Acc: 0.9966
Epoch 2/50, Train Loss: 0.8129, Train Acc: 0.6461, Val Loss: 0.5593, Val Acc: 0.6196
Epoch 3/50, Train Loss: 0.7681, Train Acc: 0.6566, Val Loss: 1.3738, Val Acc: 0.3970
Epoch 4/50, Train Loss: 0.5381, Train Acc: 0.7788, Val Loss: 0.1574, Val Acc: 0.9949
Epoch 5/50, Train Loss: 0.5697, Train Acc: 0.8478, Val Loss: 0.6461, Val Acc: 0.7983
Epoch 6/50, Train Loss: 0.6951, Train Acc: 0.8220, Val Loss: 0.0121, Val Acc: 0.9993
Epoch 7/50, Train Loss: 0.5527, Train Acc: 0.9189, Val Loss: 0.0157, Val Acc: 0.9988
Epoch 8/50, Train Loss: 0.4961, Train Acc: 0.9153, Val Loss: 0.0169, Val Acc: 0.9990
Epoch 9/50, Train Loss: 0.4494, Train Acc: 0.9194, Val Loss: 0.4780, Val Acc: 0.8008
Epoch 10/50, Train Loss: 0.2740, Train Acc: 0.9484, Val Loss: 0.0133, Val Acc: 0.9988
Epoch 11/50, Train Loss: 0.0048, Train Acc: 0.9995, Val Loss: 0.0057, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0038, Train Acc: 0.9996, Val Loss: 0.0042, Val Acc: 0.9993
Epoch 13/50, Train Loss: 0.0030, Train Acc: 0.9998, Val Loss: 0.0036, Val Acc: 0.9993
Epoch 14/50, Train Loss: 0.0033, Train Acc: 0.9997, Val Loss: 0.0027, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0008, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0027, Train Acc: 0.9997, Val Loss: 0.0010, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0022, Train Acc: 0.9997, Val Loss: 0.0028, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0022, Train Acc: 0.9997, Val Loss: 0.0018, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0022, Train Acc: 0.9997, Val Loss: 0.0014, Val Acc: 0.9993
Epoch 20/50, Train Loss: 0.0020, Train Acc: 0.9997, Val Loss: 0.0030, Val Acc: 0.9993
Early stopping!

Run 8/10
Epoch 1/50, Train Loss: 1.1303, Train Acc: 0.4351, Val Loss: 0.6438, Val Acc: 0.6282
Epoch 2/50, Train Loss: 0.7535, Train Acc: 0.6866, Val Loss: 1.8991, Val Acc: 0.4292
Epoch 3/50, Train Loss: 0.8795, Train Acc: 0.5771, Val Loss: 0.6865, Val Acc: 0.5874
Epoch 4/50, Train Loss: 0.5177, Train Acc: 0.7540, Val Loss: 0.2685, Val Acc: 0.8010
Epoch 5/50, Train Loss: 0.3018, Train Acc: 0.8714, Val Loss: 0.0833, Val Acc: 0.9980
Epoch 6/50, Train Loss: 0.1744, Train Acc: 0.9011, Val Loss: 0.2691, Val Acc: 0.8154
Epoch 7/50, Train Loss: 0.1503, Train Acc: 0.9296, Val Loss: 0.0101, Val Acc: 0.9985
Epoch 8/50, Train Loss: 1.3152, Train Acc: 0.8032, Val Loss: 0.0414, Val Acc: 0.9993
Epoch 9/50, Train Loss: 0.6313, Train Acc: 0.8627, Val Loss: 2.2297, Val Acc: 0.7979
Epoch 10/50, Train Loss: 0.4669, Train Acc: 0.9168, Val Loss: 0.0086, Val Acc: 0.9988
Epoch 11/50, Train Loss: 0.0033, Train Acc: 0.9996, Val Loss: 0.0041, Val Acc: 0.9990
Epoch 12/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0040, Val Acc: 0.9993
Epoch 13/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0043, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0033, Val Acc: 0.9990
Epoch 15/50, Train Loss: 0.0026, Train Acc: 0.9997, Val Loss: 0.0038, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0024, Train Acc: 0.9998, Val Loss: 0.0042, Val Acc: 0.9988
Epoch 17/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0036, Val Acc: 0.9988
Epoch 18/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0039, Val Acc: 0.9988
Epoch 19/50, Train Loss: 0.0111, Train Acc: 0.9960, Val Loss: 0.0045, Val Acc: 0.9993
Early stopping!

Run 9/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.2485, Train Acc: 0.3792, Val Loss: 0.5521, Val Acc: 0.7981
Epoch 2/50, Train Loss: 0.6086, Train Acc: 0.6489, Val Loss: 0.4441, Val Acc: 0.7546
Epoch 3/50, Train Loss: 0.9044, Train Acc: 0.6649, Val Loss: 0.3766, Val Acc: 0.7764
Epoch 4/50, Train Loss: 0.6922, Train Acc: 0.7614, Val Loss: 0.2694, Val Acc: 0.9734
Epoch 5/50, Train Loss: 0.5657, Train Acc: 0.8378, Val Loss: 0.0156, Val Acc: 0.9983
Epoch 6/50, Train Loss: 0.6321, Train Acc: 0.8557, Val Loss: 0.0973, Val Acc: 0.9878
Epoch 7/50, Train Loss: 0.1930, Train Acc: 0.9315, Val Loss: 0.1551, Val Acc: 0.9189
Epoch 8/50, Train Loss: 0.7948, Train Acc: 0.8500, Val Loss: 0.4544, Val Acc: 0.8042
Epoch 9/50, Train Loss: 0.4080, Train Acc: 0.8959, Val Loss: 0.0194, Val Acc: 0.9983
Epoch 10/50, Train Loss: 0.6178, Train Acc: 0.8531, Val Loss: 0.1589, Val Acc: 0.8037
Early stopping!

Run 10/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Train Loss: 1.2812, Train Acc: 0.3990, Val Loss: 0.5625, Val Acc: 0.9214
Epoch 2/50, Train Loss: 0.6143, Train Acc: 0.6549, Val Loss: 0.4411, Val Acc: 0.7063
Epoch 3/50, Train Loss: 0.9529, Train Acc: 0.6991, Val Loss: 0.6521, Val Acc: 0.7041
Epoch 4/50, Train Loss: 0.4390, Train Acc: 0.8202, Val Loss: 0.2853, Val Acc: 0.8057
Epoch 5/50, Train Loss: 0.7514, Train Acc: 0.7943, Val Loss: 0.3309, Val Acc: 0.8027
Epoch 6/50, Train Loss: 0.1666, Train Acc: 0.9157, Val Loss: 1.9332, Val Acc: 0.5222
Epoch 7/50, Train Loss: 0.9747, Train Acc: 0.8273, Val Loss: 0.0208, Val Acc: 0.9980
Epoch 8/50, Train Loss: 0.6524, Train Acc: 0.8561, Val Loss: 1.6020, Val Acc: 0.6909
Epoch 9/50, Train Loss: 0.4945, Train Acc: 0.8504, Val Loss: 0.2652, Val Acc: 0.8042
Epoch 10/50, Train Loss: 0.2644, Train Acc: 0.8990, Val Loss: 0.3832, Val Acc: 0.8032
Epoch 11/50, Train Loss: 0.0103, Train Acc: 0.9969, Val Loss: 0.0082, Val Acc: 0.9993
Epoch 12/50, Train Loss: 0.0044, Train Acc: 0.9993, Val Loss: 0.0064, Val Acc: 0.9993
Epoch 13/50, Train Loss: 0.0034, Train Acc: 0.9993, Val Loss: 0.0040, Val Acc: 0.9990
Epoch 14/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0033, Val Acc: 0.9993
Epoch 15/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0051, Val Acc: 0.9990
Epoch 16/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0032, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0110, Train Acc: 0.9954, Val Loss: 0.0018, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0034, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9988
Epoch 20/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0038, Val Acc: 0.9993
Epoch 21/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0027, Val Acc: 0.9993
Epoch 22/50, Train Loss: 0.0011, Train Acc: 0.9998, Val Loss: 0.0026, Val Acc: 0.9995
Early stopping!

Source performance: 95.99 95.82 95.94 94.69
Target performance: 57.26 59.35 56.62 49.65

bpsk: 90.00
qpsk: 92.15
4qam: 99.76
16qam: 0.13
apsk: 1.05
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1071, Domain Loss: 1.4109, Class Loss: 1.6962
Epoch 2/25, Loss: 3.2818, Domain Loss: 1.6401, Class Loss: 1.6418
Epoch 3/25, Loss: 2.7643, Domain Loss: 1.3867, Class Loss: 1.3776
Epoch 4/25, Loss: 2.4275, Domain Loss: 1.3569, Class Loss: 1.0706
Epoch 5/25, Loss: 2.4688, Domain Loss: 1.4124, Class Loss: 1.0564
Epoch 6/25, Loss: 1.9821, Domain Loss: 1.3244, Class Loss: 0.6576
Epoch 7/25, Loss: 1.8985, Domain Loss: 1.3370, Class Loss: 0.5615
Epoch 8/25, Loss: 2.2865, Domain Loss: 1.4416, Class Loss: 0.8449
Epoch 9/25, Loss: 1.6410, Domain Loss: 1.3147, Class Loss: 0.3263
Epoch 10/25, Loss: 1.5916, Domain Loss: 1.3063, Class Loss: 0.2853
Epoch 11/25, Loss: 1.5558, Domain Loss: 1.3053, Class Loss: 0.2505
Epoch 12/25, Loss: 1.6574, Domain Loss: 1.2652, Class Loss: 0.3922
Epoch 13/25, Loss: 1.4921, Domain Loss: 1.2500, Class Loss: 0.2420
Epoch 14/25, Loss: 1.3892, Domain Loss: 1.2390, Class Loss: 0.1503
Epoch 15/25, Loss: 1.9477, Domain Loss: 1.2407, Class Loss: 0.7069
Epoch 16/25, Loss: 1.5746, Domain Loss: 1.2383, Class Loss: 0.3363
Epoch 17/25, Loss: 1.4048, Domain Loss: 1.2345, Class Loss: 0.1703
Epoch 18/25, Loss: 1.3218, Domain Loss: 1.2310, Class Loss: 0.0908
Epoch 19/25, Loss: 1.2798, Domain Loss: 1.2382, Class Loss: 0.0416
Epoch 20/25, Loss: 1.5137, Domain Loss: 1.2360, Class Loss: 0.2777
Epoch 21/25, Loss: 1.3173, Domain Loss: 1.2275, Class Loss: 0.0898
Epoch 22/25, Loss: 1.2623, Domain Loss: 1.2339, Class Loss: 0.0283
Epoch 23/25, Loss: 1.2524, Domain Loss: 1.2394, Class Loss: 0.0130
Epoch 24/25, Loss: 1.2496, Domain Loss: 1.2411, Class Loss: 0.0085
Epoch 25/25, Loss: 1.5029, Domain Loss: 1.2467, Class Loss: 0.2561
60.47


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.0965, Domain Loss: 1.4032, Class Loss: 1.6933
Epoch 2/25, Loss: 2.8519, Domain Loss: 1.4675, Class Loss: 1.3844
Epoch 3/25, Loss: 2.3317, Domain Loss: 1.3056, Class Loss: 1.0262
Epoch 4/25, Loss: 2.2910, Domain Loss: 1.2944, Class Loss: 0.9966
Epoch 5/25, Loss: 2.0759, Domain Loss: 1.2603, Class Loss: 0.8157
Epoch 6/25, Loss: 2.0972, Domain Loss: 1.2753, Class Loss: 0.8220
Epoch 7/25, Loss: 1.7997, Domain Loss: 1.2510, Class Loss: 0.5487
Epoch 8/25, Loss: 1.8063, Domain Loss: 1.2357, Class Loss: 0.5706
Epoch 9/25, Loss: 1.5717, Domain Loss: 1.2276, Class Loss: 0.3441
Epoch 10/25, Loss: 1.4997, Domain Loss: 1.1848, Class Loss: 0.3148
Epoch 11/25, Loss: 1.4683, Domain Loss: 1.1505, Class Loss: 0.3177
Epoch 12/25, Loss: 7.1359, Domain Loss: 4.0413, Class Loss: 3.0946
Epoch 13/25, Loss: 8.0820, Domain Loss: 6.1045, Class Loss: 1.9776
Epoch 14/25, Loss: 11.8510, Domain Loss: 10.0913, Class Loss: 1.7597
Epoch 15/25, Loss: 8.5221, Domain Loss: 6.9119, Class Loss: 1.6102
Epoch 16/25, Loss: 11.9701, Domain Loss: 10.4149, Class Loss: 1.5552
Epoch 17/25, Loss: 12.3766, Domain Loss: 11.1594, Class Loss: 1.2172
Epoch 18/25, Loss: 7.8325, Domain Loss: 7.0137, Class Loss: 0.8188
Epoch 19/25, Loss: 4.2912, Domain Loss: 2.9527, Class Loss: 1.3386
Epoch 20/25, Loss: 2.8956, Domain Loss: 1.7875, Class Loss: 1.1081
Epoch 21/25, Loss: 2.7700, Domain Loss: 1.7116, Class Loss: 1.0584
Epoch 22/25, Loss: 2.5062, Domain Loss: 1.6981, Class Loss: 0.8081
Epoch 23/25, Loss: 3.0268, Domain Loss: 1.8586, Class Loss: 1.1682
Epoch 24/25, Loss: 2.5934, Domain Loss: 1.5683, Class Loss: 1.0251
Epoch 25/25, Loss: 2.0318, Domain Loss: 1.5271, Class Loss: 0.5047
20.58


Epoch 1/25, Loss: 3.0793, Domain Loss: 1.4046, Class Loss: 1.6747
Epoch 2/25, Loss: 2.7126, Domain Loss: 1.3665, Class Loss: 1.3461
Epoch 3/25, Loss: 2.9536, Domain Loss: 1.3429, Class Loss: 1.6107
Epoch 4/25, Loss: 2.7624, Domain Loss: 1.3228, Class Loss: 1.4396
Epoch 5/25, Loss: 2.2758, Domain Loss: 1.3003, Class Loss: 0.9755
Epoch 6/25, Loss: 2.4122, Domain Loss: 1.3336, Class Loss: 1.0787
Epoch 7/25, Loss: 1.8924, Domain Loss: 1.2974, Class Loss: 0.5950
Epoch 8/25, Loss: 2.0908, Domain Loss: 1.3083, Class Loss: 0.7825
Epoch 9/25, Loss: 1.7509, Domain Loss: 1.3086, Class Loss: 0.4423
Epoch 10/25, Loss: 1.5241, Domain Loss: 1.2562, Class Loss: 0.2680
Epoch 11/25, Loss: 2.5305, Domain Loss: 1.2537, Class Loss: 1.2768
Epoch 12/25, Loss: 1.7191, Domain Loss: 1.2317, Class Loss: 0.4874
Epoch 13/25, Loss: 1.5399, Domain Loss: 1.2316, Class Loss: 0.3083
Epoch 14/25, Loss: 1.4595, Domain Loss: 1.2252, Class Loss: 0.2344
Epoch 15/25, Loss: 1.3994, Domain Loss: 1.2328, Class Loss: 0.1666
Epoch 16/25, Loss: 1.7474, Domain Loss: 1.2387, Class Loss: 0.5087
Epoch 17/25, Loss: 1.9503, Domain Loss: 1.2381, Class Loss: 0.7122
Epoch 18/25, Loss: 1.4984, Domain Loss: 1.2286, Class Loss: 0.2698
Epoch 19/25, Loss: 1.4505, Domain Loss: 1.2319, Class Loss: 0.2186
Epoch 20/25, Loss: 1.3496, Domain Loss: 1.1897, Class Loss: 0.1599
Epoch 21/25, Loss: 1.3642, Domain Loss: 1.1248, Class Loss: 0.2394
Epoch 22/25, Loss: 1.2572, Domain Loss: 1.0648, Class Loss: 0.1924
Epoch 23/25, Loss: 1.2115, Domain Loss: 1.0633, Class Loss: 0.1482
Epoch 24/25, Loss: 2.3862, Domain Loss: 1.2015, Class Loss: 1.1847
Epoch 25/25, Loss: 1.5991, Domain Loss: 1.2257, Class Loss: 0.3733
60.06


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1649, Domain Loss: 1.4508, Class Loss: 1.7141
Epoch 2/25, Loss: 2.8238, Domain Loss: 1.3625, Class Loss: 1.4613
Epoch 3/25, Loss: 2.4129, Domain Loss: 1.2797, Class Loss: 1.1332
Epoch 4/25, Loss: 2.2535, Domain Loss: 1.2640, Class Loss: 0.9895
Epoch 5/25, Loss: 2.3591, Domain Loss: 1.2775, Class Loss: 1.0816
Epoch 6/25, Loss: 1.8606, Domain Loss: 1.2381, Class Loss: 0.6225
Epoch 7/25, Loss: 2.2827, Domain Loss: 1.2673, Class Loss: 1.0154
Epoch 8/25, Loss: 2.1530, Domain Loss: 1.2738, Class Loss: 0.8792
Epoch 9/25, Loss: 1.5590, Domain Loss: 1.2289, Class Loss: 0.3301
Epoch 10/25, Loss: 1.7105, Domain Loss: 1.2293, Class Loss: 0.4812
Epoch 11/25, Loss: 1.5378, Domain Loss: 1.2378, Class Loss: 0.3000
Epoch 12/25, Loss: 1.3945, Domain Loss: 1.1672, Class Loss: 0.2273
Epoch 13/25, Loss: 1.2250, Domain Loss: 1.0680, Class Loss: 0.1570
Epoch 14/25, Loss: 1.7560, Domain Loss: 1.2012, Class Loss: 0.5547
Epoch 15/25, Loss: 2.6580, Domain Loss: 1.6872, Class Loss: 0.9708
Epoch 16/25, Loss: 1.6512, Domain Loss: 1.2668, Class Loss: 0.3844
Epoch 17/25, Loss: 1.4769, Domain Loss: 1.2335, Class Loss: 0.2433
Epoch 18/25, Loss: 1.4257, Domain Loss: 1.2362, Class Loss: 0.1895
Epoch 19/25, Loss: 1.4697, Domain Loss: 1.3153, Class Loss: 0.1544
Epoch 20/25, Loss: 2.7928, Domain Loss: 1.5191, Class Loss: 1.2736
Epoch 21/25, Loss: 1.6001, Domain Loss: 1.1952, Class Loss: 0.4048
Epoch 22/25, Loss: 1.4203, Domain Loss: 1.1170, Class Loss: 0.3033
Epoch 23/25, Loss: 1.2668, Domain Loss: 1.1090, Class Loss: 0.1578
Epoch 24/25, Loss: 5.2521, Domain Loss: 2.3700, Class Loss: 2.8821
Epoch 25/25, Loss: 5.4855, Domain Loss: 4.7038, Class Loss: 0.7817
33.52


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1597, Domain Loss: 1.4543, Class Loss: 1.7054
Epoch 2/25, Loss: 3.0174, Domain Loss: 1.4022, Class Loss: 1.6151
Epoch 3/25, Loss: 2.9150, Domain Loss: 1.4299, Class Loss: 1.4852
Epoch 4/25, Loss: 2.4224, Domain Loss: 1.3407, Class Loss: 1.0817
Epoch 5/25, Loss: 2.1879, Domain Loss: 1.3157, Class Loss: 0.8722
Epoch 6/25, Loss: 1.8753, Domain Loss: 1.3086, Class Loss: 0.5667
Epoch 7/25, Loss: 1.8291, Domain Loss: 1.2535, Class Loss: 0.5756
Epoch 8/25, Loss: 1.4716, Domain Loss: 1.2431, Class Loss: 0.2285
Epoch 9/25, Loss: 2.0437, Domain Loss: 1.2340, Class Loss: 0.8097
Epoch 10/25, Loss: 1.5046, Domain Loss: 1.2393, Class Loss: 0.2653
Epoch 11/25, Loss: 1.5267, Domain Loss: 1.2388, Class Loss: 0.2879
Epoch 12/25, Loss: 1.4390, Domain Loss: 1.2389, Class Loss: 0.2002
Epoch 13/25, Loss: 1.5977, Domain Loss: 1.2300, Class Loss: 0.3677
Epoch 14/25, Loss: 1.4700, Domain Loss: 1.2350, Class Loss: 0.2349
Epoch 15/25, Loss: 1.4336, Domain Loss: 1.2421, Class Loss: 0.1915
Epoch 16/25, Loss: 1.3555, Domain Loss: 1.2271, Class Loss: 0.1284
Epoch 17/25, Loss: 1.7776, Domain Loss: 1.2395, Class Loss: 0.5381
Epoch 18/25, Loss: 1.4070, Domain Loss: 1.2305, Class Loss: 0.1765
Epoch 19/25, Loss: 1.3156, Domain Loss: 1.2425, Class Loss: 0.0731
Epoch 20/25, Loss: 1.2642, Domain Loss: 1.2293, Class Loss: 0.0350
Epoch 21/25, Loss: 1.2380, Domain Loss: 1.2331, Class Loss: 0.0049
Epoch 22/25, Loss: 1.2471, Domain Loss: 1.2358, Class Loss: 0.0113
Epoch 23/25, Loss: 1.2188, Domain Loss: 1.2155, Class Loss: 0.0033
Epoch 24/25, Loss: 2.0727, Domain Loss: 1.2194, Class Loss: 0.8533
Epoch 25/25, Loss: 1.5111, Domain Loss: 1.2275, Class Loss: 0.2836
60.11


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1121, Domain Loss: 1.4275, Class Loss: 1.6846
Epoch 2/25, Loss: 2.5996, Domain Loss: 1.3300, Class Loss: 1.2696
Epoch 3/25, Loss: 2.1831, Domain Loss: 1.2608, Class Loss: 0.9223
Epoch 4/25, Loss: 1.8905, Domain Loss: 1.2369, Class Loss: 0.6535
Epoch 5/25, Loss: 1.8009, Domain Loss: 1.2904, Class Loss: 0.5105
Epoch 6/25, Loss: 1.6598, Domain Loss: 1.2216, Class Loss: 0.4382
Epoch 7/25, Loss: 1.5389, Domain Loss: 1.2313, Class Loss: 0.3076
Epoch 8/25, Loss: 1.4873, Domain Loss: 1.2381, Class Loss: 0.2492
Epoch 9/25, Loss: 1.7464, Domain Loss: 1.2332, Class Loss: 0.5132
Epoch 10/25, Loss: 1.7463, Domain Loss: 1.2312, Class Loss: 0.5151
Epoch 11/25, Loss: 1.4313, Domain Loss: 1.2268, Class Loss: 0.2045
Epoch 12/25, Loss: 1.3002, Domain Loss: 1.2219, Class Loss: 0.0783
Epoch 13/25, Loss: 1.7292, Domain Loss: 1.2328, Class Loss: 0.4964
Epoch 14/25, Loss: 1.4360, Domain Loss: 1.2250, Class Loss: 0.2110
Epoch 15/25, Loss: 1.3451, Domain Loss: 1.2317, Class Loss: 0.1135
Epoch 16/25, Loss: 1.2572, Domain Loss: 1.2330, Class Loss: 0.0242
Epoch 17/25, Loss: 2.6886, Domain Loss: 1.3289, Class Loss: 1.3598
Epoch 18/25, Loss: 1.6025, Domain Loss: 1.2545, Class Loss: 0.3480
Epoch 19/25, Loss: 1.4201, Domain Loss: 1.2368, Class Loss: 0.1833
Epoch 20/25, Loss: 1.3839, Domain Loss: 1.2368, Class Loss: 0.1471
Epoch 21/25, Loss: 1.3390, Domain Loss: 1.2341, Class Loss: 0.1049
Epoch 22/25, Loss: 1.3534, Domain Loss: 1.2308, Class Loss: 0.1226
Epoch 23/25, Loss: 1.3374, Domain Loss: 1.2285, Class Loss: 0.1089
Epoch 24/25, Loss: 1.2447, Domain Loss: 1.2245, Class Loss: 0.0202
Epoch 25/25, Loss: 1.2430, Domain Loss: 1.2302, Class Loss: 0.0128
60.42


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1324, Domain Loss: 1.4186, Class Loss: 1.7139
Epoch 2/25, Loss: 3.0234, Domain Loss: 1.4011, Class Loss: 1.6222
Epoch 3/25, Loss: 2.9832, Domain Loss: 1.4399, Class Loss: 1.5433
Epoch 4/25, Loss: 3.0029, Domain Loss: 1.6686, Class Loss: 1.3342
Epoch 5/25, Loss: 2.4636, Domain Loss: 1.4469, Class Loss: 1.0167
Epoch 6/25, Loss: 2.7164, Domain Loss: 1.6329, Class Loss: 1.0836
Epoch 7/25, Loss: 2.1325, Domain Loss: 1.3503, Class Loss: 0.7822
Epoch 8/25, Loss: 1.7883, Domain Loss: 1.3196, Class Loss: 0.4687
Epoch 9/25, Loss: 1.8550, Domain Loss: 1.3000, Class Loss: 0.5550
Epoch 10/25, Loss: 1.5147, Domain Loss: 1.2731, Class Loss: 0.2415
Epoch 11/25, Loss: 1.5035, Domain Loss: 1.2456, Class Loss: 0.2580
Epoch 12/25, Loss: 1.8287, Domain Loss: 1.2700, Class Loss: 0.5586
Epoch 13/25, Loss: 1.3759, Domain Loss: 1.2338, Class Loss: 0.1421
Epoch 14/25, Loss: 1.8476, Domain Loss: 1.2381, Class Loss: 0.6095
Epoch 15/25, Loss: 1.7598, Domain Loss: 1.2471, Class Loss: 0.5127
Epoch 16/25, Loss: 1.3594, Domain Loss: 1.2535, Class Loss: 0.1059
Epoch 17/25, Loss: 1.4325, Domain Loss: 1.2395, Class Loss: 0.1930
Epoch 18/25, Loss: 1.3261, Domain Loss: 1.2331, Class Loss: 0.0930
Epoch 19/25, Loss: 1.2487, Domain Loss: 1.2234, Class Loss: 0.0252
Epoch 20/25, Loss: 1.2434, Domain Loss: 1.2279, Class Loss: 0.0155
Epoch 21/25, Loss: 1.2481, Domain Loss: 1.2381, Class Loss: 0.0100
Epoch 22/25, Loss: 1.2467, Domain Loss: 1.2381, Class Loss: 0.0086
Epoch 23/25, Loss: 1.2437, Domain Loss: 1.2360, Class Loss: 0.0077
Epoch 24/25, Loss: 1.2506, Domain Loss: 1.2423, Class Loss: 0.0083
Epoch 25/25, Loss: 1.2398, Domain Loss: 1.2382, Class Loss: 0.0016
59.64


Epoch 1/25, Loss: 3.1180, Domain Loss: 1.4358, Class Loss: 1.6821
Epoch 2/25, Loss: 2.6958, Domain Loss: 1.3495, Class Loss: 1.3463
Epoch 3/25, Loss: 2.6164, Domain Loss: 1.3023, Class Loss: 1.3142
Epoch 4/25, Loss: 1.9751, Domain Loss: 1.2508, Class Loss: 0.7243
Epoch 5/25, Loss: 4.9909, Domain Loss: 1.7946, Class Loss: 3.1963
Epoch 6/25, Loss: 2.9851, Domain Loss: 1.3790, Class Loss: 1.6060
Epoch 7/25, Loss: 2.9310, Domain Loss: 1.3782, Class Loss: 1.5527
Epoch 8/25, Loss: 2.7125, Domain Loss: 1.3779, Class Loss: 1.3345
Epoch 9/25, Loss: 3.1905, Domain Loss: 1.3899, Class Loss: 1.8006
Epoch 10/25, Loss: 2.4820, Domain Loss: 1.3328, Class Loss: 1.1492
Epoch 11/25, Loss: 2.7809, Domain Loss: 1.5934, Class Loss: 1.1875
Epoch 12/25, Loss: 3.3694, Domain Loss: 1.9070, Class Loss: 1.4624
Epoch 13/25, Loss: 2.1541, Domain Loss: 1.3150, Class Loss: 0.8391
Epoch 14/25, Loss: 1.9570, Domain Loss: 1.3191, Class Loss: 0.6380
Epoch 15/25, Loss: 1.8001, Domain Loss: 1.3075, Class Loss: 0.4925
Epoch 16/25, Loss: 2.0971, Domain Loss: 1.3128, Class Loss: 0.7842
Epoch 17/25, Loss: 1.6697, Domain Loss: 1.3108, Class Loss: 0.3590
Epoch 18/25, Loss: 1.6360, Domain Loss: 1.3103, Class Loss: 0.3258
Epoch 19/25, Loss: 2.0066, Domain Loss: 1.3230, Class Loss: 0.6835
Epoch 20/25, Loss: 1.6151, Domain Loss: 1.3040, Class Loss: 0.3112
Epoch 21/25, Loss: 1.5035, Domain Loss: 1.2882, Class Loss: 0.2153
Epoch 22/25, Loss: 1.6034, Domain Loss: 1.2807, Class Loss: 0.3227
Epoch 23/25, Loss: 1.8215, Domain Loss: 1.2811, Class Loss: 0.5404
Epoch 24/25, Loss: 1.5177, Domain Loss: 1.2774, Class Loss: 0.2404
Epoch 25/25, Loss: 1.4537, Domain Loss: 1.2634, Class Loss: 0.1903
40.26


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1006, Domain Loss: 1.4070, Class Loss: 1.6936
Epoch 2/25, Loss: 3.0804, Domain Loss: 1.4567, Class Loss: 1.6237
Epoch 3/25, Loss: 2.7825, Domain Loss: 1.4024, Class Loss: 1.3802
Epoch 4/25, Loss: 2.6295, Domain Loss: 1.4723, Class Loss: 1.1571
Epoch 5/25, Loss: 2.0929, Domain Loss: 1.3131, Class Loss: 0.7799
Epoch 6/25, Loss: 2.1313, Domain Loss: 1.2742, Class Loss: 0.8571
Epoch 7/25, Loss: 1.7779, Domain Loss: 1.2446, Class Loss: 0.5333
Epoch 8/25, Loss: 1.5208, Domain Loss: 1.2425, Class Loss: 0.2782
Epoch 9/25, Loss: 1.8325, Domain Loss: 1.2421, Class Loss: 0.5904
Epoch 10/25, Loss: 1.5098, Domain Loss: 1.2306, Class Loss: 0.2792
Epoch 11/25, Loss: 1.4282, Domain Loss: 1.2288, Class Loss: 0.1994
Epoch 12/25, Loss: 1.3418, Domain Loss: 1.2331, Class Loss: 0.1088
Epoch 13/25, Loss: 1.4375, Domain Loss: 1.2416, Class Loss: 0.1959
Epoch 14/25, Loss: 1.7579, Domain Loss: 1.2300, Class Loss: 0.5280
Epoch 15/25, Loss: 1.4538, Domain Loss: 1.2296, Class Loss: 0.2241
Epoch 16/25, Loss: 1.2514, Domain Loss: 1.1785, Class Loss: 0.0729
Epoch 17/25, Loss: 1.8343, Domain Loss: 1.1597, Class Loss: 0.6746
Epoch 18/25, Loss: 1.3075, Domain Loss: 1.1051, Class Loss: 0.2024
Epoch 19/25, Loss: 1.1869, Domain Loss: 1.0703, Class Loss: 0.1166
Epoch 20/25, Loss: 1.1160, Domain Loss: 1.0542, Class Loss: 0.0618
Epoch 21/25, Loss: 1.6339, Domain Loss: 1.1023, Class Loss: 0.5316
Epoch 22/25, Loss: 1.6872, Domain Loss: 1.1213, Class Loss: 0.5659
Epoch 23/25, Loss: 1.1489, Domain Loss: 1.0500, Class Loss: 0.0989
Epoch 24/25, Loss: 1.0824, Domain Loss: 1.0508, Class Loss: 0.0315
Epoch 25/25, Loss: 1.0591, Domain Loss: 1.0491, Class Loss: 0.0100
60.40


Epoch 1/25, Loss: 3.1469, Domain Loss: 1.4364, Class Loss: 1.7105
Epoch 2/25, Loss: 2.9281, Domain Loss: 1.3752, Class Loss: 1.5529
Epoch 3/25, Loss: 2.3954, Domain Loss: 1.3016, Class Loss: 1.0937
Epoch 4/25, Loss: 2.3440, Domain Loss: 1.2813, Class Loss: 1.0627
Epoch 5/25, Loss: 3.4944, Domain Loss: 1.4406, Class Loss: 2.0538
Epoch 6/25, Loss: 2.9403, Domain Loss: 1.3703, Class Loss: 1.5700
Epoch 7/25, Loss: 2.7959, Domain Loss: 1.3705, Class Loss: 1.4254
Epoch 8/25, Loss: 2.5278, Domain Loss: 1.3576, Class Loss: 1.1702
Epoch 9/25, Loss: 2.4623, Domain Loss: 1.3359, Class Loss: 1.1264
Epoch 10/25, Loss: 2.4478, Domain Loss: 1.3724, Class Loss: 1.0755
Epoch 11/25, Loss: 2.0853, Domain Loss: 1.3287, Class Loss: 0.7566
Epoch 12/25, Loss: 2.2195, Domain Loss: 1.3145, Class Loss: 0.9050
Epoch 13/25, Loss: 1.8471, Domain Loss: 1.3045, Class Loss: 0.5426
Epoch 14/25, Loss: 2.8453, Domain Loss: 1.4019, Class Loss: 1.4435
Epoch 15/25, Loss: 2.3328, Domain Loss: 1.3561, Class Loss: 0.9767
Epoch 16/25, Loss: 1.9357, Domain Loss: 1.3218, Class Loss: 0.6139
Epoch 17/25, Loss: 1.6451, Domain Loss: 1.3202, Class Loss: 0.3250
Epoch 18/25, Loss: 2.3656, Domain Loss: 1.3401, Class Loss: 1.0254
Epoch 19/25, Loss: 1.8250, Domain Loss: 1.3056, Class Loss: 0.5194
Epoch 20/25, Loss: 1.5448, Domain Loss: 1.2919, Class Loss: 0.2529
Epoch 21/25, Loss: 1.6927, Domain Loss: 1.2825, Class Loss: 0.4102
Epoch 22/25, Loss: 1.5400, Domain Loss: 1.2813, Class Loss: 0.2587
Epoch 23/25, Loss: 1.4897, Domain Loss: 1.2693, Class Loss: 0.2205
Epoch 24/25, Loss: 1.5747, Domain Loss: 1.2725, Class Loss: 0.3022
Epoch 25/25, Loss: 1.4583, Domain Loss: 1.2810, Class Loss: 0.1772
41.94


Source performance:
88.32 88.92 88.35 85.93 
Target performance:
49.74 46.76 49.19 41.14 

Per-class target performance: 90.00 77.10 78.48 0.18 0.21 
Run 1/10
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch [1/50], Class Loss: 3.2757, Discrepancy Loss: 0.1008
Epoch [2/50], Class Loss: 0.7377, Discrepancy Loss: 0.0934
Epoch [3/50], Class Loss: 0.7327, Discrepancy Loss: 0.0835
Epoch [4/50], Class Loss: 0.4256, Discrepancy Loss: 0.0805
Epoch [5/50], Class Loss: 0.3930, Discrepancy Loss: 0.0758
Epoch [6/50], Class Loss: 0.3212, Discrepancy Loss: 0.0641
Epoch [7/50], Class Loss: 0.2292, Discrepancy Loss: 0.0549
Epoch [8/50], Class Loss: 0.2137, Discrepancy Loss: 0.0683
Epoch [9/50], Class Loss: 0.0928, Discrepancy Loss: 0.0482
Epoch [10/50], Class Loss: 0.2526, Discrepancy Loss: 0.0588
Epoch [11/50], Class Loss: 0.1718, Discrepancy Loss: 0.0786
Epoch [12/50], Class Loss: 0.0863, Discrepancy Loss: 0.0685
Epoch [13/50], Class Loss: 0.0464, Discrepancy Loss: 0.0532
Epoch [14/50], Class Loss: 0.0453, Discrepancy Loss: 0.0594
Epoch [15/50], Class Loss: 0.0436, Discrepancy Loss: 0.0419
Epoch [16/50], Class Loss: 0.0485, Discrepancy Loss: 0.0510
Epoch [17/50], Class Loss: 0.0374, Discrepancy Loss: 0.0380
Epoch [18/50], Class Loss: 0.0399, Discrepancy Loss: 0.0521
Epoch [19/50], Class Loss: 0.0353, Discrepancy Loss: 0.0473
Epoch [20/50], Class Loss: 0.0328, Discrepancy Loss: 0.0413
Epoch [21/50], Class Loss: 0.0255, Discrepancy Loss: 0.0613
Epoch [22/50], Class Loss: 0.0352, Discrepancy Loss: 0.0565
Epoch [23/50], Class Loss: 0.0395, Discrepancy Loss: 0.0530
Epoch [24/50], Class Loss: 0.0381, Discrepancy Loss: 0.0571
Epoch [25/50], Class Loss: 0.0437, Discrepancy Loss: 0.0579
Epoch [26/50], Class Loss: 0.0385, Discrepancy Loss: 0.0639
Epoch [27/50], Class Loss: 0.0426, Discrepancy Loss: 0.0586
Epoch [28/50], Class Loss: 0.0335, Discrepancy Loss: 0.0579
Epoch [29/50], Class Loss: 0.0394, Discrepancy Loss: 0.0527
Epoch [30/50], Class Loss: 0.0280, Discrepancy Loss: 0.0497
Epoch [31/50], Class Loss: 0.0358, Discrepancy Loss: 0.0525
Epoch [32/50], Class Loss: 0.0360, Discrepancy Loss: 0.0497
Epoch [33/50], Class Loss: 0.0283, Discrepancy Loss: 0.0509
Epoch [34/50], Class Loss: 0.0301, Discrepancy Loss: 0.0538
Epoch [35/50], Class Loss: 0.0297, Discrepancy Loss: 0.0505
Epoch [36/50], Class Loss: 0.0297, Discrepancy Loss: 0.0493
Epoch [37/50], Class Loss: 0.0344, Discrepancy Loss: 0.0480
Epoch [38/50], Class Loss: 0.0327, Discrepancy Loss: 0.0507
Epoch [39/50], Class Loss: 0.0349, Discrepancy Loss: 0.0486
Epoch [40/50], Class Loss: 0.0247, Discrepancy Loss: 0.0436
Epoch [41/50], Class Loss: 0.0326, Discrepancy Loss: 0.0463
Epoch [42/50], Class Loss: 0.0328, Discrepancy Loss: 0.0478
Epoch [43/50], Class Loss: 0.0292, Discrepancy Loss: 0.0509
Epoch [44/50], Class Loss: 0.0307, Discrepancy Loss: 0.0470
Epoch [45/50], Class Loss: 0.0323, Discrepancy Loss: 0.0510
Epoch [46/50], Class Loss: 0.0298, Discrepancy Loss: 0.0429
Epoch [47/50], Class Loss: 0.0349, Discrepancy Loss: 0.0466
Epoch [48/50], Class Loss: 0.0266, Discrepancy Loss: 0.0481
Epoch [49/50], Class Loss: 0.0379, Discrepancy Loss: 0.0467
Epoch [50/50], Class Loss: 0.0368, Discrepancy Loss: 0.0502
Source Domain Performance - Accuracy: 97.27%, Precision: 97.57%, Recall: 97.35%, F1 Score: 97.29%
Target Domain Performance - Accuracy: 78.88%, Precision: 76.55%, Recall: 78.20%, F1 Score: 71.91%

Run 2/10
Epoch [1/50], Class Loss: 3.4666, Discrepancy Loss: 0.0939
Epoch [2/50], Class Loss: 0.6692, Discrepancy Loss: 0.0901
Epoch [3/50], Class Loss: 0.5291, Discrepancy Loss: 0.0817
Epoch [4/50], Class Loss: 0.5124, Discrepancy Loss: 0.0810
Epoch [5/50], Class Loss: 0.5760, Discrepancy Loss: 0.0829
Epoch [6/50], Class Loss: 0.2968, Discrepancy Loss: 0.0718
Epoch [7/50], Class Loss: 0.2835, Discrepancy Loss: 0.0718
Epoch [8/50], Class Loss: 0.2136, Discrepancy Loss: 0.0678
Epoch [9/50], Class Loss: 0.1926, Discrepancy Loss: 0.0646
Epoch [10/50], Class Loss: 0.2070, Discrepancy Loss: 0.0643
Epoch [11/50], Class Loss: 0.1534, Discrepancy Loss: 0.0467
Epoch [12/50], Class Loss: 0.0819, Discrepancy Loss: 0.0409
Epoch [13/50], Class Loss: 0.0434, Discrepancy Loss: 0.0365
Epoch [14/50], Class Loss: 0.0384, Discrepancy Loss: 0.0375
Epoch [15/50], Class Loss: 0.0417, Discrepancy Loss: 0.0363
Epoch [16/50], Class Loss: 0.0235, Discrepancy Loss: 0.0340
Epoch [17/50], Class Loss: 0.0291, Discrepancy Loss: 0.0431
Epoch [18/50], Class Loss: 0.0433, Discrepancy Loss: 0.0488
Epoch [19/50], Class Loss: 0.0336, Discrepancy Loss: 0.0543
Epoch [20/50], Class Loss: 0.0427, Discrepancy Loss: 0.0788
Epoch [21/50], Class Loss: 0.0347, Discrepancy Loss: 0.0917
Epoch [22/50], Class Loss: 0.0325, Discrepancy Loss: 0.0964
Epoch [23/50], Class Loss: 0.0329, Discrepancy Loss: 0.0935
Epoch [24/50], Class Loss: 0.0353, Discrepancy Loss: 0.0867
Epoch [25/50], Class Loss: 0.0378, Discrepancy Loss: 0.0902
Epoch [26/50], Class Loss: 0.0315, Discrepancy Loss: 0.0910
Epoch [27/50], Class Loss: 0.0261, Discrepancy Loss: 0.0873
Epoch [28/50], Class Loss: 0.0271, Discrepancy Loss: 0.0901
Epoch [29/50], Class Loss: 0.0248, Discrepancy Loss: 0.0842
Epoch [30/50], Class Loss: 0.0236, Discrepancy Loss: 0.0825
Epoch [31/50], Class Loss: 0.0236, Discrepancy Loss: 0.0790
Epoch [32/50], Class Loss: 0.0279, Discrepancy Loss: 0.0760
Epoch [33/50], Class Loss: 0.0203, Discrepancy Loss: 0.0799
Epoch [34/50], Class Loss: 0.0245, Discrepancy Loss: 0.0798
Epoch [35/50], Class Loss: 0.0204, Discrepancy Loss: 0.0845
Epoch [36/50], Class Loss: 0.0284, Discrepancy Loss: 0.0849
Epoch [37/50], Class Loss: 0.0271, Discrepancy Loss: 0.0831
Epoch [38/50], Class Loss: 0.0235, Discrepancy Loss: 0.0842
Epoch [39/50], Class Loss: 0.0278, Discrepancy Loss: 0.0873
Epoch [40/50], Class Loss: 0.0248, Discrepancy Loss: 0.0851
Epoch [41/50], Class Loss: 0.0226, Discrepancy Loss: 0.0815
Epoch [42/50], Class Loss: 0.0250, Discrepancy Loss: 0.0831
Epoch [43/50], Class Loss: 0.0215, Discrepancy Loss: 0.0841
Epoch [44/50], Class Loss: 0.0253, Discrepancy Loss: 0.0854
Epoch [45/50], Class Loss: 0.0243, Discrepancy Loss: 0.0833
Epoch [46/50], Class Loss: 0.0251, Discrepancy Loss: 0.0891
Epoch [47/50], Class Loss: 0.0215, Discrepancy Loss: 0.0834
Epoch [48/50], Class Loss: 0.0207, Discrepancy Loss: 0.0868
Epoch [49/50], Class Loss: 0.0168, Discrepancy Loss: 0.0825
Epoch [50/50], Class Loss: 0.0237, Discrepancy Loss: 0.0825
Source Domain Performance - Accuracy: 98.88%, Precision: 98.93%, Recall: 98.91%, F1 Score: 98.89%
Target Domain Performance - Accuracy: 72.75%, Precision: 70.20%, Recall: 72.08%, F1 Score: 68.61%

Run 3/10
Epoch [1/50], Class Loss: 3.3916, Discrepancy Loss: 0.0943
Epoch [2/50], Class Loss: 0.7704, Discrepancy Loss: 0.0946
Epoch [3/50], Class Loss: 0.6030, Discrepancy Loss: 0.0854
Epoch [4/50], Class Loss: 0.5062, Discrepancy Loss: 0.0835
Epoch [5/50], Class Loss: 0.3639, Discrepancy Loss: 0.0771
Epoch [6/50], Class Loss: 0.3422, Discrepancy Loss: 0.0867
Epoch [7/50], Class Loss: 0.3339, Discrepancy Loss: 0.0786
Epoch [8/50], Class Loss: 0.2847, Discrepancy Loss: 0.0793
Epoch [9/50], Class Loss: 0.2709, Discrepancy Loss: 0.0831
Epoch [10/50], Class Loss: 0.2629, Discrepancy Loss: 0.0759
Epoch [11/50], Class Loss: 0.0631, Discrepancy Loss: 0.0489
Epoch [12/50], Class Loss: 0.0520, Discrepancy Loss: 0.0424
Epoch [13/50], Class Loss: 0.0370, Discrepancy Loss: 0.0541
Epoch [14/50], Class Loss: 0.0403, Discrepancy Loss: 0.0468
Epoch [15/50], Class Loss: 0.0592, Discrepancy Loss: 0.0652
Epoch [16/50], Class Loss: 0.0375, Discrepancy Loss: 0.0668
Epoch [17/50], Class Loss: 0.0413, Discrepancy Loss: 0.0784
Epoch [18/50], Class Loss: 0.0334, Discrepancy Loss: 0.0639
Epoch [19/50], Class Loss: 0.0575, Discrepancy Loss: 0.0793
Epoch [20/50], Class Loss: 0.0424, Discrepancy Loss: 0.0935
Epoch [21/50], Class Loss: 0.0297, Discrepancy Loss: 0.0924
Epoch [22/50], Class Loss: 0.0383, Discrepancy Loss: 0.0953
Epoch [23/50], Class Loss: 0.0285, Discrepancy Loss: 0.0978
Epoch [24/50], Class Loss: 0.0262, Discrepancy Loss: 0.1041
Epoch [25/50], Class Loss: 0.0254, Discrepancy Loss: 0.1016
Epoch [26/50], Class Loss: 0.0272, Discrepancy Loss: 0.1047
Epoch [27/50], Class Loss: 0.0228, Discrepancy Loss: 0.0997
Epoch [28/50], Class Loss: 0.0217, Discrepancy Loss: 0.1018
Epoch [29/50], Class Loss: 0.0233, Discrepancy Loss: 0.1019
Epoch [30/50], Class Loss: 0.0273, Discrepancy Loss: 0.0992
Epoch [31/50], Class Loss: 0.0213, Discrepancy Loss: 0.1045
Epoch [32/50], Class Loss: 0.0211, Discrepancy Loss: 0.1132
Epoch [33/50], Class Loss: 0.0226, Discrepancy Loss: 0.1120
Epoch [34/50], Class Loss: 0.0227, Discrepancy Loss: 0.1082
Epoch [35/50], Class Loss: 0.0205, Discrepancy Loss: 0.1036
Epoch [36/50], Class Loss: 0.0187, Discrepancy Loss: 0.1098
Epoch [37/50], Class Loss: 0.0229, Discrepancy Loss: 0.1060
Epoch [38/50], Class Loss: 0.0248, Discrepancy Loss: 0.1086
Epoch [39/50], Class Loss: 0.0224, Discrepancy Loss: 0.1048
Epoch [40/50], Class Loss: 0.0219, Discrepancy Loss: 0.1069
Epoch [41/50], Class Loss: 0.0228, Discrepancy Loss: 0.1020
Epoch [42/50], Class Loss: 0.0177, Discrepancy Loss: 0.1087
Epoch [43/50], Class Loss: 0.0245, Discrepancy Loss: 0.1005
Epoch [44/50], Class Loss: 0.0242, Discrepancy Loss: 0.1072
Epoch [45/50], Class Loss: 0.0191, Discrepancy Loss: 0.1091
Epoch [46/50], Class Loss: 0.0192, Discrepancy Loss: 0.1007
Epoch [47/50], Class Loss: 0.0242, Discrepancy Loss: 0.1079
Epoch [48/50], Class Loss: 0.0197, Discrepancy Loss: 0.1043
Epoch [49/50], Class Loss: 0.0194, Discrepancy Loss: 0.1068
Epoch [50/50], Class Loss: 0.0221, Discrepancy Loss: 0.1055
Source Domain Performance - Accuracy: 98.12%, Precision: 98.24%, Recall: 98.17%, F1 Score: 98.14%
Target Domain Performance - Accuracy: 69.46%, Precision: 69.94%, Recall: 68.79%, F1 Score: 65.61%

Run 4/10
Epoch [1/50], Class Loss: 4.6242, Discrepancy Loss: 0.0871
Epoch [2/50], Class Loss: 0.7707, Discrepancy Loss: 0.0965
Epoch [3/50], Class Loss: 0.4847, Discrepancy Loss: 0.0874
Epoch [4/50], Class Loss: 0.4481, Discrepancy Loss: 0.0903
Epoch [5/50], Class Loss: 0.3647, Discrepancy Loss: 0.0827
Epoch [6/50], Class Loss: 0.2860, Discrepancy Loss: 0.0780
Epoch [7/50], Class Loss: 0.5889, Discrepancy Loss: 0.0698
Epoch [8/50], Class Loss: 0.3307, Discrepancy Loss: 0.0596
Epoch [9/50], Class Loss: 0.2808, Discrepancy Loss: 0.0740
Epoch [10/50], Class Loss: 0.2546, Discrepancy Loss: 0.0733
Epoch [11/50], Class Loss: 0.0977, Discrepancy Loss: 0.0677
Epoch [12/50], Class Loss: 0.0469, Discrepancy Loss: 0.0673
Epoch [13/50], Class Loss: 0.0549, Discrepancy Loss: 0.0517
Epoch [14/50], Class Loss: 0.0400, Discrepancy Loss: 0.0416
Epoch [15/50], Class Loss: 0.0501, Discrepancy Loss: 0.0543
Epoch [16/50], Class Loss: 0.0463, Discrepancy Loss: 0.0397
Epoch [17/50], Class Loss: 0.0413, Discrepancy Loss: 0.0395
Epoch [18/50], Class Loss: 0.0530, Discrepancy Loss: 0.0471
Epoch [19/50], Class Loss: 0.0627, Discrepancy Loss: 0.0487
Epoch [20/50], Class Loss: 0.0487, Discrepancy Loss: 0.0431
Epoch [21/50], Class Loss: 0.0310, Discrepancy Loss: 0.0467
Epoch [22/50], Class Loss: 0.0301, Discrepancy Loss: 0.0489
Epoch [23/50], Class Loss: 0.0277, Discrepancy Loss: 0.0564
Epoch [24/50], Class Loss: 0.0344, Discrepancy Loss: 0.0583
Epoch [25/50], Class Loss: 0.0328, Discrepancy Loss: 0.0580
Epoch [26/50], Class Loss: 0.0327, Discrepancy Loss: 0.0597
Epoch [27/50], Class Loss: 0.0338, Discrepancy Loss: 0.0565
Epoch [28/50], Class Loss: 0.0349, Discrepancy Loss: 0.0613
Epoch [29/50], Class Loss: 0.0323, Discrepancy Loss: 0.0596
Epoch [30/50], Class Loss: 0.0387, Discrepancy Loss: 0.0667
Epoch [31/50], Class Loss: 0.0288, Discrepancy Loss: 0.0636
Epoch [32/50], Class Loss: 0.0344, Discrepancy Loss: 0.0611
Epoch [33/50], Class Loss: 0.0289, Discrepancy Loss: 0.0660
Epoch [34/50], Class Loss: 0.0332, Discrepancy Loss: 0.0638
Epoch [35/50], Class Loss: 0.0337, Discrepancy Loss: 0.0642
Epoch [36/50], Class Loss: 0.0420, Discrepancy Loss: 0.0638
Epoch [37/50], Class Loss: 0.0263, Discrepancy Loss: 0.0637
Epoch [38/50], Class Loss: 0.0376, Discrepancy Loss: 0.0651
Epoch [39/50], Class Loss: 0.0316, Discrepancy Loss: 0.0685
Epoch [40/50], Class Loss: 0.0325, Discrepancy Loss: 0.0659
Epoch [41/50], Class Loss: 0.0334, Discrepancy Loss: 0.0678
Epoch [42/50], Class Loss: 0.0312, Discrepancy Loss: 0.0652
Epoch [43/50], Class Loss: 0.0288, Discrepancy Loss: 0.0616
Epoch [44/50], Class Loss: 0.0352, Discrepancy Loss: 0.0621
Epoch [45/50], Class Loss: 0.0350, Discrepancy Loss: 0.0658
Epoch [46/50], Class Loss: 0.0287, Discrepancy Loss: 0.0698
Epoch [47/50], Class Loss: 0.0322, Discrepancy Loss: 0.0675
Epoch [48/50], Class Loss: 0.0294, Discrepancy Loss: 0.0682
Epoch [49/50], Class Loss: 0.0365, Discrepancy Loss: 0.0660
Epoch [50/50], Class Loss: 0.0378, Discrepancy Loss: 0.0632
Source Domain Performance - Accuracy: 94.24%, Precision: 95.50%, Recall: 94.41%, F1 Score: 94.23%
Target Domain Performance - Accuracy: 78.17%, Precision: 70.89%, Recall: 77.49%, F1 Score: 72.20%

Run 5/10
Epoch [1/50], Class Loss: 3.3745, Discrepancy Loss: 0.0942
Epoch [2/50], Class Loss: 0.7120, Discrepancy Loss: 0.0936
Epoch [3/50], Class Loss: 0.5902, Discrepancy Loss: 0.0911
Epoch [4/50], Class Loss: 0.8777, Discrepancy Loss: 0.0710
Epoch [5/50], Class Loss: 0.4040, Discrepancy Loss: 0.0686
Epoch [6/50], Class Loss: 0.2936, Discrepancy Loss: 0.0633
Epoch [7/50], Class Loss: 0.2821, Discrepancy Loss: 0.0549
Epoch [8/50], Class Loss: 0.2651, Discrepancy Loss: 0.0651
Epoch [9/50], Class Loss: 0.2192, Discrepancy Loss: 0.0618
Epoch [10/50], Class Loss: 0.2441, Discrepancy Loss: 0.0610
Epoch [11/50], Class Loss: 0.0247, Discrepancy Loss: 0.0471
Epoch [12/50], Class Loss: 0.0350, Discrepancy Loss: 0.0498
Epoch [13/50], Class Loss: 0.1232, Discrepancy Loss: 0.0425
Epoch [14/50], Class Loss: 0.0281, Discrepancy Loss: 0.0370
Epoch [15/50], Class Loss: 0.0391, Discrepancy Loss: 0.0447
Epoch [16/50], Class Loss: 0.0322, Discrepancy Loss: 0.0682
Epoch [17/50], Class Loss: 0.0469, Discrepancy Loss: 0.0686
Epoch [18/50], Class Loss: 0.0904, Discrepancy Loss: 0.0719
Epoch [19/50], Class Loss: 0.0315, Discrepancy Loss: 0.0658
Epoch [20/50], Class Loss: 0.0332, Discrepancy Loss: 0.0658
Epoch [21/50], Class Loss: 0.0388, Discrepancy Loss: 0.0604
Epoch [22/50], Class Loss: 0.0381, Discrepancy Loss: 0.0740
Epoch [23/50], Class Loss: 0.0363, Discrepancy Loss: 0.0789
Epoch [24/50], Class Loss: 0.0409, Discrepancy Loss: 0.0857
Epoch [25/50], Class Loss: 0.0319, Discrepancy Loss: 0.0998
Epoch [26/50], Class Loss: 0.0300, Discrepancy Loss: 0.0927
Epoch [27/50], Class Loss: 0.0288, Discrepancy Loss: 0.0684
Epoch [28/50], Class Loss: 0.0306, Discrepancy Loss: 0.0707
Epoch [29/50], Class Loss: 0.0393, Discrepancy Loss: 0.0774
Epoch [30/50], Class Loss: 0.0339, Discrepancy Loss: 0.0815
Epoch [31/50], Class Loss: 0.0531, Discrepancy Loss: 0.0862
Epoch [32/50], Class Loss: 0.0360, Discrepancy Loss: 0.0923
Epoch [33/50], Class Loss: 0.0397, Discrepancy Loss: 0.0922
Epoch [34/50], Class Loss: 0.0447, Discrepancy Loss: 0.0838
Epoch [35/50], Class Loss: 0.0389, Discrepancy Loss: 0.0859
Epoch [36/50], Class Loss: 0.0357, Discrepancy Loss: 0.0852
Epoch [37/50], Class Loss: 0.0428, Discrepancy Loss: 0.0872
Epoch [38/50], Class Loss: 0.0352, Discrepancy Loss: 0.0895
Epoch [39/50], Class Loss: 0.0366, Discrepancy Loss: 0.0898
Epoch [40/50], Class Loss: 0.0380, Discrepancy Loss: 0.0842
Epoch [41/50], Class Loss: 0.0413, Discrepancy Loss: 0.0924
Epoch [42/50], Class Loss: 0.0342, Discrepancy Loss: 0.0878
Epoch [43/50], Class Loss: 0.0390, Discrepancy Loss: 0.0915
Epoch [44/50], Class Loss: 0.0417, Discrepancy Loss: 0.0869
Epoch [45/50], Class Loss: 0.0350, Discrepancy Loss: 0.0855
Epoch [46/50], Class Loss: 0.0444, Discrepancy Loss: 0.0861
Epoch [47/50], Class Loss: 0.0399, Discrepancy Loss: 0.0897
Epoch [48/50], Class Loss: 0.0417, Discrepancy Loss: 0.0815
Epoch [49/50], Class Loss: 0.0323, Discrepancy Loss: 0.0927
Epoch [50/50], Class Loss: 0.0362, Discrepancy Loss: 0.0926
Source Domain Performance - Accuracy: 90.87%, Precision: 93.66%, Recall: 91.15%, F1 Score: 90.59%
Target Domain Performance - Accuracy: 80.13%, Precision: 74.32%, Recall: 79.45%, F1 Score: 73.26%

Run 6/10
Epoch [1/50], Class Loss: 3.7502, Discrepancy Loss: 0.0940
Epoch [2/50], Class Loss: 0.6827, Discrepancy Loss: 0.0909
Epoch [3/50], Class Loss: 0.5386, Discrepancy Loss: 0.0771
Epoch [4/50], Class Loss: 0.4605, Discrepancy Loss: 0.0808
Epoch [5/50], Class Loss: 0.3618, Discrepancy Loss: 0.0713
Epoch [6/50], Class Loss: 0.2970, Discrepancy Loss: 0.0633
Epoch [7/50], Class Loss: 0.3090, Discrepancy Loss: 0.0735
Epoch [8/50], Class Loss: 0.2867, Discrepancy Loss: 0.0607
Epoch [9/50], Class Loss: 0.2384, Discrepancy Loss: 0.0652
Epoch [10/50], Class Loss: 0.2034, Discrepancy Loss: 0.0603
Epoch [11/50], Class Loss: 0.0719, Discrepancy Loss: 0.0441
Epoch [12/50], Class Loss: 0.0409, Discrepancy Loss: 0.0388
Epoch [13/50], Class Loss: 0.0371, Discrepancy Loss: 0.0416
Epoch [14/50], Class Loss: 0.0333, Discrepancy Loss: 0.0407
Epoch [15/50], Class Loss: 0.0282, Discrepancy Loss: 0.0411
Epoch [16/50], Class Loss: 0.0281, Discrepancy Loss: 0.0443
Epoch [17/50], Class Loss: 0.0529, Discrepancy Loss: 0.0531
Epoch [18/50], Class Loss: 0.0314, Discrepancy Loss: 0.0455
Epoch [19/50], Class Loss: 0.0393, Discrepancy Loss: 0.0632
Epoch [20/50], Class Loss: 0.0494, Discrepancy Loss: 0.0829
Epoch [21/50], Class Loss: 0.0343, Discrepancy Loss: 0.0841
Epoch [22/50], Class Loss: 0.0266, Discrepancy Loss: 0.0935
Epoch [23/50], Class Loss: 0.0281, Discrepancy Loss: 0.0954
Epoch [24/50], Class Loss: 0.0231, Discrepancy Loss: 0.0926
Epoch [25/50], Class Loss: 0.0226, Discrepancy Loss: 0.0957
Epoch [26/50], Class Loss: 0.0188, Discrepancy Loss: 0.1091
Epoch [27/50], Class Loss: 0.0168, Discrepancy Loss: 0.1163
Epoch [28/50], Class Loss: 0.0157, Discrepancy Loss: 0.1245
Epoch [29/50], Class Loss: 0.0116, Discrepancy Loss: 0.1266
Epoch [30/50], Class Loss: 0.0114, Discrepancy Loss: 0.1360
Epoch [31/50], Class Loss: 0.0119, Discrepancy Loss: 0.1364
Epoch [32/50], Class Loss: 0.0119, Discrepancy Loss: 0.1398
Epoch [33/50], Class Loss: 0.0120, Discrepancy Loss: 0.1407
Epoch [34/50], Class Loss: 0.0121, Discrepancy Loss: 0.1402
Epoch [35/50], Class Loss: 0.0120, Discrepancy Loss: 0.1367
Epoch [36/50], Class Loss: 0.0098, Discrepancy Loss: 0.1401
Epoch [37/50], Class Loss: 0.0084, Discrepancy Loss: 0.1373
Epoch [38/50], Class Loss: 0.0095, Discrepancy Loss: 0.1374
Epoch [39/50], Class Loss: 0.0087, Discrepancy Loss: 0.1322
Epoch [40/50], Class Loss: 0.0119, Discrepancy Loss: 0.1277
Epoch [41/50], Class Loss: 0.0115, Discrepancy Loss: 0.1236
Epoch [42/50], Class Loss: 0.0120, Discrepancy Loss: 0.1290
Epoch [43/50], Class Loss: 0.0101, Discrepancy Loss: 0.1218
Epoch [44/50], Class Loss: 0.0107, Discrepancy Loss: 0.1214
Epoch [45/50], Class Loss: 0.0120, Discrepancy Loss: 0.1207
Epoch [46/50], Class Loss: 0.0097, Discrepancy Loss: 0.1230
Epoch [47/50], Class Loss: 0.0108, Discrepancy Loss: 0.1200
Epoch [48/50], Class Loss: 0.0100, Discrepancy Loss: 0.1224
Epoch [49/50], Class Loss: 0.0122, Discrepancy Loss: 0.1244
Epoch [50/50], Class Loss: 0.0088, Discrepancy Loss: 0.1192
Source Domain Performance - Accuracy: 99.02%, Precision: 99.05%, Recall: 99.05%, F1 Score: 99.03%
Target Domain Performance - Accuracy: 61.06%, Precision: 68.21%, Recall: 60.40%, F1 Score: 54.23%

Run 7/10
Epoch [1/50], Class Loss: 4.3226, Discrepancy Loss: 0.0861
Epoch [2/50], Class Loss: 0.8270, Discrepancy Loss: 0.0976
Epoch [3/50], Class Loss: 0.5520, Discrepancy Loss: 0.0807
Epoch [4/50], Class Loss: 0.4772, Discrepancy Loss: 0.0746
Epoch [5/50], Class Loss: 0.3863, Discrepancy Loss: 0.0667
Epoch [6/50], Class Loss: 0.4020, Discrepancy Loss: 0.0866
Epoch [7/50], Class Loss: 0.3298, Discrepancy Loss: 0.0945
Epoch [8/50], Class Loss: 0.5439, Discrepancy Loss: 0.0736
Epoch [9/50], Class Loss: 0.2824, Discrepancy Loss: 0.0737
Epoch [10/50], Class Loss: 0.2702, Discrepancy Loss: 0.0780
Epoch [11/50], Class Loss: 0.0914, Discrepancy Loss: 0.0583
Epoch [12/50], Class Loss: 0.0815, Discrepancy Loss: 0.0585
Epoch [13/50], Class Loss: 0.0496, Discrepancy Loss: 0.0624
Epoch [14/50], Class Loss: 0.0440, Discrepancy Loss: 0.0692
Epoch [15/50], Class Loss: 0.0371, Discrepancy Loss: 0.0759
Epoch [16/50], Class Loss: 0.0673, Discrepancy Loss: 0.0659
Epoch [17/50], Class Loss: 0.0495, Discrepancy Loss: 0.0600
Epoch [18/50], Class Loss: 0.0543, Discrepancy Loss: 0.0532
Epoch [19/50], Class Loss: 0.0353, Discrepancy Loss: 0.0719
Epoch [20/50], Class Loss: 0.0373, Discrepancy Loss: 0.0869
Epoch [21/50], Class Loss: 0.0239, Discrepancy Loss: 0.1022
Epoch [22/50], Class Loss: 0.0188, Discrepancy Loss: 0.1041
Epoch [23/50], Class Loss: 0.0152, Discrepancy Loss: 0.0996
Epoch [24/50], Class Loss: 0.0172, Discrepancy Loss: 0.1092
Epoch [25/50], Class Loss: 0.0198, Discrepancy Loss: 0.1067
Epoch [26/50], Class Loss: 0.0161, Discrepancy Loss: 0.1015
Epoch [27/50], Class Loss: 0.0153, Discrepancy Loss: 0.1066
Epoch [28/50], Class Loss: 0.0175, Discrepancy Loss: 0.1111
Epoch [29/50], Class Loss: 0.0200, Discrepancy Loss: 0.1164
Epoch [30/50], Class Loss: 0.0199, Discrepancy Loss: 0.1086
Epoch [31/50], Class Loss: 0.0198, Discrepancy Loss: 0.1067
Epoch [32/50], Class Loss: 0.0148, Discrepancy Loss: 0.1167
Epoch [33/50], Class Loss: 0.0174, Discrepancy Loss: 0.1097
Epoch [34/50], Class Loss: 0.0135, Discrepancy Loss: 0.1090
Epoch [35/50], Class Loss: 0.0172, Discrepancy Loss: 0.1145
Epoch [36/50], Class Loss: 0.0138, Discrepancy Loss: 0.1077
Epoch [37/50], Class Loss: 0.0133, Discrepancy Loss: 0.1116
Epoch [38/50], Class Loss: 0.0143, Discrepancy Loss: 0.1093
Epoch [39/50], Class Loss: 0.0110, Discrepancy Loss: 0.1131
Epoch [40/50], Class Loss: 0.0160, Discrepancy Loss: 0.1094
Epoch [41/50], Class Loss: 0.0152, Discrepancy Loss: 0.1102
Epoch [42/50], Class Loss: 0.0191, Discrepancy Loss: 0.1093
Epoch [43/50], Class Loss: 0.0166, Discrepancy Loss: 0.1112
Epoch [44/50], Class Loss: 0.0131, Discrepancy Loss: 0.1094
Epoch [45/50], Class Loss: 0.0139, Discrepancy Loss: 0.1069
Epoch [46/50], Class Loss: 0.0162, Discrepancy Loss: 0.1117
Epoch [47/50], Class Loss: 0.0162, Discrepancy Loss: 0.1177
Epoch [48/50], Class Loss: 0.0162, Discrepancy Loss: 0.1128
Epoch [49/50], Class Loss: 0.0143, Discrepancy Loss: 0.1109
Epoch [50/50], Class Loss: 0.0133, Discrepancy Loss: 0.1085
Source Domain Performance - Accuracy: 99.54%, Precision: 99.54%, Recall: 99.55%, F1 Score: 99.54%
Target Domain Performance - Accuracy: 60.79%, Precision: 65.58%, Recall: 60.13%, F1 Score: 53.94%

Run 8/10
Epoch [1/50], Class Loss: 4.6192, Discrepancy Loss: 0.0834
Epoch [2/50], Class Loss: 1.0134, Discrepancy Loss: 0.0876
Epoch [3/50], Class Loss: 0.5632, Discrepancy Loss: 0.0744
Epoch [4/50], Class Loss: 0.4784, Discrepancy Loss: 0.0707
Epoch [5/50], Class Loss: 0.3157, Discrepancy Loss: 0.0740
Epoch [6/50], Class Loss: 0.3898, Discrepancy Loss: 0.0672
Epoch [7/50], Class Loss: 0.2747, Discrepancy Loss: 0.0621
Epoch [8/50], Class Loss: 0.1604, Discrepancy Loss: 0.0536
Epoch [9/50], Class Loss: 0.2329, Discrepancy Loss: 0.0533
Epoch [10/50], Class Loss: 0.2290, Discrepancy Loss: 0.0633
Epoch [11/50], Class Loss: 0.0534, Discrepancy Loss: 0.0345
Epoch [12/50], Class Loss: 0.0387, Discrepancy Loss: 0.0359
Epoch [13/50], Class Loss: 0.0398, Discrepancy Loss: 0.0362
Epoch [14/50], Class Loss: 0.0407, Discrepancy Loss: 0.0355
Epoch [15/50], Class Loss: 0.0365, Discrepancy Loss: 0.0357
Epoch [16/50], Class Loss: 0.0418, Discrepancy Loss: 0.0387
Epoch [17/50], Class Loss: 0.0438, Discrepancy Loss: 0.0440
Epoch [18/50], Class Loss: 0.0343, Discrepancy Loss: 0.0513
Epoch [19/50], Class Loss: 0.0432, Discrepancy Loss: 0.0416
Epoch [20/50], Class Loss: 0.0386, Discrepancy Loss: 0.0386
Epoch [21/50], Class Loss: 0.0183, Discrepancy Loss: 0.0363
Epoch [22/50], Class Loss: 0.0241, Discrepancy Loss: 0.0367
Epoch [23/50], Class Loss: 0.0276, Discrepancy Loss: 0.0403
Epoch [24/50], Class Loss: 0.0320, Discrepancy Loss: 0.0463
Epoch [25/50], Class Loss: 0.0331, Discrepancy Loss: 0.0414
Epoch [26/50], Class Loss: 0.0301, Discrepancy Loss: 0.0452
Epoch [27/50], Class Loss: 0.0256, Discrepancy Loss: 0.0410
Epoch [28/50], Class Loss: 0.0338, Discrepancy Loss: 0.0441
Epoch [29/50], Class Loss: 0.0322, Discrepancy Loss: 0.0467
Epoch [30/50], Class Loss: 0.0359, Discrepancy Loss: 0.0462
Epoch [31/50], Class Loss: 0.0284, Discrepancy Loss: 0.0484
Epoch [32/50], Class Loss: 0.0381, Discrepancy Loss: 0.0481
Epoch [33/50], Class Loss: 0.0283, Discrepancy Loss: 0.0486
Epoch [34/50], Class Loss: 0.0341, Discrepancy Loss: 0.0495
Epoch [35/50], Class Loss: 0.0278, Discrepancy Loss: 0.0467
Epoch [36/50], Class Loss: 0.0289, Discrepancy Loss: 0.0497
Epoch [37/50], Class Loss: 0.0362, Discrepancy Loss: 0.0481
Epoch [38/50], Class Loss: 0.0259, Discrepancy Loss: 0.0496
Epoch [39/50], Class Loss: 0.0291, Discrepancy Loss: 0.0517
Epoch [40/50], Class Loss: 0.0349, Discrepancy Loss: 0.0519
Epoch [41/50], Class Loss: 0.0349, Discrepancy Loss: 0.0516
Epoch [42/50], Class Loss: 0.0320, Discrepancy Loss: 0.0486
Epoch [43/50], Class Loss: 0.0379, Discrepancy Loss: 0.0492
Epoch [44/50], Class Loss: 0.0316, Discrepancy Loss: 0.0475
Epoch [45/50], Class Loss: 0.0319, Discrepancy Loss: 0.0520
Epoch [46/50], Class Loss: 0.0291, Discrepancy Loss: 0.0512
Epoch [47/50], Class Loss: 0.0228, Discrepancy Loss: 0.0470
Epoch [48/50], Class Loss: 0.0331, Discrepancy Loss: 0.0510
Epoch [49/50], Class Loss: 0.0315, Discrepancy Loss: 0.0536
Epoch [50/50], Class Loss: 0.0307, Discrepancy Loss: 0.0476
Source Domain Performance - Accuracy: 99.00%, Precision: 99.03%, Recall: 99.03%, F1 Score: 99.01%
Target Domain Performance - Accuracy: 80.49%, Precision: 76.29%, Recall: 79.81%, F1 Score: 73.56%

Run 9/10
Epoch [1/50], Class Loss: 4.0388, Discrepancy Loss: 0.0913
Epoch [2/50], Class Loss: 0.7910, Discrepancy Loss: 0.0951
Epoch [3/50], Class Loss: 0.5597, Discrepancy Loss: 0.0786
Epoch [4/50], Class Loss: 0.4582, Discrepancy Loss: 0.0757
Epoch [5/50], Class Loss: 0.4265, Discrepancy Loss: 0.0787
Epoch [6/50], Class Loss: 0.3616, Discrepancy Loss: 0.0751
Epoch [7/50], Class Loss: 0.3145, Discrepancy Loss: 0.0707
Epoch [8/50], Class Loss: 0.2931, Discrepancy Loss: 0.0614
Epoch [9/50], Class Loss: 0.2009, Discrepancy Loss: 0.0605
Epoch [10/50], Class Loss: 0.2939, Discrepancy Loss: 0.0638
Epoch [11/50], Class Loss: 0.1350, Discrepancy Loss: 0.0607
Epoch [12/50], Class Loss: 0.0951, Discrepancy Loss: 0.0461
Epoch [13/50], Class Loss: 0.0505, Discrepancy Loss: 0.0286
Epoch [14/50], Class Loss: 0.0476, Discrepancy Loss: 0.0352
Epoch [15/50], Class Loss: 0.0417, Discrepancy Loss: 0.0426
Epoch [16/50], Class Loss: 0.0460, Discrepancy Loss: 0.0460
Epoch [17/50], Class Loss: 0.0433, Discrepancy Loss: 0.0421
Epoch [18/50], Class Loss: 0.0351, Discrepancy Loss: 0.0529
Epoch [19/50], Class Loss: 0.0327, Discrepancy Loss: 0.0398
Epoch [20/50], Class Loss: 0.0375, Discrepancy Loss: 0.0499
Epoch [21/50], Class Loss: 0.0252, Discrepancy Loss: 0.0575
Epoch [22/50], Class Loss: 0.0278, Discrepancy Loss: 0.0677
Epoch [23/50], Class Loss: 0.0343, Discrepancy Loss: 0.0589
Epoch [24/50], Class Loss: 0.0427, Discrepancy Loss: 0.0671
Epoch [25/50], Class Loss: 0.0359, Discrepancy Loss: 0.0556
Epoch [26/50], Class Loss: 0.0416, Discrepancy Loss: 0.0600
Epoch [27/50], Class Loss: 0.0361, Discrepancy Loss: 0.0563
Epoch [28/50], Class Loss: 0.0363, Discrepancy Loss: 0.0558
Epoch [29/50], Class Loss: 0.0291, Discrepancy Loss: 0.0601
Epoch [30/50], Class Loss: 0.0329, Discrepancy Loss: 0.0582
Epoch [31/50], Class Loss: 0.0393, Discrepancy Loss: 0.0605
Epoch [32/50], Class Loss: 0.0355, Discrepancy Loss: 0.0650
Epoch [33/50], Class Loss: 0.0401, Discrepancy Loss: 0.0604
Epoch [34/50], Class Loss: 0.0373, Discrepancy Loss: 0.0635
Epoch [35/50], Class Loss: 0.0352, Discrepancy Loss: 0.0585
Epoch [36/50], Class Loss: 0.0339, Discrepancy Loss: 0.0611
Epoch [37/50], Class Loss: 0.0426, Discrepancy Loss: 0.0592
Epoch [38/50], Class Loss: 0.0347, Discrepancy Loss: 0.0599
Epoch [39/50], Class Loss: 0.0341, Discrepancy Loss: 0.0612
Epoch [40/50], Class Loss: 0.0309, Discrepancy Loss: 0.0583
Epoch [41/50], Class Loss: 0.0394, Discrepancy Loss: 0.0602
Epoch [42/50], Class Loss: 0.0386, Discrepancy Loss: 0.0618
Epoch [43/50], Class Loss: 0.0374, Discrepancy Loss: 0.0603
Epoch [44/50], Class Loss: 0.0322, Discrepancy Loss: 0.0584
Epoch [45/50], Class Loss: 0.0466, Discrepancy Loss: 0.0563
Epoch [46/50], Class Loss: 0.0380, Discrepancy Loss: 0.0620
Epoch [47/50], Class Loss: 0.0318, Discrepancy Loss: 0.0562
Epoch [48/50], Class Loss: 0.0428, Discrepancy Loss: 0.0598
Epoch [49/50], Class Loss: 0.0387, Discrepancy Loss: 0.0595
Epoch [50/50], Class Loss: 0.0358, Discrepancy Loss: 0.0578
Source Domain Performance - Accuracy: 96.73%, Precision: 97.15%, Recall: 96.83%, F1 Score: 96.76%
Target Domain Performance - Accuracy: 80.49%, Precision: 80.12%, Recall: 79.81%, F1 Score: 73.54%

Run 10/10
Epoch [1/50], Class Loss: 3.6494, Discrepancy Loss: 0.1024
Epoch [2/50], Class Loss: 0.7194, Discrepancy Loss: 0.0877
Epoch [3/50], Class Loss: 0.5014, Discrepancy Loss: 0.0842
Epoch [4/50], Class Loss: 0.9904, Discrepancy Loss: 0.0814
Epoch [5/50], Class Loss: 0.4836, Discrepancy Loss: 0.0727
Epoch [6/50], Class Loss: 0.3389, Discrepancy Loss: 0.0553
Epoch [7/50], Class Loss: 0.2423, Discrepancy Loss: 0.0532
Epoch [8/50], Class Loss: 0.1598, Discrepancy Loss: 0.0498
Epoch [9/50], Class Loss: 0.1062, Discrepancy Loss: 0.0329
Epoch [10/50], Class Loss: 0.1907, Discrepancy Loss: 0.0537
Epoch [11/50], Class Loss: 0.1646, Discrepancy Loss: 0.0790
Epoch [12/50], Class Loss: 0.1094, Discrepancy Loss: 0.0744
Epoch [13/50], Class Loss: 0.0797, Discrepancy Loss: 0.0551
Epoch [14/50], Class Loss: 0.0621, Discrepancy Loss: 0.0421
Epoch [15/50], Class Loss: 0.0411, Discrepancy Loss: 0.0399
Epoch [16/50], Class Loss: 0.0325, Discrepancy Loss: 0.0345
Epoch [17/50], Class Loss: 0.0286, Discrepancy Loss: 0.0265
Epoch [18/50], Class Loss: 0.0261, Discrepancy Loss: 0.0301
Epoch [19/50], Class Loss: 0.0230, Discrepancy Loss: 0.0381
Epoch [20/50], Class Loss: 0.0311, Discrepancy Loss: 0.0442
Epoch [21/50], Class Loss: 0.0159, Discrepancy Loss: 0.0505
Epoch [22/50], Class Loss: 0.0175, Discrepancy Loss: 0.0575
Epoch [23/50], Class Loss: 0.0262, Discrepancy Loss: 0.0683
Epoch [24/50], Class Loss: 0.0203, Discrepancy Loss: 0.0704
Epoch [25/50], Class Loss: 0.0216, Discrepancy Loss: 0.0850
Epoch [26/50], Class Loss: 0.0239, Discrepancy Loss: 0.0939
Epoch [27/50], Class Loss: 0.0344, Discrepancy Loss: 0.0838
Epoch [28/50], Class Loss: 0.0321, Discrepancy Loss: 0.0852
Epoch [29/50], Class Loss: 0.0235, Discrepancy Loss: 0.0954
Epoch [30/50], Class Loss: 0.0190, Discrepancy Loss: 0.1037
Epoch [31/50], Class Loss: 0.0285, Discrepancy Loss: 0.1261
Epoch [32/50], Class Loss: 0.0255, Discrepancy Loss: 0.1340
Epoch [33/50], Class Loss: 0.0253, Discrepancy Loss: 0.1364
Epoch [34/50], Class Loss: 0.0279, Discrepancy Loss: 0.1263
Epoch [35/50], Class Loss: 0.0283, Discrepancy Loss: 0.1205
Epoch [36/50], Class Loss: 0.0195, Discrepancy Loss: 0.1201
Epoch [37/50], Class Loss: 0.0205, Discrepancy Loss: 0.1236
Epoch [38/50], Class Loss: 0.0253, Discrepancy Loss: 0.1333
Epoch [39/50], Class Loss: 0.0282, Discrepancy Loss: 0.1297
Epoch [40/50], Class Loss: 0.0188, Discrepancy Loss: 0.1252
Epoch [41/50], Class Loss: 0.0185, Discrepancy Loss: 0.1358
Epoch [42/50], Class Loss: 0.0226, Discrepancy Loss: 0.1311
Epoch [43/50], Class Loss: 0.0184, Discrepancy Loss: 0.1337
Epoch [44/50], Class Loss: 0.0226, Discrepancy Loss: 0.1259
Epoch [45/50], Class Loss: 0.0230, Discrepancy Loss: 0.1329
Epoch [46/50], Class Loss: 0.0221, Discrepancy Loss: 0.1304
Epoch [47/50], Class Loss: 0.0243, Discrepancy Loss: 0.1277
Epoch [48/50], Class Loss: 0.0199, Discrepancy Loss: 0.1344
Epoch [49/50], Class Loss: 0.0238, Discrepancy Loss: 0.1369
Epoch [50/50], Class Loss: 0.0183, Discrepancy Loss: 0.1347
Source Domain Performance - Accuracy: 99.58%, Precision: 99.59%, Recall: 99.60%, F1 Score: 99.59%
Target Domain Performance - Accuracy: 61.33%, Precision: 68.89%, Recall: 60.66%, F1 Score: 54.37%

Source performance: 97.32% 97.83% 97.40% 97.31%
Target performance: 72.36% 72.10% 71.68% 66.12%

Per-Class Accuracy on Target Domain:
bpsk: 100.00%
qpsk: 98.50%
4qam: 99.51%
16qam: 0.44%
apsk: 59.95%

Run 1/10
Epoch [1/50], Class Loss: 2.3902, Discrepancy Loss: 0.0353
Validation Loss: 1.0273
Epoch [2/50], Class Loss: 0.9412, Discrepancy Loss: 0.0260
Validation Loss: 0.9366
Epoch [3/50], Class Loss: 2.3268, Discrepancy Loss: 0.0400
Validation Loss: 2.2008
Epoch [4/50], Class Loss: 0.7172, Discrepancy Loss: 0.0241
Validation Loss: 0.1113
Epoch [5/50], Class Loss: 0.1652, Discrepancy Loss: 0.0182
Validation Loss: 0.0867
Epoch [6/50], Class Loss: 2.5870, Discrepancy Loss: 0.0328
Validation Loss: 1.0466
Epoch [7/50], Class Loss: 1.2185, Discrepancy Loss: 0.0363
Validation Loss: 0.2827
Epoch [8/50], Class Loss: 0.3202, Discrepancy Loss: 0.0115
Validation Loss: 0.3782
Epoch [9/50], Class Loss: 0.7094, Discrepancy Loss: 0.0191
Validation Loss: 0.3753
Epoch [10/50], Class Loss: 0.5111, Discrepancy Loss: 0.0128
Validation Loss: 0.2789
Early stopping!
Source Domain Performance - Accuracy: 99.34%, Precision: 99.34%, Recall: 99.34%, F1 Score: 99.34%
Target Domain Performance - Accuracy: 52.03%, Precision: 55.59%, Recall: 51.41%, F1 Score: 47.76%

Run 2/10
Epoch [1/50], Class Loss: 2.8785, Discrepancy Loss: 0.0397
Validation Loss: 1.2259
Epoch [2/50], Class Loss: 1.2563, Discrepancy Loss: 0.0315
Validation Loss: 2.1341
Epoch [3/50], Class Loss: 1.5515, Discrepancy Loss: 0.0371
Validation Loss: 1.7887
Epoch [4/50], Class Loss: 2.0432, Discrepancy Loss: 0.0733
Validation Loss: 0.6116
Epoch [5/50], Class Loss: 0.3889, Discrepancy Loss: 0.0345
Validation Loss: 0.3376
Epoch [6/50], Class Loss: 0.3919, Discrepancy Loss: 0.0347
Validation Loss: 0.5176
Epoch [7/50], Class Loss: 2.1865, Discrepancy Loss: 0.0820
Validation Loss: 0.9117
Epoch [8/50], Class Loss: 0.9599, Discrepancy Loss: 0.0327
Validation Loss: 0.2987
Epoch [9/50], Class Loss: 1.1105, Discrepancy Loss: 0.0253
Validation Loss: 0.6701
Epoch [10/50], Class Loss: 1.3277, Discrepancy Loss: 0.0375
Validation Loss: 0.7844
Epoch [11/50], Class Loss: 0.1351, Discrepancy Loss: 0.0199
Validation Loss: 0.0235
Epoch [12/50], Class Loss: 0.0548, Discrepancy Loss: 0.0123
Validation Loss: 0.0457
Epoch [13/50], Class Loss: 0.0550, Discrepancy Loss: 0.0117
Validation Loss: 0.0331
Epoch [14/50], Class Loss: 0.1650, Discrepancy Loss: 0.0107
Validation Loss: 6.4893
Epoch [15/50], Class Loss: 0.2443, Discrepancy Loss: 0.0131
Validation Loss: 0.0356
Epoch [16/50], Class Loss: 0.5025, Discrepancy Loss: 0.0178
Validation Loss: 0.0216
Epoch [17/50], Class Loss: 0.1875, Discrepancy Loss: 0.0136
Validation Loss: 0.0328
Epoch [18/50], Class Loss: 0.0361, Discrepancy Loss: 0.0122
Validation Loss: 0.0156
Epoch [19/50], Class Loss: 0.0205, Discrepancy Loss: 0.0131
Validation Loss: 0.0157
Epoch [20/50], Class Loss: 0.0823, Discrepancy Loss: 0.0112
Validation Loss: 0.0222
Epoch [21/50], Class Loss: 0.0143, Discrepancy Loss: 0.0102
Validation Loss: 0.0202
Epoch [22/50], Class Loss: 0.0141, Discrepancy Loss: 0.0099
Validation Loss: 0.0197
Epoch [23/50], Class Loss: 0.0134, Discrepancy Loss: 0.0100
Validation Loss: 0.0194
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 67.80%, Precision: 61.20%, Recall: 67.14%, F1 Score: 62.83%

Run 3/10
Epoch [1/50], Class Loss: 2.6105, Discrepancy Loss: 0.0559
Validation Loss: 1.3756
Epoch [2/50], Class Loss: 1.5997, Discrepancy Loss: 0.0285
Validation Loss: 2.3349
Epoch [3/50], Class Loss: 2.2755, Discrepancy Loss: 0.0495
Validation Loss: 1.0587
Epoch [4/50], Class Loss: 2.0355, Discrepancy Loss: 0.0687
Validation Loss: 0.9443
Epoch [5/50], Class Loss: 0.9532, Discrepancy Loss: 0.0257
Validation Loss: 0.3648
Epoch [6/50], Class Loss: 0.3559, Discrepancy Loss: 0.0167
Validation Loss: 0.2564
Epoch [7/50], Class Loss: 0.3078, Discrepancy Loss: 0.0203
Validation Loss: 0.1436
Epoch [8/50], Class Loss: 0.9717, Discrepancy Loss: 0.0188
Validation Loss: 1.1145
Epoch [9/50], Class Loss: 0.9159, Discrepancy Loss: 0.0498
Validation Loss: 9.3437
Epoch [10/50], Class Loss: 1.8148, Discrepancy Loss: 0.0595
Validation Loss: 0.2306
Epoch [11/50], Class Loss: 0.1047, Discrepancy Loss: 0.0059
Validation Loss: 0.0335
Epoch [12/50], Class Loss: 0.1184, Discrepancy Loss: 0.0145
Validation Loss: 0.0448
Epoch [13/50], Class Loss: 0.1063, Discrepancy Loss: 0.0144
Validation Loss: 0.0363
Epoch [14/50], Class Loss: 0.1184, Discrepancy Loss: 0.0128
Validation Loss: 0.0347
Epoch [15/50], Class Loss: 0.1705, Discrepancy Loss: 0.0112
Validation Loss: 0.0455
Epoch [16/50], Class Loss: 0.1953, Discrepancy Loss: 0.0129
Validation Loss: 0.0255
Epoch [17/50], Class Loss: 0.1782, Discrepancy Loss: 0.0145
Validation Loss: 0.4729
Epoch [18/50], Class Loss: 0.1329, Discrepancy Loss: 0.0122
Validation Loss: 0.0254
Epoch [19/50], Class Loss: 0.0892, Discrepancy Loss: 0.0161
Validation Loss: 0.0257
Epoch [20/50], Class Loss: 0.0942, Discrepancy Loss: 0.0153
Validation Loss: 0.0228
Epoch [21/50], Class Loss: 0.0399, Discrepancy Loss: 0.0120
Validation Loss: 0.0230
Epoch [22/50], Class Loss: 0.0441, Discrepancy Loss: 0.0117
Validation Loss: 0.0290
Epoch [23/50], Class Loss: 0.0414, Discrepancy Loss: 0.0119
Validation Loss: 0.0193
Epoch [24/50], Class Loss: 0.0401, Discrepancy Loss: 0.0109
Validation Loss: 0.0172
Epoch [25/50], Class Loss: 0.0409, Discrepancy Loss: 0.0108
Validation Loss: 0.0326
Epoch [26/50], Class Loss: 0.0395, Discrepancy Loss: 0.0108
Validation Loss: 0.0164
Epoch [27/50], Class Loss: 0.0382, Discrepancy Loss: 0.0112
Validation Loss: 0.0183
Epoch [28/50], Class Loss: 0.0417, Discrepancy Loss: 0.0110
Validation Loss: 0.0201
Epoch [29/50], Class Loss: 0.0414, Discrepancy Loss: 0.0108
Validation Loss: 0.0208
Epoch [30/50], Class Loss: 0.0334, Discrepancy Loss: 0.0107
Validation Loss: 0.0185
Epoch [31/50], Class Loss: 0.0331, Discrepancy Loss: 0.0103
Validation Loss: 0.0198
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.80%, Recall: 99.80%, F1 Score: 99.80%
Target Domain Performance - Accuracy: 72.66%, Precision: 70.07%, Recall: 71.98%, F1 Score: 68.48%

Run 4/10
Epoch [1/50], Class Loss: 2.8975, Discrepancy Loss: 0.0350
Validation Loss: 1.1992
Epoch [2/50], Class Loss: 1.3858, Discrepancy Loss: 0.0404
Validation Loss: 0.4713
Epoch [3/50], Class Loss: 1.3906, Discrepancy Loss: 0.0374
Validation Loss: 0.9028
Epoch [4/50], Class Loss: 1.2264, Discrepancy Loss: 0.0414
Validation Loss: 0.3281
Epoch [5/50], Class Loss: 2.0002, Discrepancy Loss: 0.0437
Validation Loss: 0.1339
Epoch [6/50], Class Loss: 1.9841, Discrepancy Loss: 0.0559
Validation Loss: 0.8771
Epoch [7/50], Class Loss: 1.8730, Discrepancy Loss: 0.0555
Validation Loss: 0.9304
Epoch [8/50], Class Loss: 0.8809, Discrepancy Loss: 0.0243
Validation Loss: 0.9363
Epoch [9/50], Class Loss: 0.7639, Discrepancy Loss: 0.0221
Validation Loss: 0.0549
Epoch [10/50], Class Loss: 0.7530, Discrepancy Loss: 0.0176
Validation Loss: 6.3794
Epoch [11/50], Class Loss: 0.1831, Discrepancy Loss: 0.0093
Validation Loss: 0.0225
Epoch [12/50], Class Loss: 0.0785, Discrepancy Loss: 0.0102
Validation Loss: 0.0184
Epoch [13/50], Class Loss: 0.1421, Discrepancy Loss: 0.0146
Validation Loss: 0.0251
Epoch [14/50], Class Loss: 0.0677, Discrepancy Loss: 0.0111
Validation Loss: 0.0298
Epoch [15/50], Class Loss: 0.0318, Discrepancy Loss: 0.0164
Validation Loss: 0.0149
Epoch [16/50], Class Loss: 0.0501, Discrepancy Loss: 0.0176
Validation Loss: 0.0136
Epoch [17/50], Class Loss: 0.0284, Discrepancy Loss: 0.0135
Validation Loss: 0.0173
Epoch [18/50], Class Loss: 0.0319, Discrepancy Loss: 0.0121
Validation Loss: 0.0151
Epoch [19/50], Class Loss: 0.0560, Discrepancy Loss: 0.0150
Validation Loss: 0.0144
Epoch [20/50], Class Loss: 0.0178, Discrepancy Loss: 0.0162
Validation Loss: 0.0148
Epoch [21/50], Class Loss: 0.0115, Discrepancy Loss: 0.0153
Validation Loss: 0.0126
Epoch [22/50], Class Loss: 0.0074, Discrepancy Loss: 0.0146
Validation Loss: 0.0124
Epoch [23/50], Class Loss: 0.0080, Discrepancy Loss: 0.0143
Validation Loss: 0.0124
Epoch [24/50], Class Loss: 0.0100, Discrepancy Loss: 0.0144
Validation Loss: 0.0117
Epoch [25/50], Class Loss: 0.0077, Discrepancy Loss: 0.0141
Validation Loss: 0.0131
Epoch [26/50], Class Loss: 0.0086, Discrepancy Loss: 0.0136
Validation Loss: 0.0115
Epoch [27/50], Class Loss: 0.0083, Discrepancy Loss: 0.0134
Validation Loss: 0.0110
Epoch [28/50], Class Loss: 0.0074, Discrepancy Loss: 0.0129
Validation Loss: 0.0115
Epoch [29/50], Class Loss: 0.0077, Discrepancy Loss: 0.0137
Validation Loss: 0.0109
Epoch [30/50], Class Loss: 0.0072, Discrepancy Loss: 0.0135
Validation Loss: 0.0118
Epoch [31/50], Class Loss: 0.0066, Discrepancy Loss: 0.0127
Validation Loss: 0.0126
Epoch [32/50], Class Loss: 0.0063, Discrepancy Loss: 0.0130
Validation Loss: 0.0123
Epoch [33/50], Class Loss: 0.0064, Discrepancy Loss: 0.0127
Validation Loss: 0.0117
Epoch [34/50], Class Loss: 0.0069, Discrepancy Loss: 0.0128
Validation Loss: 0.0124
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 62.50%, Precision: 59.57%, Recall: 61.86%, F1 Score: 58.55%

Run 5/10
Epoch [1/50], Class Loss: 3.2602, Discrepancy Loss: 0.0441
Validation Loss: 1.2962
Epoch [2/50], Class Loss: 1.3458, Discrepancy Loss: 0.0295
Validation Loss: 2.2003
Epoch [3/50], Class Loss: 1.3867, Discrepancy Loss: 0.0497
Validation Loss: 0.1642
Epoch [4/50], Class Loss: 1.8518, Discrepancy Loss: 0.0536
Validation Loss: 6.1359
Epoch [5/50], Class Loss: 2.1222, Discrepancy Loss: 0.0569
Validation Loss: 0.2621
Epoch [6/50], Class Loss: 1.5800, Discrepancy Loss: 0.0405
Validation Loss: 1.1412
Epoch [7/50], Class Loss: 1.2437, Discrepancy Loss: 0.0362
Validation Loss: 0.5476
Epoch [8/50], Class Loss: 1.5394, Discrepancy Loss: 0.0307
Validation Loss: 0.8302
Early stopping!
Source Domain Performance - Accuracy: 80.10%, Precision: 69.71%, Recall: 79.59%, F1 Score: 73.07%
Target Domain Performance - Accuracy: 38.38%, Precision: 19.21%, Recall: 37.97%, F1 Score: 25.49%

Run 6/10
Epoch [1/50], Class Loss: 2.6752, Discrepancy Loss: 0.0379
Validation Loss: 1.0926
Epoch [2/50], Class Loss: 1.0768, Discrepancy Loss: 0.0347
Validation Loss: 0.1026
Epoch [3/50], Class Loss: 1.9851, Discrepancy Loss: 0.0376
Validation Loss: 4.8456
Epoch [4/50], Class Loss: 1.5574, Discrepancy Loss: 0.0388
Validation Loss: 1.3869
Epoch [5/50], Class Loss: 0.5171, Discrepancy Loss: 0.0188
Validation Loss: 0.1538
Epoch [6/50], Class Loss: 0.3527, Discrepancy Loss: 0.0169
Validation Loss: 0.0750
Epoch [7/50], Class Loss: 3.2913, Discrepancy Loss: 0.0591
Validation Loss: 23.7139
Epoch [8/50], Class Loss: 1.8272, Discrepancy Loss: 0.0641
Validation Loss: 0.2072
Epoch [9/50], Class Loss: 0.8862, Discrepancy Loss: 0.0345
Validation Loss: 0.5031
Epoch [10/50], Class Loss: 0.4614, Discrepancy Loss: 0.0214
Validation Loss: 0.2284
Epoch [11/50], Class Loss: 0.0543, Discrepancy Loss: 0.0056
Validation Loss: 0.0147
Epoch [12/50], Class Loss: 0.1070, Discrepancy Loss: 0.0086
Validation Loss: 0.0270
Epoch [13/50], Class Loss: 0.2060, Discrepancy Loss: 0.0100
Validation Loss: 0.0574
Epoch [14/50], Class Loss: 0.0434, Discrepancy Loss: 0.0190
Validation Loss: 0.0508
Epoch [15/50], Class Loss: 0.0543, Discrepancy Loss: 0.0187
Validation Loss: 0.0202
Epoch [16/50], Class Loss: 0.0268, Discrepancy Loss: 0.0139
Validation Loss: 0.2908
Early stopping!
Source Domain Performance - Accuracy: 95.39%, Precision: 95.91%, Recall: 95.41%, F1 Score: 95.32%
Target Domain Performance - Accuracy: 66.28%, Precision: 61.40%, Recall: 65.65%, F1 Score: 59.17%

Run 7/10
Epoch [1/50], Class Loss: 3.2312, Discrepancy Loss: 0.0086
Validation Loss: 3.2192
Epoch [2/50], Class Loss: 3.2194, Discrepancy Loss: 0.0001
Validation Loss: 3.2189
Epoch [3/50], Class Loss: 3.2191, Discrepancy Loss: 0.0000
Validation Loss: 3.2189
Epoch [4/50], Class Loss: 3.2191, Discrepancy Loss: 0.0000
Validation Loss: 3.2190
Epoch [5/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2191
Epoch [6/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2191
Epoch [7/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2190
Early stopping!
Source Domain Performance - Accuracy: 19.48%, Precision: 3.90%, Recall: 20.00%, F1 Score: 6.52%
Target Domain Performance - Accuracy: 20.21%, Precision: 4.04%, Recall: 20.00%, F1 Score: 6.73%

Run 8/10
Epoch [1/50], Class Loss: 2.8257, Discrepancy Loss: 0.0366
Validation Loss: 1.0613
Epoch [2/50], Class Loss: 1.6295, Discrepancy Loss: 0.0353
Validation Loss: 1.8047
Epoch [3/50], Class Loss: 1.7621, Discrepancy Loss: 0.0700
Validation Loss: 1.4415
Epoch [4/50], Class Loss: 1.9403, Discrepancy Loss: 0.0553
Validation Loss: 1.4178
Epoch [5/50], Class Loss: 1.6487, Discrepancy Loss: 0.0553
Validation Loss: 1.9038
Epoch [6/50], Class Loss: 1.8204, Discrepancy Loss: 0.0367
Validation Loss: 1.0573
Epoch [7/50], Class Loss: 1.5689, Discrepancy Loss: 0.0459
Validation Loss: 2.1102
Epoch [8/50], Class Loss: 1.4484, Discrepancy Loss: 0.0471
Validation Loss: 1.5169
Epoch [9/50], Class Loss: 1.2469, Discrepancy Loss: 0.0454
Validation Loss: 0.9376
Epoch [10/50], Class Loss: 1.1325, Discrepancy Loss: 0.0295
Validation Loss: 2.8085
Epoch [11/50], Class Loss: 0.2999, Discrepancy Loss: 0.0108
Validation Loss: 0.0584
Epoch [12/50], Class Loss: 0.1468, Discrepancy Loss: 0.0058
Validation Loss: 0.0327
Epoch [13/50], Class Loss: 0.0772, Discrepancy Loss: 0.0059
Validation Loss: 0.0351
Epoch [14/50], Class Loss: 0.0638, Discrepancy Loss: 0.0070
Validation Loss: 0.0329
Epoch [15/50], Class Loss: 0.0540, Discrepancy Loss: 0.0072
Validation Loss: 0.0288
Epoch [16/50], Class Loss: 0.0655, Discrepancy Loss: 0.0078
Validation Loss: 0.0254
Epoch [17/50], Class Loss: 0.0895, Discrepancy Loss: 0.0105
Validation Loss: 0.0271
Epoch [18/50], Class Loss: 0.1765, Discrepancy Loss: 0.0120
Validation Loss: 0.0304
Epoch [19/50], Class Loss: 0.0830, Discrepancy Loss: 0.0110
Validation Loss: 0.5703
Epoch [20/50], Class Loss: 0.0998, Discrepancy Loss: 0.0124
Validation Loss: 0.0321
Epoch [21/50], Class Loss: 0.0384, Discrepancy Loss: 0.0095
Validation Loss: 0.0249
Epoch [22/50], Class Loss: 0.0286, Discrepancy Loss: 0.0092
Validation Loss: 0.0236
Epoch [23/50], Class Loss: 0.0291, Discrepancy Loss: 0.0087
Validation Loss: 0.0244
Epoch [24/50], Class Loss: 0.0311, Discrepancy Loss: 0.0088
Validation Loss: 0.0217
Epoch [25/50], Class Loss: 0.0437, Discrepancy Loss: 0.0086
Validation Loss: 0.0220
Epoch [26/50], Class Loss: 0.0336, Discrepancy Loss: 0.0083
Validation Loss: 0.0224
Epoch [27/50], Class Loss: 0.0340, Discrepancy Loss: 0.0083
Validation Loss: 0.0248
Epoch [28/50], Class Loss: 0.0370, Discrepancy Loss: 0.0084
Validation Loss: 0.0229
Epoch [29/50], Class Loss: 0.0379, Discrepancy Loss: 0.0085
Validation Loss: 0.0261
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.81%, Recall: 99.81%, F1 Score: 99.81%
Target Domain Performance - Accuracy: 54.93%, Precision: 60.66%, Recall: 54.29%, F1 Score: 50.34%

Run 9/10
Epoch [1/50], Class Loss: 1.9716, Discrepancy Loss: 0.0337
Validation Loss: 0.3145
Epoch [2/50], Class Loss: 1.9426, Discrepancy Loss: 0.0381
Validation Loss: 2.0298
Epoch [3/50], Class Loss: 1.1816, Discrepancy Loss: 0.0235
Validation Loss: 1.5141
Epoch [4/50], Class Loss: 1.7905, Discrepancy Loss: 0.0312
Validation Loss: 0.6242
Epoch [5/50], Class Loss: 1.7330, Discrepancy Loss: 0.0534
Validation Loss: 0.5014
Epoch [6/50], Class Loss: 1.5790, Discrepancy Loss: 0.0426
Validation Loss: 2.4742
Early stopping!
Source Domain Performance - Accuracy: 60.03%, Precision: 55.74%, Recall: 59.53%, F1 Score: 54.75%
Target Domain Performance - Accuracy: 20.04%, Precision: 6.71%, Recall: 19.98%, F1 Score: 10.05%

Run 10/10
Epoch [1/50], Class Loss: 2.7051, Discrepancy Loss: 0.0346
Validation Loss: 0.9702
Epoch [2/50], Class Loss: 1.9549, Discrepancy Loss: 0.0468
Validation Loss: 1.1682
Epoch [3/50], Class Loss: 2.0825, Discrepancy Loss: 0.0470
Validation Loss: 3.9268
Epoch [4/50], Class Loss: 3.0205, Discrepancy Loss: 0.0451
Validation Loss: 1.2660
Epoch [5/50], Class Loss: 0.3389, Discrepancy Loss: 0.0159
Validation Loss: 0.1542
Epoch [6/50], Class Loss: 2.0410, Discrepancy Loss: 0.0270
Validation Loss: 0.9466
Epoch [7/50], Class Loss: 1.5012, Discrepancy Loss: 0.0214
Validation Loss: 2.6087
Epoch [8/50], Class Loss: 1.1188, Discrepancy Loss: 0.0156
Validation Loss: 0.0529
Epoch [9/50], Class Loss: 2.9282, Discrepancy Loss: 0.0779
Validation Loss: 0.2099
Epoch [10/50], Class Loss: 0.6898, Discrepancy Loss: 0.0229
Validation Loss: 0.1079
Epoch [11/50], Class Loss: 0.0345, Discrepancy Loss: 0.0036
Validation Loss: 0.0494
Epoch [12/50], Class Loss: 0.0336, Discrepancy Loss: 0.0098
Validation Loss: 0.0647
Epoch [13/50], Class Loss: 0.0283, Discrepancy Loss: 0.0130
Validation Loss: 0.0327
Epoch [14/50], Class Loss: 0.0250, Discrepancy Loss: 0.0117
Validation Loss: 0.0265
Epoch [15/50], Class Loss: 0.0165, Discrepancy Loss: 0.0108
Validation Loss: 0.0241
Epoch [16/50], Class Loss: 0.0160, Discrepancy Loss: 0.0108
Validation Loss: 0.0188
Epoch [17/50], Class Loss: 0.0244, Discrepancy Loss: 0.0101
Validation Loss: 0.0133
Epoch [18/50], Class Loss: 0.0154, Discrepancy Loss: 0.0105
Validation Loss: 0.0197
Epoch [19/50], Class Loss: 0.0156, Discrepancy Loss: 0.0094
Validation Loss: 0.0184
Epoch [20/50], Class Loss: 0.0230, Discrepancy Loss: 0.0119
Validation Loss: 0.0137
Epoch [21/50], Class Loss: 0.0113, Discrepancy Loss: 0.0078
Validation Loss: 0.0109
Epoch [22/50], Class Loss: 0.0117, Discrepancy Loss: 0.0076
Validation Loss: 0.0111
Epoch [23/50], Class Loss: 0.0123, Discrepancy Loss: 0.0075
Validation Loss: 0.0103
Epoch [24/50], Class Loss: 0.0109, Discrepancy Loss: 0.0074
Validation Loss: 0.0104
Epoch [25/50], Class Loss: 0.0104, Discrepancy Loss: 0.0070
Validation Loss: 0.0118
Epoch [26/50], Class Loss: 0.0108, Discrepancy Loss: 0.0074
Validation Loss: 0.0104
Epoch [27/50], Class Loss: 0.0112, Discrepancy Loss: 0.0079
Validation Loss: 0.0100
Epoch [28/50], Class Loss: 0.0106, Discrepancy Loss: 0.0083
Validation Loss: 0.0105
Epoch [29/50], Class Loss: 0.0110, Discrepancy Loss: 0.0083
Validation Loss: 0.0112
Epoch [30/50], Class Loss: 0.0100, Discrepancy Loss: 0.0082
Validation Loss: 0.0114
Epoch [31/50], Class Loss: 0.0103, Discrepancy Loss: 0.0079
Validation Loss: 0.0116
Epoch [32/50], Class Loss: 0.0100, Discrepancy Loss: 0.0080
Validation Loss: 0.0116
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 56.05%, Precision: 59.02%, Recall: 55.42%, F1 Score: 52.53%

Source performance: 85.36% 82.39% 85.32% 82.83%
Target performance: 51.09% 45.75% 50.57% 44.19%

Per-Class Accuracy on Target Domain:
bpsk: 80.00%
qpsk: 55.40%
4qam: 78.79%
16qam: 0.11%
apsk: 38.54%

Run 1/10
Epoch [1/50], Class Loss: 1.2841, CORAL Loss: 0.0073
Validation Loss: 0.5139
Epoch [2/50], Class Loss: 0.5062, CORAL Loss: 0.0293
Validation Loss: 0.3927
Epoch [3/50], Class Loss: 0.3762, CORAL Loss: 0.0240
Validation Loss: 0.7967
Epoch [4/50], Class Loss: 0.2603, CORAL Loss: 0.0061
Validation Loss: 0.3247
Epoch [5/50], Class Loss: 0.3230, CORAL Loss: 0.0096
Validation Loss: 0.0288
Epoch [6/50], Class Loss: 0.2734, CORAL Loss: 0.0060
Validation Loss: 0.1319
Epoch [7/50], Class Loss: 0.2626, CORAL Loss: 0.0022
Validation Loss: 0.2638
Epoch [8/50], Class Loss: 0.1514, CORAL Loss: 0.0055
Validation Loss: 0.1736
Epoch [9/50], Class Loss: 0.0406, CORAL Loss: 0.0074
Validation Loss: 0.0095
Epoch [10/50], Class Loss: 0.0085, CORAL Loss: 0.0055
Validation Loss: 0.0045
Epoch [11/50], Class Loss: 0.0059, CORAL Loss: 0.0038
Validation Loss: 0.0046
Epoch [12/50], Class Loss: 0.0060, CORAL Loss: 0.0036
Validation Loss: 0.0048
Epoch [13/50], Class Loss: 0.0054, CORAL Loss: 0.0034
Validation Loss: 0.0050
Epoch [14/50], Class Loss: 0.0055, CORAL Loss: 0.0030
Validation Loss: 0.0046
Epoch [15/50], Class Loss: 0.0056, CORAL Loss: 0.0031
Validation Loss: 0.0043
Epoch [16/50], Class Loss: 0.0055, CORAL Loss: 0.0029
Validation Loss: 0.0046
Epoch [17/50], Class Loss: 0.0047, CORAL Loss: 0.0027
Validation Loss: 0.0036
Epoch [18/50], Class Loss: 0.0051, CORAL Loss: 0.0026
Validation Loss: 0.0041
Epoch [19/50], Class Loss: 0.0049, CORAL Loss: 0.0025
Validation Loss: 0.0044
Epoch [20/50], Class Loss: 0.0046, CORAL Loss: 0.0023
Validation Loss: 0.0036
Epoch [21/50], Class Loss: 0.0042, CORAL Loss: 0.0021
Validation Loss: 0.0035
Epoch [22/50], Class Loss: 0.0042, CORAL Loss: 0.0020
Validation Loss: 0.0035
Epoch [23/50], Class Loss: 0.0043, CORAL Loss: 0.0022
Validation Loss: 0.0036
Epoch [24/50], Class Loss: 0.0040, CORAL Loss: 0.0022
Validation Loss: 0.0035
Epoch [25/50], Class Loss: 0.0042, CORAL Loss: 0.0022
Validation Loss: 0.0034
Epoch [26/50], Class Loss: 0.0043, CORAL Loss: 0.0021
Validation Loss: 0.0037
Epoch [27/50], Class Loss: 0.0041, CORAL Loss: 0.0022
Validation Loss: 0.0034
Epoch [28/50], Class Loss: 0.0039, CORAL Loss: 0.0021
Validation Loss: 0.0037
Epoch [29/50], Class Loss: 0.0040, CORAL Loss: 0.0020
Validation Loss: 0.0035
Epoch [30/50], Class Loss: 0.0040, CORAL Loss: 0.0021
Validation Loss: 0.0032
Epoch [31/50], Class Loss: 0.0041, CORAL Loss: 0.0021
Validation Loss: 0.0032
Epoch [32/50], Class Loss: 0.0039, CORAL Loss: 0.0020
Validation Loss: 0.0033
Epoch [33/50], Class Loss: 0.0040, CORAL Loss: 0.0022
Validation Loss: 0.0034
Epoch [34/50], Class Loss: 0.0043, CORAL Loss: 0.0021
Validation Loss: 0.0034
Epoch [35/50], Class Loss: 0.0036, CORAL Loss: 0.0021
Validation Loss: 0.0034
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 60.64%, Precision: 50.15%, Recall: 59.98%, F1 Score: 53.48%

Run 2/10
Epoch [1/50], Class Loss: 1.4493, CORAL Loss: 0.0072
Validation Loss: 0.9339
Epoch [2/50], Class Loss: 0.6538, CORAL Loss: 0.0339
Validation Loss: 0.2909
Epoch [3/50], Class Loss: 0.3525, CORAL Loss: 0.0247
Validation Loss: 0.1738
Epoch [4/50], Class Loss: 0.2616, CORAL Loss: 0.0150
Validation Loss: 0.2495
Epoch [5/50], Class Loss: 1.1163, CORAL Loss: 0.0330
Validation Loss: 0.4252
Epoch [6/50], Class Loss: 0.5176, CORAL Loss: 0.0310
Validation Loss: 0.2585
Epoch [7/50], Class Loss: 0.3510, CORAL Loss: 0.0177
Validation Loss: 0.2911
Epoch [8/50], Class Loss: 0.4074, CORAL Loss: 0.0139
Validation Loss: 2.0442
Early stopping!
Source Domain Performance - Accuracy: 19.92%, Precision: 10.00%, Recall: 20.02%, F1 Score: 13.34%
Target Domain Performance - Accuracy: 39.55%, Precision: 30.04%, Recall: 40.22%, F1 Score: 33.42%

Run 3/10
Epoch [1/50], Class Loss: 1.3736, CORAL Loss: 0.0077
Validation Loss: 1.1532
Epoch [2/50], Class Loss: 0.5617, CORAL Loss: 0.0248
Validation Loss: 0.2053
Epoch [3/50], Class Loss: 0.3651, CORAL Loss: 0.0172
Validation Loss: 0.3154
Epoch [4/50], Class Loss: 0.2942, CORAL Loss: 0.0086
Validation Loss: 0.2540
Epoch [5/50], Class Loss: 0.1658, CORAL Loss: 0.0088
Validation Loss: 0.0667
Epoch [6/50], Class Loss: 0.1757, CORAL Loss: 0.0038
Validation Loss: 0.0200
Epoch [7/50], Class Loss: 0.0102, CORAL Loss: 0.0031
Validation Loss: 0.0101
Epoch [8/50], Class Loss: 0.3875, CORAL Loss: 0.0155
Validation Loss: 0.0329
Epoch [9/50], Class Loss: 0.1407, CORAL Loss: 0.0072
Validation Loss: 0.0076
Epoch [10/50], Class Loss: 0.0060, CORAL Loss: 0.0030
Validation Loss: 0.0051
Epoch [11/50], Class Loss: 0.0050, CORAL Loss: 0.0024
Validation Loss: 0.0043
Epoch [12/50], Class Loss: 0.0051, CORAL Loss: 0.0022
Validation Loss: 0.0043
Epoch [13/50], Class Loss: 0.0049, CORAL Loss: 0.0022
Validation Loss: 0.0043
Epoch [14/50], Class Loss: 0.0050, CORAL Loss: 0.0021
Validation Loss: 0.0043
Epoch [15/50], Class Loss: 0.0048, CORAL Loss: 0.0019
Validation Loss: 0.0041
Epoch [16/50], Class Loss: 0.0048, CORAL Loss: 0.0020
Validation Loss: 0.0040
Epoch [17/50], Class Loss: 0.0045, CORAL Loss: 0.0019
Validation Loss: 0.0037
Epoch [18/50], Class Loss: 0.0045, CORAL Loss: 0.0021
Validation Loss: 0.0037
Epoch [19/50], Class Loss: 0.0044, CORAL Loss: 0.0018
Validation Loss: 0.0042
Epoch [20/50], Class Loss: 0.0045, CORAL Loss: 0.0016
Validation Loss: 0.0037
Epoch [21/50], Class Loss: 0.0038, CORAL Loss: 0.0017
Validation Loss: 0.0038
Epoch [22/50], Class Loss: 0.0042, CORAL Loss: 0.0017
Validation Loss: 0.0038
Epoch [23/50], Class Loss: 0.0044, CORAL Loss: 0.0017
Validation Loss: 0.0037
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 60.64%, Precision: 70.13%, Recall: 59.98%, F1 Score: 53.54%

Run 4/10
Epoch [1/50], Class Loss: 1.3745, CORAL Loss: 0.0027
Validation Loss: 0.8248
Epoch [2/50], Class Loss: 0.6831, CORAL Loss: 0.0284
Validation Loss: 1.1631
Epoch [3/50], Class Loss: 0.4432, CORAL Loss: 0.0235
Validation Loss: 0.2818
Epoch [4/50], Class Loss: 0.2657, CORAL Loss: 0.0159
Validation Loss: 0.3256
Epoch [5/50], Class Loss: 0.2257, CORAL Loss: 0.0092
Validation Loss: 0.4681
Epoch [6/50], Class Loss: 21.0540, CORAL Loss: 16.0758
Validation Loss: 1.9084
Epoch [7/50], Class Loss: 1.7893, CORAL Loss: 0.0099
Validation Loss: 1.6458
Epoch [8/50], Class Loss: 1.6659, CORAL Loss: 0.0073
Validation Loss: 1.6275
Early stopping!
Source Domain Performance - Accuracy: 19.90%, Precision: 3.98%, Recall: 20.00%, F1 Score: 6.64%
Target Domain Performance - Accuracy: 19.31%, Precision: 3.86%, Recall: 20.00%, F1 Score: 6.47%

Run 5/10
Epoch [1/50], Class Loss: 1.3436, CORAL Loss: 0.0081
Validation Loss: 0.6608
Epoch [2/50], Class Loss: 0.9216, CORAL Loss: 0.0218
Validation Loss: 0.6695
Epoch [3/50], Class Loss: 0.5901, CORAL Loss: 0.0269
Validation Loss: 0.2809
Epoch [4/50], Class Loss: 0.3285, CORAL Loss: 0.0314
Validation Loss: 0.3311
Epoch [5/50], Class Loss: 0.2746, CORAL Loss: 0.0159
Validation Loss: 0.1572
Epoch [6/50], Class Loss: 0.2316, CORAL Loss: 0.0132
Validation Loss: 0.3363
Epoch [7/50], Class Loss: 0.7040, CORAL Loss: 0.0143
Validation Loss: 2.7843
Epoch [8/50], Class Loss: 0.7882, CORAL Loss: 0.0263
Validation Loss: 0.2755
Epoch [9/50], Class Loss: 0.3563, CORAL Loss: 0.0248
Validation Loss: 0.1974
Epoch [10/50], Class Loss: 0.2907, CORAL Loss: 0.0169
Validation Loss: 0.5175
Early stopping!
Source Domain Performance - Accuracy: 82.57%, Precision: 90.53%, Recall: 83.10%, F1 Score: 79.38%
Target Domain Performance - Accuracy: 80.49%, Precision: 80.12%, Recall: 79.81%, F1 Score: 73.54%

Run 6/10
Epoch [1/50], Class Loss: 1.1972, CORAL Loss: 0.0106
Validation Loss: 0.6012
Epoch [2/50], Class Loss: 0.4948, CORAL Loss: 0.0272
Validation Loss: 0.2675
Epoch [3/50], Class Loss: 0.2876, CORAL Loss: 0.0192
Validation Loss: 0.5226
Epoch [4/50], Class Loss: 0.2580, CORAL Loss: 0.0103
Validation Loss: 0.0681
Epoch [5/50], Class Loss: 0.2267, CORAL Loss: 0.0150
Validation Loss: 0.0788
Epoch [6/50], Class Loss: 0.0633, CORAL Loss: 0.0067
Validation Loss: 0.0982
Epoch [7/50], Class Loss: 0.3092, CORAL Loss: 0.0135
Validation Loss: 0.0275
Epoch [8/50], Class Loss: 0.0129, CORAL Loss: 0.0044
Validation Loss: 0.0070
Epoch [9/50], Class Loss: 0.1879, CORAL Loss: 0.0056
Validation Loss: 0.0240
Epoch [10/50], Class Loss: 0.0096, CORAL Loss: 0.0028
Validation Loss: 0.0071
Epoch [11/50], Class Loss: 0.0049, CORAL Loss: 0.0016
Validation Loss: 0.0047
Epoch [12/50], Class Loss: 0.0048, CORAL Loss: 0.0017
Validation Loss: 0.0051
Epoch [13/50], Class Loss: 0.0045, CORAL Loss: 0.0018
Validation Loss: 0.0046
Epoch [14/50], Class Loss: 0.0044, CORAL Loss: 0.0015
Validation Loss: 0.0048
Epoch [15/50], Class Loss: 0.0043, CORAL Loss: 0.0017
Validation Loss: 0.0047
Epoch [16/50], Class Loss: 0.0044, CORAL Loss: 0.0017
Validation Loss: 0.0058
Epoch [17/50], Class Loss: 0.0041, CORAL Loss: 0.0017
Validation Loss: 0.0040
Epoch [18/50], Class Loss: 0.0041, CORAL Loss: 0.0016
Validation Loss: 0.0040
Epoch [19/50], Class Loss: 0.0042, CORAL Loss: 0.0014
Validation Loss: 0.0043
Epoch [20/50], Class Loss: 0.0039, CORAL Loss: 0.0015
Validation Loss: 0.0038
Epoch [21/50], Class Loss: 0.0035, CORAL Loss: 0.0014
Validation Loss: 0.0037
Epoch [22/50], Class Loss: 0.0035, CORAL Loss: 0.0016
Validation Loss: 0.0038
Epoch [23/50], Class Loss: 0.0033, CORAL Loss: 0.0015
Validation Loss: 0.0040
Epoch [24/50], Class Loss: 0.0034, CORAL Loss: 0.0013
Validation Loss: 0.0038
Epoch [25/50], Class Loss: 0.0034, CORAL Loss: 0.0015
Validation Loss: 0.0038
Epoch [26/50], Class Loss: 0.0034, CORAL Loss: 0.0015
Validation Loss: 0.0037
Epoch [27/50], Class Loss: 0.0034, CORAL Loss: 0.0014
Validation Loss: 0.0038
Epoch [28/50], Class Loss: 0.0035, CORAL Loss: 0.0014
Validation Loss: 0.0037
Epoch [29/50], Class Loss: 0.0035, CORAL Loss: 0.0014
Validation Loss: 0.0036
Epoch [30/50], Class Loss: 0.0032, CORAL Loss: 0.0014
Validation Loss: 0.0038
Epoch [31/50], Class Loss: 0.0032, CORAL Loss: 0.0014
Validation Loss: 0.0038
Epoch [32/50], Class Loss: 0.0030, CORAL Loss: 0.0013
Validation Loss: 0.0038
Epoch [33/50], Class Loss: 0.0031, CORAL Loss: 0.0014
Validation Loss: 0.0038
Epoch [34/50], Class Loss: 0.0030, CORAL Loss: 0.0013
Validation Loss: 0.0038
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 61.04%, Precision: 70.15%, Recall: 60.37%, F1 Score: 54.25%

Run 7/10
Epoch [1/50], Class Loss: 1.2900, CORAL Loss: 0.0074
Validation Loss: 0.7456
Epoch [2/50], Class Loss: 0.4321, CORAL Loss: 0.0249
Validation Loss: 0.1312
Epoch [3/50], Class Loss: 1.0666, CORAL Loss: 0.7204
Validation Loss: 0.4531
Epoch [4/50], Class Loss: 0.5852, CORAL Loss: 0.0329
Validation Loss: 0.5909
Epoch [5/50], Class Loss: 0.4115, CORAL Loss: 0.0360
Validation Loss: 0.2584
Epoch [6/50], Class Loss: 0.3666, CORAL Loss: 0.0319
Validation Loss: 0.2105
Epoch [7/50], Class Loss: 0.2783, CORAL Loss: 0.0245
Validation Loss: 0.2823
Early stopping!
Source Domain Performance - Accuracy: 79.79%, Precision: 83.90%, Recall: 79.88%, F1 Score: 73.41%
Target Domain Performance - Accuracy: 36.96%, Precision: 29.06%, Recall: 36.46%, F1 Score: 29.08%

Run 8/10
Epoch [1/50], Class Loss: 1.2559, CORAL Loss: 0.0133
Validation Loss: 0.5778
Epoch [2/50], Class Loss: 1.3236, CORAL Loss: 0.1466
Validation Loss: 0.9440
Epoch [3/50], Class Loss: 0.8680, CORAL Loss: 0.0194
Validation Loss: 0.5626
Epoch [4/50], Class Loss: 0.5383, CORAL Loss: 0.0412
Validation Loss: 0.3282
Epoch [5/50], Class Loss: 0.3613, CORAL Loss: 0.0224
Validation Loss: 0.1907
Epoch [6/50], Class Loss: 0.3670, CORAL Loss: 0.0180
Validation Loss: 0.2534
Epoch [7/50], Class Loss: 0.2663, CORAL Loss: 0.0150
Validation Loss: 0.1334
Epoch [8/50], Class Loss: 0.1838, CORAL Loss: 0.0134
Validation Loss: 1.1111
Epoch [9/50], Class Loss: 0.2598, CORAL Loss: 0.0106
Validation Loss: 0.0929
Epoch [10/50], Class Loss: 0.3232, CORAL Loss: 0.0122
Validation Loss: 0.5191
Epoch [11/50], Class Loss: 0.2745, CORAL Loss: 0.0022
Validation Loss: 0.1414
Epoch [12/50], Class Loss: 0.1124, CORAL Loss: 0.0060
Validation Loss: 0.0687
Epoch [13/50], Class Loss: 0.0543, CORAL Loss: 0.0097
Validation Loss: 0.0353
Epoch [14/50], Class Loss: 0.0281, CORAL Loss: 0.0108
Validation Loss: 0.0240
Epoch [15/50], Class Loss: 0.0185, CORAL Loss: 0.0102
Validation Loss: 0.0193
Epoch [16/50], Class Loss: 0.0159, CORAL Loss: 0.0094
Validation Loss: 0.0175
Epoch [17/50], Class Loss: 0.0138, CORAL Loss: 0.0086
Validation Loss: 0.0160
Epoch [18/50], Class Loss: 0.0125, CORAL Loss: 0.0079
Validation Loss: 0.0183
Epoch [19/50], Class Loss: 0.0131, CORAL Loss: 0.0075
Validation Loss: 0.0154
Epoch [20/50], Class Loss: 0.0122, CORAL Loss: 0.0072
Validation Loss: 0.0149
Epoch [21/50], Class Loss: 0.0115, CORAL Loss: 0.0069
Validation Loss: 0.0153
Epoch [22/50], Class Loss: 0.0116, CORAL Loss: 0.0068
Validation Loss: 0.0151
Epoch [23/50], Class Loss: 0.0109, CORAL Loss: 0.0065
Validation Loss: 0.0141
Epoch [24/50], Class Loss: 0.0114, CORAL Loss: 0.0066
Validation Loss: 0.0145
Epoch [25/50], Class Loss: 0.0112, CORAL Loss: 0.0065
Validation Loss: 0.0138
Epoch [26/50], Class Loss: 0.0116, CORAL Loss: 0.0064
Validation Loss: 0.0142
Epoch [27/50], Class Loss: 0.0112, CORAL Loss: 0.0063
Validation Loss: 0.0140
Epoch [28/50], Class Loss: 0.0110, CORAL Loss: 0.0063
Validation Loss: 0.0149
Epoch [29/50], Class Loss: 0.0105, CORAL Loss: 0.0063
Validation Loss: 0.0142
Epoch [30/50], Class Loss: 0.0107, CORAL Loss: 0.0063
Validation Loss: 0.0145
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.85%, Recall: 99.85%, F1 Score: 99.85%
Target Domain Performance - Accuracy: 63.04%, Precision: 70.14%, Recall: 62.37%, F1 Score: 57.80%

Run 9/10
Epoch [1/50], Class Loss: 1.3596, CORAL Loss: 0.0053
Validation Loss: 0.5216
Epoch [2/50], Class Loss: 0.5568, CORAL Loss: 0.0308
Validation Loss: 0.2811
Epoch [3/50], Class Loss: 0.3600, CORAL Loss: 0.0250
Validation Loss: 1.9844
Epoch [4/50], Class Loss: 0.3116, CORAL Loss: 0.0163
Validation Loss: 0.1410
Epoch [5/50], Class Loss: 0.2552, CORAL Loss: 0.0117
Validation Loss: 0.0856
Epoch [6/50], Class Loss: 0.9088, CORAL Loss: 0.0377
Validation Loss: 0.3708
Epoch [7/50], Class Loss: 0.3278, CORAL Loss: 0.0339
Validation Loss: 0.1939
Epoch [8/50], Class Loss: 0.3375, CORAL Loss: 0.0137
Validation Loss: 0.5427
Epoch [9/50], Class Loss: 0.3413, CORAL Loss: 0.0083
Validation Loss: 0.2300
Epoch [10/50], Class Loss: 0.1480, CORAL Loss: 0.0060
Validation Loss: 0.0174
Epoch [11/50], Class Loss: 0.0205, CORAL Loss: 0.0057
Validation Loss: 0.0139
Epoch [12/50], Class Loss: 0.0152, CORAL Loss: 0.0059
Validation Loss: 0.0122
Epoch [13/50], Class Loss: 0.0123, CORAL Loss: 0.0059
Validation Loss: 0.0106
Epoch [14/50], Class Loss: 0.0105, CORAL Loss: 0.0055
Validation Loss: 0.0097
Epoch [15/50], Class Loss: 0.0101, CORAL Loss: 0.0054
Validation Loss: 0.0098
Epoch [16/50], Class Loss: 0.0092, CORAL Loss: 0.0049
Validation Loss: 0.0094
Epoch [17/50], Class Loss: 0.0081, CORAL Loss: 0.0046
Validation Loss: 0.0087
Epoch [18/50], Class Loss: 0.0082, CORAL Loss: 0.0043
Validation Loss: 0.0089
Epoch [19/50], Class Loss: 0.0074, CORAL Loss: 0.0040
Validation Loss: 0.0098
Epoch [20/50], Class Loss: 0.0079, CORAL Loss: 0.0036
Validation Loss: 0.0080
Epoch [21/50], Class Loss: 0.0074, CORAL Loss: 0.0036
Validation Loss: 0.0076
Epoch [22/50], Class Loss: 0.0072, CORAL Loss: 0.0035
Validation Loss: 0.0070
Epoch [23/50], Class Loss: 0.0074, CORAL Loss: 0.0034
Validation Loss: 0.0078
Epoch [24/50], Class Loss: 0.0069, CORAL Loss: 0.0035
Validation Loss: 0.0079
Epoch [25/50], Class Loss: 0.0069, CORAL Loss: 0.0034
Validation Loss: 0.0082
Epoch [26/50], Class Loss: 0.0071, CORAL Loss: 0.0033
Validation Loss: 0.0075
Epoch [27/50], Class Loss: 0.0074, CORAL Loss: 0.0033
Validation Loss: 0.0072
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 61.55%, Precision: 70.16%, Recall: 60.88%, F1 Score: 55.33%

Run 10/10
Epoch [1/50], Class Loss: 1.3464, CORAL Loss: 0.0094
Validation Loss: 0.8651
Epoch [2/50], Class Loss: 0.6089, CORAL Loss: 0.0378
Validation Loss: 0.5111
Epoch [3/50], Class Loss: 0.3983, CORAL Loss: 0.0253
Validation Loss: 0.5624
Epoch [4/50], Class Loss: 0.4480, CORAL Loss: 0.0161
Validation Loss: 0.3842
Epoch [5/50], Class Loss: 0.2035, CORAL Loss: 0.0158
Validation Loss: 0.0215
Epoch [6/50], Class Loss: 0.3565, CORAL Loss: 0.0191
Validation Loss: 1.7084
Epoch [7/50], Class Loss: 0.3452, CORAL Loss: 0.0150
Validation Loss: 0.2501
Epoch [8/50], Class Loss: 0.1101, CORAL Loss: 0.0085
Validation Loss: 0.0121
Epoch [9/50], Class Loss: 0.0072, CORAL Loss: 0.0023
Validation Loss: 0.0065
Epoch [10/50], Class Loss: 0.8145, CORAL Loss: 0.0128
Validation Loss: 0.2886
Epoch [11/50], Class Loss: 0.2597, CORAL Loss: 0.0413
Validation Loss: 0.2034
Epoch [12/50], Class Loss: 0.1785, CORAL Loss: 0.0423
Validation Loss: 0.1057
Epoch [13/50], Class Loss: 0.0617, CORAL Loss: 0.0325
Validation Loss: 0.0221
Epoch [14/50], Class Loss: 0.0180, CORAL Loss: 0.0169
Validation Loss: 0.0196
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 60.55%, Precision: 50.14%, Recall: 59.88%, F1 Score: 53.42%

Source performance: 80.16% 78.78% 80.24% 77.22%
Target performance: 54.38% 52.39% 53.99% 47.03%

Per-Class Accuracy on Target Domain:
bpsk: 80.00%
qpsk: 70.85%
4qam: 77.07%
16qam: 20.11%
apsk: 21.94%

Run 1/10
Epoch [1/50], Class Loss: 1.4524, JMMD Loss: 0.2029
Validation Loss: 1.1522
Epoch [2/50], Class Loss: 0.7149, JMMD Loss: 0.3318
Validation Loss: 0.5645
Epoch [3/50], Class Loss: 0.3074, JMMD Loss: 0.3300
Validation Loss: 0.2729
Epoch [4/50], Class Loss: 0.3917, JMMD Loss: 0.3390
Validation Loss: 0.2726
Epoch [5/50], Class Loss: 0.2711, JMMD Loss: 0.3484
Validation Loss: 0.0675
Epoch [6/50], Class Loss: 0.2289, JMMD Loss: 0.3525
Validation Loss: 0.4906
Epoch [7/50], Class Loss: 0.3959, JMMD Loss: 0.3543
Validation Loss: 0.0452
Epoch [8/50], Class Loss: 0.1599, JMMD Loss: 0.3639
Validation Loss: 0.0346
Epoch [9/50], Class Loss: 0.2636, JMMD Loss: 0.3657
Validation Loss: 0.1531
Epoch [10/50], Class Loss: 0.0567, JMMD Loss: 0.3627
Validation Loss: 0.6096
Epoch [11/50], Class Loss: 0.0210, JMMD Loss: 0.3739
Validation Loss: 0.0132
Epoch [12/50], Class Loss: 0.0106, JMMD Loss: 0.3764
Validation Loss: 0.0120
Epoch [13/50], Class Loss: 0.0098, JMMD Loss: 0.3819
Validation Loss: 0.0116
Epoch [14/50], Class Loss: 0.0094, JMMD Loss: 0.3767
Validation Loss: 0.0116
Epoch [15/50], Class Loss: 0.0092, JMMD Loss: 0.3763
Validation Loss: 0.0108
Epoch [16/50], Class Loss: 0.0089, JMMD Loss: 0.3799
Validation Loss: 0.0106
Epoch [17/50], Class Loss: 0.0088, JMMD Loss: 0.3846
Validation Loss: 0.0103
Epoch [18/50], Class Loss: 0.0090, JMMD Loss: 0.3838
Validation Loss: 0.0099
Epoch [19/50], Class Loss: 0.0088, JMMD Loss: 0.3924
Validation Loss: 0.0097
Epoch [20/50], Class Loss: 0.0090, JMMD Loss: 0.3909
Validation Loss: 0.0091
Epoch [21/50], Class Loss: 0.0093, JMMD Loss: 0.3897
Validation Loss: 0.0089
Epoch [22/50], Class Loss: 0.0096, JMMD Loss: 0.3933
Validation Loss: 0.0091
Epoch [23/50], Class Loss: 0.0095, JMMD Loss: 0.3922
Validation Loss: 0.0091
Epoch [24/50], Class Loss: 0.0096, JMMD Loss: 0.4005
Validation Loss: 0.0090
Epoch [25/50], Class Loss: 0.0099, JMMD Loss: 0.4051
Validation Loss: 0.0093
Epoch [26/50], Class Loss: 0.0100, JMMD Loss: 0.4175
Validation Loss: 0.0094
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 60.62%, Precision: 50.14%, Recall: 59.95%, F1 Score: 53.46%

Run 2/10
Epoch [1/50], Class Loss: 1.5698, JMMD Loss: 0.1374
Validation Loss: 0.9522
Epoch [2/50], Class Loss: 1.0362, JMMD Loss: 0.3125
Validation Loss: 0.7982
Epoch [3/50], Class Loss: 0.3267, JMMD Loss: 0.3303
Validation Loss: 0.1325
Epoch [4/50], Class Loss: 0.2608, JMMD Loss: 0.3415
Validation Loss: 0.1176
Epoch [5/50], Class Loss: 0.2426, JMMD Loss: 0.3502
Validation Loss: 0.2238
Epoch [6/50], Class Loss: 0.0658, JMMD Loss: 0.3520
Validation Loss: 0.0163
Epoch [7/50], Class Loss: 0.1411, JMMD Loss: 0.3561
Validation Loss: 0.0373
Epoch [8/50], Class Loss: 0.0143, JMMD Loss: 0.3678
Validation Loss: 0.0141
Epoch [9/50], Class Loss: 0.0101, JMMD Loss: 0.3839
Validation Loss: 0.0116
Epoch [10/50], Class Loss: 0.3486, JMMD Loss: 0.3765
Validation Loss: 0.0231
Epoch [11/50], Class Loss: 0.0151, JMMD Loss: 0.3736
Validation Loss: 0.0142
Epoch [12/50], Class Loss: 0.0128, JMMD Loss: 0.3725
Validation Loss: 0.0128
Epoch [13/50], Class Loss: 0.0114, JMMD Loss: 0.3750
Validation Loss: 0.0121
Epoch [14/50], Class Loss: 0.0109, JMMD Loss: 0.3808
Validation Loss: 0.0111
Epoch [15/50], Class Loss: 0.0099, JMMD Loss: 0.3822
Validation Loss: 0.0104
Epoch [16/50], Class Loss: 0.0098, JMMD Loss: 0.3764
Validation Loss: 0.0100
Epoch [17/50], Class Loss: 0.0089, JMMD Loss: 0.3857
Validation Loss: 0.0099
Epoch [18/50], Class Loss: 0.0089, JMMD Loss: 0.3818
Validation Loss: 0.0093
Epoch [19/50], Class Loss: 0.0087, JMMD Loss: 0.3794
Validation Loss: 0.0095
Epoch [20/50], Class Loss: 0.0088, JMMD Loss: 0.3912
Validation Loss: 0.0088
Epoch [21/50], Class Loss: 0.0083, JMMD Loss: 0.3848
Validation Loss: 0.0088
Epoch [22/50], Class Loss: 0.0083, JMMD Loss: 0.3873
Validation Loss: 0.0086
Epoch [23/50], Class Loss: 0.0085, JMMD Loss: 0.3819
Validation Loss: 0.0085
Epoch [24/50], Class Loss: 0.0084, JMMD Loss: 0.3873
Validation Loss: 0.0087
Epoch [25/50], Class Loss: 0.0086, JMMD Loss: 0.3912
Validation Loss: 0.0088
Epoch [26/50], Class Loss: 0.0086, JMMD Loss: 0.3864
Validation Loss: 0.0084
Epoch [27/50], Class Loss: 0.0086, JMMD Loss: 0.3882
Validation Loss: 0.0087
Epoch [28/50], Class Loss: 0.0088, JMMD Loss: 0.3885
Validation Loss: 0.0084
Epoch [29/50], Class Loss: 0.0087, JMMD Loss: 0.3876
Validation Loss: 0.0085
Epoch [30/50], Class Loss: 0.0088, JMMD Loss: 0.3864
Validation Loss: 0.0087
Epoch [31/50], Class Loss: 0.0088, JMMD Loss: 0.3841
Validation Loss: 0.0085
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 60.57%, Precision: 50.17%, Recall: 59.91%, F1 Score: 53.44%

Run 3/10
Epoch [1/50], Class Loss: 1.2728, JMMD Loss: 0.2449
Validation Loss: 0.8885
Epoch [2/50], Class Loss: 0.5869, JMMD Loss: 0.3505
Validation Loss: 0.4069
Epoch [3/50], Class Loss: 0.2870, JMMD Loss: 0.3561
Validation Loss: 0.0954
Epoch [4/50], Class Loss: 0.1799, JMMD Loss: 0.3650
Validation Loss: 0.1189
Epoch [5/50], Class Loss: 0.2832, JMMD Loss: 0.3778
Validation Loss: 0.2004
Epoch [6/50], Class Loss: 0.1687, JMMD Loss: 0.3736
Validation Loss: 0.0338
Epoch [7/50], Class Loss: 0.1213, JMMD Loss: 0.3915
Validation Loss: 1.3087
Epoch [8/50], Class Loss: 0.3581, JMMD Loss: 0.3528
Validation Loss: 1.0665
Epoch [9/50], Class Loss: 0.1721, JMMD Loss: 0.3665
Validation Loss: 0.2656
Epoch [10/50], Class Loss: 0.1406, JMMD Loss: 0.3682
Validation Loss: 0.1150
Epoch [11/50], Class Loss: 0.0866, JMMD Loss: 0.3798
Validation Loss: 0.0677
Early stopping!
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.83%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 60.47%, Precision: 50.13%, Recall: 59.81%, F1 Score: 53.38%

Run 4/10
Epoch [1/50], Class Loss: 1.4302, JMMD Loss: 0.2136
Validation Loss: 0.9506
Epoch [2/50], Class Loss: 0.9071, JMMD Loss: 0.3327
Validation Loss: 4.4478
Epoch [3/50], Class Loss: 0.6424, JMMD Loss: 0.3355
Validation Loss: 0.1435
Epoch [4/50], Class Loss: 0.2617, JMMD Loss: 0.3396
Validation Loss: 0.2442
Epoch [5/50], Class Loss: 0.5078, JMMD Loss: 0.3489
Validation Loss: 0.7147
Epoch [6/50], Class Loss: 0.5692, JMMD Loss: 0.3461
Validation Loss: 0.2386
Epoch [7/50], Class Loss: 0.1957, JMMD Loss: 0.3720
Validation Loss: 0.1543
Epoch [8/50], Class Loss: 0.1602, JMMD Loss: 0.3724
Validation Loss: 0.0306
Epoch [9/50], Class Loss: 0.0994, JMMD Loss: 0.3796
Validation Loss: 1.1962
Epoch [10/50], Class Loss: 0.1885, JMMD Loss: 0.3742
Validation Loss: 1.5256
Epoch [11/50], Class Loss: 0.1092, JMMD Loss: 0.3791
Validation Loss: 0.0206
Epoch [12/50], Class Loss: 0.0148, JMMD Loss: 0.3753
Validation Loss: 0.0144
Epoch [13/50], Class Loss: 0.0112, JMMD Loss: 0.3748
Validation Loss: 0.0123
Epoch [14/50], Class Loss: 0.0102, JMMD Loss: 0.3807
Validation Loss: 0.0116
Epoch [15/50], Class Loss: 0.0098, JMMD Loss: 0.3794
Validation Loss: 0.0112
Epoch [16/50], Class Loss: 0.0093, JMMD Loss: 0.3779
Validation Loss: 0.0110
Epoch [17/50], Class Loss: 0.0092, JMMD Loss: 0.3731
Validation Loss: 0.0113
Epoch [18/50], Class Loss: 0.0088, JMMD Loss: 0.3797
Validation Loss: 0.0107
Epoch [19/50], Class Loss: 0.0089, JMMD Loss: 0.3865
Validation Loss: 0.0109
Epoch [20/50], Class Loss: 0.0085, JMMD Loss: 0.3818
Validation Loss: 0.0114
Epoch [21/50], Class Loss: 0.0088, JMMD Loss: 0.3798
Validation Loss: 0.0111
Epoch [22/50], Class Loss: 0.0088, JMMD Loss: 0.3787
Validation Loss: 0.0111
Epoch [23/50], Class Loss: 0.0088, JMMD Loss: 0.3828
Validation Loss: 0.0110
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 60.42%, Precision: 69.92%, Recall: 59.76%, F1 Score: 53.32%

Run 5/10
Epoch [1/50], Class Loss: 1.3431, JMMD Loss: 0.2273
Validation Loss: 0.7259
Epoch [2/50], Class Loss: 0.6218, JMMD Loss: 0.3192
Validation Loss: 0.2487
Epoch [3/50], Class Loss: 0.2752, JMMD Loss: 0.3350
Validation Loss: 0.1977
Epoch [4/50], Class Loss: 0.3589, JMMD Loss: 0.3284
Validation Loss: 0.1377
Epoch [5/50], Class Loss: 0.2726, JMMD Loss: 0.3348
Validation Loss: 0.6081
Epoch [6/50], Class Loss: 0.3015, JMMD Loss: 0.3357
Validation Loss: 0.3028
Epoch [7/50], Class Loss: 0.0526, JMMD Loss: 0.3378
Validation Loss: 0.0185
Epoch [8/50], Class Loss: 0.0565, JMMD Loss: 0.3088
Validation Loss: 0.0204
Epoch [9/50], Class Loss: 0.0073, JMMD Loss: 0.2830
Validation Loss: 0.0200
Epoch [10/50], Class Loss: 0.0100, JMMD Loss: 0.2742
Validation Loss: 0.0127
Epoch [11/50], Class Loss: 0.0062, JMMD Loss: 0.2475
Validation Loss: 0.0132
Epoch [12/50], Class Loss: 0.0060, JMMD Loss: 0.2383
Validation Loss: 0.0129
Epoch [13/50], Class Loss: 0.0063, JMMD Loss: 0.2329
Validation Loss: 0.0147
Epoch [14/50], Class Loss: 0.0058, JMMD Loss: 0.2177
Validation Loss: 0.0131
Epoch [15/50], Class Loss: 0.0059, JMMD Loss: 0.2221
Validation Loss: 0.0132
Early stopping!
Source Domain Performance - Accuracy: 99.78%, Precision: 99.78%, Recall: 99.78%, F1 Score: 99.78%
Target Domain Performance - Accuracy: 61.06%, Precision: 69.23%, Recall: 60.39%, F1 Score: 54.47%

Run 6/10
Epoch [1/50], Class Loss: 1.3059, JMMD Loss: 0.2456
Validation Loss: 0.8919
Epoch [2/50], Class Loss: 0.5014, JMMD Loss: 0.3392
Validation Loss: 0.2660
Epoch [3/50], Class Loss: 0.3212, JMMD Loss: 0.3436
Validation Loss: 0.0961
Epoch [4/50], Class Loss: 0.1737, JMMD Loss: 0.3669
Validation Loss: 0.0173
Epoch [5/50], Class Loss: 0.5557, JMMD Loss: 0.3521
Validation Loss: 0.0787
Epoch [6/50], Class Loss: 0.2512, JMMD Loss: 0.3572
Validation Loss: 0.0347
Epoch [7/50], Class Loss: 0.1419, JMMD Loss: 0.3641
Validation Loss: 0.0300
Epoch [8/50], Class Loss: 0.1723, JMMD Loss: 0.3676
Validation Loss: 0.3872
Epoch [9/50], Class Loss: 0.1066, JMMD Loss: 0.3727
Validation Loss: 0.0221
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.81%, Recall: 99.80%, F1 Score: 99.81%
Target Domain Performance - Accuracy: 60.47%, Precision: 50.14%, Recall: 59.81%, F1 Score: 53.38%

Run 7/10
Epoch [1/50], Class Loss: 1.6161, JMMD Loss: 0.0785
Validation Loss: 1.6097
Epoch [2/50], Class Loss: 1.6097, JMMD Loss: 0.0762
Validation Loss: 1.6095
Epoch [3/50], Class Loss: 1.6098, JMMD Loss: 0.0767
Validation Loss: 1.6094
Epoch [4/50], Class Loss: 1.6099, JMMD Loss: 0.0765
Validation Loss: 1.6096
Epoch [5/50], Class Loss: 1.6095, JMMD Loss: 0.0765
Validation Loss: 1.6095
Epoch [6/50], Class Loss: 1.6096, JMMD Loss: 0.0765
Validation Loss: 1.6095
Epoch [7/50], Class Loss: 1.6096, JMMD Loss: 0.0767
Validation Loss: 1.6095
Epoch [8/50], Class Loss: 1.6095, JMMD Loss: 0.0770
Validation Loss: 1.6096
Early stopping!
Source Domain Performance - Accuracy: 19.48%, Precision: 3.90%, Recall: 20.00%, F1 Score: 6.52%
Target Domain Performance - Accuracy: 20.21%, Precision: 4.04%, Recall: 20.00%, F1 Score: 6.73%

Run 8/10
Epoch [1/50], Class Loss: 1.5111, JMMD Loss: 0.1868
Validation Loss: 1.2700
Epoch [2/50], Class Loss: 0.7362, JMMD Loss: 0.3369
Validation Loss: 0.4077
Epoch [3/50], Class Loss: 0.3548, JMMD Loss: 0.3404
Validation Loss: 0.1975
Epoch [4/50], Class Loss: 0.3047, JMMD Loss: 0.3509
Validation Loss: 0.8937
Epoch [5/50], Class Loss: 0.2021, JMMD Loss: 0.3579
Validation Loss: 0.0378
Epoch [6/50], Class Loss: 0.1208, JMMD Loss: 0.3675
Validation Loss: 0.0219
Epoch [7/50], Class Loss: 0.2470, JMMD Loss: 0.3773
Validation Loss: 0.0885
Epoch [8/50], Class Loss: 0.0366, JMMD Loss: 0.3818
Validation Loss: 0.0471
Epoch [9/50], Class Loss: 0.0147, JMMD Loss: 0.3887
Validation Loss: 0.0101
Epoch [10/50], Class Loss: 0.1634, JMMD Loss: 0.3760
Validation Loss: 0.0993
Epoch [11/50], Class Loss: 0.0553, JMMD Loss: 0.3659
Validation Loss: 0.0406
Epoch [12/50], Class Loss: 0.0308, JMMD Loss: 0.3697
Validation Loss: 0.0258
Epoch [13/50], Class Loss: 0.0200, JMMD Loss: 0.3766
Validation Loss: 0.0204
Epoch [14/50], Class Loss: 0.0150, JMMD Loss: 0.3766
Validation Loss: 0.0158
Early stopping!
Source Domain Performance - Accuracy: 99.80%, Precision: 99.81%, Recall: 99.81%, F1 Score: 99.81%
Target Domain Performance - Accuracy: 60.45%, Precision: 50.14%, Recall: 59.78%, F1 Score: 53.37%

Run 9/10
Epoch [1/50], Class Loss: 1.6098, JMMD Loss: 0.1783
Validation Loss: 1.1831
Epoch [2/50], Class Loss: 0.8735, JMMD Loss: 0.3358
Validation Loss: 0.3927
Epoch [3/50], Class Loss: 0.6795, JMMD Loss: 0.3408
Validation Loss: 0.2974
Epoch [4/50], Class Loss: 0.3999, JMMD Loss: 0.3456
Validation Loss: 0.3444
Epoch [5/50], Class Loss: 0.2114, JMMD Loss: 0.3460
Validation Loss: 0.2408
Epoch [6/50], Class Loss: 0.1687, JMMD Loss: 0.3555
Validation Loss: 0.2041
Epoch [7/50], Class Loss: 0.1844, JMMD Loss: 0.3565
Validation Loss: 0.0460
Epoch [8/50], Class Loss: 0.0197, JMMD Loss: 0.3731
Validation Loss: 0.0180
Epoch [9/50], Class Loss: 0.2977, JMMD Loss: 0.3681
Validation Loss: 0.0424
Epoch [10/50], Class Loss: 0.1206, JMMD Loss: 0.3709
Validation Loss: 0.0225
Epoch [11/50], Class Loss: 0.0089, JMMD Loss: 0.3725
Validation Loss: 0.0142
Epoch [12/50], Class Loss: 0.0079, JMMD Loss: 0.3759
Validation Loss: 0.0131
Epoch [13/50], Class Loss: 0.0074, JMMD Loss: 0.3756
Validation Loss: 0.0127
Epoch [14/50], Class Loss: 0.0076, JMMD Loss: 0.3757
Validation Loss: 0.0120
Epoch [15/50], Class Loss: 0.0072, JMMD Loss: 0.3769
Validation Loss: 0.0113
Epoch [16/50], Class Loss: 0.0071, JMMD Loss: 0.3706
Validation Loss: 0.0111
Epoch [17/50], Class Loss: 0.0073, JMMD Loss: 0.3729
Validation Loss: 0.0108
Epoch [18/50], Class Loss: 0.0074, JMMD Loss: 0.3732
Validation Loss: 0.0107
Epoch [19/50], Class Loss: 0.0081, JMMD Loss: 0.3787
Validation Loss: 0.0106
Epoch [20/50], Class Loss: 0.0079, JMMD Loss: 0.3782
Validation Loss: 0.0106
Epoch [21/50], Class Loss: 0.0081, JMMD Loss: 0.3808
Validation Loss: 0.0105
Epoch [22/50], Class Loss: 0.0078, JMMD Loss: 0.3752
Validation Loss: 0.0107
Epoch [23/50], Class Loss: 0.0082, JMMD Loss: 0.3757
Validation Loss: 0.0105
Epoch [24/50], Class Loss: 0.0082, JMMD Loss: 0.3795
Validation Loss: 0.0106
Epoch [25/50], Class Loss: 0.0085, JMMD Loss: 0.3778
Validation Loss: 0.0105
Epoch [26/50], Class Loss: 0.0085, JMMD Loss: 0.3833
Validation Loss: 0.0105
Epoch [27/50], Class Loss: 0.0088, JMMD Loss: 0.3844
Validation Loss: 0.0104
Epoch [28/50], Class Loss: 0.0089, JMMD Loss: 0.3804
Validation Loss: 0.0105
Epoch [29/50], Class Loss: 0.0092, JMMD Loss: 0.3824
Validation Loss: 0.0104
Epoch [30/50], Class Loss: 0.0089, JMMD Loss: 0.3782
Validation Loss: 0.0105
Epoch [31/50], Class Loss: 0.0097, JMMD Loss: 0.3800
Validation Loss: 0.0104
Epoch [32/50], Class Loss: 0.0092, JMMD Loss: 0.3834
Validation Loss: 0.0104
Epoch [33/50], Class Loss: 0.0095, JMMD Loss: 0.3749
Validation Loss: 0.0104
Epoch [34/50], Class Loss: 0.0095, JMMD Loss: 0.3763
Validation Loss: 0.0104
Epoch [35/50], Class Loss: 0.0094, JMMD Loss: 0.3760
Validation Loss: 0.0104
Epoch [36/50], Class Loss: 0.0096, JMMD Loss: 0.3759
Validation Loss: 0.0104
Epoch [37/50], Class Loss: 0.0096, JMMD Loss: 0.3825
Validation Loss: 0.0104
Epoch [38/50], Class Loss: 0.0094, JMMD Loss: 0.3730
Validation Loss: 0.0104
Epoch [39/50], Class Loss: 0.0097, JMMD Loss: 0.3747
Validation Loss: 0.0103
Epoch [40/50], Class Loss: 0.0095, JMMD Loss: 0.3735
Validation Loss: 0.0105
Epoch [41/50], Class Loss: 0.0097, JMMD Loss: 0.3748
Validation Loss: 0.0103
Epoch [42/50], Class Loss: 0.0097, JMMD Loss: 0.3718
Validation Loss: 0.0104
Epoch [43/50], Class Loss: 0.0096, JMMD Loss: 0.3746
Validation Loss: 0.0103
Epoch [44/50], Class Loss: 0.0096, JMMD Loss: 0.3748
Validation Loss: 0.0104
Epoch [45/50], Class Loss: 0.0098, JMMD Loss: 0.3771
Validation Loss: 0.0104
Epoch [46/50], Class Loss: 0.0099, JMMD Loss: 0.3758
Validation Loss: 0.0104
Epoch [47/50], Class Loss: 0.0099, JMMD Loss: 0.3778
Validation Loss: 0.0104
Epoch [48/50], Class Loss: 0.0096, JMMD Loss: 0.3744
Validation Loss: 0.0103
Epoch [49/50], Class Loss: 0.0096, JMMD Loss: 0.3740
Validation Loss: 0.0103
Epoch [50/50], Class Loss: 0.0097, JMMD Loss: 0.3804
Validation Loss: 0.0103
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 60.57%, Precision: 50.13%, Recall: 59.90%, F1 Score: 53.43%

Run 10/10
Epoch [1/50], Class Loss: 1.5701, JMMD Loss: 0.1642
Validation Loss: 0.9901
Epoch [2/50], Class Loss: 0.6011, JMMD Loss: 0.3413
Validation Loss: 0.2480
Epoch [3/50], Class Loss: 0.4189, JMMD Loss: 0.3467
Validation Loss: 0.2084
Epoch [4/50], Class Loss: 0.2329, JMMD Loss: 0.3584
Validation Loss: 0.0918
Epoch [5/50], Class Loss: 0.1841, JMMD Loss: 0.3721
Validation Loss: 0.1047
Epoch [6/50], Class Loss: 0.2841, JMMD Loss: 0.3802
Validation Loss: 0.2117
Epoch [7/50], Class Loss: 0.2686, JMMD Loss: 0.3755
Validation Loss: 0.1073
Epoch [8/50], Class Loss: 0.0823, JMMD Loss: 0.3862
Validation Loss: 0.0128
Epoch [9/50], Class Loss: 0.0106, JMMD Loss: 0.4003
Validation Loss: 0.0110
Epoch [10/50], Class Loss: 0.1547, JMMD Loss: 0.3989
Validation Loss: 0.3161
Epoch [11/50], Class Loss: 0.2419, JMMD Loss: 0.3779
Validation Loss: 0.1760
Epoch [12/50], Class Loss: 0.1354, JMMD Loss: 0.3792
Validation Loss: 0.0887
Epoch [13/50], Class Loss: 0.0679, JMMD Loss: 0.3787
Validation Loss: 0.0447
Epoch [14/50], Class Loss: 0.0357, JMMD Loss: 0.3763
Validation Loss: 0.0257
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 60.45%, Precision: 50.07%, Recall: 59.78%, F1 Score: 53.35%

Source performance: 91.82% 90.26% 91.87% 90.52%
Target performance: 56.53% 49.41% 55.91% 48.83%

Per-Class Accuracy on Target Domain (Mean over runs):
  Class 0: 100.00%
  Class 1: 89.57%
  Class 2: 89.57%
  Class 3: 0.11%
  Class 4: 0.29%

Run 1/10
Epoch 1/50, Train Loss: 1.3338, Train Acc: 0.3956, Val Loss: 0.7774, Val Acc: 0.5137
Epoch 2/50, Train Loss: 0.6913, Train Acc: 0.6559, Val Loss: 1.9061, Val Acc: 0.6038
Epoch 3/50, Train Loss: 0.6908, Train Acc: 0.7122, Val Loss: 0.2099, Val Acc: 0.8108
Epoch 4/50, Train Loss: 1.0542, Train Acc: 0.7006, Val Loss: 0.7573, Val Acc: 0.4927
Epoch 5/50, Train Loss: 0.5735, Train Acc: 0.7098, Val Loss: 0.1661, Val Acc: 0.8047
Epoch 6/50, Train Loss: 0.8305, Train Acc: 0.8345, Val Loss: 0.2168, Val Acc: 0.8323
Epoch 7/50, Train Loss: 0.3230, Train Acc: 0.8853, Val Loss: 1.2228, Val Acc: 0.8008
Epoch 8/50, Train Loss: 0.2957, Train Acc: 0.9010, Val Loss: 0.0051, Val Acc: 0.9995
Epoch 9/50, Train Loss: 0.2391, Train Acc: 0.9451, Val Loss: 0.0467, Val Acc: 0.9993
Epoch 10/50, Train Loss: 0.3010, Train Acc: 0.9308, Val Loss: 0.0038, Val Acc: 0.9995
Epoch 11/50, Train Loss: 0.0024, Train Acc: 0.9995, Val Loss: 0.0032, Val Acc: 0.9998
Epoch 12/50, Train Loss: 0.0035, Train Acc: 0.9996, Val Loss: 0.0030, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0035, Train Acc: 0.9995, Val Loss: 0.0029, Val Acc: 0.9998
Epoch 14/50, Train Loss: 0.0028, Train Acc: 0.9995, Val Loss: 0.0028, Val Acc: 0.9998
Epoch 15/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0028, Val Acc: 0.9998
Epoch 16/50, Train Loss: 0.0019, Train Acc: 0.9998, Val Loss: 0.0027, Val Acc: 0.9998
Epoch 17/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0022, Val Acc: 0.9998
Epoch 18/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0028, Val Acc: 0.9998
Epoch 19/50, Train Loss: 0.0015, Train Acc: 0.9998, Val Loss: 0.0025, Val Acc: 0.9998
Epoch 20/50, Train Loss: 0.0013, Train Acc: 0.9998, Val Loss: 0.0024, Val Acc: 0.9998
Epoch 21/50, Train Loss: 0.0012, Train Acc: 0.9998, Val Loss: 0.0024, Val Acc: 0.9998
Epoch 22/50, Train Loss: 0.0011, Train Acc: 0.9999, Val Loss: 0.0022, Val Acc: 0.9998
Early stopping!

Run 2/10
Epoch 1/50, Train Loss: 1.5772, Train Acc: 0.3619, Val Loss: 0.7194, Val Acc: 0.8040
Epoch 2/50, Train Loss: 0.9318, Train Acc: 0.6721, Val Loss: 0.6922, Val Acc: 0.7344
Epoch 3/50, Train Loss: 0.7042, Train Acc: 0.6369, Val Loss: 1.1260, Val Acc: 0.4409
Epoch 4/50, Train Loss: 0.7411, Train Acc: 0.7304, Val Loss: 0.0635, Val Acc: 0.9995
Epoch 5/50, Train Loss: 0.7371, Train Acc: 0.7974, Val Loss: 0.1227, Val Acc: 0.9995
Epoch 6/50, Train Loss: 0.6430, Train Acc: 0.8123, Val Loss: 0.0080, Val Acc: 0.9995
Epoch 7/50, Train Loss: 0.5413, Train Acc: 0.8284, Val Loss: 0.0534, Val Acc: 0.9995
Epoch 8/50, Train Loss: 0.2912, Train Acc: 0.9150, Val Loss: 0.0126, Val Acc: 0.9995
Epoch 9/50, Train Loss: 0.5629, Train Acc: 0.8998, Val Loss: 0.3175, Val Acc: 0.8040
Epoch 10/50, Train Loss: 0.4746, Train Acc: 0.9182, Val Loss: 0.0067, Val Acc: 0.9995
Epoch 11/50, Train Loss: 0.0044, Train Acc: 0.9993, Val Loss: 0.0054, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0032, Train Acc: 0.9994, Val Loss: 0.0045, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0026, Train Acc: 0.9995, Val Loss: 0.0037, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0047, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0044, Train Acc: 0.9987, Val Loss: 0.0044, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0023, Train Acc: 0.9995, Val Loss: 0.0035, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0039, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0048, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0043, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0016, Train Acc: 0.9999, Val Loss: 0.0037, Val Acc: 0.9995
Epoch 21/50, Train Loss: 0.0016, Train Acc: 0.9998, Val Loss: 0.0039, Val Acc: 0.9995
Early stopping!

Run 3/10
Epoch 1/50, Train Loss: 1.4398, Train Acc: 0.3911, Val Loss: 0.3751, Val Acc: 0.7791
Epoch 2/50, Train Loss: 0.5739, Train Acc: 0.6722, Val Loss: 0.4902, Val Acc: 0.7192
Epoch 3/50, Train Loss: 1.3398, Train Acc: 0.7216, Val Loss: 0.6743, Val Acc: 0.7534
Epoch 4/50, Train Loss: 0.8377, Train Acc: 0.7313, Val Loss: 0.5686, Val Acc: 0.8066
Epoch 5/50, Train Loss: 0.3948, Train Acc: 0.8307, Val Loss: 0.1930, Val Acc: 0.8074
Epoch 6/50, Train Loss: 0.2839, Train Acc: 0.8519, Val Loss: 0.2093, Val Acc: 0.8064
Epoch 7/50, Train Loss: 0.7461, Train Acc: 0.8495, Val Loss: 2.8281, Val Acc: 0.5862
Epoch 8/50, Train Loss: 0.2959, Train Acc: 0.8629, Val Loss: 0.3661, Val Acc: 0.8042
Epoch 9/50, Train Loss: 0.2666, Train Acc: 0.8998, Val Loss: 0.9731, Val Acc: 0.5452
Epoch 10/50, Train Loss: 0.5695, Train Acc: 0.8820, Val Loss: 0.3368, Val Acc: 0.8320
Early stopping!

Run 4/10
Epoch 1/50, Train Loss: 1.2193, Train Acc: 0.4367, Val Loss: 0.4974, Val Acc: 0.9214
Epoch 2/50, Train Loss: 0.5829, Train Acc: 0.7892, Val Loss: 0.2605, Val Acc: 0.9990
Epoch 3/50, Train Loss: 1.1109, Train Acc: 0.6627, Val Loss: 0.1576, Val Acc: 0.9995
Epoch 4/50, Train Loss: 0.7648, Train Acc: 0.7469, Val Loss: 0.4128, Val Acc: 0.8062
Epoch 5/50, Train Loss: 0.9262, Train Acc: 0.6840, Val Loss: 0.2224, Val Acc: 0.9802
Epoch 6/50, Train Loss: 0.2435, Train Acc: 0.8702, Val Loss: 0.1009, Val Acc: 0.9993
Epoch 7/50, Train Loss: 0.2021, Train Acc: 0.8727, Val Loss: 0.0531, Val Acc: 0.9990
Epoch 8/50, Train Loss: 0.4503, Train Acc: 0.8885, Val Loss: 0.0894, Val Acc: 0.9761
Epoch 9/50, Train Loss: 0.4590, Train Acc: 0.8890, Val Loss: 0.1364, Val Acc: 0.9536
Epoch 10/50, Train Loss: 0.2853, Train Acc: 0.9282, Val Loss: 0.0062, Val Acc: 0.9995
Epoch 11/50, Train Loss: 0.0046, Train Acc: 0.9995, Val Loss: 0.0050, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0045, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0045, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0045, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0048, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0022, Train Acc: 0.9997, Val Loss: 0.0047, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0025, Train Acc: 0.9997, Val Loss: 0.0041, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0046, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0019, Train Acc: 0.9998, Val Loss: 0.0050, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0047, Val Acc: 0.9995
Epoch 21/50, Train Loss: 0.0018, Train Acc: 0.9998, Val Loss: 0.0049, Val Acc: 0.9995
Epoch 22/50, Train Loss: 0.0019, Train Acc: 0.9998, Val Loss: 0.0049, Val Acc: 0.9995
Early stopping!

Run 5/10
Epoch 1/50, Train Loss: 1.2409, Train Acc: 0.3895, Val Loss: 0.5236, Val Acc: 0.7827
Epoch 2/50, Train Loss: 1.0063, Train Acc: 0.6414, Val Loss: 0.3551, Val Acc: 0.9126
Epoch 3/50, Train Loss: 0.9506, Train Acc: 0.6253, Val Loss: 0.8369, Val Acc: 0.4214
Epoch 4/50, Train Loss: 0.6277, Train Acc: 0.6751, Val Loss: 0.1394, Val Acc: 0.9983
Epoch 5/50, Train Loss: 0.6956, Train Acc: 0.8530, Val Loss: 0.0915, Val Acc: 0.9729
Epoch 6/50, Train Loss: 1.0209, Train Acc: 0.7885, Val Loss: 0.4782, Val Acc: 0.7656
Epoch 7/50, Train Loss: 0.1996, Train Acc: 0.9406, Val Loss: 0.0032, Val Acc: 0.9993
Epoch 8/50, Train Loss: 0.7371, Train Acc: 0.8676, Val Loss: 0.0064, Val Acc: 0.9995
Epoch 9/50, Train Loss: 0.2919, Train Acc: 0.9445, Val Loss: 0.6883, Val Acc: 0.8108
Epoch 10/50, Train Loss: 0.4156, Train Acc: 0.9015, Val Loss: 0.7542, Val Acc: 0.8008
Epoch 11/50, Train Loss: 0.0286, Train Acc: 0.9926, Val Loss: 0.0026, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0028, Train Acc: 0.9994, Val Loss: 0.0027, Val Acc: 0.9998
Epoch 13/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0029, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0030, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0020, Train Acc: 0.9997, Val Loss: 0.0036, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0033, Val Acc: 0.9995
Early stopping!

Run 6/10
Epoch 1/50, Train Loss: 1.3793, Train Acc: 0.3932, Val Loss: 0.6366, Val Acc: 0.5957
Epoch 2/50, Train Loss: 0.5912, Train Acc: 0.6604, Val Loss: 0.3854, Val Acc: 0.7983
Epoch 3/50, Train Loss: 0.7827, Train Acc: 0.7182, Val Loss: 3.1429, Val Acc: 0.3999
Epoch 4/50, Train Loss: 1.0477, Train Acc: 0.7161, Val Loss: 2.4816, Val Acc: 0.3982
Epoch 5/50, Train Loss: 0.7092, Train Acc: 0.8059, Val Loss: 0.0636, Val Acc: 0.9966
Epoch 6/50, Train Loss: 0.1567, Train Acc: 0.9365, Val Loss: 0.0819, Val Acc: 0.9651
Epoch 7/50, Train Loss: 0.2655, Train Acc: 0.9514, Val Loss: 0.0087, Val Acc: 0.9993
Epoch 8/50, Train Loss: 1.0540, Train Acc: 0.7865, Val Loss: 2.0191, Val Acc: 0.4426
Epoch 9/50, Train Loss: 0.4389, Train Acc: 0.8271, Val Loss: 0.0047, Val Acc: 0.9990
Epoch 10/50, Train Loss: 0.5646, Train Acc: 0.8590, Val Loss: 0.0134, Val Acc: 0.9995
Epoch 11/50, Train Loss: 0.0078, Train Acc: 0.9993, Val Loss: 0.0055, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0043, Train Acc: 0.9993, Val Loss: 0.0047, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0034, Train Acc: 0.9994, Val Loss: 0.0042, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0032, Train Acc: 0.9994, Val Loss: 0.0043, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0029, Train Acc: 0.9995, Val Loss: 0.0039, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0035, Train Acc: 0.9993, Val Loss: 0.0035, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0029, Train Acc: 0.9995, Val Loss: 0.0039, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0020, Train Acc: 0.9997, Val Loss: 0.0039, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0059, Train Acc: 0.9973, Val Loss: 0.0041, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0036, Val Acc: 0.9995
Epoch 21/50, Train Loss: 0.0018, Train Acc: 0.9998, Val Loss: 0.0037, Val Acc: 0.9995
Early stopping!

Run 7/10
Epoch 1/50, Train Loss: 1.2283, Train Acc: 0.3871, Val Loss: 0.6275, Val Acc: 0.6533
Epoch 2/50, Train Loss: 0.6056, Train Acc: 0.6715, Val Loss: 0.7576, Val Acc: 0.5618
Epoch 3/50, Train Loss: 0.4544, Train Acc: 0.7557, Val Loss: 0.3531, Val Acc: 0.7810
Epoch 4/50, Train Loss: 0.8293, Train Acc: 0.6437, Val Loss: 0.1691, Val Acc: 0.9897
Epoch 5/50, Train Loss: 0.7904, Train Acc: 0.8312, Val Loss: 0.2434, Val Acc: 0.8074
Epoch 6/50, Train Loss: 0.8895, Train Acc: 0.8058, Val Loss: 0.9032, Val Acc: 0.8010
Epoch 7/50, Train Loss: 0.7985, Train Acc: 0.7975, Val Loss: 0.6678, Val Acc: 0.6951
Epoch 8/50, Train Loss: 0.5043, Train Acc: 0.8715, Val Loss: 0.9502, Val Acc: 0.6912
Epoch 9/50, Train Loss: 0.4424, Train Acc: 0.9299, Val Loss: 0.1611, Val Acc: 0.9185
Epoch 10/50, Train Loss: 0.5423, Train Acc: 0.8734, Val Loss: 0.0070, Val Acc: 0.9993
Epoch 11/50, Train Loss: 0.0040, Train Acc: 0.9995, Val Loss: 0.0054, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0056, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0053, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0050, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0024, Train Acc: 0.9998, Val Loss: 0.0057, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0028, Train Acc: 0.9997, Val Loss: 0.0052, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0026, Train Acc: 0.9998, Val Loss: 0.0052, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0055, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0047, Val Acc: 0.9995
Epoch 20/50, Train Loss: 0.0025, Train Acc: 0.9998, Val Loss: 0.0047, Val Acc: 0.9995
Epoch 21/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0042, Val Acc: 0.9995
Epoch 22/50, Train Loss: 0.0023, Train Acc: 0.9998, Val Loss: 0.0045, Val Acc: 0.9995
Epoch 23/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0043, Val Acc: 0.9995
Epoch 24/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0046, Val Acc: 0.9995
Epoch 25/50, Train Loss: 0.0022, Train Acc: 0.9998, Val Loss: 0.0044, Val Acc: 0.9995
Epoch 26/50, Train Loss: 0.0020, Train Acc: 0.9998, Val Loss: 0.0043, Val Acc: 0.9995
Early stopping!

Run 8/10
Epoch 1/50, Train Loss: 1.2896, Train Acc: 0.3694, Val Loss: 0.4787, Val Acc: 0.8042
Epoch 2/50, Train Loss: 0.5540, Train Acc: 0.6970, Val Loss: 0.3171, Val Acc: 0.8042
Epoch 3/50, Train Loss: 1.1073, Train Acc: 0.6851, Val Loss: 0.1787, Val Acc: 0.9958
Epoch 4/50, Train Loss: 0.8635, Train Acc: 0.7291, Val Loss: 0.2310, Val Acc: 0.8057
Epoch 5/50, Train Loss: 0.9749, Train Acc: 0.7746, Val Loss: 0.1845, Val Acc: 0.9946
Epoch 6/50, Train Loss: 0.5962, Train Acc: 0.8089, Val Loss: 0.0552, Val Acc: 0.9993
Epoch 7/50, Train Loss: 0.6166, Train Acc: 0.8399, Val Loss: 2.2284, Val Acc: 0.5967
Epoch 8/50, Train Loss: 0.5161, Train Acc: 0.8854, Val Loss: 3.9431, Val Acc: 0.6550
Epoch 9/50, Train Loss: 0.4588, Train Acc: 0.9357, Val Loss: 0.1892, Val Acc: 0.9766
Epoch 10/50, Train Loss: 0.1917, Train Acc: 0.9214, Val Loss: 0.5757, Val Acc: 0.8052
Epoch 11/50, Train Loss: 0.0120, Train Acc: 0.9963, Val Loss: 0.0034, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0022, Train Acc: 0.9995, Val Loss: 0.0030, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0026, Train Acc: 0.9994, Val Loss: 0.0036, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0038, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0033, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0048, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0021, Train Acc: 0.9998, Val Loss: 0.0032, Val Acc: 0.9995
Early stopping!

Run 9/10
Epoch 1/50, Train Loss: 1.1659, Train Acc: 0.4578, Val Loss: 1.6850, Val Acc: 0.4685
Epoch 2/50, Train Loss: 0.6878, Train Acc: 0.6403, Val Loss: 0.3520, Val Acc: 0.8025
Epoch 3/50, Train Loss: 0.7532, Train Acc: 0.6143, Val Loss: 0.7236, Val Acc: 0.5239
Epoch 4/50, Train Loss: 0.5460, Train Acc: 0.7296, Val Loss: 0.4064, Val Acc: 0.7986
Epoch 5/50, Train Loss: 0.7303, Train Acc: 0.7531, Val Loss: 0.2012, Val Acc: 0.9751
Epoch 6/50, Train Loss: 0.5612, Train Acc: 0.7927, Val Loss: 0.8943, Val Acc: 0.8025
Epoch 7/50, Train Loss: 0.3091, Train Acc: 0.8693, Val Loss: 1.4573, Val Acc: 0.7976
Epoch 8/50, Train Loss: 0.6466, Train Acc: 0.8879, Val Loss: 0.7062, Val Acc: 0.6143
Epoch 9/50, Train Loss: 0.3088, Train Acc: 0.8842, Val Loss: 0.0047, Val Acc: 0.9993
Epoch 10/50, Train Loss: 0.1943, Train Acc: 0.9340, Val Loss: 0.2905, Val Acc: 0.8474
Epoch 11/50, Train Loss: 0.0103, Train Acc: 0.9979, Val Loss: 0.0035, Val Acc: 0.9995
Epoch 12/50, Train Loss: 0.0056, Train Acc: 0.9994, Val Loss: 0.0037, Val Acc: 0.9995
Epoch 13/50, Train Loss: 0.0044, Train Acc: 0.9996, Val Loss: 0.0031, Val Acc: 0.9995
Epoch 14/50, Train Loss: 0.0033, Train Acc: 0.9996, Val Loss: 0.0031, Val Acc: 0.9995
Epoch 15/50, Train Loss: 0.0036, Train Acc: 0.9990, Val Loss: 0.0037, Val Acc: 0.9995
Epoch 16/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0033, Val Acc: 0.9995
Epoch 17/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0037, Val Acc: 0.9995
Epoch 18/50, Train Loss: 0.0032, Train Acc: 0.9995, Val Loss: 0.0038, Val Acc: 0.9995
Epoch 19/50, Train Loss: 0.0030, Train Acc: 0.9995, Val Loss: 0.0037, Val Acc: 0.9995
Early stopping!

Run 10/10
Epoch 1/50, Train Loss: 1.3909, Train Acc: 0.3608, Val Loss: 0.5211, Val Acc: 0.6812
Epoch 2/50, Train Loss: 0.8242, Train Acc: 0.6271, Val Loss: 1.1176, Val Acc: 0.4019
Epoch 3/50, Train Loss: 0.8691, Train Acc: 0.5842, Val Loss: 1.3174, Val Acc: 0.4021
Epoch 4/50, Train Loss: 0.7958, Train Acc: 0.7019, Val Loss: 1.8522, Val Acc: 0.4067
Epoch 5/50, Train Loss: 0.2629, Train Acc: 0.9084, Val Loss: 0.0088, Val Acc: 0.9995
Epoch 6/50, Train Loss: 0.2925, Train Acc: 0.8687, Val Loss: 0.0762, Val Acc: 0.9995
Epoch 7/50, Train Loss: 0.4526, Train Acc: 0.8638, Val Loss: 0.0316, Val Acc: 0.9990
Epoch 8/50, Train Loss: 0.5550, Train Acc: 0.8865, Val Loss: 0.7017, Val Acc: 0.8035
Epoch 9/50, Train Loss: 0.4013, Train Acc: 0.9177, Val Loss: 0.0101, Val Acc: 0.9995
Epoch 10/50, Train Loss: 0.1946, Train Acc: 0.9506, Val Loss: 0.0089, Val Acc: 0.9995
Early stopping!

Source performance: 98.28 99.01 98.27 97.89
Target performance: 40.98 39.75 41.01 32.01

bpsk: 99.99
qpsk: 97.75
4qam: 6.67
16qam: 0.62
apsk: 0.00
Epoch 1/25, Loss: 3.1171, Domain Loss: 1.4108, Class Loss: 1.7063
Epoch 2/25, Loss: 3.0646, Domain Loss: 1.4354, Class Loss: 1.6292
Epoch 3/25, Loss: 3.2349, Domain Loss: 1.6866, Class Loss: 1.5483
Epoch 4/25, Loss: 2.9926, Domain Loss: 1.5623, Class Loss: 1.4303
Epoch 5/25, Loss: 2.7201, Domain Loss: 1.3780, Class Loss: 1.3421
Epoch 6/25, Loss: 2.0913, Domain Loss: 1.3188, Class Loss: 0.7724
Epoch 7/25, Loss: 1.8247, Domain Loss: 1.3135, Class Loss: 0.5112
Epoch 8/25, Loss: 1.6770, Domain Loss: 1.2971, Class Loss: 0.3799
Epoch 9/25, Loss: 1.6562, Domain Loss: 1.2576, Class Loss: 0.3986
Epoch 10/25, Loss: 2.5255, Domain Loss: 1.2725, Class Loss: 1.2530
Epoch 11/25, Loss: 1.5908, Domain Loss: 1.2169, Class Loss: 0.3739
Epoch 12/25, Loss: 1.4859, Domain Loss: 1.2196, Class Loss: 0.2664
Epoch 13/25, Loss: 1.4897, Domain Loss: 1.2322, Class Loss: 0.2575
Epoch 14/25, Loss: 1.3463, Domain Loss: 1.2170, Class Loss: 0.1293
Epoch 15/25, Loss: 1.7016, Domain Loss: 1.2205, Class Loss: 0.4811
Epoch 16/25, Loss: 1.4392, Domain Loss: 1.2112, Class Loss: 0.2281
Epoch 17/25, Loss: 1.3531, Domain Loss: 1.2017, Class Loss: 0.1514
Epoch 18/25, Loss: 1.2383, Domain Loss: 1.1978, Class Loss: 0.0405
Epoch 19/25, Loss: 1.5298, Domain Loss: 1.1940, Class Loss: 0.3357
Epoch 20/25, Loss: 1.4287, Domain Loss: 1.1958, Class Loss: 0.2329
Epoch 21/25, Loss: 1.2992, Domain Loss: 1.1860, Class Loss: 0.1132
Epoch 22/25, Loss: 1.2663, Domain Loss: 1.1942, Class Loss: 0.0721
Epoch 23/25, Loss: 1.2204, Domain Loss: 1.1826, Class Loss: 0.0378
Epoch 24/25, Loss: 1.2000, Domain Loss: 1.1808, Class Loss: 0.0192
Epoch 25/25, Loss: 1.7976, Domain Loss: 1.2169, Class Loss: 0.5807
40.19


Epoch 1/25, Loss: 3.1095, Domain Loss: 1.3986, Class Loss: 1.7109
Epoch 2/25, Loss: 3.0297, Domain Loss: 1.3950, Class Loss: 1.6347
Epoch 3/25, Loss: 2.9253, Domain Loss: 1.4334, Class Loss: 1.4919
Epoch 4/25, Loss: 2.8703, Domain Loss: 1.5548, Class Loss: 1.3155
Epoch 5/25, Loss: 2.1553, Domain Loss: 1.3342, Class Loss: 0.8211
Epoch 6/25, Loss: 2.0876, Domain Loss: 1.2795, Class Loss: 0.8081
Epoch 7/25, Loss: 1.7098, Domain Loss: 1.2585, Class Loss: 0.4512
Epoch 8/25, Loss: 2.3117, Domain Loss: 1.2545, Class Loss: 1.0572
Epoch 9/25, Loss: 1.6981, Domain Loss: 1.2367, Class Loss: 0.4614
Epoch 10/25, Loss: 1.4256, Domain Loss: 1.2242, Class Loss: 0.2014
Epoch 11/25, Loss: 1.4830, Domain Loss: 1.2315, Class Loss: 0.2515
Epoch 12/25, Loss: 1.5349, Domain Loss: 1.2349, Class Loss: 0.3000
Epoch 13/25, Loss: 1.4583, Domain Loss: 1.2286, Class Loss: 0.2297
Epoch 14/25, Loss: 1.4176, Domain Loss: 1.2291, Class Loss: 0.1885
Epoch 15/25, Loss: 1.3314, Domain Loss: 1.2256, Class Loss: 0.1058
Epoch 16/25, Loss: 1.7007, Domain Loss: 1.2325, Class Loss: 0.4682
Epoch 17/25, Loss: 1.3864, Domain Loss: 1.2347, Class Loss: 0.1517
Epoch 18/25, Loss: 1.3146, Domain Loss: 1.2187, Class Loss: 0.0960
Epoch 19/25, Loss: 1.2760, Domain Loss: 1.2279, Class Loss: 0.0480
Epoch 20/25, Loss: 1.3172, Domain Loss: 1.2344, Class Loss: 0.0828
Epoch 21/25, Loss: 1.2443, Domain Loss: 1.2284, Class Loss: 0.0159
Epoch 22/25, Loss: 1.2582, Domain Loss: 1.2243, Class Loss: 0.0339
Epoch 23/25, Loss: 1.4077, Domain Loss: 1.2185, Class Loss: 0.1891
Epoch 24/25, Loss: 1.3218, Domain Loss: 1.2268, Class Loss: 0.0950
Epoch 25/25, Loss: 1.2591, Domain Loss: 1.2224, Class Loss: 0.0367
40.21


Epoch 1/25, Loss: 3.1355, Domain Loss: 1.4321, Class Loss: 1.7034
Epoch 2/25, Loss: 3.0659, Domain Loss: 1.4731, Class Loss: 1.5928
Epoch 3/25, Loss: 2.7751, Domain Loss: 1.3938, Class Loss: 1.3813
Epoch 4/25, Loss: 2.2200, Domain Loss: 1.3120, Class Loss: 0.9079
Epoch 5/25, Loss: 2.8952, Domain Loss: 1.3020, Class Loss: 1.5932
Epoch 6/25, Loss: 1.9903, Domain Loss: 1.2374, Class Loss: 0.7529
Epoch 7/25, Loss: 1.6561, Domain Loss: 1.2308, Class Loss: 0.4253
Epoch 8/25, Loss: 1.6095, Domain Loss: 1.2342, Class Loss: 0.3753
Epoch 9/25, Loss: 1.4251, Domain Loss: 1.2238, Class Loss: 0.2013
Epoch 10/25, Loss: 1.3318, Domain Loss: 1.2193, Class Loss: 0.1125
Epoch 11/25, Loss: 2.1164, Domain Loss: 1.2282, Class Loss: 0.8882
Epoch 12/25, Loss: 1.6563, Domain Loss: 1.2246, Class Loss: 0.4317
Epoch 13/25, Loss: 1.4642, Domain Loss: 1.2149, Class Loss: 0.2493
Epoch 14/25, Loss: 1.3886, Domain Loss: 1.2175, Class Loss: 0.1712
Epoch 15/25, Loss: 1.2833, Domain Loss: 1.1958, Class Loss: 0.0875
Epoch 16/25, Loss: 1.2150, Domain Loss: 1.1886, Class Loss: 0.0263
Epoch 17/25, Loss: 1.4983, Domain Loss: 1.1994, Class Loss: 0.2990
Epoch 18/25, Loss: 1.3354, Domain Loss: 1.1859, Class Loss: 0.1495
Epoch 19/25, Loss: 1.2641, Domain Loss: 1.1682, Class Loss: 0.0959
Epoch 20/25, Loss: 2.4349, Domain Loss: 1.2372, Class Loss: 1.1977
Epoch 21/25, Loss: 1.4768, Domain Loss: 1.2313, Class Loss: 0.2455
Epoch 22/25, Loss: 1.4092, Domain Loss: 1.2203, Class Loss: 0.1890
Epoch 23/25, Loss: 1.3972, Domain Loss: 1.2056, Class Loss: 0.1915
Epoch 24/25, Loss: 1.3011, Domain Loss: 1.1817, Class Loss: 0.1194
Epoch 25/25, Loss: 1.1997, Domain Loss: 1.1718, Class Loss: 0.0279
39.97


Epoch 1/25, Loss: 3.0981, Domain Loss: 1.4137, Class Loss: 1.6844
Epoch 2/25, Loss: 2.5481, Domain Loss: 1.3208, Class Loss: 1.2273
Epoch 3/25, Loss: 3.7125, Domain Loss: 1.4483, Class Loss: 2.2642
Epoch 4/25, Loss: 2.7335, Domain Loss: 1.3638, Class Loss: 1.3696
Epoch 5/25, Loss: 2.5760, Domain Loss: 1.4535, Class Loss: 1.1225
Epoch 6/25, Loss: 2.2875, Domain Loss: 1.3387, Class Loss: 0.9488
Epoch 7/25, Loss: 1.9593, Domain Loss: 1.3038, Class Loss: 0.6555
Epoch 8/25, Loss: 2.6601, Domain Loss: 1.3353, Class Loss: 1.3248
Epoch 9/25, Loss: 1.9171, Domain Loss: 1.2917, Class Loss: 0.6254
Epoch 10/25, Loss: 1.6098, Domain Loss: 1.2616, Class Loss: 0.3482
Epoch 11/25, Loss: 1.7093, Domain Loss: 1.2384, Class Loss: 0.4709
Epoch 12/25, Loss: 1.4785, Domain Loss: 1.2366, Class Loss: 0.2419
Epoch 13/25, Loss: 1.4544, Domain Loss: 1.2273, Class Loss: 0.2271
Epoch 14/25, Loss: 1.4383, Domain Loss: 1.2292, Class Loss: 0.2091
Epoch 15/25, Loss: 1.8646, Domain Loss: 1.2303, Class Loss: 0.6343
Epoch 16/25, Loss: 1.8649, Domain Loss: 1.2337, Class Loss: 0.6311
Epoch 17/25, Loss: 1.4486, Domain Loss: 1.2191, Class Loss: 0.2295
Epoch 18/25, Loss: 1.3462, Domain Loss: 1.2226, Class Loss: 0.1236
Epoch 19/25, Loss: 1.2472, Domain Loss: 1.1629, Class Loss: 0.0843
Epoch 20/25, Loss: 1.6826, Domain Loss: 1.1890, Class Loss: 0.4936
Epoch 21/25, Loss: 1.5284, Domain Loss: 1.2017, Class Loss: 0.3267
Epoch 22/25, Loss: 1.3727, Domain Loss: 1.1682, Class Loss: 0.2046
Epoch 23/25, Loss: 1.3120, Domain Loss: 1.1844, Class Loss: 0.1276
Epoch 24/25, Loss: 4.5933, Domain Loss: 1.6502, Class Loss: 2.9432
Epoch 25/25, Loss: 2.0614, Domain Loss: 1.2696, Class Loss: 0.7918
46.63


Epoch 1/25, Loss: 3.1571, Domain Loss: 1.4479, Class Loss: 1.7092
Epoch 2/25, Loss: 2.9060, Domain Loss: 1.3781, Class Loss: 1.5279
Epoch 3/25, Loss: 2.4988, Domain Loss: 1.3524, Class Loss: 1.1464
Epoch 4/25, Loss: 2.2371, Domain Loss: 1.3085, Class Loss: 0.9286
Epoch 5/25, Loss: 3.2078, Domain Loss: 1.3027, Class Loss: 1.9050
Epoch 6/25, Loss: 2.1570, Domain Loss: 1.2569, Class Loss: 0.9001
Epoch 7/25, Loss: 1.7778, Domain Loss: 1.2364, Class Loss: 0.5414
Epoch 8/25, Loss: 1.5391, Domain Loss: 1.2297, Class Loss: 0.3095
Epoch 9/25, Loss: 1.8908, Domain Loss: 1.2365, Class Loss: 0.6543
Epoch 10/25, Loss: 1.5529, Domain Loss: 1.2308, Class Loss: 0.3221
Epoch 11/25, Loss: 1.4170, Domain Loss: 1.2375, Class Loss: 0.1795
Epoch 12/25, Loss: 1.7173, Domain Loss: 1.2301, Class Loss: 0.4872
Epoch 13/25, Loss: 1.5267, Domain Loss: 1.2240, Class Loss: 0.3028
Epoch 14/25, Loss: 1.3657, Domain Loss: 1.2255, Class Loss: 0.1402
Epoch 15/25, Loss: 1.3435, Domain Loss: 1.2280, Class Loss: 0.1155
Epoch 16/25, Loss: 2.1660, Domain Loss: 1.2274, Class Loss: 0.9386
Epoch 17/25, Loss: 1.5603, Domain Loss: 1.2167, Class Loss: 0.3436
Epoch 18/25, Loss: 1.4483, Domain Loss: 1.2197, Class Loss: 0.2286
Epoch 19/25, Loss: 1.3572, Domain Loss: 1.2259, Class Loss: 0.1313
Epoch 20/25, Loss: 1.4307, Domain Loss: 1.2302, Class Loss: 0.2005
Epoch 21/25, Loss: 1.3140, Domain Loss: 1.2220, Class Loss: 0.0920
Epoch 22/25, Loss: 1.2591, Domain Loss: 1.2268, Class Loss: 0.0323
Epoch 23/25, Loss: 1.3667, Domain Loss: 1.2233, Class Loss: 0.1434
Epoch 24/25, Loss: 1.9207, Domain Loss: 1.2292, Class Loss: 0.6915
Epoch 25/25, Loss: 1.4283, Domain Loss: 1.2267, Class Loss: 0.2016
41.60


Epoch 1/25, Loss: 3.1300, Domain Loss: 1.4349, Class Loss: 1.6951
Epoch 2/25, Loss: 2.8209, Domain Loss: 1.3836, Class Loss: 1.4373
Epoch 3/25, Loss: 2.2379, Domain Loss: 1.2795, Class Loss: 0.9584
Epoch 4/25, Loss: 2.2662, Domain Loss: 1.2742, Class Loss: 0.9920
Epoch 5/25, Loss: 1.9517, Domain Loss: 1.2459, Class Loss: 0.7058
Epoch 6/25, Loss: 1.9816, Domain Loss: 1.2472, Class Loss: 0.7343
Epoch 7/25, Loss: 1.5641, Domain Loss: 1.2280, Class Loss: 0.3362
Epoch 8/25, Loss: 2.3478, Domain Loss: 1.2487, Class Loss: 1.0992
Epoch 9/25, Loss: 1.5370, Domain Loss: 1.2329, Class Loss: 0.3040
Epoch 10/25, Loss: 1.4834, Domain Loss: 1.2286, Class Loss: 0.2548
Epoch 11/25, Loss: 1.5317, Domain Loss: 1.2338, Class Loss: 0.2980
Epoch 12/25, Loss: 1.4076, Domain Loss: 1.2276, Class Loss: 0.1800
Epoch 13/25, Loss: 2.1044, Domain Loss: 1.2393, Class Loss: 0.8651
Epoch 14/25, Loss: 1.9124, Domain Loss: 1.2386, Class Loss: 0.6738
Epoch 15/25, Loss: 1.4583, Domain Loss: 1.2272, Class Loss: 0.2312
Epoch 16/25, Loss: 1.3718, Domain Loss: 1.2302, Class Loss: 0.1416
Epoch 17/25, Loss: 1.7493, Domain Loss: 1.2186, Class Loss: 0.5307
Epoch 18/25, Loss: 1.6083, Domain Loss: 1.2221, Class Loss: 0.3863
Epoch 19/25, Loss: 1.3751, Domain Loss: 1.2082, Class Loss: 0.1669
Epoch 20/25, Loss: 1.2417, Domain Loss: 1.1940, Class Loss: 0.0477
Epoch 21/25, Loss: 1.1985, Domain Loss: 1.1796, Class Loss: 0.0189
Epoch 22/25, Loss: 1.2096, Domain Loss: 1.1686, Class Loss: 0.0410
Epoch 23/25, Loss: 2.3896, Domain Loss: 1.2403, Class Loss: 1.1493
Epoch 24/25, Loss: 1.4198, Domain Loss: 1.2303, Class Loss: 0.1896
Epoch 25/25, Loss: 1.3179, Domain Loss: 1.2267, Class Loss: 0.0912
40.06


Epoch 1/25, Loss: 3.1381, Domain Loss: 1.4237, Class Loss: 1.7143
Epoch 2/25, Loss: 3.1521, Domain Loss: 1.5139, Class Loss: 1.6382
Epoch 3/25, Loss: 3.0281, Domain Loss: 1.4101, Class Loss: 1.6179
Epoch 4/25, Loss: 3.3797, Domain Loss: 1.8502, Class Loss: 1.5295
Epoch 5/25, Loss: 3.1406, Domain Loss: 1.6902, Class Loss: 1.4505
Epoch 6/25, Loss: 2.5685, Domain Loss: 1.3473, Class Loss: 1.2212
Epoch 7/25, Loss: 2.7772, Domain Loss: 1.6142, Class Loss: 1.1629
Epoch 8/25, Loss: 3.2949, Domain Loss: 1.9563, Class Loss: 1.3387
Epoch 9/25, Loss: 2.3957, Domain Loss: 1.3746, Class Loss: 1.0211
Epoch 10/25, Loss: 2.5575, Domain Loss: 1.4331, Class Loss: 1.1244
Epoch 11/25, Loss: 2.1971, Domain Loss: 1.3371, Class Loss: 0.8600
Epoch 12/25, Loss: 1.8630, Domain Loss: 1.3393, Class Loss: 0.5237
Epoch 13/25, Loss: 1.6681, Domain Loss: 1.3560, Class Loss: 0.3121
Epoch 14/25, Loss: 1.9494, Domain Loss: 1.3766, Class Loss: 0.5727
Epoch 15/25, Loss: 1.5581, Domain Loss: 1.3305, Class Loss: 0.2276
Epoch 16/25, Loss: 1.4955, Domain Loss: 1.3279, Class Loss: 0.1676
Epoch 17/25, Loss: 1.6310, Domain Loss: 1.2933, Class Loss: 0.3377
Epoch 18/25, Loss: 1.8546, Domain Loss: 1.2750, Class Loss: 0.5796
Epoch 19/25, Loss: 1.9143, Domain Loss: 1.2661, Class Loss: 0.6482
Epoch 20/25, Loss: 1.4991, Domain Loss: 1.2474, Class Loss: 0.2517
Epoch 21/25, Loss: 1.3781, Domain Loss: 1.2474, Class Loss: 0.1307
Epoch 22/25, Loss: 1.8099, Domain Loss: 1.2450, Class Loss: 0.5650
Epoch 23/25, Loss: 1.4963, Domain Loss: 1.2358, Class Loss: 0.2605
Epoch 24/25, Loss: 1.3422, Domain Loss: 1.2106, Class Loss: 0.1317
Epoch 25/25, Loss: 1.2392, Domain Loss: 1.1886, Class Loss: 0.0507
44.58


Epoch 1/25, Loss: 3.1440, Domain Loss: 1.4230, Class Loss: 1.7210
Epoch 2/25, Loss: 2.8508, Domain Loss: 1.3576, Class Loss: 1.4932
Epoch 3/25, Loss: 2.7666, Domain Loss: 1.3372, Class Loss: 1.4294
Epoch 4/25, Loss: 2.4862, Domain Loss: 1.3793, Class Loss: 1.1069
Epoch 5/25, Loss: 2.1094, Domain Loss: 1.3719, Class Loss: 0.7375
Epoch 6/25, Loss: 2.0136, Domain Loss: 1.3519, Class Loss: 0.6617
Epoch 7/25, Loss: 1.5548, Domain Loss: 1.2510, Class Loss: 0.3038
Epoch 8/25, Loss: 2.5618, Domain Loss: 1.2530, Class Loss: 1.3088
Epoch 9/25, Loss: 1.5744, Domain Loss: 1.2316, Class Loss: 0.3428
Epoch 10/25, Loss: 1.5683, Domain Loss: 1.2361, Class Loss: 0.3322
Epoch 11/25, Loss: 1.4680, Domain Loss: 1.2286, Class Loss: 0.2395
Epoch 12/25, Loss: 1.4238, Domain Loss: 1.2273, Class Loss: 0.1965
Epoch 13/25, Loss: 1.3511, Domain Loss: 1.2284, Class Loss: 0.1226
Epoch 14/25, Loss: 2.6596, Domain Loss: 1.2403, Class Loss: 1.4193
Epoch 15/25, Loss: 1.5882, Domain Loss: 1.2245, Class Loss: 0.3637
Epoch 16/25, Loss: 1.4276, Domain Loss: 1.2316, Class Loss: 0.1960
Epoch 17/25, Loss: 1.3308, Domain Loss: 1.2236, Class Loss: 0.1072
Epoch 18/25, Loss: 1.4235, Domain Loss: 1.2272, Class Loss: 0.1963
Epoch 19/25, Loss: 1.3245, Domain Loss: 1.2258, Class Loss: 0.0987
Epoch 20/25, Loss: 1.2062, Domain Loss: 1.1782, Class Loss: 0.0280
Epoch 21/25, Loss: 1.9030, Domain Loss: 1.1616, Class Loss: 0.7414
Epoch 22/25, Loss: 1.3882, Domain Loss: 1.1469, Class Loss: 0.2412
Epoch 23/25, Loss: 1.2528, Domain Loss: 1.1289, Class Loss: 0.1238
Epoch 24/25, Loss: 1.7378, Domain Loss: 1.2887, Class Loss: 0.4492
Epoch 25/25, Loss: 1.3704, Domain Loss: 1.2021, Class Loss: 0.1683
39.70


</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/25, Loss: 3.1029, Domain Loss: 1.3995, Class Loss: 1.7034
Epoch 2/25, Loss: 2.6746, Domain Loss: 1.3377, Class Loss: 1.3370
Epoch 3/25, Loss: 2.3680, Domain Loss: 1.2567, Class Loss: 1.1114
Epoch 4/25, Loss: 2.5205, Domain Loss: 1.2937, Class Loss: 1.2268
Epoch 5/25, Loss: 1.9757, Domain Loss: 1.2488, Class Loss: 0.7269
Epoch 6/25, Loss: 1.7964, Domain Loss: 1.2504, Class Loss: 0.5460
Epoch 7/25, Loss: 1.9501, Domain Loss: 1.2472, Class Loss: 0.7029
Epoch 8/25, Loss: 1.5666, Domain Loss: 1.2356, Class Loss: 0.3310
Epoch 9/25, Loss: 1.4566, Domain Loss: 1.2228, Class Loss: 0.2337
Epoch 10/25, Loss: 1.5841, Domain Loss: 1.2367, Class Loss: 0.3474
Epoch 11/25, Loss: 1.4528, Domain Loss: 1.2346, Class Loss: 0.2181
Epoch 12/25, Loss: 1.4667, Domain Loss: 1.2207, Class Loss: 0.2460
Epoch 13/25, Loss: 1.3830, Domain Loss: 1.2276, Class Loss: 0.1554
Epoch 14/25, Loss: 1.7533, Domain Loss: 1.2311, Class Loss: 0.5222
Epoch 15/25, Loss: 1.5561, Domain Loss: 1.2234, Class Loss: 0.3327
Epoch 16/25, Loss: 1.4149, Domain Loss: 1.2301, Class Loss: 0.1848
Epoch 17/25, Loss: 1.3932, Domain Loss: 1.2311, Class Loss: 0.1621
Epoch 18/25, Loss: 1.2926, Domain Loss: 1.2197, Class Loss: 0.0729
Epoch 19/25, Loss: 1.5470, Domain Loss: 1.2286, Class Loss: 0.3184
Epoch 20/25, Loss: 1.4305, Domain Loss: 1.2286, Class Loss: 0.2019
Epoch 21/25, Loss: 1.3310, Domain Loss: 1.2252, Class Loss: 0.1058
Epoch 22/25, Loss: 1.2876, Domain Loss: 1.2271, Class Loss: 0.0604
Epoch 23/25, Loss: 1.4166, Domain Loss: 1.2282, Class Loss: 0.1883
Epoch 24/25, Loss: 1.2687, Domain Loss: 1.2297, Class Loss: 0.0389
Epoch 25/25, Loss: 1.3006, Domain Loss: 1.2329, Class Loss: 0.0677
41.31


Epoch 1/25, Loss: 3.1106, Domain Loss: 1.3970, Class Loss: 1.7135
Epoch 2/25, Loss: 2.9623, Domain Loss: 1.3967, Class Loss: 1.5656
Epoch 3/25, Loss: 2.7853, Domain Loss: 1.6169, Class Loss: 1.1684
Epoch 4/25, Loss: 2.2388, Domain Loss: 1.3969, Class Loss: 0.8419
Epoch 5/25, Loss: 2.0658, Domain Loss: 1.3560, Class Loss: 0.7099
Epoch 6/25, Loss: 1.7811, Domain Loss: 1.2980, Class Loss: 0.4831
Epoch 7/25, Loss: 2.1312, Domain Loss: 1.2780, Class Loss: 0.8533
Epoch 8/25, Loss: 1.5713, Domain Loss: 1.2614, Class Loss: 0.3099
Epoch 9/25, Loss: 1.4972, Domain Loss: 1.2336, Class Loss: 0.2637
Epoch 10/25, Loss: 1.5079, Domain Loss: 1.2245, Class Loss: 0.2835
Epoch 11/25, Loss: 1.3918, Domain Loss: 1.2303, Class Loss: 0.1616
Epoch 12/25, Loss: 1.5113, Domain Loss: 1.2329, Class Loss: 0.2784
Epoch 13/25, Loss: 1.3105, Domain Loss: 1.2293, Class Loss: 0.0811
Epoch 14/25, Loss: 1.2441, Domain Loss: 1.2287, Class Loss: 0.0154
Epoch 15/25, Loss: 2.8392, Domain Loss: 1.2578, Class Loss: 1.5814
Epoch 16/25, Loss: 1.7557, Domain Loss: 1.2320, Class Loss: 0.5237
Epoch 17/25, Loss: 1.4785, Domain Loss: 1.2172, Class Loss: 0.2613
Epoch 18/25, Loss: 1.4276, Domain Loss: 1.2383, Class Loss: 0.1893
Epoch 19/25, Loss: 1.4563, Domain Loss: 1.2329, Class Loss: 0.2234
Epoch 20/25, Loss: 1.3131, Domain Loss: 1.2407, Class Loss: 0.0723
Epoch 21/25, Loss: 1.2873, Domain Loss: 1.2184, Class Loss: 0.0689
Epoch 22/25, Loss: 1.8734, Domain Loss: 1.2315, Class Loss: 0.6418
Epoch 23/25, Loss: 1.3463, Domain Loss: 1.2187, Class Loss: 0.1276
Epoch 24/25, Loss: 1.2738, Domain Loss: 1.2144, Class Loss: 0.0594
Epoch 25/25, Loss: 1.2478, Domain Loss: 1.2193, Class Loss: 0.0285
41.70


Source performance:
93.67 93.30 93.58 92.59 
Target performance:
41.59 38.02 41.62 32.37 

Per-class target performance: 89.89 97.72 6.64 13.85 0.00 
Run 1/10
Epoch [1/50], Class Loss: 3.4807, Discrepancy Loss: 0.0922
Epoch [2/50], Class Loss: 0.8060, Discrepancy Loss: 0.0951
Epoch [3/50], Class Loss: 1.0407, Discrepancy Loss: 0.0902
Epoch [4/50], Class Loss: 0.5081, Discrepancy Loss: 0.0896
Epoch [5/50], Class Loss: 0.3933, Discrepancy Loss: 0.0817
Epoch [6/50], Class Loss: 0.2746, Discrepancy Loss: 0.0771
Epoch [7/50], Class Loss: 0.2417, Discrepancy Loss: 0.0714
Epoch [8/50], Class Loss: 0.2987, Discrepancy Loss: 0.0761
Epoch [9/50], Class Loss: 0.1649, Discrepancy Loss: 0.0707
Epoch [10/50], Class Loss: 0.3945, Discrepancy Loss: 0.0700
Epoch [11/50], Class Loss: 0.1131, Discrepancy Loss: 0.0812
Epoch [12/50], Class Loss: 0.0575, Discrepancy Loss: 0.0793
Epoch [13/50], Class Loss: 0.0575, Discrepancy Loss: 0.0857
Epoch [14/50], Class Loss: 0.0445, Discrepancy Loss: 0.0878
Epoch [15/50], Class Loss: 0.0512, Discrepancy Loss: 0.0878
Epoch [16/50], Class Loss: 0.0499, Discrepancy Loss: 0.0871
Epoch [17/50], Class Loss: 0.0525, Discrepancy Loss: 0.0780
Epoch [18/50], Class Loss: 0.0476, Discrepancy Loss: 0.0979
Epoch [19/50], Class Loss: 0.0469, Discrepancy Loss: 0.0980
Epoch [20/50], Class Loss: 0.0407, Discrepancy Loss: 0.0931
Epoch [21/50], Class Loss: 0.0212, Discrepancy Loss: 0.0992
Epoch [22/50], Class Loss: 0.0223, Discrepancy Loss: 0.0829
Epoch [23/50], Class Loss: 0.0291, Discrepancy Loss: 0.0801
Epoch [24/50], Class Loss: 0.0310, Discrepancy Loss: 0.0806
Epoch [25/50], Class Loss: 0.0323, Discrepancy Loss: 0.0867
Epoch [26/50], Class Loss: 0.0339, Discrepancy Loss: 0.0766
Epoch [27/50], Class Loss: 0.0310, Discrepancy Loss: 0.0797
Epoch [28/50], Class Loss: 0.0282, Discrepancy Loss: 0.0842
Epoch [29/50], Class Loss: 0.0283, Discrepancy Loss: 0.0806
Epoch [30/50], Class Loss: 0.0291, Discrepancy Loss: 0.0859
Epoch [31/50], Class Loss: 0.0236, Discrepancy Loss: 0.0848
Epoch [32/50], Class Loss: 0.0184, Discrepancy Loss: 0.0842
Epoch [33/50], Class Loss: 0.0283, Discrepancy Loss: 0.0887
Epoch [34/50], Class Loss: 0.0262, Discrepancy Loss: 0.0888
Epoch [35/50], Class Loss: 0.0230, Discrepancy Loss: 0.0900
Epoch [36/50], Class Loss: 0.0252, Discrepancy Loss: 0.0936
Epoch [37/50], Class Loss: 0.0240, Discrepancy Loss: 0.0950
Epoch [38/50], Class Loss: 0.0285, Discrepancy Loss: 0.0912
Epoch [39/50], Class Loss: 0.0232, Discrepancy Loss: 0.0990
Epoch [40/50], Class Loss: 0.0276, Discrepancy Loss: 0.0925
Epoch [41/50], Class Loss: 0.0235, Discrepancy Loss: 0.1026
Epoch [42/50], Class Loss: 0.0249, Discrepancy Loss: 0.0928
Epoch [43/50], Class Loss: 0.0229, Discrepancy Loss: 0.0945
Epoch [44/50], Class Loss: 0.0279, Discrepancy Loss: 0.0957
Epoch [45/50], Class Loss: 0.0282, Discrepancy Loss: 0.0933
Epoch [46/50], Class Loss: 0.0308, Discrepancy Loss: 0.0935
Epoch [47/50], Class Loss: 0.0261, Discrepancy Loss: 0.1002
Epoch [48/50], Class Loss: 0.0230, Discrepancy Loss: 0.0915
Epoch [49/50], Class Loss: 0.0211, Discrepancy Loss: 0.0939
Epoch [50/50], Class Loss: 0.0254, Discrepancy Loss: 0.0990
Source Domain Performance - Accuracy: 99.76%, Precision: 99.76%, Recall: 99.76%, F1 Score: 99.76%
Target Domain Performance - Accuracy: 59.25%, Precision: 70.73%, Recall: 59.34%, F1 Score: 56.90%

Run 2/10
Epoch [1/50], Class Loss: 4.1510, Discrepancy Loss: 0.0911
Epoch [2/50], Class Loss: 0.6934, Discrepancy Loss: 0.0844
Epoch [3/50], Class Loss: 0.7099, Discrepancy Loss: 0.0798
Epoch [4/50], Class Loss: 0.4766, Discrepancy Loss: 0.0688
Epoch [5/50], Class Loss: 0.4412, Discrepancy Loss: 0.0673
Epoch [6/50], Class Loss: 0.5276, Discrepancy Loss: 0.0775
Epoch [7/50], Class Loss: 0.3662, Discrepancy Loss: 0.0702
Epoch [8/50], Class Loss: 0.2184, Discrepancy Loss: 0.0751
Epoch [9/50], Class Loss: 0.2712, Discrepancy Loss: 0.0681
Epoch [10/50], Class Loss: 0.2908, Discrepancy Loss: 0.0580
Epoch [11/50], Class Loss: 0.0615, Discrepancy Loss: 0.0538
Epoch [12/50], Class Loss: 0.0453, Discrepancy Loss: 0.0678
Epoch [13/50], Class Loss: 0.0443, Discrepancy Loss: 0.0734
Epoch [14/50], Class Loss: 0.0330, Discrepancy Loss: 0.0764
Epoch [15/50], Class Loss: 0.0397, Discrepancy Loss: 0.0654
Epoch [16/50], Class Loss: 0.0677, Discrepancy Loss: 0.0511
Epoch [17/50], Class Loss: 0.0478, Discrepancy Loss: 0.0647
Epoch [18/50], Class Loss: 0.0299, Discrepancy Loss: 0.0608
Epoch [19/50], Class Loss: 0.0600, Discrepancy Loss: 0.0698
Epoch [20/50], Class Loss: 0.0462, Discrepancy Loss: 0.0658
Epoch [21/50], Class Loss: 0.0237, Discrepancy Loss: 0.0819
Epoch [22/50], Class Loss: 0.0264, Discrepancy Loss: 0.0976
Epoch [23/50], Class Loss: 0.0258, Discrepancy Loss: 0.0999
Epoch [24/50], Class Loss: 0.0237, Discrepancy Loss: 0.1008
Epoch [25/50], Class Loss: 0.0235, Discrepancy Loss: 0.1048
Epoch [26/50], Class Loss: 0.0229, Discrepancy Loss: 0.1011
Epoch [27/50], Class Loss: 0.0259, Discrepancy Loss: 0.1059
Epoch [28/50], Class Loss: 0.0262, Discrepancy Loss: 0.1084
Epoch [29/50], Class Loss: 0.0233, Discrepancy Loss: 0.1119
Epoch [30/50], Class Loss: 0.0277, Discrepancy Loss: 0.1144
Epoch [31/50], Class Loss: 0.0207, Discrepancy Loss: 0.1190
Epoch [32/50], Class Loss: 0.0267, Discrepancy Loss: 0.1135
Epoch [33/50], Class Loss: 0.0252, Discrepancy Loss: 0.1182
Epoch [34/50], Class Loss: 0.0296, Discrepancy Loss: 0.1074
Epoch [35/50], Class Loss: 0.0276, Discrepancy Loss: 0.1151
Epoch [36/50], Class Loss: 0.0237, Discrepancy Loss: 0.1127
Epoch [37/50], Class Loss: 0.0324, Discrepancy Loss: 0.1157
Epoch [38/50], Class Loss: 0.0337, Discrepancy Loss: 0.1109
Epoch [39/50], Class Loss: 0.0257, Discrepancy Loss: 0.1151
Epoch [40/50], Class Loss: 0.0281, Discrepancy Loss: 0.1112
Epoch [41/50], Class Loss: 0.0227, Discrepancy Loss: 0.1138
Epoch [42/50], Class Loss: 0.0241, Discrepancy Loss: 0.1132
Epoch [43/50], Class Loss: 0.0222, Discrepancy Loss: 0.1171
Epoch [44/50], Class Loss: 0.0241, Discrepancy Loss: 0.1156
Epoch [45/50], Class Loss: 0.0234, Discrepancy Loss: 0.1149
Epoch [46/50], Class Loss: 0.0190, Discrepancy Loss: 0.1189
Epoch [47/50], Class Loss: 0.0265, Discrepancy Loss: 0.1131
Epoch [48/50], Class Loss: 0.0246, Discrepancy Loss: 0.1129
Epoch [49/50], Class Loss: 0.0194, Discrepancy Loss: 0.1145
Epoch [50/50], Class Loss: 0.0251, Discrepancy Loss: 0.1092
Source Domain Performance - Accuracy: 99.07%, Precision: 99.08%, Recall: 99.09%, F1 Score: 99.08%
Target Domain Performance - Accuracy: 73.39%, Precision: 79.13%, Recall: 73.50%, F1 Score: 67.47%

Run 3/10
Epoch [1/50], Class Loss: 4.0039, Discrepancy Loss: 0.0838
Epoch [2/50], Class Loss: 0.6688, Discrepancy Loss: 0.0864
Epoch [3/50], Class Loss: 0.7435, Discrepancy Loss: 0.0838
Epoch [4/50], Class Loss: 0.4209, Discrepancy Loss: 0.0775
Epoch [5/50], Class Loss: 0.3760, Discrepancy Loss: 0.0745
Epoch [6/50], Class Loss: 0.3021, Discrepancy Loss: 0.0768
Epoch [7/50], Class Loss: 0.1786, Discrepancy Loss: 0.0606
Epoch [8/50], Class Loss: 0.2201, Discrepancy Loss: 0.0628
Epoch [9/50], Class Loss: 0.2239, Discrepancy Loss: 0.0664
Epoch [10/50], Class Loss: 0.1637, Discrepancy Loss: 0.0746
Epoch [11/50], Class Loss: 0.0799, Discrepancy Loss: 0.0608
Epoch [12/50], Class Loss: 0.0447, Discrepancy Loss: 0.0590
Epoch [13/50], Class Loss: 0.0363, Discrepancy Loss: 0.0581
Epoch [14/50], Class Loss: 0.0261, Discrepancy Loss: 0.0653
Epoch [15/50], Class Loss: 0.0215, Discrepancy Loss: 0.0526
Epoch [16/50], Class Loss: 0.0277, Discrepancy Loss: 0.0543
Epoch [17/50], Class Loss: 0.0380, Discrepancy Loss: 0.0733
Epoch [18/50], Class Loss: 0.0425, Discrepancy Loss: 0.0923
Epoch [19/50], Class Loss: 0.0426, Discrepancy Loss: 0.0915
Epoch [20/50], Class Loss: 0.0361, Discrepancy Loss: 0.0991
Epoch [21/50], Class Loss: 0.0341, Discrepancy Loss: 0.0944
Epoch [22/50], Class Loss: 0.0363, Discrepancy Loss: 0.0970
Epoch [23/50], Class Loss: 0.0331, Discrepancy Loss: 0.1044
Epoch [24/50], Class Loss: 0.0345, Discrepancy Loss: 0.1008
Epoch [25/50], Class Loss: 0.0377, Discrepancy Loss: 0.1073
Epoch [26/50], Class Loss: 0.0325, Discrepancy Loss: 0.1100
Epoch [27/50], Class Loss: 0.0357, Discrepancy Loss: 0.1151
Epoch [28/50], Class Loss: 0.0314, Discrepancy Loss: 0.1043
Epoch [29/50], Class Loss: 0.0352, Discrepancy Loss: 0.1108
Epoch [30/50], Class Loss: 0.0329, Discrepancy Loss: 0.1072
Epoch [31/50], Class Loss: 0.0326, Discrepancy Loss: 0.1031
Epoch [32/50], Class Loss: 0.0333, Discrepancy Loss: 0.1069
Epoch [33/50], Class Loss: 0.0335, Discrepancy Loss: 0.1152
Epoch [34/50], Class Loss: 0.0356, Discrepancy Loss: 0.1111
Epoch [35/50], Class Loss: 0.0339, Discrepancy Loss: 0.1141
Epoch [36/50], Class Loss: 0.0349, Discrepancy Loss: 0.1101
Epoch [37/50], Class Loss: 0.0346, Discrepancy Loss: 0.1134
Epoch [38/50], Class Loss: 0.0379, Discrepancy Loss: 0.1120
Epoch [39/50], Class Loss: 0.0397, Discrepancy Loss: 0.1068
Epoch [40/50], Class Loss: 0.0371, Discrepancy Loss: 0.1128
Epoch [41/50], Class Loss: 0.0365, Discrepancy Loss: 0.1058
Epoch [42/50], Class Loss: 0.0349, Discrepancy Loss: 0.1127
Epoch [43/50], Class Loss: 0.0356, Discrepancy Loss: 0.1126
Epoch [44/50], Class Loss: 0.0339, Discrepancy Loss: 0.1100
Epoch [45/50], Class Loss: 0.0354, Discrepancy Loss: 0.1165
Epoch [46/50], Class Loss: 0.0297, Discrepancy Loss: 0.1111
Epoch [47/50], Class Loss: 0.0383, Discrepancy Loss: 0.1083
Epoch [48/50], Class Loss: 0.0306, Discrepancy Loss: 0.1103
Epoch [49/50], Class Loss: 0.0341, Discrepancy Loss: 0.1144
Epoch [50/50], Class Loss: 0.0337, Discrepancy Loss: 0.1100
Source Domain Performance - Accuracy: 99.85%, Precision: 99.86%, Recall: 99.85%, F1 Score: 99.86%
Target Domain Performance - Accuracy: 48.41%, Precision: 60.35%, Recall: 48.49%, F1 Score: 42.38%

Run 4/10
Epoch [1/50], Class Loss: 3.7193, Discrepancy Loss: 0.0903
Epoch [2/50], Class Loss: 0.8073, Discrepancy Loss: 0.0885
Epoch [3/50], Class Loss: 0.4854, Discrepancy Loss: 0.0717
Epoch [4/50], Class Loss: 0.4283, Discrepancy Loss: 0.0781
Epoch [5/50], Class Loss: 0.5536, Discrepancy Loss: 0.0713
Epoch [6/50], Class Loss: 0.3415, Discrepancy Loss: 0.0791
Epoch [7/50], Class Loss: 0.2140, Discrepancy Loss: 0.0824
Epoch [8/50], Class Loss: 0.2331, Discrepancy Loss: 0.0773
Epoch [9/50], Class Loss: 0.1949, Discrepancy Loss: 0.0686
Epoch [10/50], Class Loss: 0.2027, Discrepancy Loss: 0.0715
Epoch [11/50], Class Loss: 0.0534, Discrepancy Loss: 0.0471
Epoch [12/50], Class Loss: 0.0317, Discrepancy Loss: 0.0517
Epoch [13/50], Class Loss: 0.0333, Discrepancy Loss: 0.0658
Epoch [14/50], Class Loss: 0.0390, Discrepancy Loss: 0.0646
Epoch [15/50], Class Loss: 0.0391, Discrepancy Loss: 0.0739
Epoch [16/50], Class Loss: 0.0483, Discrepancy Loss: 0.0575
Epoch [17/50], Class Loss: 0.0434, Discrepancy Loss: 0.0700
Epoch [18/50], Class Loss: 0.0609, Discrepancy Loss: 0.0684
Epoch [19/50], Class Loss: 0.0502, Discrepancy Loss: 0.0601
Epoch [20/50], Class Loss: 0.0281, Discrepancy Loss: 0.0572
Epoch [21/50], Class Loss: 0.0180, Discrepancy Loss: 0.0628
Epoch [22/50], Class Loss: 0.0171, Discrepancy Loss: 0.0722
Epoch [23/50], Class Loss: 0.0251, Discrepancy Loss: 0.0950
Epoch [24/50], Class Loss: 0.0335, Discrepancy Loss: 0.0991
Epoch [25/50], Class Loss: 0.0336, Discrepancy Loss: 0.1033
Epoch [26/50], Class Loss: 0.0329, Discrepancy Loss: 0.0953
Epoch [27/50], Class Loss: 0.0337, Discrepancy Loss: 0.0915
Epoch [28/50], Class Loss: 0.0346, Discrepancy Loss: 0.0939
Epoch [29/50], Class Loss: 0.0382, Discrepancy Loss: 0.0850
Epoch [30/50], Class Loss: 0.0421, Discrepancy Loss: 0.0913
Epoch [31/50], Class Loss: 0.0391, Discrepancy Loss: 0.0854
Epoch [32/50], Class Loss: 0.0364, Discrepancy Loss: 0.0917
Epoch [33/50], Class Loss: 0.0357, Discrepancy Loss: 0.0871
Epoch [34/50], Class Loss: 0.0392, Discrepancy Loss: 0.0917
Epoch [35/50], Class Loss: 0.0336, Discrepancy Loss: 0.0890
Epoch [36/50], Class Loss: 0.0435, Discrepancy Loss: 0.0934
Epoch [37/50], Class Loss: 0.0447, Discrepancy Loss: 0.0925
Epoch [38/50], Class Loss: 0.0417, Discrepancy Loss: 0.0923
Epoch [39/50], Class Loss: 0.0384, Discrepancy Loss: 0.0892
Epoch [40/50], Class Loss: 0.0470, Discrepancy Loss: 0.0924
Epoch [41/50], Class Loss: 0.0360, Discrepancy Loss: 0.0863
Epoch [42/50], Class Loss: 0.0333, Discrepancy Loss: 0.0893
Epoch [43/50], Class Loss: 0.0373, Discrepancy Loss: 0.0909
Epoch [44/50], Class Loss: 0.0435, Discrepancy Loss: 0.0878
Epoch [45/50], Class Loss: 0.0413, Discrepancy Loss: 0.0864
Epoch [46/50], Class Loss: 0.0382, Discrepancy Loss: 0.0907
Epoch [47/50], Class Loss: 0.0416, Discrepancy Loss: 0.0897
Epoch [48/50], Class Loss: 0.0436, Discrepancy Loss: 0.0888
Epoch [49/50], Class Loss: 0.0466, Discrepancy Loss: 0.0891
Epoch [50/50], Class Loss: 0.0444, Discrepancy Loss: 0.0877
Source Domain Performance - Accuracy: 94.21%, Precision: 95.41%, Recall: 94.13%, F1 Score: 94.11%
Target Domain Performance - Accuracy: 71.80%, Precision: 78.13%, Recall: 71.95%, F1 Score: 66.83%

Run 5/10
Epoch [1/50], Class Loss: 3.3918, Discrepancy Loss: 0.0905
Epoch [2/50], Class Loss: 0.6769, Discrepancy Loss: 0.0886
Epoch [3/50], Class Loss: 0.5187, Discrepancy Loss: 0.0764
Epoch [4/50], Class Loss: 0.4344, Discrepancy Loss: 0.0805
Epoch [5/50], Class Loss: 0.3504, Discrepancy Loss: 0.0661
Epoch [6/50], Class Loss: 0.3002, Discrepancy Loss: 0.0691
Epoch [7/50], Class Loss: 0.2698, Discrepancy Loss: 0.0693
Epoch [8/50], Class Loss: 0.2171, Discrepancy Loss: 0.0663
Epoch [9/50], Class Loss: 0.2117, Discrepancy Loss: 0.0692
Epoch [10/50], Class Loss: 0.1849, Discrepancy Loss: 0.0669
Epoch [11/50], Class Loss: 0.0663, Discrepancy Loss: 0.0794
Epoch [12/50], Class Loss: 0.0373, Discrepancy Loss: 0.0859
Epoch [13/50], Class Loss: 0.0381, Discrepancy Loss: 0.0822
Epoch [14/50], Class Loss: 0.0430, Discrepancy Loss: 0.0934
Epoch [15/50], Class Loss: 0.0422, Discrepancy Loss: 0.0859
Epoch [16/50], Class Loss: 0.0422, Discrepancy Loss: 0.0759
Epoch [17/50], Class Loss: 0.0435, Discrepancy Loss: 0.0725
Epoch [18/50], Class Loss: 0.0426, Discrepancy Loss: 0.0878
Epoch [19/50], Class Loss: 0.0520, Discrepancy Loss: 0.0766
Epoch [20/50], Class Loss: 0.0464, Discrepancy Loss: 0.0768
Epoch [21/50], Class Loss: 0.0419, Discrepancy Loss: 0.0833
Epoch [22/50], Class Loss: 0.0411, Discrepancy Loss: 0.0777
Epoch [23/50], Class Loss: 0.0470, Discrepancy Loss: 0.0786
Epoch [24/50], Class Loss: 0.0429, Discrepancy Loss: 0.0754
Epoch [25/50], Class Loss: 0.0393, Discrepancy Loss: 0.0762
Epoch [26/50], Class Loss: 0.0352, Discrepancy Loss: 0.0751
Epoch [27/50], Class Loss: 0.0343, Discrepancy Loss: 0.0930
Epoch [28/50], Class Loss: 0.0411, Discrepancy Loss: 0.0995
Epoch [29/50], Class Loss: 0.0354, Discrepancy Loss: 0.1002
Epoch [30/50], Class Loss: 0.0517, Discrepancy Loss: 0.1029
Epoch [31/50], Class Loss: 0.0444, Discrepancy Loss: 0.0981
Epoch [32/50], Class Loss: 0.0450, Discrepancy Loss: 0.0969
Epoch [33/50], Class Loss: 0.0440, Discrepancy Loss: 0.0892
Epoch [34/50], Class Loss: 0.0426, Discrepancy Loss: 0.1009
Epoch [35/50], Class Loss: 0.0436, Discrepancy Loss: 0.0957
Epoch [36/50], Class Loss: 0.0424, Discrepancy Loss: 0.0953
Epoch [37/50], Class Loss: 0.0391, Discrepancy Loss: 0.1027
Epoch [38/50], Class Loss: 0.0408, Discrepancy Loss: 0.1006
Epoch [39/50], Class Loss: 0.0462, Discrepancy Loss: 0.0970
Epoch [40/50], Class Loss: 0.0382, Discrepancy Loss: 0.0981
Epoch [41/50], Class Loss: 0.0443, Discrepancy Loss: 0.1007
Epoch [42/50], Class Loss: 0.0426, Discrepancy Loss: 0.0992
Epoch [43/50], Class Loss: 0.0418, Discrepancy Loss: 0.1006
Epoch [44/50], Class Loss: 0.0405, Discrepancy Loss: 0.1017
Epoch [45/50], Class Loss: 0.0461, Discrepancy Loss: 0.1015
Epoch [46/50], Class Loss: 0.0480, Discrepancy Loss: 0.0981
Epoch [47/50], Class Loss: 0.0342, Discrepancy Loss: 0.1009
Epoch [48/50], Class Loss: 0.0403, Discrepancy Loss: 0.0990
Epoch [49/50], Class Loss: 0.0425, Discrepancy Loss: 0.0971
Epoch [50/50], Class Loss: 0.0391, Discrepancy Loss: 0.1022
Source Domain Performance - Accuracy: 95.51%, Precision: 96.04%, Recall: 95.64%, F1 Score: 95.53%
Target Domain Performance - Accuracy: 78.22%, Precision: 78.52%, Recall: 78.36%, F1 Score: 71.81%

Run 6/10
Epoch [1/50], Class Loss: 3.5745, Discrepancy Loss: 0.0902
Epoch [2/50], Class Loss: 0.6946, Discrepancy Loss: 0.0894
Epoch [3/50], Class Loss: 0.4494, Discrepancy Loss: 0.0800
Epoch [4/50], Class Loss: 0.5314, Discrepancy Loss: 0.0821
Epoch [5/50], Class Loss: 0.3876, Discrepancy Loss: 0.0773
Epoch [6/50], Class Loss: 0.3024, Discrepancy Loss: 0.0803
Epoch [7/50], Class Loss: 0.2679, Discrepancy Loss: 0.0770
Epoch [8/50], Class Loss: 0.2107, Discrepancy Loss: 0.0784
Epoch [9/50], Class Loss: 0.3006, Discrepancy Loss: 0.0625
Epoch [10/50], Class Loss: 0.3155, Discrepancy Loss: 0.0637
Epoch [11/50], Class Loss: 0.0566, Discrepancy Loss: 0.0687
Epoch [12/50], Class Loss: 0.0337, Discrepancy Loss: 0.0824
Epoch [13/50], Class Loss: 0.0328, Discrepancy Loss: 0.0863
Epoch [14/50], Class Loss: 0.0389, Discrepancy Loss: 0.0837
Epoch [15/50], Class Loss: 0.0346, Discrepancy Loss: 0.0791
Epoch [16/50], Class Loss: 0.0310, Discrepancy Loss: 0.0844
Epoch [17/50], Class Loss: 0.0461, Discrepancy Loss: 0.0818
Epoch [18/50], Class Loss: 0.0279, Discrepancy Loss: 0.0857
Epoch [19/50], Class Loss: 0.0304, Discrepancy Loss: 0.0910
Epoch [20/50], Class Loss: 0.0296, Discrepancy Loss: 0.0909
Epoch [21/50], Class Loss: 0.0284, Discrepancy Loss: 0.1013
Epoch [22/50], Class Loss: 0.0312, Discrepancy Loss: 0.0993
Epoch [23/50], Class Loss: 0.0303, Discrepancy Loss: 0.1009
Epoch [24/50], Class Loss: 0.0335, Discrepancy Loss: 0.1092
Epoch [25/50], Class Loss: 0.0364, Discrepancy Loss: 0.1088
Epoch [26/50], Class Loss: 0.0295, Discrepancy Loss: 0.1238
Epoch [27/50], Class Loss: 0.0234, Discrepancy Loss: 0.1222
Epoch [28/50], Class Loss: 0.0231, Discrepancy Loss: 0.1227
Epoch [29/50], Class Loss: 0.0207, Discrepancy Loss: 0.1185
Epoch [30/50], Class Loss: 0.0280, Discrepancy Loss: 0.1253
Epoch [31/50], Class Loss: 0.0298, Discrepancy Loss: 0.1233
Epoch [32/50], Class Loss: 0.0222, Discrepancy Loss: 0.1308
Epoch [33/50], Class Loss: 0.0214, Discrepancy Loss: 0.1236
Epoch [34/50], Class Loss: 0.0281, Discrepancy Loss: 0.1220
Epoch [35/50], Class Loss: 0.0237, Discrepancy Loss: 0.1296
Epoch [36/50], Class Loss: 0.0285, Discrepancy Loss: 0.1179
Epoch [37/50], Class Loss: 0.0227, Discrepancy Loss: 0.1244
Epoch [38/50], Class Loss: 0.0211, Discrepancy Loss: 0.1237
Epoch [39/50], Class Loss: 0.0209, Discrepancy Loss: 0.1250
Epoch [40/50], Class Loss: 0.0208, Discrepancy Loss: 0.1299
Epoch [41/50], Class Loss: 0.0164, Discrepancy Loss: 0.1238
Epoch [42/50], Class Loss: 0.0218, Discrepancy Loss: 0.1290
Epoch [43/50], Class Loss: 0.0252, Discrepancy Loss: 0.1238
Epoch [44/50], Class Loss: 0.0231, Discrepancy Loss: 0.1303
Epoch [45/50], Class Loss: 0.0303, Discrepancy Loss: 0.1267
Epoch [46/50], Class Loss: 0.0225, Discrepancy Loss: 0.1344
Epoch [47/50], Class Loss: 0.0237, Discrepancy Loss: 0.1302
Epoch [48/50], Class Loss: 0.0206, Discrepancy Loss: 0.1305
Epoch [49/50], Class Loss: 0.0185, Discrepancy Loss: 0.1376
Epoch [50/50], Class Loss: 0.0245, Discrepancy Loss: 0.1368
Source Domain Performance - Accuracy: 99.83%, Precision: 99.83%, Recall: 99.84%, F1 Score: 99.83%
Target Domain Performance - Accuracy: 59.69%, Precision: 69.77%, Recall: 59.67%, F1 Score: 58.20%

Run 7/10
Epoch [1/50], Class Loss: 3.7592, Discrepancy Loss: 0.0866
Epoch [2/50], Class Loss: 0.7005, Discrepancy Loss: 0.0865
Epoch [3/50], Class Loss: 0.4892, Discrepancy Loss: 0.0746
Epoch [4/50], Class Loss: 0.4663, Discrepancy Loss: 0.0767
Epoch [5/50], Class Loss: 0.3585, Discrepancy Loss: 0.0721
Epoch [6/50], Class Loss: 0.3345, Discrepancy Loss: 0.0773
Epoch [7/50], Class Loss: 0.1592, Discrepancy Loss: 0.0622
Epoch [8/50], Class Loss: 0.2785, Discrepancy Loss: 0.0859
Epoch [9/50], Class Loss: 0.2426, Discrepancy Loss: 0.0776
Epoch [10/50], Class Loss: 0.1463, Discrepancy Loss: 0.0648
Epoch [11/50], Class Loss: 0.0420, Discrepancy Loss: 0.0323
Epoch [12/50], Class Loss: 0.0288, Discrepancy Loss: 0.0410
Epoch [13/50], Class Loss: 0.0229, Discrepancy Loss: 0.0450
Epoch [14/50], Class Loss: 0.0251, Discrepancy Loss: 0.0603
Epoch [15/50], Class Loss: 0.0486, Discrepancy Loss: 0.0715
Epoch [16/50], Class Loss: 0.0317, Discrepancy Loss: 0.0817
Epoch [17/50], Class Loss: 0.0353, Discrepancy Loss: 0.0836
Epoch [18/50], Class Loss: 0.0347, Discrepancy Loss: 0.0727
Epoch [19/50], Class Loss: 0.0454, Discrepancy Loss: 0.0767
Epoch [20/50], Class Loss: 0.0373, Discrepancy Loss: 0.0709
Epoch [21/50], Class Loss: 0.0299, Discrepancy Loss: 0.0604
Epoch [22/50], Class Loss: 0.0379, Discrepancy Loss: 0.0629
Epoch [23/50], Class Loss: 0.0328, Discrepancy Loss: 0.0611
Epoch [24/50], Class Loss: 0.0300, Discrepancy Loss: 0.0643
Epoch [25/50], Class Loss: 0.0297, Discrepancy Loss: 0.0642
Epoch [26/50], Class Loss: 0.0309, Discrepancy Loss: 0.0644
Epoch [27/50], Class Loss: 0.0316, Discrepancy Loss: 0.0672
Epoch [28/50], Class Loss: 0.0342, Discrepancy Loss: 0.0712
Epoch [29/50], Class Loss: 0.0316, Discrepancy Loss: 0.0675
Epoch [30/50], Class Loss: 0.0375, Discrepancy Loss: 0.0677
Epoch [31/50], Class Loss: 0.0257, Discrepancy Loss: 0.0776
Epoch [32/50], Class Loss: 0.0218, Discrepancy Loss: 0.0670
Epoch [33/50], Class Loss: 0.0312, Discrepancy Loss: 0.0725
Epoch [34/50], Class Loss: 0.0268, Discrepancy Loss: 0.0696
Epoch [35/50], Class Loss: 0.0268, Discrepancy Loss: 0.0793
Epoch [36/50], Class Loss: 0.0283, Discrepancy Loss: 0.0747
Epoch [37/50], Class Loss: 0.0310, Discrepancy Loss: 0.0758
Epoch [38/50], Class Loss: 0.0272, Discrepancy Loss: 0.0750
Epoch [39/50], Class Loss: 0.0247, Discrepancy Loss: 0.0823
Epoch [40/50], Class Loss: 0.0296, Discrepancy Loss: 0.0753
Epoch [41/50], Class Loss: 0.0303, Discrepancy Loss: 0.0778
Epoch [42/50], Class Loss: 0.0327, Discrepancy Loss: 0.0773
Epoch [43/50], Class Loss: 0.0317, Discrepancy Loss: 0.0771
Epoch [44/50], Class Loss: 0.0314, Discrepancy Loss: 0.0816
Epoch [45/50], Class Loss: 0.0300, Discrepancy Loss: 0.0777
Epoch [46/50], Class Loss: 0.0267, Discrepancy Loss: 0.0772
Epoch [47/50], Class Loss: 0.0284, Discrepancy Loss: 0.0785
Epoch [48/50], Class Loss: 0.0232, Discrepancy Loss: 0.0748
Epoch [49/50], Class Loss: 0.0291, Discrepancy Loss: 0.0724
Epoch [50/50], Class Loss: 0.0372, Discrepancy Loss: 0.0730
Source Domain Performance - Accuracy: 99.05%, Precision: 99.08%, Recall: 99.05%, F1 Score: 99.05%
Target Domain Performance - Accuracy: 69.12%, Precision: 81.52%, Recall: 69.25%, F1 Score: 65.28%

Run 8/10
Epoch [1/50], Class Loss: 3.6089, Discrepancy Loss: 0.0879
Epoch [2/50], Class Loss: 0.7245, Discrepancy Loss: 0.0867
Epoch [3/50], Class Loss: 0.5267, Discrepancy Loss: 0.0779
Epoch [4/50], Class Loss: 0.4058, Discrepancy Loss: 0.0744
Epoch [5/50], Class Loss: 0.3236, Discrepancy Loss: 0.0698
Epoch [6/50], Class Loss: 0.3310, Discrepancy Loss: 0.0706
Epoch [7/50], Class Loss: 0.2613, Discrepancy Loss: 0.0848
Epoch [8/50], Class Loss: 0.1522, Discrepancy Loss: 0.0682
Epoch [9/50], Class Loss: 0.1660, Discrepancy Loss: 0.0820
Epoch [10/50], Class Loss: 0.1919, Discrepancy Loss: 0.0670
Epoch [11/50], Class Loss: 0.1043, Discrepancy Loss: 0.0620
Epoch [12/50], Class Loss: 0.0593, Discrepancy Loss: 0.0598
Epoch [13/50], Class Loss: 0.0360, Discrepancy Loss: 0.0561
Epoch [14/50], Class Loss: 0.0267, Discrepancy Loss: 0.0612
Epoch [15/50], Class Loss: 0.0454, Discrepancy Loss: 0.0559
Epoch [16/50], Class Loss: 0.0346, Discrepancy Loss: 0.0529
Epoch [17/50], Class Loss: 0.0259, Discrepancy Loss: 0.0416
Epoch [18/50], Class Loss: 0.0254, Discrepancy Loss: 0.0467
Epoch [19/50], Class Loss: 0.0297, Discrepancy Loss: 0.0560
Epoch [20/50], Class Loss: 0.0339, Discrepancy Loss: 0.0639
Epoch [21/50], Class Loss: 0.0171, Discrepancy Loss: 0.0809
Epoch [22/50], Class Loss: 0.0240, Discrepancy Loss: 0.0749
Epoch [23/50], Class Loss: 0.0222, Discrepancy Loss: 0.0769
Epoch [24/50], Class Loss: 0.0252, Discrepancy Loss: 0.0713
Epoch [25/50], Class Loss: 0.0276, Discrepancy Loss: 0.0889
Epoch [26/50], Class Loss: 0.0304, Discrepancy Loss: 0.0735
Epoch [27/50], Class Loss: 0.0368, Discrepancy Loss: 0.0794
Epoch [28/50], Class Loss: 0.0366, Discrepancy Loss: 0.0717
Epoch [29/50], Class Loss: 0.0382, Discrepancy Loss: 0.0637
Epoch [30/50], Class Loss: 0.0438, Discrepancy Loss: 0.0643
Epoch [31/50], Class Loss: 0.0321, Discrepancy Loss: 0.0664
Epoch [32/50], Class Loss: 0.0338, Discrepancy Loss: 0.0603
Epoch [33/50], Class Loss: 0.0307, Discrepancy Loss: 0.0614
Epoch [34/50], Class Loss: 0.0458, Discrepancy Loss: 0.0630
Epoch [35/50], Class Loss: 0.0434, Discrepancy Loss: 0.0634
Epoch [36/50], Class Loss: 0.0490, Discrepancy Loss: 0.0639
Epoch [37/50], Class Loss: 0.0426, Discrepancy Loss: 0.0611
Epoch [38/50], Class Loss: 0.0430, Discrepancy Loss: 0.0689
Epoch [39/50], Class Loss: 0.0421, Discrepancy Loss: 0.0691
Epoch [40/50], Class Loss: 0.0480, Discrepancy Loss: 0.0662
Epoch [41/50], Class Loss: 0.0416, Discrepancy Loss: 0.0700
Epoch [42/50], Class Loss: 0.0453, Discrepancy Loss: 0.0720
Epoch [43/50], Class Loss: 0.0371, Discrepancy Loss: 0.0695
Epoch [44/50], Class Loss: 0.0520, Discrepancy Loss: 0.0676
Epoch [45/50], Class Loss: 0.0406, Discrepancy Loss: 0.0682
Epoch [46/50], Class Loss: 0.0432, Discrepancy Loss: 0.0661
Epoch [47/50], Class Loss: 0.0387, Discrepancy Loss: 0.0692
Epoch [48/50], Class Loss: 0.0485, Discrepancy Loss: 0.0691
Epoch [49/50], Class Loss: 0.0450, Discrepancy Loss: 0.0659
Epoch [50/50], Class Loss: 0.0379, Discrepancy Loss: 0.0685
Source Domain Performance - Accuracy: 95.95%, Precision: 96.19%, Recall: 96.02%, F1 Score: 95.98%
Target Domain Performance - Accuracy: 78.76%, Precision: 79.03%, Recall: 78.90%, F1 Score: 72.42%

Run 9/10
Epoch [1/50], Class Loss: 4.3134, Discrepancy Loss: 0.0861
Epoch [2/50], Class Loss: 0.7475, Discrepancy Loss: 0.0926
Epoch [3/50], Class Loss: 0.5600, Discrepancy Loss: 0.0778
Epoch [4/50], Class Loss: 0.5184, Discrepancy Loss: 0.0804
Epoch [5/50], Class Loss: 0.3786, Discrepancy Loss: 0.0760
Epoch [6/50], Class Loss: 0.3158, Discrepancy Loss: 0.0684
Epoch [7/50], Class Loss: 0.2931, Discrepancy Loss: 0.0774
Epoch [8/50], Class Loss: 0.3006, Discrepancy Loss: 0.0583
Epoch [9/50], Class Loss: 0.3305, Discrepancy Loss: 0.0708
Epoch [10/50], Class Loss: 0.1427, Discrepancy Loss: 0.0656
Epoch [11/50], Class Loss: 0.0769, Discrepancy Loss: 0.1071
Epoch [12/50], Class Loss: 0.0684, Discrepancy Loss: 0.0574
Epoch [13/50], Class Loss: 0.0565, Discrepancy Loss: 0.0703
Epoch [14/50], Class Loss: 0.0477, Discrepancy Loss: 0.0709
Epoch [15/50], Class Loss: 0.0473, Discrepancy Loss: 0.0859
Epoch [16/50], Class Loss: 0.0518, Discrepancy Loss: 0.0796
Epoch [17/50], Class Loss: 0.0483, Discrepancy Loss: 0.0802
Epoch [18/50], Class Loss: 0.0373, Discrepancy Loss: 0.0934
Epoch [19/50], Class Loss: 0.0511, Discrepancy Loss: 0.0851
Epoch [20/50], Class Loss: 0.0468, Discrepancy Loss: 0.0787
Epoch [21/50], Class Loss: 0.0257, Discrepancy Loss: 0.0617
Epoch [22/50], Class Loss: 0.0235, Discrepancy Loss: 0.0648
Epoch [23/50], Class Loss: 0.0311, Discrepancy Loss: 0.0703
Epoch [24/50], Class Loss: 0.0300, Discrepancy Loss: 0.0678
Epoch [25/50], Class Loss: 0.0318, Discrepancy Loss: 0.0780
Epoch [26/50], Class Loss: 0.0307, Discrepancy Loss: 0.0825
Epoch [27/50], Class Loss: 0.0307, Discrepancy Loss: 0.0825
Epoch [28/50], Class Loss: 0.0345, Discrepancy Loss: 0.0886
Epoch [29/50], Class Loss: 0.0372, Discrepancy Loss: 0.0994
Epoch [30/50], Class Loss: 0.0417, Discrepancy Loss: 0.0939
Epoch [31/50], Class Loss: 0.0369, Discrepancy Loss: 0.0978
Epoch [32/50], Class Loss: 0.0405, Discrepancy Loss: 0.0953
Epoch [33/50], Class Loss: 0.0407, Discrepancy Loss: 0.1004
Epoch [34/50], Class Loss: 0.0416, Discrepancy Loss: 0.0942
Epoch [35/50], Class Loss: 0.0359, Discrepancy Loss: 0.0947
Epoch [36/50], Class Loss: 0.0364, Discrepancy Loss: 0.0947
Epoch [37/50], Class Loss: 0.0403, Discrepancy Loss: 0.0993
Epoch [38/50], Class Loss: 0.0434, Discrepancy Loss: 0.0996
Epoch [39/50], Class Loss: 0.0425, Discrepancy Loss: 0.1015
Epoch [40/50], Class Loss: 0.0469, Discrepancy Loss: 0.0982
Epoch [41/50], Class Loss: 0.0376, Discrepancy Loss: 0.0977
Epoch [42/50], Class Loss: 0.0440, Discrepancy Loss: 0.0954
Epoch [43/50], Class Loss: 0.0503, Discrepancy Loss: 0.0993
Epoch [44/50], Class Loss: 0.0381, Discrepancy Loss: 0.0939
Epoch [45/50], Class Loss: 0.0475, Discrepancy Loss: 0.0941
Epoch [46/50], Class Loss: 0.0423, Discrepancy Loss: 0.0963
Epoch [47/50], Class Loss: 0.0435, Discrepancy Loss: 0.0966
Epoch [48/50], Class Loss: 0.0437, Discrepancy Loss: 0.0988
Epoch [49/50], Class Loss: 0.0470, Discrepancy Loss: 0.0968
Epoch [50/50], Class Loss: 0.0443, Discrepancy Loss: 0.0978
Source Domain Performance - Accuracy: 96.31%, Precision: 96.80%, Recall: 96.27%, F1 Score: 96.30%
Target Domain Performance - Accuracy: 74.27%, Precision: 85.89%, Recall: 74.41%, F1 Score: 69.93%

Run 10/10
Epoch [1/50], Class Loss: 3.4580, Discrepancy Loss: 0.0883
Epoch [2/50], Class Loss: 0.6493, Discrepancy Loss: 0.0887
Epoch [3/50], Class Loss: 0.5746, Discrepancy Loss: 0.0831
Epoch [4/50], Class Loss: 0.5331, Discrepancy Loss: 0.0759
Epoch [5/50], Class Loss: 0.4163, Discrepancy Loss: 0.0740
Epoch [6/50], Class Loss: 0.5650, Discrepancy Loss: 0.0757
Epoch [7/50], Class Loss: 0.5807, Discrepancy Loss: 0.0690
Epoch [8/50], Class Loss: 0.4687, Discrepancy Loss: 0.0639
Epoch [9/50], Class Loss: 0.2676, Discrepancy Loss: 0.0484
Epoch [10/50], Class Loss: 0.2403, Discrepancy Loss: 0.0510
Epoch [11/50], Class Loss: 0.0690, Discrepancy Loss: 0.0410
Epoch [12/50], Class Loss: 0.0427, Discrepancy Loss: 0.0420
Epoch [13/50], Class Loss: 0.0373, Discrepancy Loss: 0.0363
Epoch [14/50], Class Loss: 0.0241, Discrepancy Loss: 0.0393
Epoch [15/50], Class Loss: 0.0273, Discrepancy Loss: 0.0434
Epoch [16/50], Class Loss: 0.0245, Discrepancy Loss: 0.0513
Epoch [17/50], Class Loss: 0.0269, Discrepancy Loss: 0.0503
Epoch [18/50], Class Loss: 0.0215, Discrepancy Loss: 0.0560
Epoch [19/50], Class Loss: 0.0180, Discrepancy Loss: 0.0583
Epoch [20/50], Class Loss: 0.0291, Discrepancy Loss: 0.0706
Epoch [21/50], Class Loss: 0.0160, Discrepancy Loss: 0.0652
Epoch [22/50], Class Loss: 0.0189, Discrepancy Loss: 0.0728
Epoch [23/50], Class Loss: 0.0148, Discrepancy Loss: 0.0741
Epoch [24/50], Class Loss: 0.0213, Discrepancy Loss: 0.0761
Epoch [25/50], Class Loss: 0.0242, Discrepancy Loss: 0.0805
Epoch [26/50], Class Loss: 0.0226, Discrepancy Loss: 0.0795
Epoch [27/50], Class Loss: 0.0239, Discrepancy Loss: 0.0848
Epoch [28/50], Class Loss: 0.0264, Discrepancy Loss: 0.0820
Epoch [29/50], Class Loss: 0.0302, Discrepancy Loss: 0.0892
Epoch [30/50], Class Loss: 0.0240, Discrepancy Loss: 0.0815
Epoch [31/50], Class Loss: 0.0176, Discrepancy Loss: 0.0859
Epoch [32/50], Class Loss: 0.0218, Discrepancy Loss: 0.0871
Epoch [33/50], Class Loss: 0.0211, Discrepancy Loss: 0.0848
Epoch [34/50], Class Loss: 0.0216, Discrepancy Loss: 0.0858
Epoch [35/50], Class Loss: 0.0208, Discrepancy Loss: 0.0886
Epoch [36/50], Class Loss: 0.0169, Discrepancy Loss: 0.0812
Epoch [37/50], Class Loss: 0.0196, Discrepancy Loss: 0.0839
Epoch [38/50], Class Loss: 0.0239, Discrepancy Loss: 0.0835
Epoch [39/50], Class Loss: 0.0213, Discrepancy Loss: 0.0870
Epoch [40/50], Class Loss: 0.0201, Discrepancy Loss: 0.0861
Epoch [41/50], Class Loss: 0.0223, Discrepancy Loss: 0.0879
Epoch [42/50], Class Loss: 0.0195, Discrepancy Loss: 0.0883
Epoch [43/50], Class Loss: 0.0198, Discrepancy Loss: 0.0922
Epoch [44/50], Class Loss: 0.0184, Discrepancy Loss: 0.0882
Epoch [45/50], Class Loss: 0.0198, Discrepancy Loss: 0.0848
Epoch [46/50], Class Loss: 0.0224, Discrepancy Loss: 0.0867
Epoch [47/50], Class Loss: 0.0240, Discrepancy Loss: 0.0868
Epoch [48/50], Class Loss: 0.0130, Discrepancy Loss: 0.0888
Epoch [49/50], Class Loss: 0.0197, Discrepancy Loss: 0.0860
Epoch [50/50], Class Loss: 0.0189, Discrepancy Loss: 0.0926
Source Domain Performance - Accuracy: 96.51%, Precision: 96.96%, Recall: 96.47%, F1 Score: 96.50%
Target Domain Performance - Accuracy: 64.99%, Precision: 74.42%, Recall: 65.11%, F1 Score: 60.44%

Source performance: 97.60% 97.90% 97.61% 97.60%
Target performance: 67.79% 75.75% 67.90% 63.17%

Per-Class Accuracy on Target Domain:
bpsk: 100.00%
qpsk: 97.52%
4qam: 7.25%
16qam: 58.83%
apsk: 75.88%

Run 1/10
Epoch [1/50], Class Loss: 2.5670, Discrepancy Loss: 0.0368
Validation Loss: 1.0005
Epoch [2/50], Class Loss: 1.1640, Discrepancy Loss: 0.0234
Validation Loss: 0.7578
Epoch [3/50], Class Loss: 1.8456, Discrepancy Loss: 0.0396
Validation Loss: 0.5223
Epoch [4/50], Class Loss: 0.8003, Discrepancy Loss: 0.0118
Validation Loss: 2.6223
Epoch [5/50], Class Loss: 2.2322, Discrepancy Loss: 0.0513
Validation Loss: 0.9613
Epoch [6/50], Class Loss: 1.4872, Discrepancy Loss: 0.0489
Validation Loss: 0.4806
Epoch [7/50], Class Loss: 0.7444, Discrepancy Loss: 0.0314
Validation Loss: 0.4970
Epoch [8/50], Class Loss: 1.1516, Discrepancy Loss: 0.0290
Validation Loss: 0.1274
Epoch [9/50], Class Loss: 0.8840, Discrepancy Loss: 0.0343
Validation Loss: 0.0979
Epoch [10/50], Class Loss: 1.2058, Discrepancy Loss: 0.0299
Validation Loss: 0.2837
Epoch [11/50], Class Loss: 0.0807, Discrepancy Loss: 0.0152
Validation Loss: 0.0223
Epoch [12/50], Class Loss: 0.0341, Discrepancy Loss: 0.0125
Validation Loss: 0.0202
Epoch [13/50], Class Loss: 0.1376, Discrepancy Loss: 0.0138
Validation Loss: 0.0161
Epoch [14/50], Class Loss: 0.2531, Discrepancy Loss: 0.0129
Validation Loss: 0.0473
Epoch [15/50], Class Loss: 0.0820, Discrepancy Loss: 0.0136
Validation Loss: 0.0149
Epoch [16/50], Class Loss: 0.1763, Discrepancy Loss: 0.0143
Validation Loss: 0.0656
Epoch [17/50], Class Loss: 0.1836, Discrepancy Loss: 0.0139
Validation Loss: 0.0206
Epoch [18/50], Class Loss: 0.0548, Discrepancy Loss: 0.0129
Validation Loss: 0.0143
Epoch [19/50], Class Loss: 0.0393, Discrepancy Loss: 0.0122
Validation Loss: 0.0399
Epoch [20/50], Class Loss: 0.1241, Discrepancy Loss: 0.0155
Validation Loss: 0.0235
Epoch [21/50], Class Loss: 0.0199, Discrepancy Loss: 0.0130
Validation Loss: 0.0157
Epoch [22/50], Class Loss: 0.0134, Discrepancy Loss: 0.0119
Validation Loss: 0.0148
Epoch [23/50], Class Loss: 0.0127, Discrepancy Loss: 0.0120
Validation Loss: 0.0128
Epoch [24/50], Class Loss: 0.0127, Discrepancy Loss: 0.0119
Validation Loss: 0.0134
Epoch [25/50], Class Loss: 0.0128, Discrepancy Loss: 0.0120
Validation Loss: 0.0138
Epoch [26/50], Class Loss: 0.0111, Discrepancy Loss: 0.0114
Validation Loss: 0.0175
Epoch [27/50], Class Loss: 0.0117, Discrepancy Loss: 0.0117
Validation Loss: 0.0156
Epoch [28/50], Class Loss: 0.0119, Discrepancy Loss: 0.0116
Validation Loss: 0.0140
Early stopping!
Source Domain Performance - Accuracy: 99.90%, Precision: 99.90%, Recall: 99.90%, F1 Score: 99.90%
Target Domain Performance - Accuracy: 57.71%, Precision: 60.89%, Recall: 57.73%, F1 Score: 56.33%

Run 2/10
Epoch [1/50], Class Loss: 3.2880, Discrepancy Loss: 0.0407
Validation Loss: 1.2170
Epoch [2/50], Class Loss: 1.1398, Discrepancy Loss: 0.0194
Validation Loss: 0.4804
Epoch [3/50], Class Loss: 1.8634, Discrepancy Loss: 0.0271
Validation Loss: 1.7868
Epoch [4/50], Class Loss: 1.1414, Discrepancy Loss: 0.0257
Validation Loss: 3.9367
Epoch [5/50], Class Loss: 2.0697, Discrepancy Loss: 0.0470
Validation Loss: 0.1577
Epoch [6/50], Class Loss: 1.1153, Discrepancy Loss: 0.0347
Validation Loss: 0.0399
Epoch [7/50], Class Loss: 0.6118, Discrepancy Loss: 0.0302
Validation Loss: 3.5584
Epoch [8/50], Class Loss: 1.3538, Discrepancy Loss: 0.0534
Validation Loss: 1.5938
Epoch [9/50], Class Loss: 0.5788, Discrepancy Loss: 0.0225
Validation Loss: 0.1725
Epoch [10/50], Class Loss: 1.2306, Discrepancy Loss: 0.0186
Validation Loss: 0.9290
Epoch [11/50], Class Loss: 0.0914, Discrepancy Loss: 0.0115
Validation Loss: 0.0157
Epoch [12/50], Class Loss: 0.1412, Discrepancy Loss: 0.0166
Validation Loss: 0.0294
Epoch [13/50], Class Loss: 0.1529, Discrepancy Loss: 0.0169
Validation Loss: 0.8487
Epoch [14/50], Class Loss: 0.5365, Discrepancy Loss: 0.0140
Validation Loss: 0.2345
Epoch [15/50], Class Loss: 0.2438, Discrepancy Loss: 0.0167
Validation Loss: 0.0144
Epoch [16/50], Class Loss: 0.1032, Discrepancy Loss: 0.0190
Validation Loss: 0.0244
Epoch [17/50], Class Loss: 0.1667, Discrepancy Loss: 0.0206
Validation Loss: 0.0596
Epoch [18/50], Class Loss: 0.1191, Discrepancy Loss: 0.0196
Validation Loss: 0.0158
Epoch [19/50], Class Loss: 0.1154, Discrepancy Loss: 0.0196
Validation Loss: 0.0612
Epoch [20/50], Class Loss: 0.2959, Discrepancy Loss: 0.0193
Validation Loss: 1.6424
Early stopping!
Source Domain Performance - Accuracy: 76.93%, Precision: 66.87%, Recall: 76.28%, F1 Score: 69.65%
Target Domain Performance - Accuracy: 46.88%, Precision: 43.07%, Recall: 46.99%, F1 Score: 39.26%

Run 3/10
Epoch [1/50], Class Loss: 3.1221, Discrepancy Loss: 0.0321
Validation Loss: 2.1826
Epoch [2/50], Class Loss: 2.1486, Discrepancy Loss: 0.0563
Validation Loss: 1.6824
Epoch [3/50], Class Loss: 0.5516, Discrepancy Loss: 0.0261
Validation Loss: 0.5817
Epoch [4/50], Class Loss: 1.6720, Discrepancy Loss: 0.0405
Validation Loss: 0.4278
Epoch [5/50], Class Loss: 3.0809, Discrepancy Loss: 0.0605
Validation Loss: 0.7401
Epoch [6/50], Class Loss: 0.4058, Discrepancy Loss: 0.0246
Validation Loss: 0.2635
Epoch [7/50], Class Loss: 1.0690, Discrepancy Loss: 0.0188
Validation Loss: 0.2686
Epoch [8/50], Class Loss: 0.9001, Discrepancy Loss: 0.0154
Validation Loss: 0.2074
Epoch [9/50], Class Loss: 0.1032, Discrepancy Loss: 0.0044
Validation Loss: 0.0625
Epoch [10/50], Class Loss: 0.5296, Discrepancy Loss: 0.0127
Validation Loss: 1.6856
Epoch [11/50], Class Loss: 0.0544, Discrepancy Loss: 0.0039
Validation Loss: 0.0107
Epoch [12/50], Class Loss: 0.0356, Discrepancy Loss: 0.0025
Validation Loss: 0.0183
Epoch [13/50], Class Loss: 0.0809, Discrepancy Loss: 0.0036
Validation Loss: 0.0125
Epoch [14/50], Class Loss: 0.0990, Discrepancy Loss: 0.0069
Validation Loss: 0.0175
Epoch [15/50], Class Loss: 0.1770, Discrepancy Loss: 0.0088
Validation Loss: 0.0207
Epoch [16/50], Class Loss: 0.0744, Discrepancy Loss: 0.0124
Validation Loss: 0.0426
Early stopping!
Source Domain Performance - Accuracy: 99.78%, Precision: 99.78%, Recall: 99.78%, F1 Score: 99.78%
Target Domain Performance - Accuracy: 43.80%, Precision: 48.63%, Recall: 43.84%, F1 Score: 35.58%

Run 4/10
Epoch [1/50], Class Loss: 2.7660, Discrepancy Loss: 0.0237
Validation Loss: 1.0476
Epoch [2/50], Class Loss: 1.2451, Discrepancy Loss: 0.0125
Validation Loss: 0.8167
Epoch [3/50], Class Loss: 1.6123, Discrepancy Loss: 0.0360
Validation Loss: 0.6077
Epoch [4/50], Class Loss: 2.5519, Discrepancy Loss: 0.0686
Validation Loss: 2.5885
Epoch [5/50], Class Loss: 1.9863, Discrepancy Loss: 0.0551
Validation Loss: 1.1848
Epoch [6/50], Class Loss: 2.1596, Discrepancy Loss: 0.0339
Validation Loss: 0.4910
Epoch [7/50], Class Loss: 1.5777, Discrepancy Loss: 0.0342
Validation Loss: 0.7439
Epoch [8/50], Class Loss: 1.4948, Discrepancy Loss: 0.0384
Validation Loss: 0.3435
Epoch [9/50], Class Loss: 1.8917, Discrepancy Loss: 0.0329
Validation Loss: 1.0016
Epoch [10/50], Class Loss: 2.0839, Discrepancy Loss: 0.0731
Validation Loss: 22.2824
Epoch [11/50], Class Loss: 1.1075, Discrepancy Loss: 0.0123
Validation Loss: 0.0811
Epoch [12/50], Class Loss: 0.1490, Discrepancy Loss: 0.0071
Validation Loss: 0.0324
Epoch [13/50], Class Loss: 0.1640, Discrepancy Loss: 0.0077
Validation Loss: 0.0260
Epoch [14/50], Class Loss: 0.1791, Discrepancy Loss: 0.0146
Validation Loss: 0.0243
Epoch [15/50], Class Loss: 0.1503, Discrepancy Loss: 0.0109
Validation Loss: 0.0218
Epoch [16/50], Class Loss: 0.0961, Discrepancy Loss: 0.0063
Validation Loss: 0.0283
Epoch [17/50], Class Loss: 0.0729, Discrepancy Loss: 0.0095
Validation Loss: 0.0280
Epoch [18/50], Class Loss: 0.2552, Discrepancy Loss: 0.0112
Validation Loss: 0.0110
Epoch [19/50], Class Loss: 0.1859, Discrepancy Loss: 0.0128
Validation Loss: 0.0372
Epoch [20/50], Class Loss: 0.4981, Discrepancy Loss: 0.0219
Validation Loss: 0.0277
Epoch [21/50], Class Loss: 0.0300, Discrepancy Loss: 0.0085
Validation Loss: 0.0146
Epoch [22/50], Class Loss: 0.0302, Discrepancy Loss: 0.0078
Validation Loss: 0.0179
Epoch [23/50], Class Loss: 0.0290, Discrepancy Loss: 0.0072
Validation Loss: 0.0254
Early stopping!
Source Domain Performance - Accuracy: 99.73%, Precision: 99.73%, Recall: 99.74%, F1 Score: 99.73%
Target Domain Performance - Accuracy: 50.73%, Precision: 54.76%, Recall: 50.65%, F1 Score: 46.67%

Run 5/10
Epoch [1/50], Class Loss: 3.2104, Discrepancy Loss: 0.0138
Validation Loss: 2.5087
Epoch [2/50], Class Loss: 2.0210, Discrepancy Loss: 0.0506
Validation Loss: 0.7734
Epoch [3/50], Class Loss: 1.7892, Discrepancy Loss: 0.0522
Validation Loss: 0.7995
Epoch [4/50], Class Loss: 0.3644, Discrepancy Loss: 0.0115
Validation Loss: 0.2402
Epoch [5/50], Class Loss: 0.5298, Discrepancy Loss: 0.0158
Validation Loss: 2.1866
Epoch [6/50], Class Loss: 1.2059, Discrepancy Loss: 0.0277
Validation Loss: 0.2940
Epoch [7/50], Class Loss: 1.2491, Discrepancy Loss: 0.0404
Validation Loss: 0.0284
Epoch [8/50], Class Loss: 1.9338, Discrepancy Loss: 0.0349
Validation Loss: 0.8116
Epoch [9/50], Class Loss: 0.7253, Discrepancy Loss: 0.0256
Validation Loss: 0.3135
Epoch [10/50], Class Loss: 0.8331, Discrepancy Loss: 0.0216
Validation Loss: 0.0384
Epoch [11/50], Class Loss: 0.0521, Discrepancy Loss: 0.0084
Validation Loss: 0.0297
Epoch [12/50], Class Loss: 0.0393, Discrepancy Loss: 0.0121
Validation Loss: 0.0206
Epoch [13/50], Class Loss: 0.0252, Discrepancy Loss: 0.0093
Validation Loss: 0.0108
Epoch [14/50], Class Loss: 0.0291, Discrepancy Loss: 0.0128
Validation Loss: 0.5573
Epoch [15/50], Class Loss: 0.0536, Discrepancy Loss: 0.0185
Validation Loss: 0.0420
Epoch [16/50], Class Loss: 0.3424, Discrepancy Loss: 0.0231
Validation Loss: 0.1820
Epoch [17/50], Class Loss: 0.1184, Discrepancy Loss: 0.0188
Validation Loss: 0.2562
Epoch [18/50], Class Loss: 0.0688, Discrepancy Loss: 0.0151
Validation Loss: 0.0737
Early stopping!
Source Domain Performance - Accuracy: 99.05%, Precision: 99.07%, Recall: 99.05%, F1 Score: 99.05%
Target Domain Performance - Accuracy: 56.52%, Precision: 63.56%, Recall: 56.41%, F1 Score: 56.11%

Run 6/10
Epoch [1/50], Class Loss: 3.0698, Discrepancy Loss: 0.0458
Validation Loss: 1.2230
Epoch [2/50], Class Loss: 1.5759, Discrepancy Loss: 0.0364
Validation Loss: 1.9529
Epoch [3/50], Class Loss: 1.5949, Discrepancy Loss: 0.0375
Validation Loss: 0.6333
Epoch [4/50], Class Loss: 0.6055, Discrepancy Loss: 0.0373
Validation Loss: 0.7881
Epoch [5/50], Class Loss: 0.4713, Discrepancy Loss: 0.0184
Validation Loss: 0.5980
Epoch [6/50], Class Loss: 0.4169, Discrepancy Loss: 0.0154
Validation Loss: 0.5253
Epoch [7/50], Class Loss: 0.3539, Discrepancy Loss: 0.0160
Validation Loss: 0.3861
Epoch [8/50], Class Loss: 0.2994, Discrepancy Loss: 0.0122
Validation Loss: 0.2765
Epoch [9/50], Class Loss: 0.2773, Discrepancy Loss: 0.0210
Validation Loss: 0.1386
Epoch [10/50], Class Loss: 0.9770, Discrepancy Loss: 0.0195
Validation Loss: 0.0442
Epoch [11/50], Class Loss: 0.3946, Discrepancy Loss: 0.0199
Validation Loss: 0.0212
Epoch [12/50], Class Loss: 0.0747, Discrepancy Loss: 0.0127
Validation Loss: 0.0146
Epoch [13/50], Class Loss: 0.1186, Discrepancy Loss: 0.0096
Validation Loss: 0.0078
Epoch [14/50], Class Loss: 0.1742, Discrepancy Loss: 0.0100
Validation Loss: 0.2434
Epoch [15/50], Class Loss: 0.2430, Discrepancy Loss: 0.0171
Validation Loss: 0.1267
Epoch [16/50], Class Loss: 0.2020, Discrepancy Loss: 0.0144
Validation Loss: 0.6505
Epoch [17/50], Class Loss: 0.3801, Discrepancy Loss: 0.0154
Validation Loss: 0.1459
Epoch [18/50], Class Loss: 0.1132, Discrepancy Loss: 0.0101
Validation Loss: 0.0549
Early stopping!
Source Domain Performance - Accuracy: 99.49%, Precision: 99.49%, Recall: 99.50%, F1 Score: 99.49%
Target Domain Performance - Accuracy: 43.26%, Precision: 48.46%, Recall: 43.29%, F1 Score: 33.91%

Run 7/10
Epoch [1/50], Class Loss: 3.2442, Discrepancy Loss: 0.0129
Validation Loss: 3.2203
Epoch [2/50], Class Loss: 3.2191, Discrepancy Loss: 0.0001
Validation Loss: 3.2197
Epoch [3/50], Class Loss: 3.2191, Discrepancy Loss: 0.0000
Validation Loss: 3.2195
Epoch [4/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Epoch [5/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Epoch [6/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Epoch [7/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2193
Epoch [8/50], Class Loss: 3.2189, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Epoch [9/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Epoch [10/50], Class Loss: 3.2190, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Epoch [11/50], Class Loss: 3.2188, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Epoch [12/50], Class Loss: 3.2188, Discrepancy Loss: 0.0000
Validation Loss: 3.2194
Early stopping!
Source Domain Performance - Accuracy: 19.21%, Precision: 3.84%, Recall: 20.00%, F1 Score: 6.45%
Target Domain Performance - Accuracy: 20.07%, Precision: 4.01%, Recall: 20.00%, F1 Score: 6.69%

Run 8/10
Epoch [1/50], Class Loss: 3.4135, Discrepancy Loss: 0.0384
Validation Loss: 4.0181
Epoch [2/50], Class Loss: 1.1650, Discrepancy Loss: 0.0247
Validation Loss: 0.5935
Epoch [3/50], Class Loss: 1.1522, Discrepancy Loss: 0.0235
Validation Loss: 0.8705
Epoch [4/50], Class Loss: 1.6889, Discrepancy Loss: 0.0401
Validation Loss: 2.7322
Epoch [5/50], Class Loss: 1.1999, Discrepancy Loss: 0.0269
Validation Loss: 12.8781
Epoch [6/50], Class Loss: 3.5123, Discrepancy Loss: 0.0718
Validation Loss: 0.2284
Epoch [7/50], Class Loss: 1.0436, Discrepancy Loss: 0.0165
Validation Loss: 0.5559
Epoch [8/50], Class Loss: 1.7996, Discrepancy Loss: 0.0335
Validation Loss: 0.0747
Epoch [9/50], Class Loss: 1.2119, Discrepancy Loss: 0.0342
Validation Loss: 1.8037
Epoch [10/50], Class Loss: 1.1605, Discrepancy Loss: 0.0253
Validation Loss: 0.6925
Epoch [11/50], Class Loss: 0.0569, Discrepancy Loss: 0.0068
Validation Loss: 0.0123
Epoch [12/50], Class Loss: 0.1059, Discrepancy Loss: 0.0142
Validation Loss: 0.0197
Epoch [13/50], Class Loss: 0.0617, Discrepancy Loss: 0.0133
Validation Loss: 0.0970
Epoch [14/50], Class Loss: 0.1713, Discrepancy Loss: 0.0129
Validation Loss: 5.9916
Epoch [15/50], Class Loss: 0.6050, Discrepancy Loss: 0.0190
Validation Loss: 0.1261
Epoch [16/50], Class Loss: 0.2262, Discrepancy Loss: 0.0123
Validation Loss: 0.0135
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 43.87%, Precision: 46.62%, Recall: 43.93%, F1 Score: 36.52%

Run 9/10
Epoch [1/50], Class Loss: 2.7108, Discrepancy Loss: 0.0461
Validation Loss: 0.7859
Epoch [2/50], Class Loss: 0.6181, Discrepancy Loss: 0.0179
Validation Loss: 0.4430
Epoch [3/50], Class Loss: 0.4928, Discrepancy Loss: 0.0122
Validation Loss: 0.3757
Epoch [4/50], Class Loss: 0.4448, Discrepancy Loss: 0.0087
Validation Loss: 0.4995
Epoch [5/50], Class Loss: 0.8745, Discrepancy Loss: 0.0083
Validation Loss: 1.8078
Epoch [6/50], Class Loss: 1.6288, Discrepancy Loss: 0.0417
Validation Loss: 0.4953
Epoch [7/50], Class Loss: 0.2937, Discrepancy Loss: 0.0186
Validation Loss: 0.1939
Epoch [8/50], Class Loss: 1.0157, Discrepancy Loss: 0.0211
Validation Loss: 0.2133
Epoch [9/50], Class Loss: 1.8775, Discrepancy Loss: 0.0338
Validation Loss: 0.8164
Epoch [10/50], Class Loss: 1.3611, Discrepancy Loss: 0.0283
Validation Loss: 0.6896
Epoch [11/50], Class Loss: 0.1714, Discrepancy Loss: 0.0092
Validation Loss: 0.0175
Epoch [12/50], Class Loss: 0.0780, Discrepancy Loss: 0.0120
Validation Loss: 0.0247
Epoch [13/50], Class Loss: 0.0305, Discrepancy Loss: 0.0079
Validation Loss: 0.0327
Epoch [14/50], Class Loss: 0.0303, Discrepancy Loss: 0.0093
Validation Loss: 0.0205
Epoch [15/50], Class Loss: 0.5066, Discrepancy Loss: 0.0071
Validation Loss: 0.0373
Epoch [16/50], Class Loss: 1.6221, Discrepancy Loss: 0.0330
Validation Loss: 0.0346
Early stopping!
Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%
Target Domain Performance - Accuracy: 41.50%, Precision: 60.07%, Recall: 41.53%, F1 Score: 33.86%

Run 10/10
Epoch [1/50], Class Loss: 2.7644, Discrepancy Loss: 0.0355
Validation Loss: 1.6373
Epoch [2/50], Class Loss: 1.6355, Discrepancy Loss: 0.0386
Validation Loss: 19.2937
Epoch [3/50], Class Loss: 1.4968, Discrepancy Loss: 0.0295
Validation Loss: 1.3693
Epoch [4/50], Class Loss: 1.6484, Discrepancy Loss: 0.0390
Validation Loss: 3.7803
Epoch [5/50], Class Loss: 4.3935, Discrepancy Loss: 0.0560
Validation Loss: 0.6385
Epoch [6/50], Class Loss: 1.5921, Discrepancy Loss: 0.0234
Validation Loss: 0.8165
Epoch [7/50], Class Loss: 2.7937, Discrepancy Loss: 0.0484
Validation Loss: 1.2842
Epoch [8/50], Class Loss: 1.9321, Discrepancy Loss: 0.0509
Validation Loss: 0.3207
Epoch [9/50], Class Loss: 1.0708, Discrepancy Loss: 0.0286
Validation Loss: 0.4651
Epoch [10/50], Class Loss: 0.5116, Discrepancy Loss: 0.0211
Validation Loss: 0.4015
Epoch [11/50], Class Loss: 0.0541, Discrepancy Loss: 0.0123
Validation Loss: 0.2487
Epoch [12/50], Class Loss: 0.1854, Discrepancy Loss: 0.0172
Validation Loss: 0.0335
Epoch [13/50], Class Loss: 0.7124, Discrepancy Loss: 0.0215
Validation Loss: 0.0567
Epoch [14/50], Class Loss: 0.0615, Discrepancy Loss: 0.0177
Validation Loss: 0.0275
Epoch [15/50], Class Loss: 0.0896, Discrepancy Loss: 0.0193
Validation Loss: 0.0259
Epoch [16/50], Class Loss: 0.0448, Discrepancy Loss: 0.0242
Validation Loss: 0.7149
Epoch [17/50], Class Loss: 0.0870, Discrepancy Loss: 0.0237
Validation Loss: 0.0427
Epoch [18/50], Class Loss: 0.1231, Discrepancy Loss: 0.0261
Validation Loss: 0.0259
Epoch [19/50], Class Loss: 0.0695, Discrepancy Loss: 0.0235
Validation Loss: 0.0196
Epoch [20/50], Class Loss: 0.1677, Discrepancy Loss: 0.0191
Validation Loss: 0.4022
Epoch [21/50], Class Loss: 0.0350, Discrepancy Loss: 0.0192
Validation Loss: 0.0371
Epoch [22/50], Class Loss: 0.0220, Discrepancy Loss: 0.0198
Validation Loss: 0.0198
Epoch [23/50], Class Loss: 0.0232, Discrepancy Loss: 0.0199
Validation Loss: 0.0206
Epoch [24/50], Class Loss: 0.0244, Discrepancy Loss: 0.0189
Validation Loss: 0.0208
Early stopping!
Source Domain Performance - Accuracy: 99.85%, Precision: 99.86%, Recall: 99.86%, F1 Score: 99.86%
Target Domain Performance - Accuracy: 47.05%, Precision: 55.74%, Recall: 46.92%, F1 Score: 44.98%

Source performance: 89.38% 86.83% 89.39% 87.37%
Target performance: 45.14% 48.58% 45.13% 38.99%

Per-Class Accuracy on Target Domain:
bpsk: 90.00%
qpsk: 70.74%
4qam: 28.18%
16qam: 19.05%
apsk: 17.68%

Run 1/10
Epoch [1/50], Class Loss: 1.1761, CORAL Loss: 0.0112
Validation Loss: 0.8960
Epoch [2/50], Class Loss: 0.4859, CORAL Loss: 0.0251
Validation Loss: 0.2255
Epoch [3/50], Class Loss: 0.3002, CORAL Loss: 0.0122
Validation Loss: 0.2381
Epoch [4/50], Class Loss: 0.9476, CORAL Loss: 0.2238
Validation Loss: 0.6628
Epoch [5/50], Class Loss: 0.6425, CORAL Loss: 0.0304
Validation Loss: 0.7276
Epoch [6/50], Class Loss: 0.3910, CORAL Loss: 0.0209
Validation Loss: 0.1764
Epoch [7/50], Class Loss: 0.3661, CORAL Loss: 0.0138
Validation Loss: 1.5482
Epoch [8/50], Class Loss: 0.2581, CORAL Loss: 0.0120
Validation Loss: 0.1163
Epoch [9/50], Class Loss: 0.2527, CORAL Loss: 0.0100
Validation Loss: 0.1526
Epoch [10/50], Class Loss: 0.0475, CORAL Loss: 0.0078
Validation Loss: 0.0060
Epoch [11/50], Class Loss: 0.0091, CORAL Loss: 0.0061
Validation Loss: 0.0061
Epoch [12/50], Class Loss: 0.0088, CORAL Loss: 0.0060
Validation Loss: 0.0069
Epoch [13/50], Class Loss: 0.0090, CORAL Loss: 0.0057
Validation Loss: 0.0063
Epoch [14/50], Class Loss: 0.0088, CORAL Loss: 0.0053
Validation Loss: 0.0062
Epoch [15/50], Class Loss: 0.0090, CORAL Loss: 0.0051
Validation Loss: 0.0062
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 40.84%, Precision: 47.57%, Recall: 40.88%, F1 Score: 30.97%

Run 2/10
Epoch [1/50], Class Loss: 1.5747, CORAL Loss: 0.0006
Validation Loss: 1.2061
Epoch [2/50], Class Loss: 0.9194, CORAL Loss: 0.0242
Validation Loss: 0.4423
Epoch [3/50], Class Loss: 0.3880, CORAL Loss: 0.0300
Validation Loss: 0.8074
Epoch [4/50], Class Loss: 0.4993, CORAL Loss: 0.0191
Validation Loss: 0.1933
Epoch [5/50], Class Loss: 0.4840, CORAL Loss: 0.0172
Validation Loss: 0.1872
Epoch [6/50], Class Loss: 0.2971, CORAL Loss: 0.0224
Validation Loss: 0.1431
Epoch [7/50], Class Loss: 0.2722, CORAL Loss: 0.0112
Validation Loss: 0.0659
Epoch [8/50], Class Loss: 0.0347, CORAL Loss: 0.0065
Validation Loss: 0.0059
Epoch [9/50], Class Loss: 0.0069, CORAL Loss: 0.0024
Validation Loss: 3.4290
Epoch [10/50], Class Loss: 0.4039, CORAL Loss: 0.0166
Validation Loss: 0.0591
Epoch [11/50], Class Loss: 0.0380, CORAL Loss: 0.0128
Validation Loss: 0.0244
Epoch [12/50], Class Loss: 0.0256, CORAL Loss: 0.0111
Validation Loss: 0.0165
Epoch [13/50], Class Loss: 0.0187, CORAL Loss: 0.0089
Validation Loss: 0.0119
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.14%, Precision: 34.85%, Recall: 40.17%, F1 Score: 30.27%

Run 3/10
Epoch [1/50], Class Loss: 1.3313, CORAL Loss: 0.0119
Validation Loss: 2.0806
Epoch [2/50], Class Loss: 0.5923, CORAL Loss: 0.0312
Validation Loss: 0.3044
Epoch [3/50], Class Loss: 0.3659, CORAL Loss: 0.0220
Validation Loss: 0.1818
Epoch [4/50], Class Loss: 0.3142, CORAL Loss: 0.0140
Validation Loss: 0.3548
Epoch [5/50], Class Loss: 1.5786, CORAL Loss: 21.5181
Validation Loss: 1.5711
Epoch [6/50], Class Loss: 1.4957, CORAL Loss: 0.0010
Validation Loss: 1.3979
Epoch [7/50], Class Loss: 1.3734, CORAL Loss: 0.0023
Validation Loss: 1.3146
Epoch [8/50], Class Loss: 1.3011, CORAL Loss: 0.0037
Validation Loss: 1.2496
Early stopping!
Source Domain Performance - Accuracy: 39.94%, Precision: 42.85%, Recall: 40.22%, F1 Score: 28.25%
Target Domain Performance - Accuracy: 20.07%, Precision: 4.46%, Recall: 20.00%, F1 Score: 7.29%

Run 4/10
Epoch [1/50], Class Loss: 1.2882, CORAL Loss: 0.0148
Validation Loss: 0.4480
Epoch [2/50], Class Loss: 1.2542, CORAL Loss: 1.4445
Validation Loss: 1.5039
Epoch [3/50], Class Loss: 1.4303, CORAL Loss: 0.0003
Validation Loss: 1.3301
Epoch [4/50], Class Loss: 0.8637, CORAL Loss: 0.0317
Validation Loss: 1.1806
Epoch [5/50], Class Loss: 0.6510, CORAL Loss: 0.0392
Validation Loss: 0.2282
Epoch [6/50], Class Loss: 0.3614, CORAL Loss: 0.0398
Validation Loss: 0.2307
Epoch [7/50], Class Loss: 0.4326, CORAL Loss: 0.0274
Validation Loss: 0.2162
Epoch [8/50], Class Loss: 0.2524, CORAL Loss: 0.0370
Validation Loss: 0.1718
Epoch [9/50], Class Loss: 0.3743, CORAL Loss: 0.0771
Validation Loss: 5.7017
Epoch [10/50], Class Loss: 1.0988, CORAL Loss: 0.0015
Validation Loss: 0.6288
Epoch [11/50], Class Loss: 0.6375, CORAL Loss: 0.0081
Validation Loss: 0.5172
Epoch [12/50], Class Loss: 0.5984, CORAL Loss: 0.0118
Validation Loss: 0.4666
Epoch [13/50], Class Loss: 0.5675, CORAL Loss: 0.0165
Validation Loss: 0.4774
Early stopping!
Source Domain Performance - Accuracy: 80.13%, Precision: 82.65%, Recall: 79.98%, F1 Score: 73.50%
Target Domain Performance - Accuracy: 40.67%, Precision: 30.74%, Recall: 40.47%, F1 Score: 34.04%

Run 5/10
Epoch [1/50], Class Loss: 1.2869, CORAL Loss: 0.0091
Validation Loss: 0.6291
Epoch [2/50], Class Loss: 0.5424, CORAL Loss: 0.0265
Validation Loss: 0.2530
Epoch [3/50], Class Loss: 0.3098, CORAL Loss: 0.0197
Validation Loss: 0.3090
Epoch [4/50], Class Loss: 0.2798, CORAL Loss: 0.0146
Validation Loss: 0.0768
Epoch [5/50], Class Loss: 0.3079, CORAL Loss: 0.0143
Validation Loss: 0.1480
Epoch [6/50], Class Loss: 0.1881, CORAL Loss: 0.0102
Validation Loss: 0.0093
Epoch [7/50], Class Loss: 0.0623, CORAL Loss: 0.0042
Validation Loss: 0.0056
Epoch [8/50], Class Loss: 0.2516, CORAL Loss: 0.0054
Validation Loss: 0.2481
Epoch [9/50], Class Loss: 0.0629, CORAL Loss: 0.0024
Validation Loss: 0.0054
Epoch [10/50], Class Loss: 0.0058, CORAL Loss: 0.0021
Validation Loss: 0.0270
Epoch [11/50], Class Loss: 0.0039, CORAL Loss: 0.0018
Validation Loss: 0.0033
Epoch [12/50], Class Loss: 0.0038, CORAL Loss: 0.0017
Validation Loss: 0.0032
Epoch [13/50], Class Loss: 0.0038, CORAL Loss: 0.0017
Validation Loss: 0.0033
Epoch [14/50], Class Loss: 0.0039, CORAL Loss: 0.0016
Validation Loss: 0.0031
Epoch [15/50], Class Loss: 0.0038, CORAL Loss: 0.0016
Validation Loss: 0.0031
Epoch [16/50], Class Loss: 0.0039, CORAL Loss: 0.0017
Validation Loss: 0.0030
Epoch [17/50], Class Loss: 0.0039, CORAL Loss: 0.0015
Validation Loss: 0.0037
Epoch [18/50], Class Loss: 0.0034, CORAL Loss: 0.0015
Validation Loss: 0.0031
Epoch [19/50], Class Loss: 0.0034, CORAL Loss: 0.0015
Validation Loss: 0.0034
Epoch [20/50], Class Loss: 0.0032, CORAL Loss: 0.0016
Validation Loss: 0.0029
Epoch [21/50], Class Loss: 0.0029, CORAL Loss: 0.0014
Validation Loss: 0.0028
Epoch [22/50], Class Loss: 0.0032, CORAL Loss: 0.0015
Validation Loss: 0.0029
Epoch [23/50], Class Loss: 0.0031, CORAL Loss: 0.0015
Validation Loss: 0.0029
Epoch [24/50], Class Loss: 0.0031, CORAL Loss: 0.0014
Validation Loss: 0.0029
Epoch [25/50], Class Loss: 0.0031, CORAL Loss: 0.0015
Validation Loss: 0.0028
Epoch [26/50], Class Loss: 0.0028, CORAL Loss: 0.0013
Validation Loss: 0.0028
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 40.06%, Precision: 36.75%, Recall: 40.10%, F1 Score: 30.21%

Run 6/10
Epoch [1/50], Class Loss: 1.3719, CORAL Loss: 0.0073
Validation Loss: 0.6915
Epoch [2/50], Class Loss: 0.5009, CORAL Loss: 0.0268
Validation Loss: 0.2190
Epoch [3/50], Class Loss: 0.3102, CORAL Loss: 0.0169
Validation Loss: 0.3013
Epoch [4/50], Class Loss: 0.3086, CORAL Loss: 0.0133
Validation Loss: 0.0878
Epoch [5/50], Class Loss: 0.2596, CORAL Loss: 0.0119
Validation Loss: 0.1034
Epoch [6/50], Class Loss: 0.1509, CORAL Loss: 0.0066
Validation Loss: 0.0258
Epoch [7/50], Class Loss: 0.1389, CORAL Loss: 0.0097
Validation Loss: 0.0364
Epoch [8/50], Class Loss: 0.1793, CORAL Loss: 0.0087
Validation Loss: 0.0161
Epoch [9/50], Class Loss: 0.1795, CORAL Loss: 0.0066
Validation Loss: 0.0112
Epoch [10/50], Class Loss: 0.0078, CORAL Loss: 0.0028
Validation Loss: 0.0048
Epoch [11/50], Class Loss: 0.0050, CORAL Loss: 0.0019
Validation Loss: 0.0044
Epoch [12/50], Class Loss: 0.0046, CORAL Loss: 0.0016
Validation Loss: 0.0043
Epoch [13/50], Class Loss: 0.0047, CORAL Loss: 0.0013
Validation Loss: 0.0043
Epoch [14/50], Class Loss: 0.0046, CORAL Loss: 0.0014
Validation Loss: 0.0040
Epoch [15/50], Class Loss: 0.0042, CORAL Loss: 0.0016
Validation Loss: 0.0039
Epoch [16/50], Class Loss: 0.0043, CORAL Loss: 0.0014
Validation Loss: 0.0038
Epoch [17/50], Class Loss: 0.0042, CORAL Loss: 0.0014
Validation Loss: 0.0037
Epoch [18/50], Class Loss: 0.0038, CORAL Loss: 0.0014
Validation Loss: 0.0036
Epoch [19/50], Class Loss: 0.0042, CORAL Loss: 0.0012
Validation Loss: 0.0035
Epoch [20/50], Class Loss: 0.0037, CORAL Loss: 0.0013
Validation Loss: 0.0033
Epoch [21/50], Class Loss: 0.0035, CORAL Loss: 0.0012
Validation Loss: 0.0033
Epoch [22/50], Class Loss: 0.0035, CORAL Loss: 0.0012
Validation Loss: 0.0033
Epoch [23/50], Class Loss: 0.0034, CORAL Loss: 0.0013
Validation Loss: 0.0033
Epoch [24/50], Class Loss: 0.0034, CORAL Loss: 0.0012
Validation Loss: 0.0033
Epoch [25/50], Class Loss: 0.0035, CORAL Loss: 0.0012
Validation Loss: 0.0033
Epoch [26/50], Class Loss: 0.0032, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [27/50], Class Loss: 0.0032, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [28/50], Class Loss: 0.0034, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [29/50], Class Loss: 0.0034, CORAL Loss: 0.0012
Validation Loss: 0.0033
Epoch [30/50], Class Loss: 0.0034, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [31/50], Class Loss: 0.0032, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [32/50], Class Loss: 0.0035, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [33/50], Class Loss: 0.0033, CORAL Loss: 0.0011
Validation Loss: 0.0032
Epoch [34/50], Class Loss: 0.0031, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [35/50], Class Loss: 0.0034, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [36/50], Class Loss: 0.0031, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [37/50], Class Loss: 0.0030, CORAL Loss: 0.0012
Validation Loss: 0.0032
Epoch [38/50], Class Loss: 0.0033, CORAL Loss: 0.0013
Validation Loss: 0.0031
Epoch [39/50], Class Loss: 0.0032, CORAL Loss: 0.0012
Validation Loss: 0.0031
Epoch [40/50], Class Loss: 0.0032, CORAL Loss: 0.0011
Validation Loss: 0.0031
Epoch [41/50], Class Loss: 0.0032, CORAL Loss: 0.0012
Validation Loss: 0.0031
Epoch [42/50], Class Loss: 0.0032, CORAL Loss: 0.0013
Validation Loss: 0.0031
Epoch [43/50], Class Loss: 0.0032, CORAL Loss: 0.0011
Validation Loss: 0.0031
Epoch [44/50], Class Loss: 0.0031, CORAL Loss: 0.0012
Validation Loss: 0.0031
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.21%, Precision: 42.12%, Recall: 40.24%, F1 Score: 30.54%

Run 7/10
Epoch [1/50], Class Loss: 1.2894, CORAL Loss: 0.0062
Validation Loss: 0.6345
Epoch [2/50], Class Loss: 0.5432, CORAL Loss: 0.0331
Validation Loss: 0.6416
Epoch [3/50], Class Loss: 0.3025, CORAL Loss: 0.0148
Validation Loss: 0.1352
Epoch [4/50], Class Loss: 0.3877, CORAL Loss: 0.0150
Validation Loss: 0.4566
Epoch [5/50], Class Loss: 0.2321, CORAL Loss: 0.0092
Validation Loss: 0.0223
Epoch [6/50], Class Loss: 0.1159, CORAL Loss: 0.0038
Validation Loss: 0.7073
Epoch [7/50], Class Loss: 0.2678, CORAL Loss: 0.0075
Validation Loss: 0.0174
Epoch [8/50], Class Loss: 0.1322, CORAL Loss: 0.0035
Validation Loss: 0.0091
Epoch [9/50], Class Loss: 0.0087, CORAL Loss: 0.0023
Validation Loss: 0.6112
Epoch [10/50], Class Loss: 0.3211, CORAL Loss: 0.0099
Validation Loss: 0.0040
Epoch [11/50], Class Loss: 0.0061, CORAL Loss: 0.0025
Validation Loss: 0.0037
Epoch [12/50], Class Loss: 0.0064, CORAL Loss: 0.0021
Validation Loss: 0.0036
Epoch [13/50], Class Loss: 0.0055, CORAL Loss: 0.0020
Validation Loss: 0.0034
Epoch [14/50], Class Loss: 0.0053, CORAL Loss: 0.0017
Validation Loss: 0.0031
Epoch [15/50], Class Loss: 0.0050, CORAL Loss: 0.0016
Validation Loss: 0.0031
Epoch [16/50], Class Loss: 0.0049, CORAL Loss: 0.0016
Validation Loss: 0.0029
Epoch [17/50], Class Loss: 0.0049, CORAL Loss: 0.0016
Validation Loss: 0.0032
Epoch [18/50], Class Loss: 0.0045, CORAL Loss: 0.0014
Validation Loss: 0.0026
Epoch [19/50], Class Loss: 0.0046, CORAL Loss: 0.0013
Validation Loss: 0.0025
Epoch [20/50], Class Loss: 0.0044, CORAL Loss: 0.0013
Validation Loss: 0.0047
Epoch [21/50], Class Loss: 0.0042, CORAL Loss: 0.0014
Validation Loss: 0.0027
Epoch [22/50], Class Loss: 0.0037, CORAL Loss: 0.0013
Validation Loss: 0.0026
Epoch [23/50], Class Loss: 0.0035, CORAL Loss: 0.0013
Validation Loss: 0.0026
Epoch [24/50], Class Loss: 0.0036, CORAL Loss: 0.0012
Validation Loss: 0.0026
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.11%, Precision: 40.70%, Recall: 40.14%, F1 Score: 30.35%

Run 8/10
Epoch [1/50], Class Loss: 1.3250, CORAL Loss: 0.0075
Validation Loss: 1.1096
Epoch [2/50], Class Loss: 0.5573, CORAL Loss: 0.0320
Validation Loss: 0.2256
Epoch [3/50], Class Loss: 0.4367, CORAL Loss: 0.0239
Validation Loss: 0.1823
Epoch [4/50], Class Loss: 0.3580, CORAL Loss: 0.0198
Validation Loss: 0.2968
Epoch [5/50], Class Loss: 0.3003, CORAL Loss: 0.0143
Validation Loss: 0.6712
Epoch [6/50], Class Loss: 0.1609, CORAL Loss: 0.0097
Validation Loss: 0.0088
Epoch [7/50], Class Loss: 0.0086, CORAL Loss: 0.0040
Validation Loss: 0.0045
Epoch [8/50], Class Loss: 0.4628, CORAL Loss: 0.0244
Validation Loss: 0.1547
Epoch [9/50], Class Loss: 0.2470, CORAL Loss: 0.0115
Validation Loss: 0.0945
Epoch [10/50], Class Loss: 0.1281, CORAL Loss: 0.0094
Validation Loss: 0.0506
Epoch [11/50], Class Loss: 0.0390, CORAL Loss: 0.0044
Validation Loss: 0.0166
Epoch [12/50], Class Loss: 0.0201, CORAL Loss: 0.0047
Validation Loss: 0.0105
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.14%, Precision: 40.14%, Recall: 40.17%, F1 Score: 30.23%

Run 9/10
Epoch [1/50], Class Loss: 1.3278, CORAL Loss: 0.0067
Validation Loss: 0.8786
Epoch [2/50], Class Loss: 0.5172, CORAL Loss: 0.0305
Validation Loss: 0.2447
Epoch [3/50], Class Loss: 0.4167, CORAL Loss: 0.0176
Validation Loss: 0.2483
Epoch [4/50], Class Loss: 0.3119, CORAL Loss: 0.0201
Validation Loss: 0.2323
Epoch [5/50], Class Loss: 0.2654, CORAL Loss: 0.0132
Validation Loss: 0.1930
Epoch [6/50], Class Loss: 0.2948, CORAL Loss: 0.0118
Validation Loss: 0.2912
Epoch [7/50], Class Loss: 0.2417, CORAL Loss: 0.0104
Validation Loss: 0.1754
Epoch [8/50], Class Loss: 0.3205, CORAL Loss: 0.0063
Validation Loss: 0.1090
Epoch [9/50], Class Loss: 0.1766, CORAL Loss: 0.0078
Validation Loss: 0.2494
Epoch [10/50], Class Loss: 0.1796, CORAL Loss: 0.0021
Validation Loss: 0.0340
Epoch [11/50], Class Loss: 0.0279, CORAL Loss: 0.0015
Validation Loss: 0.0124
Epoch [12/50], Class Loss: 0.0168, CORAL Loss: 0.0011
Validation Loss: 0.0079
Epoch [13/50], Class Loss: 0.0126, CORAL Loss: 0.0011
Validation Loss: 0.0058
Epoch [14/50], Class Loss: 0.0096, CORAL Loss: 0.0011
Validation Loss: 0.0047
Epoch [15/50], Class Loss: 0.0079, CORAL Loss: 0.0012
Validation Loss: 0.0047
Epoch [16/50], Class Loss: 0.0064, CORAL Loss: 0.0012
Validation Loss: 0.0033
Epoch [17/50], Class Loss: 0.0058, CORAL Loss: 0.0011
Validation Loss: 0.0031
Epoch [18/50], Class Loss: 0.0052, CORAL Loss: 0.0012
Validation Loss: 0.0029
Epoch [19/50], Class Loss: 0.0046, CORAL Loss: 0.0011
Validation Loss: 0.0028
Epoch [20/50], Class Loss: 0.0043, CORAL Loss: 0.0011
Validation Loss: 0.0026
Epoch [21/50], Class Loss: 0.0041, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [22/50], Class Loss: 0.0038, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [23/50], Class Loss: 0.0037, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [24/50], Class Loss: 0.0041, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [25/50], Class Loss: 0.0033, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [26/50], Class Loss: 0.0041, CORAL Loss: 0.0011
Validation Loss: 0.0025
Epoch [27/50], Class Loss: 0.0039, CORAL Loss: 0.0009
Validation Loss: 0.0025
Epoch [28/50], Class Loss: 0.0039, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [29/50], Class Loss: 0.0041, CORAL Loss: 0.0009
Validation Loss: 0.0024
Epoch [30/50], Class Loss: 0.0038, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [31/50], Class Loss: 0.0037, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [32/50], Class Loss: 0.0036, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [33/50], Class Loss: 0.0036, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [34/50], Class Loss: 0.0037, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [35/50], Class Loss: 0.0039, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [36/50], Class Loss: 0.0037, CORAL Loss: 0.0010
Validation Loss: 0.0025
Epoch [37/50], Class Loss: 0.0037, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [38/50], Class Loss: 0.0039, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [39/50], Class Loss: 0.0035, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [40/50], Class Loss: 0.0040, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [41/50], Class Loss: 0.0037, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [42/50], Class Loss: 0.0036, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [43/50], Class Loss: 0.0041, CORAL Loss: 0.0009
Validation Loss: 0.0024
Epoch [44/50], Class Loss: 0.0034, CORAL Loss: 0.0010
Validation Loss: 0.0024
Epoch [45/50], Class Loss: 0.0033, CORAL Loss: 0.0010
Validation Loss: 0.0024
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.98%, F1 Score: 99.98%
Target Domain Performance - Accuracy: 40.31%, Precision: 57.01%, Recall: 40.34%, F1 Score: 30.79%

Run 10/10
Epoch [1/50], Class Loss: 1.2983, CORAL Loss: 0.0106
Validation Loss: 0.7446
Epoch [2/50], Class Loss: 0.5052, CORAL Loss: 0.0305
Validation Loss: 0.3076
Epoch [3/50], Class Loss: 0.3373, CORAL Loss: 0.0132
Validation Loss: 0.2246
Epoch [4/50], Class Loss: 0.3126, CORAL Loss: 0.0076
Validation Loss: 0.2197
Epoch [5/50], Class Loss: 0.2741, CORAL Loss: 0.0085
Validation Loss: 0.1678
Epoch [6/50], Class Loss: 0.0368, CORAL Loss: 0.0063
Validation Loss: 0.0058
Epoch [7/50], Class Loss: 0.3706, CORAL Loss: 0.0089
Validation Loss: 1.8777
Epoch [8/50], Class Loss: 0.1818, CORAL Loss: 0.0180
Validation Loss: 0.0102
Epoch [9/50], Class Loss: 0.1547, CORAL Loss: 0.0043
Validation Loss: 0.0086
Epoch [10/50], Class Loss: 0.0075, CORAL Loss: 0.0030
Validation Loss: 0.0043
Epoch [11/50], Class Loss: 0.0052, CORAL Loss: 0.0022
Validation Loss: 0.0049
Epoch [12/50], Class Loss: 0.0052, CORAL Loss: 0.0022
Validation Loss: 0.0039
Epoch [13/50], Class Loss: 0.0048, CORAL Loss: 0.0022
Validation Loss: 0.0039
Epoch [14/50], Class Loss: 0.0049, CORAL Loss: 0.0021
Validation Loss: 0.0038
Epoch [15/50], Class Loss: 0.0046, CORAL Loss: 0.0021
Validation Loss: 0.0037
Epoch [16/50], Class Loss: 0.0045, CORAL Loss: 0.0018
Validation Loss: 0.0036
Epoch [17/50], Class Loss: 0.0044, CORAL Loss: 0.0019
Validation Loss: 0.0035
Epoch [18/50], Class Loss: 0.0042, CORAL Loss: 0.0017
Validation Loss: 0.0041
Epoch [19/50], Class Loss: 0.0042, CORAL Loss: 0.0018
Validation Loss: 0.0034
Epoch [20/50], Class Loss: 0.0041, CORAL Loss: 0.0019
Validation Loss: 0.0033
Epoch [21/50], Class Loss: 0.0036, CORAL Loss: 0.0017
Validation Loss: 0.0033
Epoch [22/50], Class Loss: 0.0038, CORAL Loss: 0.0016
Validation Loss: 0.0033
Epoch [23/50], Class Loss: 0.0036, CORAL Loss: 0.0017
Validation Loss: 0.0033
Epoch [24/50], Class Loss: 0.0038, CORAL Loss: 0.0015
Validation Loss: 0.0033
Epoch [25/50], Class Loss: 0.0039, CORAL Loss: 0.0017
Validation Loss: 0.0034
Epoch [26/50], Class Loss: 0.0036, CORAL Loss: 0.0016
Validation Loss: 0.0033
Epoch [27/50], Class Loss: 0.0036, CORAL Loss: 0.0016
Validation Loss: 0.0033
Epoch [28/50], Class Loss: 0.0036, CORAL Loss: 0.0018
Validation Loss: 0.0033
Epoch [29/50], Class Loss: 0.0037, CORAL Loss: 0.0017
Validation Loss: 0.0032
Epoch [30/50], Class Loss: 0.0035, CORAL Loss: 0.0017
Validation Loss: 0.0033
Epoch [31/50], Class Loss: 0.0036, CORAL Loss: 0.0016
Validation Loss: 0.0032
Epoch [32/50], Class Loss: 0.0035, CORAL Loss: 0.0016
Validation Loss: 0.0032
Epoch [33/50], Class Loss: 0.0033, CORAL Loss: 0.0016
Validation Loss: 0.0032
Epoch [34/50], Class Loss: 0.0036, CORAL Loss: 0.0017
Validation Loss: 0.0032
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.09%, Precision: 38.18%, Recall: 40.12%, F1 Score: 30.26%

Source performance: 91.97% 92.51% 91.98% 90.13%
Target performance: 38.26% 37.25% 38.26% 28.49%

Per-Class Accuracy on Target Domain:
bpsk: 100.00%
qpsk: 79.89%
4qam: 10.45%
16qam: 0.94%
apsk: 0.04%

Run 1/10
Epoch [1/50], Class Loss: 1.4982, JMMD Loss: 0.1746
Validation Loss: 2.3893
Epoch [2/50], Class Loss: 0.6073, JMMD Loss: 0.3364
Validation Loss: 0.1709
Epoch [3/50], Class Loss: 0.3394, JMMD Loss: 0.3423
Validation Loss: 0.1373
Epoch [4/50], Class Loss: 0.1925, JMMD Loss: 0.3521
Validation Loss: 0.0260
Epoch [5/50], Class Loss: 0.3696, JMMD Loss: 0.3537
Validation Loss: 0.3171
Epoch [6/50], Class Loss: 0.1720, JMMD Loss: 0.3568
Validation Loss: 0.0566
Epoch [7/50], Class Loss: 0.2776, JMMD Loss: 0.3598
Validation Loss: 0.2663
Epoch [8/50], Class Loss: 0.0617, JMMD Loss: 0.3544
Validation Loss: 0.0055
Epoch [9/50], Class Loss: 0.2236, JMMD Loss: 0.3567
Validation Loss: 0.1563
Epoch [10/50], Class Loss: 0.0592, JMMD Loss: 0.3623
Validation Loss: 0.0246
Epoch [11/50], Class Loss: 0.0116, JMMD Loss: 0.3688
Validation Loss: 0.0098
Epoch [12/50], Class Loss: 0.0094, JMMD Loss: 0.3650
Validation Loss: 0.0082
Epoch [13/50], Class Loss: 0.0083, JMMD Loss: 0.3683
Validation Loss: 0.0068
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.06%, Precision: 35.37%, Recall: 40.10%, F1 Score: 30.24%

Run 2/10
Epoch [1/50], Class Loss: 1.4915, JMMD Loss: 0.1818
Validation Loss: 0.7989
Epoch [2/50], Class Loss: 1.0196, JMMD Loss: 0.3411
Validation Loss: 4.3020
Epoch [3/50], Class Loss: 0.7792, JMMD Loss: 0.3445
Validation Loss: 0.2631
Epoch [4/50], Class Loss: 0.3796, JMMD Loss: 0.3604
Validation Loss: 0.3500
Epoch [5/50], Class Loss: 0.1970, JMMD Loss: 0.3597
Validation Loss: 0.0626
Epoch [6/50], Class Loss: 0.2818, JMMD Loss: 0.3662
Validation Loss: 0.1917
Epoch [7/50], Class Loss: 0.1357, JMMD Loss: 0.3620
Validation Loss: 0.0384
Epoch [8/50], Class Loss: 0.0540, JMMD Loss: 0.3665
Validation Loss: 0.0074
Epoch [9/50], Class Loss: 0.1332, JMMD Loss: 0.3719
Validation Loss: 0.0162
Epoch [10/50], Class Loss: 0.0744, JMMD Loss: 0.3826
Validation Loss: 0.1675
Epoch [11/50], Class Loss: 0.0967, JMMD Loss: 0.3598
Validation Loss: 0.0431
Epoch [12/50], Class Loss: 0.0322, JMMD Loss: 0.3583
Validation Loss: 0.0168
Epoch [13/50], Class Loss: 0.0157, JMMD Loss: 0.3595
Validation Loss: 0.0094
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.98%, F1 Score: 99.98%
Target Domain Performance - Accuracy: 46.95%, Precision: 42.11%, Recall: 46.89%, F1 Score: 42.29%

Run 3/10
Epoch [1/50], Class Loss: 1.5581, JMMD Loss: 0.1517
Validation Loss: 1.0454
Epoch [2/50], Class Loss: 0.7185, JMMD Loss: 0.3400
Validation Loss: 0.4868
Epoch [3/50], Class Loss: 0.4754, JMMD Loss: 0.3485
Validation Loss: 0.1786
Epoch [4/50], Class Loss: 0.2800, JMMD Loss: 0.3543
Validation Loss: 0.5538
Epoch [5/50], Class Loss: 0.2211, JMMD Loss: 0.3559
Validation Loss: 0.0733
Epoch [6/50], Class Loss: 0.2305, JMMD Loss: 0.3659
Validation Loss: 0.0948
Epoch [7/50], Class Loss: 0.1474, JMMD Loss: 0.3750
Validation Loss: 0.0373
Epoch [8/50], Class Loss: 0.0280, JMMD Loss: 0.3921
Validation Loss: 0.0294
Epoch [9/50], Class Loss: 0.0127, JMMD Loss: 0.4057
Validation Loss: 0.0106
Epoch [10/50], Class Loss: 0.1801, JMMD Loss: 0.3725
Validation Loss: 0.2642
Epoch [11/50], Class Loss: 0.2197, JMMD Loss: 0.3726
Validation Loss: 0.1683
Epoch [12/50], Class Loss: 0.1296, JMMD Loss: 0.3741
Validation Loss: 0.0740
Epoch [13/50], Class Loss: 0.0586, JMMD Loss: 0.3783
Validation Loss: 0.0297
Epoch [14/50], Class Loss: 0.0292, JMMD Loss: 0.3801
Validation Loss: 0.0163
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 39.99%, Precision: 33.41%, Recall: 40.02%, F1 Score: 30.14%

Run 4/10
Epoch [1/50], Class Loss: 1.4695, JMMD Loss: 0.1715
Validation Loss: 0.8907
Epoch [2/50], Class Loss: 0.5487, JMMD Loss: 0.3495
Validation Loss: 0.2271
Epoch [3/50], Class Loss: 0.3842, JMMD Loss: 0.3645
Validation Loss: 0.2196
Epoch [4/50], Class Loss: 0.2673, JMMD Loss: 0.3676
Validation Loss: 0.0772
Epoch [5/50], Class Loss: 0.2877, JMMD Loss: 0.3737
Validation Loss: 2.3373
Epoch [6/50], Class Loss: 0.2573, JMMD Loss: 0.3626
Validation Loss: 0.0398
Epoch [7/50], Class Loss: 0.1476, JMMD Loss: 0.3623
Validation Loss: 0.0240
Epoch [8/50], Class Loss: 0.1495, JMMD Loss: 0.3664
Validation Loss: 0.0554
Epoch [9/50], Class Loss: 0.0191, JMMD Loss: 0.3751
Validation Loss: 0.0039
Epoch [10/50], Class Loss: 0.0100, JMMD Loss: 0.3784
Validation Loss: 0.0100
Epoch [11/50], Class Loss: 0.0061, JMMD Loss: 0.3844
Validation Loss: 0.0044
Epoch [12/50], Class Loss: 0.0050, JMMD Loss: 0.3868
Validation Loss: 0.0043
Epoch [13/50], Class Loss: 0.0057, JMMD Loss: 0.3875
Validation Loss: 0.0049
Epoch [14/50], Class Loss: 0.0066, JMMD Loss: 0.3749
Validation Loss: 0.0055
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.62%, Precision: 43.77%, Recall: 40.65%, F1 Score: 31.43%

Run 5/10
Epoch [1/50], Class Loss: 1.4275, JMMD Loss: 0.2291
Validation Loss: 2.7829
Epoch [2/50], Class Loss: 0.8745, JMMD Loss: 0.3426
Validation Loss: 0.2688
Epoch [3/50], Class Loss: 0.4733, JMMD Loss: 0.3532
Validation Loss: 0.1422
Epoch [4/50], Class Loss: 0.3579, JMMD Loss: 0.3593
Validation Loss: 0.1589
Epoch [5/50], Class Loss: 0.1583, JMMD Loss: 0.3575
Validation Loss: 0.6989
Epoch [6/50], Class Loss: 0.2488, JMMD Loss: 0.3606
Validation Loss: 0.0360
Epoch [7/50], Class Loss: 0.0215, JMMD Loss: 0.3730
Validation Loss: 0.0074
Epoch [8/50], Class Loss: 0.1384, JMMD Loss: 0.3691
Validation Loss: 0.0109
Epoch [9/50], Class Loss: 0.0101, JMMD Loss: 0.3822
Validation Loss: 0.0065
Epoch [10/50], Class Loss: 0.2848, JMMD Loss: 0.3750
Validation Loss: 0.0329
Epoch [11/50], Class Loss: 0.0213, JMMD Loss: 0.3716
Validation Loss: 0.0138
Epoch [12/50], Class Loss: 0.0148, JMMD Loss: 0.3717
Validation Loss: 0.0110
Epoch [13/50], Class Loss: 0.0122, JMMD Loss: 0.3716
Validation Loss: 0.0092
Epoch [14/50], Class Loss: 0.0100, JMMD Loss: 0.3717
Validation Loss: 0.0082
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.04%, Precision: 35.34%, Recall: 40.07%, F1 Score: 30.21%

Run 6/10
Epoch [1/50], Class Loss: 1.3198, JMMD Loss: 0.2416
Validation Loss: 0.7467
Epoch [2/50], Class Loss: 0.4988, JMMD Loss: 0.3673
Validation Loss: 0.1719
Epoch [3/50], Class Loss: 0.3501, JMMD Loss: 0.3673
Validation Loss: 0.0481
Epoch [4/50], Class Loss: 0.2034, JMMD Loss: 0.3657
Validation Loss: 0.0285
Epoch [5/50], Class Loss: 0.0898, JMMD Loss: 0.3751
Validation Loss: 0.0185
Epoch [6/50], Class Loss: 0.1799, JMMD Loss: 0.3752
Validation Loss: 0.0396
Epoch [7/50], Class Loss: 0.0178, JMMD Loss: 0.3876
Validation Loss: 0.0094
Epoch [8/50], Class Loss: 0.1625, JMMD Loss: 0.3926
Validation Loss: 1.9071
Epoch [9/50], Class Loss: 0.1610, JMMD Loss: 0.3925
Validation Loss: 0.0150
Epoch [10/50], Class Loss: 0.0124, JMMD Loss: 0.3995
Validation Loss: 0.0084
Epoch [11/50], Class Loss: 0.0072, JMMD Loss: 0.3953
Validation Loss: 0.0070
Epoch [12/50], Class Loss: 0.0072, JMMD Loss: 0.3941
Validation Loss: 0.0070
Epoch [13/50], Class Loss: 0.0074, JMMD Loss: 0.3939
Validation Loss: 0.0079
Epoch [14/50], Class Loss: 0.0076, JMMD Loss: 0.3884
Validation Loss: 0.0073
Epoch [15/50], Class Loss: 0.0076, JMMD Loss: 0.3875
Validation Loss: 0.0070
Epoch [16/50], Class Loss: 0.0080, JMMD Loss: 0.3806
Validation Loss: 0.0083
Epoch [17/50], Class Loss: 0.0083, JMMD Loss: 0.3624
Validation Loss: 0.0072
Epoch [18/50], Class Loss: 0.0089, JMMD Loss: 0.3356
Validation Loss: 0.0069
Epoch [19/50], Class Loss: 0.0094, JMMD Loss: 0.3160
Validation Loss: 0.0068
Epoch [20/50], Class Loss: 0.0094, JMMD Loss: 0.2951
Validation Loss: 0.0067
Epoch [21/50], Class Loss: 0.0088, JMMD Loss: 0.2903
Validation Loss: 0.0068
Epoch [22/50], Class Loss: 0.0089, JMMD Loss: 0.2824
Validation Loss: 0.0067
Epoch [23/50], Class Loss: 0.0090, JMMD Loss: 0.2809
Validation Loss: 0.0066
Epoch [24/50], Class Loss: 0.0088, JMMD Loss: 0.2786
Validation Loss: 0.0066
Epoch [25/50], Class Loss: 0.0091, JMMD Loss: 0.2830
Validation Loss: 0.0065
Epoch [26/50], Class Loss: 0.0090, JMMD Loss: 0.2769
Validation Loss: 0.0066
Epoch [27/50], Class Loss: 0.0088, JMMD Loss: 0.2772
Validation Loss: 0.0064
Epoch [28/50], Class Loss: 0.0088, JMMD Loss: 0.2752
Validation Loss: 0.0065
Epoch [29/50], Class Loss: 0.0087, JMMD Loss: 0.2741
Validation Loss: 0.0066
Epoch [30/50], Class Loss: 0.0089, JMMD Loss: 0.2699
Validation Loss: 0.0067
Epoch [31/50], Class Loss: 0.0089, JMMD Loss: 0.2662
Validation Loss: 0.0066
Epoch [32/50], Class Loss: 0.0088, JMMD Loss: 0.2651
Validation Loss: 0.0065
Early stopping!
Source Domain Performance - Accuracy: 99.98%, Precision: 99.98%, Recall: 99.98%, F1 Score: 99.98%
Target Domain Performance - Accuracy: 40.48%, Precision: 42.17%, Recall: 40.51%, F1 Score: 31.01%

Run 7/10
Epoch [1/50], Class Loss: 1.5112, JMMD Loss: 0.1903
Validation Loss: 1.0672
Epoch [2/50], Class Loss: 1.0518, JMMD Loss: 0.3463
Validation Loss: 1.1404
Epoch [3/50], Class Loss: 0.4348, JMMD Loss: 0.3470
Validation Loss: 0.2482
Epoch [4/50], Class Loss: 0.6252, JMMD Loss: 0.3510
Validation Loss: 0.2251
Epoch [5/50], Class Loss: 0.1899, JMMD Loss: 0.3478
Validation Loss: 0.2192
Epoch [6/50], Class Loss: 0.1768, JMMD Loss: 0.3525
Validation Loss: 0.1587
Epoch [7/50], Class Loss: 0.3351, JMMD Loss: 0.3608
Validation Loss: 0.0214
Epoch [8/50], Class Loss: 0.1527, JMMD Loss: 0.3591
Validation Loss: 0.0173
Epoch [9/50], Class Loss: 0.1485, JMMD Loss: 0.3632
Validation Loss: 0.0813
Epoch [10/50], Class Loss: 0.0567, JMMD Loss: 0.3734
Validation Loss: 0.0064
Epoch [11/50], Class Loss: 0.0087, JMMD Loss: 0.3741
Validation Loss: 0.0061
Epoch [12/50], Class Loss: 0.0076, JMMD Loss: 0.3742
Validation Loss: 0.0065
Epoch [13/50], Class Loss: 0.0069, JMMD Loss: 0.3775
Validation Loss: 0.0064
Epoch [14/50], Class Loss: 0.0064, JMMD Loss: 0.3796
Validation Loss: 0.0065
Epoch [15/50], Class Loss: 0.0063, JMMD Loss: 0.3725
Validation Loss: 0.0062
Epoch [16/50], Class Loss: 0.0061, JMMD Loss: 0.3745
Validation Loss: 0.0057
Epoch [17/50], Class Loss: 0.0064, JMMD Loss: 0.3695
Validation Loss: 0.0063
Epoch [18/50], Class Loss: 0.0062, JMMD Loss: 0.3705
Validation Loss: 0.0089
Epoch [19/50], Class Loss: 0.0061, JMMD Loss: 0.3716
Validation Loss: 0.0065
Epoch [20/50], Class Loss: 0.0057, JMMD Loss: 0.3741
Validation Loss: 0.0063
Epoch [21/50], Class Loss: 0.0057, JMMD Loss: 0.3726
Validation Loss: 0.0060
Early stopping!
Source Domain Performance - Accuracy: 99.93%, Precision: 99.93%, Recall: 99.93%, F1 Score: 99.93%
Target Domain Performance - Accuracy: 40.09%, Precision: 36.80%, Recall: 40.12%, F1 Score: 30.21%

Run 8/10
Epoch [1/50], Class Loss: 1.4585, JMMD Loss: 0.1831
Validation Loss: 1.2701
Epoch [2/50], Class Loss: 0.6834, JMMD Loss: 0.3344
Validation Loss: 0.1470
Epoch [3/50], Class Loss: 0.4511, JMMD Loss: 0.3459
Validation Loss: 0.2031
Epoch [4/50], Class Loss: 0.1817, JMMD Loss: 0.3503
Validation Loss: 0.0393
Epoch [5/50], Class Loss: 0.3609, JMMD Loss: 0.3573
Validation Loss: 0.0779
Epoch [6/50], Class Loss: 0.3333, JMMD Loss: 0.3586
Validation Loss: 0.0957
Epoch [7/50], Class Loss: 0.0435, JMMD Loss: 0.3593
Validation Loss: 0.0087
Epoch [8/50], Class Loss: 0.0210, JMMD Loss: 0.3711
Validation Loss: 0.0058
Epoch [9/50], Class Loss: 0.3106, JMMD Loss: 0.3724
Validation Loss: 0.0852
Epoch [10/50], Class Loss: 0.0617, JMMD Loss: 0.3679
Validation Loss: 0.0080
Epoch [11/50], Class Loss: 0.0146, JMMD Loss: 0.3827
Validation Loss: 0.0073
Epoch [12/50], Class Loss: 0.0132, JMMD Loss: 0.3819
Validation Loss: 0.0068
Epoch [13/50], Class Loss: 0.0124, JMMD Loss: 0.3821
Validation Loss: 0.0064
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 41.38%, Precision: 43.82%, Recall: 41.40%, F1 Score: 33.11%

Run 9/10
Epoch [1/50], Class Loss: 1.4118, JMMD Loss: 0.2084
Validation Loss: 1.3388
Epoch [2/50], Class Loss: 0.7451, JMMD Loss: 0.3486
Validation Loss: 0.4624
Epoch [3/50], Class Loss: 0.3864, JMMD Loss: 0.3526
Validation Loss: 0.2109
Epoch [4/50], Class Loss: 0.2611, JMMD Loss: 0.3539
Validation Loss: 0.3645
Epoch [5/50], Class Loss: 0.3394, JMMD Loss: 0.3518
Validation Loss: 0.1471
Epoch [6/50], Class Loss: 0.0849, JMMD Loss: 0.3609
Validation Loss: 0.0099
Epoch [7/50], Class Loss: 0.2825, JMMD Loss: 0.3659
Validation Loss: 0.2810
Epoch [8/50], Class Loss: 0.1025, JMMD Loss: 0.3686
Validation Loss: 0.0112
Epoch [9/50], Class Loss: 0.1517, JMMD Loss: 0.3517
Validation Loss: 0.0097
Epoch [10/50], Class Loss: 0.2880, JMMD Loss: 0.3567
Validation Loss: 0.0525
Epoch [11/50], Class Loss: 0.0551, JMMD Loss: 0.3562
Validation Loss: 0.0361
Epoch [12/50], Class Loss: 0.0417, JMMD Loss: 0.3581
Validation Loss: 0.0257
Epoch [13/50], Class Loss: 0.0322, JMMD Loss: 0.3595
Validation Loss: 0.0189
Epoch [14/50], Class Loss: 0.0249, JMMD Loss: 0.3577
Validation Loss: 0.0149
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 42.26%, Precision: 43.59%, Recall: 42.27%, F1 Score: 34.90%

Run 10/10
Epoch [1/50], Class Loss: 1.3661, JMMD Loss: 0.2523
Validation Loss: 0.9069
Epoch [2/50], Class Loss: 0.7038, JMMD Loss: 0.3447
Validation Loss: 0.2036
Epoch [3/50], Class Loss: 0.4188, JMMD Loss: 0.3528
Validation Loss: 0.4062
Epoch [4/50], Class Loss: 0.3404, JMMD Loss: 0.3488
Validation Loss: 0.1037
Epoch [5/50], Class Loss: 0.2455, JMMD Loss: 0.3464
Validation Loss: 0.1221
Epoch [6/50], Class Loss: 0.1905, JMMD Loss: 0.3551
Validation Loss: 0.0636
Epoch [7/50], Class Loss: 0.1412, JMMD Loss: 0.3634
Validation Loss: 0.0235
Epoch [8/50], Class Loss: 0.4448, JMMD Loss: 0.3650
Validation Loss: 0.3601
Epoch [9/50], Class Loss: 0.1289, JMMD Loss: 0.3728
Validation Loss: 0.0379
Epoch [10/50], Class Loss: 0.1108, JMMD Loss: 0.3771
Validation Loss: 0.0195
Epoch [11/50], Class Loss: 0.0120, JMMD Loss: 0.3779
Validation Loss: 0.0088
Epoch [12/50], Class Loss: 0.0104, JMMD Loss: 0.3763
Validation Loss: 0.0080
Epoch [13/50], Class Loss: 0.0093, JMMD Loss: 0.3731
Validation Loss: 0.0073
Epoch [14/50], Class Loss: 0.0089, JMMD Loss: 0.3694
Validation Loss: 0.0070
Epoch [15/50], Class Loss: 0.0089, JMMD Loss: 0.3663
Validation Loss: 0.0069
Epoch [16/50], Class Loss: 0.0089, JMMD Loss: 0.3612
Validation Loss: 0.0067
Epoch [17/50], Class Loss: 0.0088, JMMD Loss: 0.3468
Validation Loss: 0.0069
Epoch [18/50], Class Loss: 0.0093, JMMD Loss: 0.3264
Validation Loss: 0.0067
Epoch [19/50], Class Loss: 0.0093, JMMD Loss: 0.3065
Validation Loss: 0.0067
Epoch [20/50], Class Loss: 0.0088, JMMD Loss: 0.2893
Validation Loss: 0.0066
Epoch [21/50], Class Loss: 0.0083, JMMD Loss: 0.2883
Validation Loss: 0.0064
Epoch [22/50], Class Loss: 0.0081, JMMD Loss: 0.2847
Validation Loss: 0.0065
Epoch [23/50], Class Loss: 0.0084, JMMD Loss: 0.2812
Validation Loss: 0.0063
Epoch [24/50], Class Loss: 0.0080, JMMD Loss: 0.2761
Validation Loss: 0.0064
Epoch [25/50], Class Loss: 0.0085, JMMD Loss: 0.2766
Validation Loss: 0.0063
Epoch [26/50], Class Loss: 0.0080, JMMD Loss: 0.2702
Validation Loss: 0.0062
Epoch [27/50], Class Loss: 0.0086, JMMD Loss: 0.2724
Validation Loss: 0.0062
Epoch [28/50], Class Loss: 0.0083, JMMD Loss: 0.2713
Validation Loss: 0.0061
Epoch [29/50], Class Loss: 0.0082, JMMD Loss: 0.2647
Validation Loss: 0.0064
Epoch [30/50], Class Loss: 0.0078, JMMD Loss: 0.2702
Validation Loss: 0.0062
Epoch [31/50], Class Loss: 0.0078, JMMD Loss: 0.2667
Validation Loss: 0.0061
Epoch [32/50], Class Loss: 0.0080, JMMD Loss: 0.2628
Validation Loss: 0.0061
Epoch [33/50], Class Loss: 0.0081, JMMD Loss: 0.2673
Validation Loss: 0.0061
Early stopping!
Source Domain Performance - Accuracy: 99.95%, Precision: 99.95%, Recall: 99.95%, F1 Score: 99.95%
Target Domain Performance - Accuracy: 40.28%, Precision: 41.13%, Recall: 40.31%, F1 Score: 30.63%

Source performance: 99.95% 99.95% 99.96% 99.95%
Target performance: 41.22% 39.75% 41.24% 32.42%

Per-Class Accuracy on Target Domain (Mean over runs):
  Class 0: 99.91%
  Class 1: 97.29%
  Class 2: 8.13%
  Class 3: 0.84%
  Class 4: 0.00%
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=5a75f4d8-b552-4e01-8024-24f80cc6eaa3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">base_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Base'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dann_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Dann'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">star_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'^'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Star'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mcd_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'D'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'MCD'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">coral_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'v'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'CORAL'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">jan_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'x'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'JANN'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'SNR (dB)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Acc (%)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=99f9cbcd-da1a-4fdf-ae8d-5abab06fdeeb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
