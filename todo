# Modular
    # Define each model to be used: CNN, CLDNN, etc
    # Define DA method: DANN, MCD, etc
    # Define Confusion matrices & performance metrics
    # Define tensor and dataloader
    # Define data selection and saving: modulation selection, SNR(|| others)
    

# BaseLine
# split the main data into S/T_X/Y_selected.npy
#   select the z_value (snr) that you want for source and target
# optional: plot a sample for each label selected, or a random one
# define your model
#   criterion, optimizer, etc
# repeat for source and target:
    # load saved data, convert to tensors, create tensordataset, dataloaders
    # split into train and validation
# define and compute train and test
    # what loader are you using for train source or target
    # run the validation set in train
    # evaluate on source, then target on the S/T_val_loaders
# compute mean metrics
# confusion metrics


# DANN
# define grl & model & dann
# Load saved S/T_X/Y_selected.npy
# for source and target domain
    # convert to tensor, create tensordataset, dataloaders
    # split train and val 
# define train and test
    # train using source and target, combine losses
    # evaluation is basically the same as baseline
    # eva on source, target, compute metrics, confusion matrices
