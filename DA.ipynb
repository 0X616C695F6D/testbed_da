{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c77d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Over the air domain adaptation.\n",
    "\n",
    "4 Modulations: bpsk, qpsk, 16qam and 16apsk.\n",
    "Source SNR as 24, target from 10 to 22.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import funcs\n",
    "import jan\n",
    "import coral\n",
    "import star\n",
    "import mcd\n",
    "import dann\n",
    "import base\n",
    "import plots\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2036317-47cb-4da7-9caa-b1f64b1857ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "class CLDNN(nn.Module):\n",
    "    def __init__(self, output_dim=4):\n",
    "        super(CLDNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=8, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # After conv1 and pooling: input length 4096 becomes 4089 then 2044 after pooling.\n",
    "        # So the flattened output from the LSTM will be 2044 * 64.\n",
    "        self.fc1 = nn.Linear(2044 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x has shape: (batch, 2, 4096)\n",
    "        x = self.conv1(x)      # -> (batch, 64, 4089)\n",
    "        x = self.pool(x)       # -> (batch, 64, 2044)\n",
    "        \n",
    "        # Permute to have sequence first: (batch, 2044, 64)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x, _ = self.lstm1(x)   # -> (batch, 2044, 64)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)   # -> (batch, 2044, 64)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Flatten: (batch, 2044*64)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "#%% DANN\n",
    "from torch.autograd import Function\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "def grad_reverse(x, alpha=1.0):\n",
    "    return ReverseLayerF.apply(x, alpha)\n",
    "class CLDNN_FA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLDNN_FA, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=8, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        return x\n",
    "\n",
    "class CLDNN_LP(nn.Module):\n",
    "    def __init__(self, output_dim=7):\n",
    "        super(CLDNN_LP, self).__init__()\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(2044 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CLDNN_DC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLDNN_DC, self).__init__()\n",
    "        self.fc1 = nn.Linear(2044 * 64, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        x = ReverseLayerF.apply(x, alpha)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# star\n",
    "class STAR_G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAR_G, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=8, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class STAR_C(nn.Module):\n",
    "    def __init__(self, output_dim, num_classifiers_train=2, num_classifiers_test=20, init='kaiming_u', use_init=False):\n",
    "        super(STAR_C, self).__init__()\n",
    "        self.num_classifiers_train = num_classifiers_train\n",
    "        self.num_classifiers_test = num_classifiers_test\n",
    "        self.init = init\n",
    "\n",
    "        function_init = {\n",
    "            'kaiming_u': nn.init.kaiming_uniform_,\n",
    "            'kaiming_n': nn.init.kaiming_normal_,\n",
    "            'xavier': nn.init.xavier_normal_\n",
    "        }\n",
    "\n",
    "        self.fc1 = nn.Linear(2044 * 64, 128)\n",
    "        self.bn1_fc = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.mu2 = nn.Parameter(torch.randn(output_dim, 128))\n",
    "        self.sigma2 = nn.Parameter(torch.zeros(output_dim, 128))\n",
    "\n",
    "        if use_init:\n",
    "            all_parameters = [self.mu2, self.sigma2]\n",
    "            for item in all_parameters:\n",
    "                function_init[self.init](item)\n",
    "\n",
    "        self.b2 = nn.Parameter(torch.zeros(output_dim))\n",
    "\n",
    "    def forward(self, x, only_mu=True):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn1_fc(x))\n",
    "\n",
    "        sigma2_pos = torch.sigmoid(self.sigma2)\n",
    "        fc2_distribution = torch.distributions.Normal(self.mu2, sigma2_pos)\n",
    "\n",
    "        if self.training:\n",
    "            classifiers = []\n",
    "            for _ in range(self.num_classifiers_train):\n",
    "                fc2_w = fc2_distribution.rsample()\n",
    "                classifiers.append([fc2_w, self.b2])\n",
    "\n",
    "            outputs = []\n",
    "            for classifier in classifiers:\n",
    "                out = F.linear(x, classifier[0], classifier[1])\n",
    "                outputs.append(out)\n",
    "\n",
    "            return outputs\n",
    "        else:\n",
    "            if only_mu:\n",
    "                out = F.linear(x, self.mu2, self.b2)\n",
    "                return [out]\n",
    "            else:\n",
    "                classifiers = []\n",
    "                for _ in range(self.num_classifiers_test):\n",
    "                    fc2_w = fc2_distribution.rsample()\n",
    "                    classifiers.append([fc2_w, self.b2])\n",
    "\n",
    "                outputs = []\n",
    "                for classifier in classifiers:\n",
    "                    out = F.linear(x, classifier[0], classifier[1])\n",
    "                    outputs.append(out)\n",
    "                return outputs\n",
    "\n",
    "\n",
    "#%% mcd\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.view_as(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.lambda_, None\n",
    "\n",
    "def grad_reverse(x, lambda_=1.0):\n",
    "    return GradReverse.apply(x, lambda_)\n",
    "\n",
    "class MCD_G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MCD_G, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=8, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "class MCD_C(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(MCD_C, self).__init__()\n",
    "        self.fc1 = nn.Linear(2044 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "    \n",
    "    def forward(self, x, reverse=False, lambda_=1.0):\n",
    "        if reverse:\n",
    "            x = grad_reverse(x, lambda_)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5022b5-1350-4b3b-8bcc-c653e90518d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 1/5\n",
      "Epoch 1/50, Train Loss: 1.0364, Train Acc: 0.5303, Val Loss: 0.7761, Val Acc: 0.6211\n",
      "Epoch 2/50, Train Loss: 0.7108, Train Acc: 0.6491, Val Loss: 0.5078, Val Acc: 0.7416\n",
      "Epoch 3/50, Train Loss: 0.2640, Train Acc: 0.8998, Val Loss: 0.0426, Val Acc: 0.9886\n",
      "Epoch 4/50, Train Loss: 0.1324, Train Acc: 0.9640, Val Loss: 0.1633, Val Acc: 0.9532\n",
      "Epoch 5/50, Train Loss: 0.1069, Train Acc: 0.9724, Val Loss: 0.1089, Val Acc: 0.9682\n",
      "Epoch 6/50, Train Loss: 0.0332, Train Acc: 0.9898, Val Loss: 0.0818, Val Acc: 0.9814\n",
      "Epoch 7/50, Train Loss: 0.0449, Train Acc: 0.9897, Val Loss: 0.0225, Val Acc: 0.9928\n",
      "Epoch 8/50, Train Loss: 0.0865, Train Acc: 0.9807, Val Loss: 0.0161, Val Acc: 0.9952\n",
      "Epoch 9/50, Train Loss: 0.0169, Train Acc: 0.9964, Val Loss: 0.1032, Val Acc: 0.9790\n",
      "Epoch 10/50, Train Loss: 0.0226, Train Acc: 0.9939, Val Loss: 0.0502, Val Acc: 0.9868\n",
      "Epoch 11/50, Train Loss: 0.0048, Train Acc: 0.9987, Val Loss: 0.0075, Val Acc: 0.9976\n",
      "Epoch 12/50, Train Loss: 0.0033, Train Acc: 0.9991, Val Loss: 0.0068, Val Acc: 0.9988\n",
      "Epoch 13/50, Train Loss: 0.0030, Train Acc: 0.9994, Val Loss: 0.0085, Val Acc: 0.9976\n",
      "Epoch 14/50, Train Loss: 0.0033, Train Acc: 0.9993, Val Loss: 0.0073, Val Acc: 0.9976\n",
      "Epoch 15/50, Train Loss: 0.0028, Train Acc: 0.9993, Val Loss: 0.0082, Val Acc: 0.9988\n",
      "Epoch 16/50, Train Loss: 0.0019, Train Acc: 0.9994, Val Loss: 0.0323, Val Acc: 0.9928\n",
      "Epoch 17/50, Train Loss: 0.0029, Train Acc: 0.9993, Val Loss: 0.0112, Val Acc: 0.9970\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 2/5\n",
      "Epoch 1/50, Train Loss: 1.1355, Train Acc: 0.5268, Val Loss: 0.7137, Val Acc: 0.6193\n",
      "Epoch 2/50, Train Loss: 0.7280, Train Acc: 0.6329, Val Loss: 0.6112, Val Acc: 0.6865\n",
      "Epoch 3/50, Train Loss: 0.2496, Train Acc: 0.9025, Val Loss: 0.0683, Val Acc: 0.9832\n",
      "Epoch 4/50, Train Loss: 0.0843, Train Acc: 0.9735, Val Loss: 0.1839, Val Acc: 0.9538\n",
      "Epoch 5/50, Train Loss: 0.0863, Train Acc: 0.9772, Val Loss: 0.0248, Val Acc: 0.9910\n",
      "Epoch 6/50, Train Loss: 0.0275, Train Acc: 0.9925, Val Loss: 0.0217, Val Acc: 0.9940\n",
      "Epoch 7/50, Train Loss: 0.0752, Train Acc: 0.9778, Val Loss: 0.0312, Val Acc: 0.9898\n",
      "Epoch 8/50, Train Loss: 0.0274, Train Acc: 0.9924, Val Loss: 0.0262, Val Acc: 0.9934\n",
      "Epoch 9/50, Train Loss: 0.0257, Train Acc: 0.9942, Val Loss: 0.0206, Val Acc: 0.9940\n",
      "Epoch 10/50, Train Loss: 0.0353, Train Acc: 0.9903, Val Loss: 0.0226, Val Acc: 0.9928\n",
      "Epoch 11/50, Train Loss: 0.0036, Train Acc: 0.9988, Val Loss: 0.0121, Val Acc: 0.9946\n",
      "Epoch 12/50, Train Loss: 0.0035, Train Acc: 0.9991, Val Loss: 0.0125, Val Acc: 0.9946\n",
      "Epoch 13/50, Train Loss: 0.0034, Train Acc: 0.9993, Val Loss: 0.0091, Val Acc: 0.9964\n",
      "Epoch 14/50, Train Loss: 0.0031, Train Acc: 0.9994, Val Loss: 0.0082, Val Acc: 0.9964\n",
      "Epoch 15/50, Train Loss: 0.0025, Train Acc: 0.9994, Val Loss: 0.0087, Val Acc: 0.9964\n",
      "Epoch 16/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0096, Val Acc: 0.9970\n",
      "Epoch 17/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0106, Val Acc: 0.9958\n",
      "Epoch 18/50, Train Loss: 0.0026, Train Acc: 0.9994, Val Loss: 0.0242, Val Acc: 0.9940\n",
      "Epoch 19/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0082, Val Acc: 0.9976\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 3/5\n",
      "Epoch 1/50, Train Loss: 1.0545, Train Acc: 0.5406, Val Loss: 0.9535, Val Acc: 0.5294\n",
      "Epoch 2/50, Train Loss: 0.7433, Train Acc: 0.6230, Val Loss: 0.7214, Val Acc: 0.6241\n",
      "Epoch 3/50, Train Loss: 0.6095, Train Acc: 0.7185, Val Loss: 1.2357, Val Acc: 0.6739\n",
      "Epoch 4/50, Train Loss: 0.2063, Train Acc: 0.9352, Val Loss: 0.1517, Val Acc: 0.9371\n",
      "Epoch 5/50, Train Loss: 0.0820, Train Acc: 0.9766, Val Loss: 0.1564, Val Acc: 0.9556\n",
      "Epoch 6/50, Train Loss: 0.0552, Train Acc: 0.9843, Val Loss: 0.0145, Val Acc: 0.9934\n",
      "Epoch 7/50, Train Loss: 0.0393, Train Acc: 0.9880, Val Loss: 0.0384, Val Acc: 0.9922\n",
      "Epoch 8/50, Train Loss: 0.0608, Train Acc: 0.9868, Val Loss: 0.0517, Val Acc: 0.9868\n",
      "Epoch 9/50, Train Loss: 0.0981, Train Acc: 0.9766, Val Loss: 0.0324, Val Acc: 0.9922\n",
      "Epoch 10/50, Train Loss: 0.0161, Train Acc: 0.9961, Val Loss: 0.0776, Val Acc: 0.9832\n",
      "Epoch 11/50, Train Loss: 0.0081, Train Acc: 0.9978, Val Loss: 0.0070, Val Acc: 0.9976\n",
      "Epoch 12/50, Train Loss: 0.0031, Train Acc: 0.9993, Val Loss: 0.0118, Val Acc: 0.9958\n",
      "Epoch 13/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0058, Val Acc: 0.9982\n",
      "Epoch 14/50, Train Loss: 0.0022, Train Acc: 0.9994, Val Loss: 0.0053, Val Acc: 0.9976\n",
      "Epoch 15/50, Train Loss: 0.0032, Train Acc: 0.9993, Val Loss: 0.0114, Val Acc: 0.9976\n",
      "Epoch 16/50, Train Loss: 0.0030, Train Acc: 0.9994, Val Loss: 0.0061, Val Acc: 0.9976\n",
      "Epoch 17/50, Train Loss: 0.0028, Train Acc: 0.9994, Val Loss: 0.0116, Val Acc: 0.9982\n",
      "Epoch 18/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0201, Val Acc: 0.9952\n",
      "Epoch 19/50, Train Loss: 0.0024, Train Acc: 0.9994, Val Loss: 0.0103, Val Acc: 0.9982\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 4/5\n",
      "Epoch 1/50, Train Loss: 1.0041, Train Acc: 0.5474, Val Loss: 0.7251, Val Acc: 0.6271\n",
      "Epoch 2/50, Train Loss: 0.6397, Train Acc: 0.6813, Val Loss: 0.3311, Val Acc: 0.8777\n",
      "Epoch 3/50, Train Loss: 0.2472, Train Acc: 0.9267, Val Loss: 0.0271, Val Acc: 0.9928\n",
      "Epoch 4/50, Train Loss: 0.0777, Train Acc: 0.9772, Val Loss: 0.4777, Val Acc: 0.9209\n",
      "Epoch 5/50, Train Loss: 0.0727, Train Acc: 0.9793, Val Loss: 0.3439, Val Acc: 0.9335\n",
      "Epoch 6/50, Train Loss: 0.0311, Train Acc: 0.9906, Val Loss: 0.0133, Val Acc: 0.9982\n",
      "Epoch 7/50, Train Loss: 0.0444, Train Acc: 0.9901, Val Loss: 0.0350, Val Acc: 0.9910\n",
      "Epoch 8/50, Train Loss: 0.0459, Train Acc: 0.9861, Val Loss: 0.0507, Val Acc: 0.9808\n",
      "Epoch 9/50, Train Loss: 0.0191, Train Acc: 0.9954, Val Loss: 0.0038, Val Acc: 0.9982\n",
      "Epoch 10/50, Train Loss: 0.0456, Train Acc: 0.9900, Val Loss: 0.0254, Val Acc: 0.9946\n",
      "Epoch 11/50, Train Loss: 0.0045, Train Acc: 0.9988, Val Loss: 0.0216, Val Acc: 0.9952\n",
      "Epoch 12/50, Train Loss: 0.0042, Train Acc: 0.9991, Val Loss: 0.0094, Val Acc: 0.9976\n",
      "Epoch 13/50, Train Loss: 0.0031, Train Acc: 0.9993, Val Loss: 0.0118, Val Acc: 0.9970\n",
      "Epoch 14/50, Train Loss: 0.0030, Train Acc: 0.9993, Val Loss: 0.0147, Val Acc: 0.9970\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 5/5\n",
      "Epoch 1/50, Train Loss: 0.9352, Train Acc: 0.5418, Val Loss: 0.8635, Val Acc: 0.5600\n",
      "Epoch 2/50, Train Loss: 0.7476, Train Acc: 0.6320, Val Loss: 0.5918, Val Acc: 0.6936\n",
      "Epoch 3/50, Train Loss: 0.2934, Train Acc: 0.8817, Val Loss: 0.1267, Val Acc: 0.9598\n",
      "Epoch 4/50, Train Loss: 0.1048, Train Acc: 0.9681, Val Loss: 0.0271, Val Acc: 0.9928\n",
      "Epoch 5/50, Train Loss: 0.0709, Train Acc: 0.9789, Val Loss: 0.3264, Val Acc: 0.9359\n",
      "Epoch 6/50, Train Loss: 0.0444, Train Acc: 0.9873, Val Loss: 0.0373, Val Acc: 0.9868\n",
      "Epoch 7/50, Train Loss: 0.0465, Train Acc: 0.9862, Val Loss: 0.0270, Val Acc: 0.9904\n",
      "Epoch 8/50, Train Loss: 0.0662, Train Acc: 0.9823, Val Loss: 0.0245, Val Acc: 0.9952\n",
      "Epoch 9/50, Train Loss: 0.0278, Train Acc: 0.9933, Val Loss: 0.0909, Val Acc: 0.9832\n",
      "Epoch 10/50, Train Loss: 0.0409, Train Acc: 0.9901, Val Loss: 0.0381, Val Acc: 0.9934\n",
      "Epoch 11/50, Train Loss: 0.0043, Train Acc: 0.9990, Val Loss: 0.0210, Val Acc: 0.9964\n",
      "Epoch 12/50, Train Loss: 0.0036, Train Acc: 0.9991, Val Loss: 0.0140, Val Acc: 0.9964\n",
      "Epoch 13/50, Train Loss: 0.0025, Train Acc: 0.9994, Val Loss: 0.0173, Val Acc: 0.9964\n",
      "Epoch 14/50, Train Loss: 0.0022, Train Acc: 0.9993, Val Loss: 0.0238, Val Acc: 0.9964\n",
      "Epoch 15/50, Train Loss: 0.0018, Train Acc: 0.9994, Val Loss: 0.0151, Val Acc: 0.9958\n",
      "Epoch 16/50, Train Loss: 0.0024, Train Acc: 0.9994, Val Loss: 0.0222, Val Acc: 0.9964\n",
      "Epoch 17/50, Train Loss: 0.0017, Train Acc: 0.9996, Val Loss: 0.0262, Val Acc: 0.9964\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source performance: 99.72 99.73 99.72 99.73\n",
      "Target performance: 51.80 42.74 51.93 44.97\n",
      "\n",
      "bpsk: 82.21\n",
      "qpsk: 0.00\n",
      "16qam: 27.80\n",
      "8apsk: 97.71\n",
      "Epoch 1/50, Loss: 3.5108, Domain Loss: 1.6322, Class Loss: 1.8786\n",
      "Epoch 2/50, Loss: 2.0047, Domain Loss: 1.1342, Class Loss: 0.8705\n",
      "Epoch 3/50, Loss: 1.8810, Domain Loss: 1.1109, Class Loss: 0.7701\n",
      "Epoch 4/50, Loss: 2.3582, Domain Loss: 1.4098, Class Loss: 0.9483\n",
      "Epoch 5/50, Loss: 2.2578, Domain Loss: 1.4037, Class Loss: 0.8541\n",
      "Epoch 6/50, Loss: 1.9842, Domain Loss: 1.1851, Class Loss: 0.7990\n",
      "Epoch 7/50, Loss: 1.8825, Domain Loss: 1.1412, Class Loss: 0.7412\n",
      "Epoch 8/50, Loss: 1.7927, Domain Loss: 1.0518, Class Loss: 0.7409\n",
      "Epoch 9/50, Loss: 1.8719, Domain Loss: 1.1092, Class Loss: 0.7628\n",
      "Epoch 10/50, Loss: 1.8629, Domain Loss: 1.1063, Class Loss: 0.7566\n",
      "Epoch 11/50, Loss: 1.8915, Domain Loss: 1.1343, Class Loss: 0.7572\n",
      "Epoch 12/50, Loss: 2.1463, Domain Loss: 1.2285, Class Loss: 0.9178\n",
      "Epoch 13/50, Loss: 12.3131, Domain Loss: 9.6029, Class Loss: 2.7103\n",
      "Epoch 14/50, Loss: 26.4123, Domain Loss: 24.6183, Class Loss: 1.7940\n",
      "Epoch 15/50, Loss: 11.5135, Domain Loss: 10.1276, Class Loss: 1.3859\n",
      "Epoch 16/50, Loss: 7.1147, Domain Loss: 5.9325, Class Loss: 1.1822\n",
      "Epoch 17/50, Loss: 5.5884, Domain Loss: 4.6017, Class Loss: 0.9867\n",
      "Epoch 18/50, Loss: 4.1851, Domain Loss: 3.1731, Class Loss: 1.0119\n",
      "Epoch 19/50, Loss: 13.9628, Domain Loss: 12.8632, Class Loss: 1.0996\n",
      "Epoch 20/50, Loss: 90.2757, Domain Loss: 88.9166, Class Loss: 1.3592\n",
      "Epoch 21/50, Loss: 77.4743, Domain Loss: 75.6174, Class Loss: 1.8569\n",
      "Epoch 22/50, Loss: 35.0499, Domain Loss: 33.1398, Class Loss: 1.9101\n",
      "Epoch 23/50, Loss: 16.5092, Domain Loss: 14.6428, Class Loss: 1.8664\n",
      "Epoch 24/50, Loss: 11.7773, Domain Loss: 9.9464, Class Loss: 1.8309\n",
      "Epoch 25/50, Loss: 8.8065, Domain Loss: 7.0020, Class Loss: 1.8045\n",
      "Epoch 26/50, Loss: 10.8429, Domain Loss: 9.0611, Class Loss: 1.7819\n",
      "Epoch 27/50, Loss: 16.7509, Domain Loss: 14.9887, Class Loss: 1.7622\n",
      "Epoch 28/50, Loss: 14.8254, Domain Loss: 13.0848, Class Loss: 1.7405\n",
      "Epoch 29/50, Loss: 13.1874, Domain Loss: 11.4634, Class Loss: 1.7241\n",
      "Epoch 30/50, Loss: 12.6834, Domain Loss: 10.9715, Class Loss: 1.7119\n",
      "Epoch 31/50, Loss: 11.3283, Domain Loss: 9.6326, Class Loss: 1.6957\n",
      "Epoch 32/50, Loss: 10.1290, Domain Loss: 8.4459, Class Loss: 1.6831\n",
      "Epoch 33/50, Loss: 9.2217, Domain Loss: 7.5504, Class Loss: 1.6712\n",
      "Epoch 34/50, Loss: 7.7627, Domain Loss: 6.1028, Class Loss: 1.6600\n",
      "Epoch 35/50, Loss: 3.5394, Domain Loss: 1.8890, Class Loss: 1.6504\n",
      "Epoch 36/50, Loss: 2.9895, Domain Loss: 1.3492, Class Loss: 1.6403\n",
      "Epoch 37/50, Loss: 3.0102, Domain Loss: 1.3784, Class Loss: 1.6317\n",
      "Epoch 38/50, Loss: 2.8753, Domain Loss: 1.2542, Class Loss: 1.6211\n",
      "Epoch 39/50, Loss: 2.9769, Domain Loss: 1.3638, Class Loss: 1.6131\n",
      "Epoch 40/50, Loss: 3.0732, Domain Loss: 1.4678, Class Loss: 1.6054\n",
      "Epoch 41/50, Loss: 2.7955, Domain Loss: 1.1971, Class Loss: 1.5984\n",
      "Epoch 42/50, Loss: 2.8651, Domain Loss: 1.2714, Class Loss: 1.5937\n",
      "Epoch 43/50, Loss: 3.1294, Domain Loss: 1.5426, Class Loss: 1.5868\n",
      "Epoch 44/50, Loss: 3.1235, Domain Loss: 1.5455, Class Loss: 1.5780\n",
      "Epoch 45/50, Loss: 3.2342, Domain Loss: 1.6615, Class Loss: 1.5727\n",
      "Epoch 46/50, Loss: 2.7545, Domain Loss: 1.1864, Class Loss: 1.5681\n",
      "Epoch 47/50, Loss: 2.8477, Domain Loss: 1.2853, Class Loss: 1.5624\n",
      "Epoch 48/50, Loss: 2.6939, Domain Loss: 1.1368, Class Loss: 1.5571\n",
      "Epoch 49/50, Loss: 2.9160, Domain Loss: 1.3638, Class Loss: 1.5522\n",
      "Epoch 50/50, Loss: 3.0064, Domain Loss: 1.4589, Class Loss: 1.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.76\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.0852, Domain Loss: 2.0894, Class Loss: 1.9958\n",
      "Epoch 2/50, Loss: 2.2424, Domain Loss: 1.1171, Class Loss: 1.1254\n",
      "Epoch 3/50, Loss: 1.7672, Domain Loss: 0.9501, Class Loss: 0.8171\n",
      "Epoch 4/50, Loss: 1.7066, Domain Loss: 0.9135, Class Loss: 0.7930\n",
      "Epoch 5/50, Loss: 1.8304, Domain Loss: 0.9691, Class Loss: 0.8613\n",
      "Epoch 6/50, Loss: 1.7820, Domain Loss: 0.9804, Class Loss: 0.8016\n",
      "Epoch 7/50, Loss: 4.6445, Domain Loss: 3.4838, Class Loss: 1.1607\n",
      "Epoch 8/50, Loss: 14.7917, Domain Loss: 13.6771, Class Loss: 1.1146\n",
      "Epoch 9/50, Loss: 22.2298, Domain Loss: 20.3646, Class Loss: 1.8652\n",
      "Epoch 10/50, Loss: 17.9260, Domain Loss: 16.6425, Class Loss: 1.2835\n",
      "Epoch 11/50, Loss: 22.7420, Domain Loss: 21.2620, Class Loss: 1.4800\n",
      "Epoch 12/50, Loss: 17.7461, Domain Loss: 16.4895, Class Loss: 1.2566\n",
      "Epoch 13/50, Loss: 9.6830, Domain Loss: 8.8825, Class Loss: 0.8004\n",
      "Epoch 14/50, Loss: 16.6832, Domain Loss: 15.2972, Class Loss: 1.3860\n",
      "Epoch 15/50, Loss: 14.6568, Domain Loss: 13.7047, Class Loss: 0.9521\n",
      "Epoch 16/50, Loss: 11.5662, Domain Loss: 10.6151, Class Loss: 0.9511\n",
      "Epoch 17/50, Loss: 6.2329, Domain Loss: 5.3386, Class Loss: 0.8943\n",
      "Epoch 18/50, Loss: 4.8121, Domain Loss: 3.9719, Class Loss: 0.8403\n",
      "Epoch 19/50, Loss: 3.3220, Domain Loss: 2.5223, Class Loss: 0.7997\n",
      "Epoch 20/50, Loss: 2.1704, Domain Loss: 1.3924, Class Loss: 0.7780\n",
      "Epoch 21/50, Loss: 2.3887, Domain Loss: 1.6258, Class Loss: 0.7629\n",
      "Epoch 22/50, Loss: 2.5944, Domain Loss: 1.8400, Class Loss: 0.7544\n",
      "Epoch 23/50, Loss: 2.1125, Domain Loss: 1.3397, Class Loss: 0.7728\n",
      "Epoch 24/50, Loss: 2.6342, Domain Loss: 1.8502, Class Loss: 0.7839\n",
      "Epoch 25/50, Loss: 2.4365, Domain Loss: 1.6982, Class Loss: 0.7383\n",
      "Epoch 26/50, Loss: 2.4298, Domain Loss: 1.6415, Class Loss: 0.7883\n",
      "Epoch 27/50, Loss: 4.3466, Domain Loss: 3.5326, Class Loss: 0.8140\n",
      "Epoch 28/50, Loss: 3.7192, Domain Loss: 2.9617, Class Loss: 0.7574\n",
      "Epoch 29/50, Loss: 2.6039, Domain Loss: 1.8922, Class Loss: 0.7118\n",
      "Epoch 30/50, Loss: 2.2738, Domain Loss: 1.5432, Class Loss: 0.7307\n",
      "Epoch 31/50, Loss: 2.5934, Domain Loss: 1.8586, Class Loss: 0.7349\n",
      "Epoch 32/50, Loss: 2.6516, Domain Loss: 1.9294, Class Loss: 0.7222\n",
      "Epoch 33/50, Loss: 2.5812, Domain Loss: 1.8643, Class Loss: 0.7170\n",
      "Epoch 34/50, Loss: 2.8071, Domain Loss: 2.1064, Class Loss: 0.7007\n",
      "Epoch 35/50, Loss: 2.2953, Domain Loss: 1.6018, Class Loss: 0.6935\n",
      "Epoch 36/50, Loss: 2.6080, Domain Loss: 1.8760, Class Loss: 0.7321\n",
      "Epoch 37/50, Loss: 3.5095, Domain Loss: 2.5435, Class Loss: 0.9660\n",
      "Epoch 38/50, Loss: 2.5250, Domain Loss: 1.7426, Class Loss: 0.7825\n",
      "Epoch 39/50, Loss: 3.0901, Domain Loss: 2.3448, Class Loss: 0.7453\n",
      "Epoch 40/50, Loss: 3.0543, Domain Loss: 2.0177, Class Loss: 1.0365\n",
      "Epoch 41/50, Loss: 4.4830, Domain Loss: 3.6552, Class Loss: 0.8278\n",
      "Epoch 42/50, Loss: 6.7943, Domain Loss: 6.0612, Class Loss: 0.7331\n",
      "Epoch 43/50, Loss: 6.1123, Domain Loss: 5.1781, Class Loss: 0.9342\n",
      "Epoch 44/50, Loss: 6.9610, Domain Loss: 5.6343, Class Loss: 1.3267\n",
      "Epoch 45/50, Loss: 6.3680, Domain Loss: 5.3558, Class Loss: 1.0121\n",
      "Epoch 46/50, Loss: 5.2586, Domain Loss: 4.4306, Class Loss: 0.8280\n",
      "Epoch 47/50, Loss: 2.3299, Domain Loss: 1.4715, Class Loss: 0.8584\n",
      "Epoch 48/50, Loss: 2.1386, Domain Loss: 1.2728, Class Loss: 0.8658\n",
      "Epoch 49/50, Loss: 2.2017, Domain Loss: 1.4535, Class Loss: 0.7482\n",
      "Epoch 50/50, Loss: 2.2220, Domain Loss: 1.4663, Class Loss: 0.7557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.98\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.6535, Domain Loss: 1.9970, Class Loss: 1.6565\n",
      "Epoch 2/50, Loss: 2.0261, Domain Loss: 1.2106, Class Loss: 0.8155\n",
      "Epoch 3/50, Loss: 1.8327, Domain Loss: 1.0629, Class Loss: 0.7699\n",
      "Epoch 4/50, Loss: 2.2705, Domain Loss: 1.5150, Class Loss: 0.7555\n",
      "Epoch 5/50, Loss: 3.2842, Domain Loss: 2.3834, Class Loss: 0.9008\n",
      "Epoch 6/50, Loss: 2.4907, Domain Loss: 1.6885, Class Loss: 0.8022\n",
      "Epoch 7/50, Loss: 4.4755, Domain Loss: 3.5905, Class Loss: 0.8851\n",
      "Epoch 8/50, Loss: 5.1621, Domain Loss: 3.9079, Class Loss: 1.2542\n",
      "Epoch 9/50, Loss: 3.2932, Domain Loss: 2.4547, Class Loss: 0.8384\n",
      "Epoch 10/50, Loss: 3.4767, Domain Loss: 2.6549, Class Loss: 0.8217\n",
      "Epoch 11/50, Loss: 5.8339, Domain Loss: 4.9397, Class Loss: 0.8942\n",
      "Epoch 12/50, Loss: 12.7820, Domain Loss: 11.8474, Class Loss: 0.9345\n",
      "Epoch 13/50, Loss: 15.1817, Domain Loss: 14.2087, Class Loss: 0.9730\n",
      "Epoch 14/50, Loss: 6.8640, Domain Loss: 6.0146, Class Loss: 0.8494\n",
      "Epoch 15/50, Loss: 4.7391, Domain Loss: 3.9319, Class Loss: 0.8072\n",
      "Epoch 16/50, Loss: 3.0215, Domain Loss: 2.2063, Class Loss: 0.8153\n",
      "Epoch 17/50, Loss: 2.1234, Domain Loss: 1.3711, Class Loss: 0.7523\n",
      "Epoch 18/50, Loss: 3.3457, Domain Loss: 1.9832, Class Loss: 1.3624\n",
      "Epoch 19/50, Loss: 3.1701, Domain Loss: 1.9929, Class Loss: 1.1772\n",
      "Epoch 20/50, Loss: 2.7135, Domain Loss: 1.7898, Class Loss: 0.9237\n",
      "Epoch 21/50, Loss: 2.3899, Domain Loss: 1.5327, Class Loss: 0.8572\n",
      "Epoch 22/50, Loss: 2.2402, Domain Loss: 1.3167, Class Loss: 0.9236\n",
      "Epoch 23/50, Loss: 2.0803, Domain Loss: 1.3089, Class Loss: 0.7715\n",
      "Epoch 24/50, Loss: 2.2586, Domain Loss: 1.4331, Class Loss: 0.8255\n",
      "Epoch 25/50, Loss: 2.7836, Domain Loss: 1.5774, Class Loss: 1.2062\n",
      "Epoch 26/50, Loss: 2.8915, Domain Loss: 1.9835, Class Loss: 0.9080\n",
      "Epoch 27/50, Loss: 3.3238, Domain Loss: 2.2725, Class Loss: 1.0514\n",
      "Epoch 28/50, Loss: 1.8082, Domain Loss: 1.0509, Class Loss: 0.7574\n",
      "Epoch 29/50, Loss: 1.7216, Domain Loss: 0.9971, Class Loss: 0.7244\n",
      "Epoch 30/50, Loss: 1.7125, Domain Loss: 0.9862, Class Loss: 0.7263\n",
      "Epoch 31/50, Loss: 1.6863, Domain Loss: 0.9556, Class Loss: 0.7306\n",
      "Epoch 32/50, Loss: 1.6745, Domain Loss: 0.9491, Class Loss: 0.7254\n",
      "Epoch 33/50, Loss: 1.6702, Domain Loss: 0.9627, Class Loss: 0.7075\n",
      "Epoch 34/50, Loss: 1.7151, Domain Loss: 0.9746, Class Loss: 0.7405\n",
      "Epoch 35/50, Loss: 1.7014, Domain Loss: 0.9112, Class Loss: 0.7902\n",
      "Epoch 36/50, Loss: 1.6611, Domain Loss: 0.9327, Class Loss: 0.7284\n",
      "Epoch 37/50, Loss: 1.6530, Domain Loss: 0.9531, Class Loss: 0.6999\n",
      "Epoch 38/50, Loss: 1.6257, Domain Loss: 0.9428, Class Loss: 0.6829\n",
      "Epoch 39/50, Loss: 1.7121, Domain Loss: 0.9211, Class Loss: 0.7910\n",
      "Epoch 40/50, Loss: 1.6541, Domain Loss: 0.9316, Class Loss: 0.7225\n",
      "Epoch 41/50, Loss: 1.6363, Domain Loss: 0.9406, Class Loss: 0.6958\n",
      "Epoch 42/50, Loss: 1.6014, Domain Loss: 0.9445, Class Loss: 0.6569\n",
      "Epoch 43/50, Loss: 1.6898, Domain Loss: 0.9692, Class Loss: 0.7207\n",
      "Epoch 44/50, Loss: 1.5947, Domain Loss: 0.9229, Class Loss: 0.6718\n",
      "Epoch 45/50, Loss: 1.5794, Domain Loss: 0.9671, Class Loss: 0.6123\n",
      "Epoch 46/50, Loss: 1.7002, Domain Loss: 0.9887, Class Loss: 0.7114\n",
      "Epoch 47/50, Loss: 1.4570, Domain Loss: 0.8924, Class Loss: 0.5646\n",
      "Epoch 48/50, Loss: 1.4095, Domain Loss: 0.9012, Class Loss: 0.5083\n",
      "Epoch 49/50, Loss: 1.3625, Domain Loss: 0.9060, Class Loss: 0.4565\n",
      "Epoch 50/50, Loss: 1.5312, Domain Loss: 0.9796, Class Loss: 0.5516\n",
      "43.11\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.6121, Domain Loss: 1.8101, Class Loss: 1.8020\n",
      "Epoch 2/50, Loss: 2.2761, Domain Loss: 1.3309, Class Loss: 0.9452\n",
      "Epoch 3/50, Loss: 2.0691, Domain Loss: 1.2587, Class Loss: 0.8104\n",
      "Epoch 4/50, Loss: 1.9187, Domain Loss: 1.1543, Class Loss: 0.7644\n",
      "Epoch 5/50, Loss: 1.8661, Domain Loss: 1.1154, Class Loss: 0.7507\n",
      "Epoch 6/50, Loss: 1.8424, Domain Loss: 1.1204, Class Loss: 0.7220\n",
      "Epoch 7/50, Loss: 1.8510, Domain Loss: 1.1061, Class Loss: 0.7449\n",
      "Epoch 8/50, Loss: 2.4763, Domain Loss: 1.4233, Class Loss: 1.0529\n",
      "Epoch 9/50, Loss: 1.8393, Domain Loss: 1.0014, Class Loss: 0.8380\n",
      "Epoch 10/50, Loss: 2.4549, Domain Loss: 1.6648, Class Loss: 0.7901\n",
      "Epoch 11/50, Loss: 21.7622, Domain Loss: 19.3250, Class Loss: 2.4372\n",
      "Epoch 12/50, Loss: 25.5207, Domain Loss: 23.5657, Class Loss: 1.9550\n",
      "Epoch 13/50, Loss: 67.3315, Domain Loss: 65.2141, Class Loss: 2.1174\n",
      "Epoch 14/50, Loss: 40.8021, Domain Loss: 39.3588, Class Loss: 1.4433\n",
      "Epoch 15/50, Loss: 36.0915, Domain Loss: 34.6955, Class Loss: 1.3960\n",
      "Epoch 16/50, Loss: 13.4148, Domain Loss: 12.0260, Class Loss: 1.3887\n",
      "Epoch 17/50, Loss: 18.0980, Domain Loss: 16.7112, Class Loss: 1.3868\n",
      "Epoch 18/50, Loss: 15.1736, Domain Loss: 13.7839, Class Loss: 1.3897\n",
      "Epoch 19/50, Loss: 39.6706, Domain Loss: 38.2903, Class Loss: 1.3804\n",
      "Epoch 20/50, Loss: 33.9418, Domain Loss: 32.5543, Class Loss: 1.3876\n",
      "Epoch 21/50, Loss: 24.8803, Domain Loss: 23.5096, Class Loss: 1.3707\n",
      "Epoch 22/50, Loss: 16.3924, Domain Loss: 15.0018, Class Loss: 1.3906\n",
      "Epoch 23/50, Loss: 17.4933, Domain Loss: 16.0945, Class Loss: 1.3988\n",
      "Epoch 24/50, Loss: 16.4199, Domain Loss: 15.0287, Class Loss: 1.3912\n",
      "Epoch 25/50, Loss: 15.7882, Domain Loss: 14.4058, Class Loss: 1.3824\n",
      "Epoch 26/50, Loss: 15.0635, Domain Loss: 13.6897, Class Loss: 1.3738\n",
      "Epoch 27/50, Loss: 14.3960, Domain Loss: 13.0476, Class Loss: 1.3485\n",
      "Epoch 28/50, Loss: 13.8383, Domain Loss: 12.4854, Class Loss: 1.3529\n",
      "Epoch 29/50, Loss: 13.4739, Domain Loss: 12.0577, Class Loss: 1.4162\n",
      "Epoch 30/50, Loss: 13.0851, Domain Loss: 11.7041, Class Loss: 1.3810\n",
      "Epoch 31/50, Loss: 12.7098, Domain Loss: 11.3552, Class Loss: 1.3546\n",
      "Epoch 32/50, Loss: 12.3422, Domain Loss: 11.0073, Class Loss: 1.3349\n",
      "Epoch 33/50, Loss: 11.7097, Domain Loss: 10.3359, Class Loss: 1.3738\n",
      "Epoch 34/50, Loss: 11.4122, Domain Loss: 10.0714, Class Loss: 1.3408\n",
      "Epoch 35/50, Loss: 11.1693, Domain Loss: 9.8290, Class Loss: 1.3402\n",
      "Epoch 36/50, Loss: 11.0855, Domain Loss: 9.8051, Class Loss: 1.2804\n",
      "Epoch 37/50, Loss: 10.3985, Domain Loss: 9.0222, Class Loss: 1.3763\n",
      "Epoch 38/50, Loss: 7.0267, Domain Loss: 5.6991, Class Loss: 1.3276\n",
      "Epoch 39/50, Loss: 6.4614, Domain Loss: 5.0117, Class Loss: 1.4497\n",
      "Epoch 40/50, Loss: 5.1955, Domain Loss: 3.8332, Class Loss: 1.3623\n",
      "Epoch 41/50, Loss: 4.4566, Domain Loss: 3.1612, Class Loss: 1.2954\n",
      "Epoch 42/50, Loss: 3.4467, Domain Loss: 2.1678, Class Loss: 1.2790\n",
      "Epoch 43/50, Loss: 3.5086, Domain Loss: 2.2324, Class Loss: 1.2762\n",
      "Epoch 44/50, Loss: 7.1712, Domain Loss: 5.9603, Class Loss: 1.2109\n",
      "Epoch 45/50, Loss: 6.3670, Domain Loss: 5.1908, Class Loss: 1.1762\n",
      "Epoch 46/50, Loss: 5.4514, Domain Loss: 4.2491, Class Loss: 1.2023\n",
      "Epoch 47/50, Loss: 4.2376, Domain Loss: 3.0403, Class Loss: 1.1973\n",
      "Epoch 48/50, Loss: 2.9288, Domain Loss: 1.7904, Class Loss: 1.1384\n",
      "Epoch 49/50, Loss: 2.8093, Domain Loss: 1.7019, Class Loss: 1.1074\n",
      "Epoch 50/50, Loss: 3.4237, Domain Loss: 2.0374, Class Loss: 1.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.40\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.7812, Domain Loss: 1.9874, Class Loss: 1.7938\n",
      "Epoch 2/50, Loss: 3.0097, Domain Loss: 2.0786, Class Loss: 0.9311\n",
      "Epoch 3/50, Loss: 3.7184, Domain Loss: 2.7218, Class Loss: 0.9966\n",
      "Epoch 4/50, Loss: 2.2141, Domain Loss: 1.3645, Class Loss: 0.8496\n",
      "Epoch 5/50, Loss: 1.9357, Domain Loss: 1.1522, Class Loss: 0.7835\n",
      "Epoch 6/50, Loss: 1.8070, Domain Loss: 1.0698, Class Loss: 0.7373\n",
      "Epoch 7/50, Loss: 1.7918, Domain Loss: 1.0694, Class Loss: 0.7224\n",
      "Epoch 8/50, Loss: 1.7776, Domain Loss: 1.0605, Class Loss: 0.7172\n",
      "Epoch 9/50, Loss: 1.7489, Domain Loss: 1.0220, Class Loss: 0.7270\n",
      "Epoch 10/50, Loss: 1.8368, Domain Loss: 1.0452, Class Loss: 0.7916\n",
      "Epoch 11/50, Loss: 1.7343, Domain Loss: 0.9935, Class Loss: 0.7408\n",
      "Epoch 12/50, Loss: 2.0299, Domain Loss: 1.1315, Class Loss: 0.8984\n",
      "Epoch 13/50, Loss: 1.8963, Domain Loss: 1.1078, Class Loss: 0.7885\n",
      "Epoch 14/50, Loss: 1.7289, Domain Loss: 0.9961, Class Loss: 0.7328\n",
      "Epoch 15/50, Loss: 1.9703, Domain Loss: 1.1301, Class Loss: 0.8401\n",
      "Epoch 16/50, Loss: 2.2215, Domain Loss: 1.2902, Class Loss: 0.9313\n",
      "Epoch 17/50, Loss: 1.9652, Domain Loss: 1.1847, Class Loss: 0.7805\n",
      "Epoch 18/50, Loss: 2.1532, Domain Loss: 1.3142, Class Loss: 0.8389\n",
      "Epoch 19/50, Loss: 2.1621, Domain Loss: 1.3978, Class Loss: 0.7643\n",
      "Epoch 20/50, Loss: 2.0345, Domain Loss: 1.3783, Class Loss: 0.6561\n",
      "Epoch 21/50, Loss: 1.9240, Domain Loss: 1.3442, Class Loss: 0.5798\n",
      "Epoch 22/50, Loss: 1.7722, Domain Loss: 1.2495, Class Loss: 0.5227\n",
      "Epoch 23/50, Loss: 1.5468, Domain Loss: 1.1426, Class Loss: 0.4041\n",
      "Epoch 24/50, Loss: 1.4203, Domain Loss: 1.1032, Class Loss: 0.3171\n",
      "Epoch 25/50, Loss: 1.5020, Domain Loss: 1.1644, Class Loss: 0.3376\n",
      "Epoch 26/50, Loss: 1.4095, Domain Loss: 1.1852, Class Loss: 0.2242\n",
      "Epoch 27/50, Loss: 1.4878, Domain Loss: 1.2780, Class Loss: 0.2099\n",
      "Epoch 28/50, Loss: 1.7214, Domain Loss: 1.6277, Class Loss: 0.0937\n",
      "Epoch 29/50, Loss: 1.6786, Domain Loss: 1.3921, Class Loss: 0.2866\n",
      "Epoch 30/50, Loss: 1.4641, Domain Loss: 1.3606, Class Loss: 0.1035\n",
      "Epoch 31/50, Loss: 1.1190, Domain Loss: 1.0087, Class Loss: 0.1103\n",
      "Epoch 32/50, Loss: 1.2957, Domain Loss: 1.1206, Class Loss: 0.1751\n",
      "Epoch 33/50, Loss: 1.2950, Domain Loss: 1.1890, Class Loss: 0.1060\n",
      "Epoch 34/50, Loss: 1.3113, Domain Loss: 1.2031, Class Loss: 0.1082\n",
      "Epoch 35/50, Loss: 1.4030, Domain Loss: 1.2641, Class Loss: 0.1389\n",
      "Epoch 36/50, Loss: 1.5647, Domain Loss: 1.3769, Class Loss: 0.1877\n",
      "Epoch 37/50, Loss: 1.4284, Domain Loss: 1.3322, Class Loss: 0.0962\n",
      "Epoch 38/50, Loss: 1.4781, Domain Loss: 1.2582, Class Loss: 0.2199\n",
      "Epoch 39/50, Loss: 1.5175, Domain Loss: 1.3710, Class Loss: 0.1465\n",
      "Epoch 40/50, Loss: 1.4423, Domain Loss: 1.3976, Class Loss: 0.0447\n",
      "Epoch 41/50, Loss: 1.4409, Domain Loss: 1.4120, Class Loss: 0.0289\n",
      "Epoch 42/50, Loss: 1.2939, Domain Loss: 1.1694, Class Loss: 0.1245\n",
      "Epoch 43/50, Loss: 1.2612, Domain Loss: 1.1353, Class Loss: 0.1259\n",
      "Epoch 44/50, Loss: 1.2378, Domain Loss: 1.1804, Class Loss: 0.0574\n",
      "Epoch 45/50, Loss: 1.4650, Domain Loss: 1.3804, Class Loss: 0.0846\n",
      "Epoch 46/50, Loss: 1.4495, Domain Loss: 1.4012, Class Loss: 0.0482\n",
      "Epoch 47/50, Loss: 1.4280, Domain Loss: 1.3976, Class Loss: 0.0304\n",
      "Epoch 48/50, Loss: 1.4181, Domain Loss: 1.3947, Class Loss: 0.0233\n",
      "Epoch 49/50, Loss: 1.4117, Domain Loss: 1.3926, Class Loss: 0.0191\n",
      "Epoch 50/50, Loss: 1.4077, Domain Loss: 1.3909, Class Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.79\n",
      "\n",
      "\n",
      "Source performance:\n",
      "57.30 48.34 57.76 50.17 \n",
      "Target performance:\n",
      "39.81 31.06 40.24 28.30 \n",
      "\n",
      "Per-class target performance: 79.90 47.75 21.78 11.52 \n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 3.2515, Discrepancy Loss: 0.1043\n",
      "Epoch [2/50], Class Loss: 1.5065, Discrepancy Loss: 0.1330\n",
      "Epoch [3/50], Class Loss: 1.2834, Discrepancy Loss: 0.1344\n",
      "Epoch [4/50], Class Loss: 0.8386, Discrepancy Loss: 0.1384\n",
      "Epoch [5/50], Class Loss: 0.2575, Discrepancy Loss: 0.1074\n",
      "Epoch [6/50], Class Loss: 0.1522, Discrepancy Loss: 0.0963\n",
      "Epoch [7/50], Class Loss: 0.1122, Discrepancy Loss: 0.0990\n",
      "Epoch [8/50], Class Loss: 0.1231, Discrepancy Loss: 0.0971\n",
      "Epoch [9/50], Class Loss: 0.0920, Discrepancy Loss: 0.0966\n",
      "Epoch [10/50], Class Loss: 0.1317, Discrepancy Loss: 0.1034\n",
      "Epoch [11/50], Class Loss: 0.1008, Discrepancy Loss: 0.0963\n",
      "Epoch [12/50], Class Loss: 0.0431, Discrepancy Loss: 0.0805\n",
      "Epoch [13/50], Class Loss: 0.0370, Discrepancy Loss: 0.0763\n",
      "Epoch [14/50], Class Loss: 0.0437, Discrepancy Loss: 0.0748\n",
      "Epoch [15/50], Class Loss: 0.0348, Discrepancy Loss: 0.0799\n",
      "Epoch [16/50], Class Loss: 0.0287, Discrepancy Loss: 0.0788\n",
      "Epoch [17/50], Class Loss: 0.0469, Discrepancy Loss: 0.0854\n",
      "Epoch [18/50], Class Loss: 0.0432, Discrepancy Loss: 0.0842\n",
      "Epoch [19/50], Class Loss: 0.0460, Discrepancy Loss: 0.0864\n",
      "Epoch [20/50], Class Loss: 0.0452, Discrepancy Loss: 0.0735\n",
      "Epoch [21/50], Class Loss: 0.0465, Discrepancy Loss: 0.0862\n",
      "Epoch [22/50], Class Loss: 0.0291, Discrepancy Loss: 0.0815\n",
      "Epoch [23/50], Class Loss: 0.0344, Discrepancy Loss: 0.0874\n",
      "Epoch [24/50], Class Loss: 0.0280, Discrepancy Loss: 0.0873\n",
      "Epoch [25/50], Class Loss: 0.0381, Discrepancy Loss: 0.0921\n",
      "Epoch [26/50], Class Loss: 0.0301, Discrepancy Loss: 0.0983\n",
      "Epoch [27/50], Class Loss: 0.0318, Discrepancy Loss: 0.0976\n",
      "Epoch [28/50], Class Loss: 0.0299, Discrepancy Loss: 0.0984\n",
      "Epoch [29/50], Class Loss: 0.0303, Discrepancy Loss: 0.0996\n",
      "Epoch [30/50], Class Loss: 0.0325, Discrepancy Loss: 0.0976\n",
      "Epoch [31/50], Class Loss: 0.0392, Discrepancy Loss: 0.0887\n",
      "Epoch [32/50], Class Loss: 0.0366, Discrepancy Loss: 0.0930\n",
      "Epoch [33/50], Class Loss: 0.0306, Discrepancy Loss: 0.0923\n",
      "Epoch [34/50], Class Loss: 0.0309, Discrepancy Loss: 0.0883\n",
      "Epoch [35/50], Class Loss: 0.0645, Discrepancy Loss: 0.0878\n",
      "Epoch [36/50], Class Loss: 0.0321, Discrepancy Loss: 0.0940\n",
      "Epoch [37/50], Class Loss: 0.0281, Discrepancy Loss: 0.0898\n",
      "Epoch [38/50], Class Loss: 0.0274, Discrepancy Loss: 0.0884\n",
      "Epoch [39/50], Class Loss: 0.0300, Discrepancy Loss: 0.0920\n",
      "Epoch [40/50], Class Loss: 0.0379, Discrepancy Loss: 0.0925\n",
      "Epoch [41/50], Class Loss: 0.0394, Discrepancy Loss: 0.0925\n",
      "Epoch [42/50], Class Loss: 0.0286, Discrepancy Loss: 0.0882\n",
      "Epoch [43/50], Class Loss: 0.0357, Discrepancy Loss: 0.0914\n",
      "Epoch [44/50], Class Loss: 0.0287, Discrepancy Loss: 0.0940\n",
      "Epoch [45/50], Class Loss: 0.0256, Discrepancy Loss: 0.0928\n",
      "Epoch [46/50], Class Loss: 0.0333, Discrepancy Loss: 0.0903\n",
      "Epoch [47/50], Class Loss: 0.0359, Discrepancy Loss: 0.0889\n",
      "Epoch [48/50], Class Loss: 0.0334, Discrepancy Loss: 0.0870\n",
      "Epoch [49/50], Class Loss: 0.0320, Discrepancy Loss: 0.0858\n",
      "Epoch [50/50], Class Loss: 0.0322, Discrepancy Loss: 0.0890\n",
      "Source Domain Performance - Accuracy: 89.87%, Precision: 91.83%, Recall: 89.99%, F1 Score: 89.76%\n",
      "Target Domain Performance - Accuracy: 66.67%, Precision: 78.03%, Recall: 66.55%, F1 Score: 62.34%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 3.1447, Discrepancy Loss: 0.1052\n",
      "Epoch [2/50], Class Loss: 1.7799, Discrepancy Loss: 0.1380\n",
      "Epoch [3/50], Class Loss: 1.2801, Discrepancy Loss: 0.1387\n",
      "Epoch [4/50], Class Loss: 1.0987, Discrepancy Loss: 0.1425\n",
      "Epoch [5/50], Class Loss: 0.8151, Discrepancy Loss: 0.1347\n",
      "Epoch [6/50], Class Loss: 0.2514, Discrepancy Loss: 0.1005\n",
      "Epoch [7/50], Class Loss: 0.1300, Discrepancy Loss: 0.0941\n",
      "Epoch [8/50], Class Loss: 0.1047, Discrepancy Loss: 0.1091\n",
      "Epoch [9/50], Class Loss: 0.5842, Discrepancy Loss: 0.1246\n",
      "Epoch [10/50], Class Loss: 0.2202, Discrepancy Loss: 0.0822\n",
      "Epoch [11/50], Class Loss: 0.0980, Discrepancy Loss: 0.0972\n",
      "Epoch [12/50], Class Loss: 0.0816, Discrepancy Loss: 0.1043\n",
      "Epoch [13/50], Class Loss: 0.0762, Discrepancy Loss: 0.1011\n",
      "Epoch [14/50], Class Loss: 0.0601, Discrepancy Loss: 0.0888\n",
      "Epoch [15/50], Class Loss: 0.0671, Discrepancy Loss: 0.0976\n",
      "Epoch [16/50], Class Loss: 0.0735, Discrepancy Loss: 0.0986\n",
      "Epoch [17/50], Class Loss: 0.0746, Discrepancy Loss: 0.0953\n",
      "Epoch [18/50], Class Loss: 0.0501, Discrepancy Loss: 0.0862\n",
      "Epoch [19/50], Class Loss: 0.0652, Discrepancy Loss: 0.0798\n",
      "Epoch [20/50], Class Loss: 0.0516, Discrepancy Loss: 0.0911\n",
      "Epoch [21/50], Class Loss: 0.0481, Discrepancy Loss: 0.0947\n",
      "Epoch [22/50], Class Loss: 0.0470, Discrepancy Loss: 0.0916\n",
      "Epoch [23/50], Class Loss: 0.0381, Discrepancy Loss: 0.0937\n",
      "Epoch [24/50], Class Loss: 0.0463, Discrepancy Loss: 0.0903\n",
      "Epoch [25/50], Class Loss: 0.0397, Discrepancy Loss: 0.0962\n",
      "Epoch [26/50], Class Loss: 0.0416, Discrepancy Loss: 0.0862\n",
      "Epoch [27/50], Class Loss: 0.0389, Discrepancy Loss: 0.0826\n",
      "Epoch [28/50], Class Loss: 0.0407, Discrepancy Loss: 0.0832\n",
      "Epoch [29/50], Class Loss: 0.0456, Discrepancy Loss: 0.0870\n",
      "Epoch [30/50], Class Loss: 0.0370, Discrepancy Loss: 0.0785\n",
      "Epoch [31/50], Class Loss: 0.0380, Discrepancy Loss: 0.0869\n",
      "Epoch [32/50], Class Loss: 0.0415, Discrepancy Loss: 0.0829\n",
      "Epoch [33/50], Class Loss: 0.0386, Discrepancy Loss: 0.0832\n",
      "Epoch [34/50], Class Loss: 0.0304, Discrepancy Loss: 0.0895\n",
      "Epoch [35/50], Class Loss: 0.0378, Discrepancy Loss: 0.0829\n",
      "Epoch [36/50], Class Loss: 0.0325, Discrepancy Loss: 0.0843\n",
      "Epoch [37/50], Class Loss: 0.0354, Discrepancy Loss: 0.0834\n",
      "Epoch [38/50], Class Loss: 0.0316, Discrepancy Loss: 0.0795\n",
      "Epoch [39/50], Class Loss: 0.0394, Discrepancy Loss: 0.0854\n",
      "Epoch [40/50], Class Loss: 0.0383, Discrepancy Loss: 0.0861\n",
      "Epoch [41/50], Class Loss: 0.0343, Discrepancy Loss: 0.0841\n",
      "Epoch [42/50], Class Loss: 0.0437, Discrepancy Loss: 0.0860\n",
      "Epoch [43/50], Class Loss: 0.0348, Discrepancy Loss: 0.0813\n",
      "Epoch [44/50], Class Loss: 0.0356, Discrepancy Loss: 0.0868\n",
      "Epoch [45/50], Class Loss: 0.0405, Discrepancy Loss: 0.0808\n",
      "Epoch [46/50], Class Loss: 0.0355, Discrepancy Loss: 0.0843\n",
      "Epoch [47/50], Class Loss: 0.0337, Discrepancy Loss: 0.0851\n",
      "Epoch [48/50], Class Loss: 0.0395, Discrepancy Loss: 0.0869\n",
      "Epoch [49/50], Class Loss: 0.0342, Discrepancy Loss: 0.0826\n",
      "Epoch [50/50], Class Loss: 0.0555, Discrepancy Loss: 0.0883\n",
      "Source Domain Performance - Accuracy: 96.82%, Precision: 96.99%, Recall: 96.85%, F1 Score: 96.80%\n",
      "Target Domain Performance - Accuracy: 63.01%, Precision: 69.53%, Recall: 62.92%, F1 Score: 62.78%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 3.6675, Discrepancy Loss: 0.0910\n",
      "Epoch [2/50], Class Loss: 1.8061, Discrepancy Loss: 0.1311\n",
      "Epoch [3/50], Class Loss: 1.3466, Discrepancy Loss: 0.1343\n",
      "Epoch [4/50], Class Loss: 1.2209, Discrepancy Loss: 0.1374\n",
      "Epoch [5/50], Class Loss: 1.1770, Discrepancy Loss: 0.1443\n",
      "Epoch [6/50], Class Loss: 1.1450, Discrepancy Loss: 0.1518\n",
      "Epoch [7/50], Class Loss: 1.0618, Discrepancy Loss: 0.1360\n",
      "Epoch [8/50], Class Loss: 1.0228, Discrepancy Loss: 0.1425\n",
      "Epoch [9/50], Class Loss: 0.9888, Discrepancy Loss: 0.1402\n",
      "Epoch [10/50], Class Loss: 0.9384, Discrepancy Loss: 0.1280\n",
      "Epoch [11/50], Class Loss: 0.9084, Discrepancy Loss: 0.1401\n",
      "Epoch [12/50], Class Loss: 0.8466, Discrepancy Loss: 0.1278\n",
      "Epoch [13/50], Class Loss: 0.7633, Discrepancy Loss: 0.1283\n",
      "Epoch [14/50], Class Loss: 0.5864, Discrepancy Loss: 0.1293\n",
      "Epoch [15/50], Class Loss: 0.4783, Discrepancy Loss: 0.1256\n",
      "Epoch [16/50], Class Loss: 0.4197, Discrepancy Loss: 0.1320\n",
      "Epoch [17/50], Class Loss: 0.3116, Discrepancy Loss: 0.1075\n",
      "Epoch [18/50], Class Loss: 0.2598, Discrepancy Loss: 0.0959\n",
      "Epoch [19/50], Class Loss: 0.2155, Discrepancy Loss: 0.1275\n",
      "Epoch [20/50], Class Loss: 0.1293, Discrepancy Loss: 0.1242\n",
      "Epoch [21/50], Class Loss: 0.1315, Discrepancy Loss: 0.1228\n",
      "Epoch [22/50], Class Loss: 0.1231, Discrepancy Loss: 0.1223\n",
      "Epoch [23/50], Class Loss: 0.1151, Discrepancy Loss: 0.1188\n",
      "Epoch [24/50], Class Loss: 0.1012, Discrepancy Loss: 0.1133\n",
      "Epoch [25/50], Class Loss: 0.1301, Discrepancy Loss: 0.1186\n",
      "Epoch [26/50], Class Loss: 0.1407, Discrepancy Loss: 0.1191\n",
      "Epoch [27/50], Class Loss: 0.0889, Discrepancy Loss: 0.1216\n",
      "Epoch [28/50], Class Loss: 0.1034, Discrepancy Loss: 0.1253\n",
      "Epoch [29/50], Class Loss: 0.1120, Discrepancy Loss: 0.1267\n",
      "Epoch [30/50], Class Loss: 0.1005, Discrepancy Loss: 0.1232\n",
      "Epoch [31/50], Class Loss: 0.1015, Discrepancy Loss: 0.1314\n",
      "Epoch [32/50], Class Loss: 0.1220, Discrepancy Loss: 0.1301\n",
      "Epoch [33/50], Class Loss: 0.1019, Discrepancy Loss: 0.1282\n",
      "Epoch [34/50], Class Loss: 0.0815, Discrepancy Loss: 0.1279\n",
      "Epoch [35/50], Class Loss: 0.1038, Discrepancy Loss: 0.1236\n",
      "Epoch [36/50], Class Loss: 0.0787, Discrepancy Loss: 0.1315\n",
      "Epoch [37/50], Class Loss: 0.1061, Discrepancy Loss: 0.1205\n",
      "Epoch [38/50], Class Loss: 0.0849, Discrepancy Loss: 0.1253\n",
      "Epoch [39/50], Class Loss: 0.0823, Discrepancy Loss: 0.1303\n",
      "Epoch [40/50], Class Loss: 0.0822, Discrepancy Loss: 0.1270\n",
      "Epoch [41/50], Class Loss: 0.1002, Discrepancy Loss: 0.1266\n",
      "Epoch [42/50], Class Loss: 0.0912, Discrepancy Loss: 0.1296\n",
      "Epoch [43/50], Class Loss: 0.0814, Discrepancy Loss: 0.1396\n",
      "Epoch [44/50], Class Loss: 0.1008, Discrepancy Loss: 0.1204\n",
      "Epoch [45/50], Class Loss: 0.0943, Discrepancy Loss: 0.1263\n",
      "Epoch [46/50], Class Loss: 0.0822, Discrepancy Loss: 0.1209\n",
      "Epoch [47/50], Class Loss: 0.0925, Discrepancy Loss: 0.1230\n",
      "Epoch [48/50], Class Loss: 0.0871, Discrepancy Loss: 0.1214\n",
      "Epoch [49/50], Class Loss: 0.0869, Discrepancy Loss: 0.1306\n",
      "Epoch [50/50], Class Loss: 0.1051, Discrepancy Loss: 0.1342\n",
      "Source Domain Performance - Accuracy: 91.31%, Precision: 92.90%, Recall: 91.62%, F1 Score: 91.36%\n",
      "Target Domain Performance - Accuracy: 61.99%, Precision: 71.53%, Recall: 61.94%, F1 Score: 56.31%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 3.1623, Discrepancy Loss: 0.1224\n",
      "Epoch [2/50], Class Loss: 1.5510, Discrepancy Loss: 0.1294\n",
      "Epoch [3/50], Class Loss: 1.2622, Discrepancy Loss: 0.1375\n",
      "Epoch [4/50], Class Loss: 1.1554, Discrepancy Loss: 0.1303\n",
      "Epoch [5/50], Class Loss: 0.5385, Discrepancy Loss: 0.1175\n",
      "Epoch [6/50], Class Loss: 0.2009, Discrepancy Loss: 0.0903\n",
      "Epoch [7/50], Class Loss: 0.2044, Discrepancy Loss: 0.0861\n",
      "Epoch [8/50], Class Loss: 0.0972, Discrepancy Loss: 0.0867\n",
      "Epoch [9/50], Class Loss: 0.1373, Discrepancy Loss: 0.1242\n",
      "Epoch [10/50], Class Loss: 0.1154, Discrepancy Loss: 0.1043\n",
      "Epoch [11/50], Class Loss: 0.0631, Discrepancy Loss: 0.1031\n",
      "Epoch [12/50], Class Loss: 0.0371, Discrepancy Loss: 0.0998\n",
      "Epoch [13/50], Class Loss: 0.0415, Discrepancy Loss: 0.0966\n",
      "Epoch [14/50], Class Loss: 0.0449, Discrepancy Loss: 0.0937\n",
      "Epoch [15/50], Class Loss: 0.0397, Discrepancy Loss: 0.0981\n",
      "Epoch [16/50], Class Loss: 0.0482, Discrepancy Loss: 0.0922\n",
      "Epoch [17/50], Class Loss: 0.0405, Discrepancy Loss: 0.0968\n",
      "Epoch [18/50], Class Loss: 0.0334, Discrepancy Loss: 0.1058\n",
      "Epoch [19/50], Class Loss: 0.0461, Discrepancy Loss: 0.1008\n",
      "Epoch [20/50], Class Loss: 0.0465, Discrepancy Loss: 0.1124\n",
      "Epoch [21/50], Class Loss: 0.0259, Discrepancy Loss: 0.1057\n",
      "Epoch [22/50], Class Loss: 0.0337, Discrepancy Loss: 0.0999\n",
      "Epoch [23/50], Class Loss: 0.0279, Discrepancy Loss: 0.1026\n",
      "Epoch [24/50], Class Loss: 0.0358, Discrepancy Loss: 0.0941\n",
      "Epoch [25/50], Class Loss: 0.0785, Discrepancy Loss: 0.0940\n",
      "Epoch [26/50], Class Loss: 0.0343, Discrepancy Loss: 0.1010\n",
      "Epoch [27/50], Class Loss: 0.0313, Discrepancy Loss: 0.0966\n",
      "Epoch [28/50], Class Loss: 0.0376, Discrepancy Loss: 0.1016\n",
      "Epoch [29/50], Class Loss: 0.0355, Discrepancy Loss: 0.0960\n",
      "Epoch [30/50], Class Loss: 0.0893, Discrepancy Loss: 0.0944\n",
      "Epoch [31/50], Class Loss: 0.0350, Discrepancy Loss: 0.0985\n",
      "Epoch [32/50], Class Loss: 0.0278, Discrepancy Loss: 0.0973\n",
      "Epoch [33/50], Class Loss: 0.0308, Discrepancy Loss: 0.1007\n",
      "Epoch [34/50], Class Loss: 0.0375, Discrepancy Loss: 0.1032\n",
      "Epoch [35/50], Class Loss: 0.0379, Discrepancy Loss: 0.0916\n",
      "Epoch [36/50], Class Loss: 0.0355, Discrepancy Loss: 0.0975\n",
      "Epoch [37/50], Class Loss: 0.0319, Discrepancy Loss: 0.0908\n",
      "Epoch [38/50], Class Loss: 0.0550, Discrepancy Loss: 0.0965\n",
      "Epoch [39/50], Class Loss: 0.0349, Discrepancy Loss: 0.0993\n",
      "Epoch [40/50], Class Loss: 0.0270, Discrepancy Loss: 0.0947\n",
      "Epoch [41/50], Class Loss: 0.0271, Discrepancy Loss: 0.0942\n",
      "Epoch [42/50], Class Loss: 0.0333, Discrepancy Loss: 0.0948\n",
      "Epoch [43/50], Class Loss: 0.0222, Discrepancy Loss: 0.0948\n",
      "Epoch [44/50], Class Loss: 0.0294, Discrepancy Loss: 0.0972\n",
      "Epoch [45/50], Class Loss: 0.0242, Discrepancy Loss: 0.0972\n",
      "Epoch [46/50], Class Loss: 0.0274, Discrepancy Loss: 0.1004\n",
      "Epoch [47/50], Class Loss: 0.0321, Discrepancy Loss: 0.0934\n",
      "Epoch [48/50], Class Loss: 0.0264, Discrepancy Loss: 0.0946\n",
      "Epoch [49/50], Class Loss: 0.0332, Discrepancy Loss: 0.0991\n",
      "Epoch [50/50], Class Loss: 0.0409, Discrepancy Loss: 0.0997\n",
      "Source Domain Performance - Accuracy: 92.33%, Precision: 93.64%, Recall: 92.42%, F1 Score: 92.28%\n",
      "Target Domain Performance - Accuracy: 65.29%, Precision: 69.63%, Recall: 65.18%, F1 Score: 60.21%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 2.8875, Discrepancy Loss: 0.1164\n",
      "Epoch [2/50], Class Loss: 1.2629, Discrepancy Loss: 0.1491\n",
      "Epoch [3/50], Class Loss: 1.1774, Discrepancy Loss: 0.1162\n",
      "Epoch [4/50], Class Loss: 1.0294, Discrepancy Loss: 0.1262\n",
      "Epoch [5/50], Class Loss: 0.5224, Discrepancy Loss: 0.1187\n",
      "Epoch [6/50], Class Loss: 0.1388, Discrepancy Loss: 0.0861\n",
      "Epoch [7/50], Class Loss: 0.1542, Discrepancy Loss: 0.1018\n",
      "Epoch [8/50], Class Loss: 0.2046, Discrepancy Loss: 0.1070\n",
      "Epoch [9/50], Class Loss: 0.1378, Discrepancy Loss: 0.0841\n",
      "Epoch [10/50], Class Loss: 0.0993, Discrepancy Loss: 0.1046\n",
      "Epoch [11/50], Class Loss: 0.0531, Discrepancy Loss: 0.1062\n",
      "Epoch [12/50], Class Loss: 0.0597, Discrepancy Loss: 0.1143\n",
      "Epoch [13/50], Class Loss: 0.0451, Discrepancy Loss: 0.1123\n",
      "Epoch [14/50], Class Loss: 0.0566, Discrepancy Loss: 0.1218\n",
      "Epoch [15/50], Class Loss: 0.0552, Discrepancy Loss: 0.1327\n",
      "Epoch [16/50], Class Loss: 0.0558, Discrepancy Loss: 0.1275\n",
      "Epoch [17/50], Class Loss: 0.0661, Discrepancy Loss: 0.1375\n",
      "Epoch [18/50], Class Loss: 0.0394, Discrepancy Loss: 0.1342\n",
      "Epoch [19/50], Class Loss: 0.0307, Discrepancy Loss: 0.1347\n",
      "Epoch [20/50], Class Loss: 0.0448, Discrepancy Loss: 0.1074\n",
      "Epoch [21/50], Class Loss: 0.0441, Discrepancy Loss: 0.1234\n",
      "Epoch [22/50], Class Loss: 0.0341, Discrepancy Loss: 0.1154\n",
      "Epoch [23/50], Class Loss: 0.0340, Discrepancy Loss: 0.1275\n",
      "Epoch [24/50], Class Loss: 0.0302, Discrepancy Loss: 0.1295\n",
      "Epoch [25/50], Class Loss: 0.0321, Discrepancy Loss: 0.1295\n",
      "Epoch [26/50], Class Loss: 0.0354, Discrepancy Loss: 0.1211\n",
      "Epoch [27/50], Class Loss: 0.0387, Discrepancy Loss: 0.1321\n",
      "Epoch [28/50], Class Loss: 0.0423, Discrepancy Loss: 0.1281\n",
      "Epoch [29/50], Class Loss: 0.0343, Discrepancy Loss: 0.1302\n",
      "Epoch [30/50], Class Loss: 0.0371, Discrepancy Loss: 0.1312\n",
      "Epoch [31/50], Class Loss: 0.0276, Discrepancy Loss: 0.1363\n",
      "Epoch [32/50], Class Loss: 0.0367, Discrepancy Loss: 0.1422\n",
      "Epoch [33/50], Class Loss: 0.0582, Discrepancy Loss: 0.1402\n",
      "Epoch [34/50], Class Loss: 0.0314, Discrepancy Loss: 0.1468\n",
      "Epoch [35/50], Class Loss: 0.0247, Discrepancy Loss: 0.1393\n",
      "Epoch [36/50], Class Loss: 0.0378, Discrepancy Loss: 0.1496\n",
      "Epoch [37/50], Class Loss: 0.0341, Discrepancy Loss: 0.1509\n",
      "Epoch [38/50], Class Loss: 0.0279, Discrepancy Loss: 0.1376\n",
      "Epoch [39/50], Class Loss: 0.0620, Discrepancy Loss: 0.1437\n",
      "Epoch [40/50], Class Loss: 0.0385, Discrepancy Loss: 0.1459\n",
      "Epoch [41/50], Class Loss: 0.0354, Discrepancy Loss: 0.1411\n",
      "Epoch [42/50], Class Loss: 0.0275, Discrepancy Loss: 0.1536\n",
      "Epoch [43/50], Class Loss: 0.0286, Discrepancy Loss: 0.1394\n",
      "Epoch [44/50], Class Loss: 0.0602, Discrepancy Loss: 0.1438\n",
      "Epoch [45/50], Class Loss: 0.0388, Discrepancy Loss: 0.1384\n",
      "Epoch [46/50], Class Loss: 0.0496, Discrepancy Loss: 0.1414\n",
      "Epoch [47/50], Class Loss: 0.0362, Discrepancy Loss: 0.1457\n",
      "Epoch [48/50], Class Loss: 0.0348, Discrepancy Loss: 0.1331\n",
      "Epoch [49/50], Class Loss: 0.0334, Discrepancy Loss: 0.1363\n",
      "Epoch [50/50], Class Loss: 0.0357, Discrepancy Loss: 0.1496\n",
      "Source Domain Performance - Accuracy: 94.48%, Precision: 95.16%, Recall: 94.54%, F1 Score: 94.44%\n",
      "Target Domain Performance - Accuracy: 63.19%, Precision: 63.25%, Recall: 63.12%, F1 Score: 57.07%\n",
      "\n",
      "Source performance: 92.96% 94.10% 93.08% 92.93%\n",
      "Target performance: 64.03% 70.39% 63.94% 59.74%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 93.27%\n",
      "qpsk: 8.28%\n",
      "16qam: 81.31%\n",
      "8apsk: 72.90%\n",
      "\n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 2.4461, Discrepancy Loss: 0.0772\n",
      "Validation Loss: 1.5180\n",
      "Epoch [2/50], Class Loss: 1.4802, Discrepancy Loss: 0.0334\n",
      "Validation Loss: 1.4341\n",
      "Epoch [3/50], Class Loss: 0.6729, Discrepancy Loss: 0.0528\n",
      "Validation Loss: 0.2175\n",
      "Epoch [4/50], Class Loss: 0.2359, Discrepancy Loss: 0.0338\n",
      "Validation Loss: 0.7946\n",
      "Epoch [5/50], Class Loss: 0.1627, Discrepancy Loss: 0.0841\n",
      "Validation Loss: 0.1085\n",
      "Epoch [6/50], Class Loss: 0.2770, Discrepancy Loss: 0.0797\n",
      "Validation Loss: 0.0648\n",
      "Epoch [7/50], Class Loss: 0.1661, Discrepancy Loss: 0.0982\n",
      "Validation Loss: 0.0673\n",
      "Epoch [8/50], Class Loss: 0.1286, Discrepancy Loss: 0.0935\n",
      "Validation Loss: 0.2440\n",
      "Epoch [9/50], Class Loss: 0.1835, Discrepancy Loss: 0.0641\n",
      "Validation Loss: 0.1906\n",
      "Epoch [10/50], Class Loss: 0.1415, Discrepancy Loss: 0.0745\n",
      "Validation Loss: 0.3805\n",
      "Epoch [11/50], Class Loss: 0.0478, Discrepancy Loss: 0.0353\n",
      "Validation Loss: 0.0232\n",
      "Epoch [12/50], Class Loss: 0.0275, Discrepancy Loss: 0.0235\n",
      "Validation Loss: 0.0195\n",
      "Epoch [13/50], Class Loss: 0.0264, Discrepancy Loss: 0.0225\n",
      "Validation Loss: 0.0132\n",
      "Epoch [14/50], Class Loss: 0.0332, Discrepancy Loss: 0.0256\n",
      "Validation Loss: 0.0147\n",
      "Epoch [15/50], Class Loss: 0.0349, Discrepancy Loss: 0.0245\n",
      "Validation Loss: 0.0122\n",
      "Epoch [16/50], Class Loss: 0.0342, Discrepancy Loss: 0.0268\n",
      "Validation Loss: 0.0265\n",
      "Epoch [17/50], Class Loss: 0.0258, Discrepancy Loss: 0.0262\n",
      "Validation Loss: 0.0136\n",
      "Epoch [18/50], Class Loss: 0.0266, Discrepancy Loss: 0.0254\n",
      "Validation Loss: 0.0582\n",
      "Epoch [19/50], Class Loss: 0.0455, Discrepancy Loss: 0.0268\n",
      "Validation Loss: 0.0246\n",
      "Epoch [20/50], Class Loss: 0.0275, Discrepancy Loss: 0.0271\n",
      "Validation Loss: 0.0290\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.58%, Precision: 99.59%, Recall: 99.59%, F1 Score: 99.59%\n",
      "Target Domain Performance - Accuracy: 62.53%, Precision: 49.91%, Recall: 62.55%, F1 Score: 55.22%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.3923, Discrepancy Loss: 0.1020\n",
      "Validation Loss: 1.5314\n",
      "Epoch [2/50], Class Loss: 1.6747, Discrepancy Loss: 0.0973\n",
      "Validation Loss: 1.6389\n",
      "Epoch [3/50], Class Loss: 1.5558, Discrepancy Loss: 0.1787\n",
      "Validation Loss: 1.5328\n",
      "Epoch [4/50], Class Loss: 0.5801, Discrepancy Loss: 0.1098\n",
      "Validation Loss: 0.1170\n",
      "Epoch [5/50], Class Loss: 0.2471, Discrepancy Loss: 0.1062\n",
      "Validation Loss: 0.2865\n",
      "Epoch [6/50], Class Loss: 0.2420, Discrepancy Loss: 0.1183\n",
      "Validation Loss: 0.2791\n",
      "Epoch [7/50], Class Loss: 0.2031, Discrepancy Loss: 0.0925\n",
      "Validation Loss: 0.3458\n",
      "Epoch [8/50], Class Loss: 0.3296, Discrepancy Loss: 0.1347\n",
      "Validation Loss: 0.0343\n",
      "Epoch [9/50], Class Loss: 0.2376, Discrepancy Loss: 0.0665\n",
      "Validation Loss: 0.0395\n",
      "Epoch [10/50], Class Loss: 0.3256, Discrepancy Loss: 0.1480\n",
      "Validation Loss: 0.0710\n",
      "Epoch [11/50], Class Loss: 0.0658, Discrepancy Loss: 0.0591\n",
      "Validation Loss: 0.0284\n",
      "Epoch [12/50], Class Loss: 0.0651, Discrepancy Loss: 0.0508\n",
      "Validation Loss: 0.0479\n",
      "Epoch [13/50], Class Loss: 0.0584, Discrepancy Loss: 0.0453\n",
      "Validation Loss: 0.0342\n",
      "Epoch [14/50], Class Loss: 0.0554, Discrepancy Loss: 0.0468\n",
      "Validation Loss: 0.1035\n",
      "Epoch [15/50], Class Loss: 0.0795, Discrepancy Loss: 0.0456\n",
      "Validation Loss: 0.0847\n",
      "Epoch [16/50], Class Loss: 0.0619, Discrepancy Loss: 0.0364\n",
      "Validation Loss: 0.0332\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.70%, Precision: 99.71%, Recall: 99.70%, F1 Score: 99.70%\n",
      "Target Domain Performance - Accuracy: 53.42%, Precision: 38.00%, Recall: 53.73%, F1 Score: 43.84%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 2.1148, Discrepancy Loss: 0.0687\n",
      "Validation Loss: 1.5320\n",
      "Epoch [2/50], Class Loss: 1.5632, Discrepancy Loss: 0.0917\n",
      "Validation Loss: 1.9023\n",
      "Epoch [3/50], Class Loss: 1.2474, Discrepancy Loss: 0.1379\n",
      "Validation Loss: 0.3926\n",
      "Epoch [4/50], Class Loss: 0.3573, Discrepancy Loss: 0.0892\n",
      "Validation Loss: 0.1058\n",
      "Epoch [5/50], Class Loss: 0.1353, Discrepancy Loss: 0.1053\n",
      "Validation Loss: 0.0340\n",
      "Epoch [6/50], Class Loss: 0.2127, Discrepancy Loss: 0.1319\n",
      "Validation Loss: 0.6641\n",
      "Epoch [7/50], Class Loss: 0.2813, Discrepancy Loss: 0.0806\n",
      "Validation Loss: 0.0559\n",
      "Epoch [8/50], Class Loss: 0.2369, Discrepancy Loss: 0.0743\n",
      "Validation Loss: 0.0972\n",
      "Epoch [9/50], Class Loss: 0.2010, Discrepancy Loss: 0.0874\n",
      "Validation Loss: 0.2365\n",
      "Epoch [10/50], Class Loss: 0.2235, Discrepancy Loss: 0.0694\n",
      "Validation Loss: 0.0459\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.52%, Precision: 99.52%, Recall: 99.53%, F1 Score: 99.53%\n",
      "Target Domain Performance - Accuracy: 63.07%, Precision: 49.87%, Recall: 63.09%, F1 Score: 55.47%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 2.1389, Discrepancy Loss: 0.0762\n",
      "Validation Loss: 1.5679\n",
      "Epoch [2/50], Class Loss: 1.2457, Discrepancy Loss: 0.0929\n",
      "Validation Loss: 0.3862\n",
      "Epoch [3/50], Class Loss: 0.2705, Discrepancy Loss: 0.0768\n",
      "Validation Loss: 0.0402\n",
      "Epoch [4/50], Class Loss: 0.2696, Discrepancy Loss: 0.0727\n",
      "Validation Loss: 0.1609\n",
      "Epoch [5/50], Class Loss: 0.2218, Discrepancy Loss: 0.0951\n",
      "Validation Loss: 0.0543\n",
      "Epoch [6/50], Class Loss: 0.1527, Discrepancy Loss: 0.0508\n",
      "Validation Loss: 0.0800\n",
      "Epoch [7/50], Class Loss: 0.1516, Discrepancy Loss: 0.0526\n",
      "Validation Loss: 0.0591\n",
      "Epoch [8/50], Class Loss: 0.1322, Discrepancy Loss: 0.0541\n",
      "Validation Loss: 0.1382\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.14%, Precision: 98.22%, Recall: 98.09%, F1 Score: 98.13%\n",
      "Target Domain Performance - Accuracy: 51.14%, Precision: 38.72%, Recall: 51.48%, F1 Score: 41.43%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 2.0947, Discrepancy Loss: 0.0500\n",
      "Validation Loss: 1.4778\n",
      "Epoch [2/50], Class Loss: 1.5204, Discrepancy Loss: 0.0300\n",
      "Validation Loss: 1.4378\n",
      "Epoch [3/50], Class Loss: 1.1164, Discrepancy Loss: 0.0406\n",
      "Validation Loss: 0.2287\n",
      "Epoch [4/50], Class Loss: 0.2796, Discrepancy Loss: 0.0437\n",
      "Validation Loss: 0.1369\n",
      "Epoch [5/50], Class Loss: 0.1482, Discrepancy Loss: 0.0466\n",
      "Validation Loss: 0.2347\n",
      "Epoch [6/50], Class Loss: 0.2814, Discrepancy Loss: 0.0713\n",
      "Validation Loss: 0.1622\n",
      "Epoch [7/50], Class Loss: 0.1780, Discrepancy Loss: 0.0565\n",
      "Validation Loss: 1.0892\n",
      "Epoch [8/50], Class Loss: 0.2072, Discrepancy Loss: 0.0626\n",
      "Validation Loss: 0.6631\n",
      "Epoch [9/50], Class Loss: 0.1782, Discrepancy Loss: 0.0781\n",
      "Validation Loss: 0.4250\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 94.36%, Precision: 94.53%, Recall: 94.50%, F1 Score: 94.37%\n",
      "Target Domain Performance - Accuracy: 60.07%, Precision: 48.53%, Recall: 60.08%, F1 Score: 52.56%\n",
      "\n",
      "Source performance: 98.26% 98.31% 98.28% 98.26%\n",
      "Target performance: 58.05% 45.01% 58.18% 49.70%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 98.97%\n",
      "qpsk: 0.00%\n",
      "16qam: 44.49%\n",
      "8apsk: 89.29%\n",
      "\n",
      "Run 1/5\n",
      "Epoch 1/50, Train Loss: 1.0623, Train Acc: 0.5453, Val Loss: 0.9461, Val Acc: 0.5126\n",
      "Epoch 2/50, Train Loss: 0.7717, Train Acc: 0.6264, Val Loss: 0.8016, Val Acc: 0.6253\n",
      "Epoch 3/50, Train Loss: 0.3209, Train Acc: 0.8532, Val Loss: 0.3019, Val Acc: 0.9011\n",
      "Epoch 4/50, Train Loss: 0.0988, Train Acc: 0.9700, Val Loss: 0.0672, Val Acc: 0.9772\n",
      "Epoch 5/50, Train Loss: 0.0568, Train Acc: 0.9843, Val Loss: 0.0253, Val Acc: 0.9928\n",
      "Epoch 6/50, Train Loss: 0.0428, Train Acc: 0.9897, Val Loss: 0.1023, Val Acc: 0.9700\n",
      "Epoch 7/50, Train Loss: 0.0235, Train Acc: 0.9924, Val Loss: 0.0268, Val Acc: 0.9970\n",
      "Epoch 8/50, Train Loss: 0.0796, Train Acc: 0.9823, Val Loss: 0.3331, Val Acc: 0.9460\n",
      "Epoch 9/50, Train Loss: 0.0544, Train Acc: 0.9867, Val Loss: 0.0511, Val Acc: 0.9880\n",
      "Epoch 10/50, Train Loss: 0.0219, Train Acc: 0.9955, Val Loss: 0.0474, Val Acc: 0.9928\n",
      "Early stopping!\n",
      "\n",
      "Run 2/5\n",
      "Epoch 1/50, Train Loss: 0.9494, Train Acc: 0.5535, Val Loss: 0.7321, Val Acc: 0.6067\n",
      "Epoch 2/50, Train Loss: 0.7312, Train Acc: 0.6378, Val Loss: 0.7651, Val Acc: 0.6007\n",
      "Epoch 3/50, Train Loss: 0.5808, Train Acc: 0.7301, Val Loss: 0.1320, Val Acc: 0.9604\n",
      "Epoch 4/50, Train Loss: 0.1438, Train Acc: 0.9484, Val Loss: 0.0333, Val Acc: 0.9928\n",
      "Epoch 5/50, Train Loss: 0.1053, Train Acc: 0.9723, Val Loss: 0.1473, Val Acc: 0.9550\n",
      "Epoch 6/50, Train Loss: 0.0456, Train Acc: 0.9873, Val Loss: 0.0297, Val Acc: 0.9970\n",
      "Epoch 7/50, Train Loss: 0.0373, Train Acc: 0.9882, Val Loss: 0.1414, Val Acc: 0.9658\n",
      "Epoch 8/50, Train Loss: 0.0229, Train Acc: 0.9943, Val Loss: 0.0699, Val Acc: 0.9868\n",
      "Epoch 9/50, Train Loss: 0.0334, Train Acc: 0.9901, Val Loss: 0.0263, Val Acc: 0.9928\n",
      "Epoch 10/50, Train Loss: 0.0163, Train Acc: 0.9954, Val Loss: 0.0344, Val Acc: 0.9964\n",
      "Epoch 11/50, Train Loss: 0.0040, Train Acc: 0.9985, Val Loss: 0.0353, Val Acc: 0.9970\n",
      "Epoch 12/50, Train Loss: 0.0021, Train Acc: 0.9993, Val Loss: 0.0334, Val Acc: 0.9964\n",
      "Epoch 13/50, Train Loss: 0.0019, Train Acc: 0.9994, Val Loss: 0.0344, Val Acc: 0.9970\n",
      "Epoch 14/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0403, Val Acc: 0.9970\n",
      "Early stopping!\n",
      "\n",
      "Run 3/5\n",
      "Epoch 1/50, Train Loss: 1.0808, Train Acc: 0.5310, Val Loss: 0.7715, Val Acc: 0.6247\n",
      "Epoch 2/50, Train Loss: 0.6571, Train Acc: 0.6807, Val Loss: 0.4416, Val Acc: 0.8459\n",
      "Epoch 3/50, Train Loss: 0.1483, Train Acc: 0.9519, Val Loss: 0.1055, Val Acc: 0.9598\n",
      "Epoch 4/50, Train Loss: 0.1063, Train Acc: 0.9697, Val Loss: 0.0237, Val Acc: 0.9934\n",
      "Epoch 5/50, Train Loss: 0.1059, Train Acc: 0.9751, Val Loss: 0.1249, Val Acc: 0.9616\n",
      "Epoch 6/50, Train Loss: 0.0644, Train Acc: 0.9822, Val Loss: 0.0440, Val Acc: 0.9862\n",
      "Epoch 7/50, Train Loss: 0.0421, Train Acc: 0.9906, Val Loss: 0.0329, Val Acc: 0.9916\n",
      "Epoch 8/50, Train Loss: 0.0426, Train Acc: 0.9874, Val Loss: 0.0981, Val Acc: 0.9832\n",
      "Epoch 9/50, Train Loss: 0.0269, Train Acc: 0.9940, Val Loss: 0.0489, Val Acc: 0.9928\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 4/5\n",
      "Epoch 1/50, Train Loss: 0.9507, Train Acc: 0.5472, Val Loss: 0.7433, Val Acc: 0.6301\n",
      "Epoch 2/50, Train Loss: 0.6868, Train Acc: 0.6540, Val Loss: 0.4613, Val Acc: 0.7092\n",
      "Epoch 3/50, Train Loss: 0.1486, Train Acc: 0.9459, Val Loss: 0.0464, Val Acc: 0.9856\n",
      "Epoch 4/50, Train Loss: 0.0811, Train Acc: 0.9756, Val Loss: 0.1956, Val Acc: 0.9400\n",
      "Epoch 5/50, Train Loss: 0.0603, Train Acc: 0.9817, Val Loss: 0.0797, Val Acc: 0.9826\n",
      "Epoch 6/50, Train Loss: 0.0707, Train Acc: 0.9820, Val Loss: 0.0380, Val Acc: 0.9928\n",
      "Epoch 7/50, Train Loss: 0.0468, Train Acc: 0.9888, Val Loss: 0.0421, Val Acc: 0.9910\n",
      "Epoch 8/50, Train Loss: 0.0434, Train Acc: 0.9883, Val Loss: 0.0701, Val Acc: 0.9868\n",
      "Epoch 9/50, Train Loss: 0.0204, Train Acc: 0.9945, Val Loss: 0.0214, Val Acc: 0.9970\n",
      "Epoch 10/50, Train Loss: 0.0098, Train Acc: 0.9981, Val Loss: 0.0230, Val Acc: 0.9952\n",
      "Epoch 11/50, Train Loss: 0.0052, Train Acc: 0.9990, Val Loss: 0.0220, Val Acc: 0.9964\n",
      "Epoch 12/50, Train Loss: 0.0032, Train Acc: 0.9996, Val Loss: 0.0180, Val Acc: 0.9964\n",
      "Epoch 13/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0207, Val Acc: 0.9964\n",
      "Epoch 14/50, Train Loss: 0.0034, Train Acc: 0.9996, Val Loss: 0.0205, Val Acc: 0.9958\n",
      "Epoch 15/50, Train Loss: 0.0031, Train Acc: 0.9994, Val Loss: 0.0245, Val Acc: 0.9958\n",
      "Epoch 16/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0207, Val Acc: 0.9958\n",
      "Epoch 17/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0194, Val Acc: 0.9964\n",
      "Early stopping!\n",
      "\n",
      "Run 5/5\n",
      "Epoch 1/50, Train Loss: 0.9658, Train Acc: 0.5450, Val Loss: 0.7809, Val Acc: 0.6199\n",
      "Epoch 2/50, Train Loss: 0.7554, Train Acc: 0.6303, Val Loss: 0.7687, Val Acc: 0.6301\n",
      "Epoch 3/50, Train Loss: 0.5890, Train Acc: 0.7205, Val Loss: 0.2558, Val Acc: 0.9185\n",
      "Epoch 4/50, Train Loss: 0.0781, Train Acc: 0.9757, Val Loss: 0.0231, Val Acc: 0.9958\n",
      "Epoch 5/50, Train Loss: 0.0707, Train Acc: 0.9793, Val Loss: 0.0687, Val Acc: 0.9808\n",
      "Epoch 6/50, Train Loss: 0.0392, Train Acc: 0.9886, Val Loss: 0.0758, Val Acc: 0.9808\n",
      "Epoch 7/50, Train Loss: 0.0630, Train Acc: 0.9838, Val Loss: 0.0767, Val Acc: 0.9844\n",
      "Epoch 8/50, Train Loss: 0.0296, Train Acc: 0.9915, Val Loss: 0.3052, Val Acc: 0.9400\n",
      "Epoch 9/50, Train Loss: 0.0525, Train Acc: 0.9871, Val Loss: 0.0251, Val Acc: 0.9970\n",
      "Early stopping!\n",
      "\n",
      "Source performance: 99.52 99.51 99.52 99.51\n",
      "Target performance: 57.78 65.40 58.15 51.46\n",
      "\n",
      "bpsk: 98.62\n",
      "qpsk: 3.42\n",
      "16qam: 30.96\n",
      "8apsk: 99.58\n",
      "Epoch 1/50, Loss: 3.4513, Domain Loss: 1.8182, Class Loss: 1.6331\n",
      "Epoch 2/50, Loss: 2.7344, Domain Loss: 1.7016, Class Loss: 1.0328\n",
      "Epoch 3/50, Loss: 2.5863, Domain Loss: 1.7306, Class Loss: 0.8557\n",
      "Epoch 4/50, Loss: 2.2010, Domain Loss: 1.4561, Class Loss: 0.7450\n",
      "Epoch 5/50, Loss: 2.0719, Domain Loss: 1.3111, Class Loss: 0.7608\n",
      "Epoch 6/50, Loss: 2.0108, Domain Loss: 1.1969, Class Loss: 0.8139\n",
      "Epoch 7/50, Loss: 2.1508, Domain Loss: 1.3007, Class Loss: 0.8501\n",
      "Epoch 8/50, Loss: 1.8888, Domain Loss: 1.1455, Class Loss: 0.7434\n",
      "Epoch 9/50, Loss: 1.9888, Domain Loss: 1.2015, Class Loss: 0.7872\n",
      "Epoch 10/50, Loss: 2.6124, Domain Loss: 1.7038, Class Loss: 0.9086\n",
      "Epoch 11/50, Loss: 3.9935, Domain Loss: 2.3826, Class Loss: 1.6109\n",
      "Epoch 12/50, Loss: 2.8293, Domain Loss: 1.3871, Class Loss: 1.4421\n",
      "Epoch 13/50, Loss: 2.7685, Domain Loss: 1.3869, Class Loss: 1.3816\n",
      "Epoch 14/50, Loss: 2.7551, Domain Loss: 1.3868, Class Loss: 1.3683\n",
      "Epoch 15/50, Loss: 2.6241, Domain Loss: 1.3941, Class Loss: 1.2300\n",
      "Epoch 16/50, Loss: 2.5894, Domain Loss: 1.6886, Class Loss: 0.9008\n",
      "Epoch 17/50, Loss: 2.3626, Domain Loss: 1.3865, Class Loss: 0.9761\n",
      "Epoch 18/50, Loss: 2.1023, Domain Loss: 1.3864, Class Loss: 0.7159\n",
      "Epoch 19/50, Loss: 2.0027, Domain Loss: 1.3887, Class Loss: 0.6140\n",
      "Epoch 20/50, Loss: 1.9341, Domain Loss: 1.3863, Class Loss: 0.5477\n",
      "Epoch 21/50, Loss: 1.8489, Domain Loss: 1.3864, Class Loss: 0.4625\n",
      "Epoch 22/50, Loss: 2.4877, Domain Loss: 1.3863, Class Loss: 1.1013\n",
      "Epoch 23/50, Loss: 1.9307, Domain Loss: 1.3839, Class Loss: 0.5468\n",
      "Epoch 24/50, Loss: 1.6308, Domain Loss: 1.3064, Class Loss: 0.3244\n",
      "Epoch 25/50, Loss: 1.8751, Domain Loss: 1.6665, Class Loss: 0.2086\n",
      "Epoch 26/50, Loss: 1.5345, Domain Loss: 1.2893, Class Loss: 0.2452\n",
      "Epoch 27/50, Loss: 1.4504, Domain Loss: 1.2607, Class Loss: 0.1896\n",
      "Epoch 28/50, Loss: 1.4953, Domain Loss: 1.3021, Class Loss: 0.1932\n",
      "Epoch 29/50, Loss: 1.5949, Domain Loss: 1.3873, Class Loss: 0.2076\n",
      "Epoch 30/50, Loss: 1.5700, Domain Loss: 1.3890, Class Loss: 0.1810\n",
      "Epoch 31/50, Loss: 1.5355, Domain Loss: 1.3884, Class Loss: 0.1471\n",
      "Epoch 32/50, Loss: 1.4717, Domain Loss: 1.3879, Class Loss: 0.0838\n",
      "Epoch 33/50, Loss: 1.4719, Domain Loss: 1.3875, Class Loss: 0.0844\n",
      "Epoch 34/50, Loss: 1.4580, Domain Loss: 1.3872, Class Loss: 0.0707\n",
      "Epoch 35/50, Loss: 1.4334, Domain Loss: 1.3870, Class Loss: 0.0464\n",
      "Epoch 36/50, Loss: 1.5648, Domain Loss: 1.3868, Class Loss: 0.1780\n",
      "Epoch 37/50, Loss: 1.4736, Domain Loss: 1.3867, Class Loss: 0.0869\n",
      "Epoch 38/50, Loss: 1.4281, Domain Loss: 1.3866, Class Loss: 0.0415\n",
      "Epoch 39/50, Loss: 1.8104, Domain Loss: 1.7688, Class Loss: 0.0415\n",
      "Epoch 40/50, Loss: 1.4366, Domain Loss: 1.3866, Class Loss: 0.0500\n",
      "Epoch 41/50, Loss: 1.4231, Domain Loss: 1.3865, Class Loss: 0.0365\n",
      "Epoch 42/50, Loss: 1.4149, Domain Loss: 1.3865, Class Loss: 0.0284\n",
      "Epoch 43/50, Loss: 1.4032, Domain Loss: 1.3864, Class Loss: 0.0168\n",
      "Epoch 44/50, Loss: 1.4085, Domain Loss: 1.3864, Class Loss: 0.0221\n",
      "Epoch 45/50, Loss: 1.4512, Domain Loss: 1.3864, Class Loss: 0.0649\n",
      "Epoch 46/50, Loss: 1.4223, Domain Loss: 1.3863, Class Loss: 0.0359\n",
      "Epoch 47/50, Loss: 1.4055, Domain Loss: 1.3863, Class Loss: 0.0192\n",
      "Epoch 48/50, Loss: 1.4101, Domain Loss: 1.3863, Class Loss: 0.0238\n",
      "Epoch 49/50, Loss: 1.4072, Domain Loss: 1.3863, Class Loss: 0.0209\n",
      "Epoch 50/50, Loss: 1.4416, Domain Loss: 1.3863, Class Loss: 0.0552\n",
      "63.55\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.5040, Domain Loss: 1.6284, Class Loss: 1.8756\n",
      "Epoch 2/50, Loss: 2.3784, Domain Loss: 1.2513, Class Loss: 1.1271\n",
      "Epoch 3/50, Loss: 2.0982, Domain Loss: 1.2924, Class Loss: 0.8058\n",
      "Epoch 4/50, Loss: 1.9700, Domain Loss: 1.2104, Class Loss: 0.7596\n",
      "Epoch 5/50, Loss: 2.0985, Domain Loss: 1.2958, Class Loss: 0.8027\n",
      "Epoch 6/50, Loss: 2.4341, Domain Loss: 1.5136, Class Loss: 0.9205\n",
      "Epoch 7/50, Loss: 2.0675, Domain Loss: 1.2945, Class Loss: 0.7730\n",
      "Epoch 8/50, Loss: 2.0032, Domain Loss: 1.2871, Class Loss: 0.7161\n",
      "Epoch 9/50, Loss: 1.9201, Domain Loss: 1.4068, Class Loss: 0.5133\n",
      "Epoch 10/50, Loss: 1.7804, Domain Loss: 1.3436, Class Loss: 0.4368\n",
      "Epoch 11/50, Loss: 1.4393, Domain Loss: 1.2632, Class Loss: 0.1761\n",
      "Epoch 12/50, Loss: 1.6516, Domain Loss: 1.4658, Class Loss: 0.1858\n",
      "Epoch 13/50, Loss: 1.4756, Domain Loss: 1.4073, Class Loss: 0.0683\n",
      "Epoch 14/50, Loss: 1.4225, Domain Loss: 1.3882, Class Loss: 0.0343\n",
      "Epoch 15/50, Loss: 1.4075, Domain Loss: 1.3860, Class Loss: 0.0215\n",
      "Epoch 16/50, Loss: 1.4011, Domain Loss: 1.3819, Class Loss: 0.0192\n",
      "Epoch 17/50, Loss: 1.3950, Domain Loss: 1.3790, Class Loss: 0.0161\n",
      "Epoch 18/50, Loss: 1.4043, Domain Loss: 1.3771, Class Loss: 0.0272\n",
      "Epoch 19/50, Loss: 1.4035, Domain Loss: 1.3785, Class Loss: 0.0250\n",
      "Epoch 20/50, Loss: 1.7117, Domain Loss: 1.3606, Class Loss: 0.3511\n",
      "Epoch 21/50, Loss: 1.5065, Domain Loss: 1.3348, Class Loss: 0.1718\n",
      "Epoch 22/50, Loss: 1.3557, Domain Loss: 1.3129, Class Loss: 0.0428\n",
      "Epoch 23/50, Loss: 1.3535, Domain Loss: 1.3121, Class Loss: 0.0414\n",
      "Epoch 24/50, Loss: 1.3594, Domain Loss: 1.3123, Class Loss: 0.0471\n",
      "Epoch 25/50, Loss: 1.4071, Domain Loss: 1.3529, Class Loss: 0.0541\n",
      "Epoch 26/50, Loss: 1.3980, Domain Loss: 1.3690, Class Loss: 0.0291\n",
      "Epoch 27/50, Loss: 1.3538, Domain Loss: 1.3095, Class Loss: 0.0443\n",
      "Epoch 28/50, Loss: 6.2831, Domain Loss: 5.6583, Class Loss: 0.6248\n",
      "Epoch 29/50, Loss: 23.6379, Domain Loss: 20.7005, Class Loss: 2.9374\n",
      "Epoch 30/50, Loss: 3.0903, Domain Loss: 1.7084, Class Loss: 1.3818\n",
      "Epoch 31/50, Loss: 2.7605, Domain Loss: 1.4094, Class Loss: 1.3511\n",
      "Epoch 32/50, Loss: 2.5626, Domain Loss: 1.4057, Class Loss: 1.1569\n",
      "Epoch 33/50, Loss: 2.9210, Domain Loss: 1.4023, Class Loss: 1.5186\n",
      "Epoch 34/50, Loss: 3.4603, Domain Loss: 1.3994, Class Loss: 2.0609\n",
      "Epoch 35/50, Loss: 3.2364, Domain Loss: 1.3970, Class Loss: 1.8394\n",
      "Epoch 36/50, Loss: 3.1950, Domain Loss: 1.3950, Class Loss: 1.8000\n",
      "Epoch 37/50, Loss: 3.1638, Domain Loss: 1.3934, Class Loss: 1.7704\n",
      "Epoch 38/50, Loss: 3.1360, Domain Loss: 1.3920, Class Loss: 1.7439\n",
      "Epoch 39/50, Loss: 3.1131, Domain Loss: 1.3909, Class Loss: 1.7222\n",
      "Epoch 40/50, Loss: 3.0935, Domain Loss: 1.3900, Class Loss: 1.7036\n",
      "Epoch 41/50, Loss: 3.0755, Domain Loss: 1.3892, Class Loss: 1.6863\n",
      "Epoch 42/50, Loss: 3.0597, Domain Loss: 1.3886, Class Loss: 1.6711\n",
      "Epoch 43/50, Loss: 3.0452, Domain Loss: 1.3881, Class Loss: 1.6571\n",
      "Epoch 44/50, Loss: 3.0325, Domain Loss: 1.3877, Class Loss: 1.6447\n",
      "Epoch 45/50, Loss: 3.0211, Domain Loss: 1.3874, Class Loss: 1.6337\n",
      "Epoch 46/50, Loss: 3.0093, Domain Loss: 1.3872, Class Loss: 1.6222\n",
      "Epoch 47/50, Loss: 3.0006, Domain Loss: 1.3870, Class Loss: 1.6137\n",
      "Epoch 48/50, Loss: 2.9904, Domain Loss: 1.3868, Class Loss: 1.6036\n",
      "Epoch 49/50, Loss: 2.9825, Domain Loss: 1.3867, Class Loss: 1.5958\n",
      "Epoch 50/50, Loss: 2.9746, Domain Loss: 1.3866, Class Loss: 1.5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.88\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8293, Domain Loss: 1.9772, Class Loss: 1.8521\n",
      "Epoch 2/50, Loss: 2.3920, Domain Loss: 1.3746, Class Loss: 1.0174\n",
      "Epoch 3/50, Loss: 2.5751, Domain Loss: 1.6600, Class Loss: 0.9151\n",
      "Epoch 4/50, Loss: 2.0177, Domain Loss: 1.2543, Class Loss: 0.7634\n",
      "Epoch 5/50, Loss: 1.8773, Domain Loss: 1.1449, Class Loss: 0.7324\n",
      "Epoch 6/50, Loss: 2.0054, Domain Loss: 1.2453, Class Loss: 0.7601\n",
      "Epoch 7/50, Loss: 1.8739, Domain Loss: 1.1557, Class Loss: 0.7182\n",
      "Epoch 8/50, Loss: 1.8969, Domain Loss: 1.1769, Class Loss: 0.7201\n",
      "Epoch 9/50, Loss: 2.0447, Domain Loss: 1.2727, Class Loss: 0.7720\n",
      "Epoch 10/50, Loss: 2.3837, Domain Loss: 1.5748, Class Loss: 0.8089\n",
      "Epoch 11/50, Loss: 30.8538, Domain Loss: 27.8062, Class Loss: 3.0476\n",
      "Epoch 12/50, Loss: 15.8376, Domain Loss: 14.3228, Class Loss: 1.5148\n",
      "Epoch 13/50, Loss: 4.4918, Domain Loss: 3.1013, Class Loss: 1.3905\n",
      "Epoch 14/50, Loss: 2.8893, Domain Loss: 1.5004, Class Loss: 1.3889\n",
      "Epoch 15/50, Loss: 2.8287, Domain Loss: 1.4407, Class Loss: 1.3880\n",
      "Epoch 16/50, Loss: 2.8366, Domain Loss: 1.4489, Class Loss: 1.3877\n",
      "Epoch 17/50, Loss: 3.0403, Domain Loss: 1.6529, Class Loss: 1.3873\n",
      "Epoch 18/50, Loss: 2.9370, Domain Loss: 1.5481, Class Loss: 1.3889\n",
      "Epoch 19/50, Loss: 2.8438, Domain Loss: 1.4531, Class Loss: 1.3907\n",
      "Epoch 20/50, Loss: 2.8283, Domain Loss: 1.4402, Class Loss: 1.3881\n",
      "Epoch 21/50, Loss: 2.8531, Domain Loss: 1.4649, Class Loss: 1.3883\n",
      "Epoch 22/50, Loss: 3.3600, Domain Loss: 1.9720, Class Loss: 1.3880\n",
      "Epoch 23/50, Loss: 2.8953, Domain Loss: 1.5071, Class Loss: 1.3883\n",
      "Epoch 24/50, Loss: 2.7888, Domain Loss: 1.4004, Class Loss: 1.3884\n",
      "Epoch 25/50, Loss: 2.7825, Domain Loss: 1.3937, Class Loss: 1.3888\n",
      "Epoch 26/50, Loss: 2.7789, Domain Loss: 1.3882, Class Loss: 1.3907\n",
      "Epoch 27/50, Loss: 2.7717, Domain Loss: 1.3836, Class Loss: 1.3881\n",
      "Epoch 28/50, Loss: 2.7703, Domain Loss: 1.3786, Class Loss: 1.3917\n",
      "Epoch 29/50, Loss: 2.7640, Domain Loss: 1.3748, Class Loss: 1.3891\n",
      "Epoch 30/50, Loss: 2.7594, Domain Loss: 1.3694, Class Loss: 1.3899\n",
      "Epoch 31/50, Loss: 2.7548, Domain Loss: 1.3666, Class Loss: 1.3881\n",
      "Epoch 32/50, Loss: 2.7521, Domain Loss: 1.3644, Class Loss: 1.3877\n",
      "Epoch 33/50, Loss: 2.7521, Domain Loss: 1.3635, Class Loss: 1.3886\n",
      "Epoch 34/50, Loss: 2.7548, Domain Loss: 1.3677, Class Loss: 1.3871\n",
      "Epoch 35/50, Loss: 2.7598, Domain Loss: 1.3709, Class Loss: 1.3889\n",
      "Epoch 36/50, Loss: 2.7563, Domain Loss: 1.3666, Class Loss: 1.3897\n",
      "Epoch 37/50, Loss: 2.7555, Domain Loss: 1.3679, Class Loss: 1.3875\n",
      "Epoch 38/50, Loss: 2.7557, Domain Loss: 1.3673, Class Loss: 1.3884\n",
      "Epoch 39/50, Loss: 2.7548, Domain Loss: 1.3693, Class Loss: 1.3855\n",
      "Epoch 40/50, Loss: 2.7549, Domain Loss: 1.3679, Class Loss: 1.3870\n",
      "Epoch 41/50, Loss: 2.7582, Domain Loss: 1.3662, Class Loss: 1.3920\n",
      "Epoch 42/50, Loss: 2.7558, Domain Loss: 1.3663, Class Loss: 1.3894\n",
      "Epoch 43/50, Loss: 2.7575, Domain Loss: 1.3699, Class Loss: 1.3876\n",
      "Epoch 44/50, Loss: 2.7671, Domain Loss: 1.3779, Class Loss: 1.3892\n",
      "Epoch 45/50, Loss: 2.7792, Domain Loss: 1.3905, Class Loss: 1.3886\n",
      "Epoch 46/50, Loss: 2.7553, Domain Loss: 1.3660, Class Loss: 1.3893\n",
      "Epoch 47/50, Loss: 2.7410, Domain Loss: 1.3535, Class Loss: 1.3876\n",
      "Epoch 48/50, Loss: 2.7625, Domain Loss: 1.3743, Class Loss: 1.3882\n",
      "Epoch 49/50, Loss: 2.7726, Domain Loss: 1.3830, Class Loss: 1.3896\n",
      "Epoch 50/50, Loss: 2.7716, Domain Loss: 1.3833, Class Loss: 1.3883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.72\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.4510, Domain Loss: 1.7168, Class Loss: 1.7342\n",
      "Epoch 2/50, Loss: 2.3519, Domain Loss: 1.4279, Class Loss: 0.9240\n",
      "Epoch 3/50, Loss: 1.9564, Domain Loss: 1.1948, Class Loss: 0.7616\n",
      "Epoch 4/50, Loss: 2.0627, Domain Loss: 1.2432, Class Loss: 0.8195\n",
      "Epoch 5/50, Loss: 1.9168, Domain Loss: 1.1423, Class Loss: 0.7746\n",
      "Epoch 6/50, Loss: 1.8808, Domain Loss: 1.1054, Class Loss: 0.7754\n",
      "Epoch 7/50, Loss: 1.8842, Domain Loss: 1.1168, Class Loss: 0.7675\n",
      "Epoch 8/50, Loss: 1.8012, Domain Loss: 1.0717, Class Loss: 0.7295\n",
      "Epoch 9/50, Loss: 2.1666, Domain Loss: 1.2761, Class Loss: 0.8905\n",
      "Epoch 10/50, Loss: 2.2476, Domain Loss: 1.2473, Class Loss: 1.0003\n",
      "Epoch 11/50, Loss: 1.9906, Domain Loss: 1.1541, Class Loss: 0.8365\n",
      "Epoch 12/50, Loss: 2.2372, Domain Loss: 1.3335, Class Loss: 0.9038\n",
      "Epoch 13/50, Loss: 2.2345, Domain Loss: 1.3063, Class Loss: 0.9281\n",
      "Epoch 14/50, Loss: 2.2920, Domain Loss: 1.3703, Class Loss: 0.9217\n",
      "Epoch 15/50, Loss: 2.1080, Domain Loss: 1.2724, Class Loss: 0.8356\n",
      "Epoch 16/50, Loss: 1.9637, Domain Loss: 1.2122, Class Loss: 0.7515\n",
      "Epoch 17/50, Loss: 2.2676, Domain Loss: 1.3545, Class Loss: 0.9131\n",
      "Epoch 18/50, Loss: 2.4654, Domain Loss: 1.5506, Class Loss: 0.9147\n",
      "Epoch 19/50, Loss: 2.3265, Domain Loss: 1.3699, Class Loss: 0.9567\n",
      "Epoch 20/50, Loss: 1.8951, Domain Loss: 1.1418, Class Loss: 0.7533\n",
      "Epoch 21/50, Loss: 1.8863, Domain Loss: 1.1755, Class Loss: 0.7108\n",
      "Epoch 22/50, Loss: 1.9001, Domain Loss: 1.1803, Class Loss: 0.7198\n",
      "Epoch 23/50, Loss: 1.8648, Domain Loss: 1.2185, Class Loss: 0.6463\n",
      "Epoch 24/50, Loss: 1.9698, Domain Loss: 1.3511, Class Loss: 0.6187\n",
      "Epoch 25/50, Loss: 1.7993, Domain Loss: 1.2881, Class Loss: 0.5112\n",
      "Epoch 26/50, Loss: 1.6552, Domain Loss: 1.2088, Class Loss: 0.4464\n",
      "Epoch 27/50, Loss: 1.6117, Domain Loss: 1.1704, Class Loss: 0.4413\n",
      "Epoch 28/50, Loss: 1.7807, Domain Loss: 1.3362, Class Loss: 0.4445\n",
      "Epoch 29/50, Loss: 1.7993, Domain Loss: 1.3853, Class Loss: 0.4140\n",
      "Epoch 30/50, Loss: 1.7236, Domain Loss: 1.3084, Class Loss: 0.4152\n",
      "Epoch 31/50, Loss: 1.6644, Domain Loss: 1.2421, Class Loss: 0.4223\n",
      "Epoch 32/50, Loss: 1.5912, Domain Loss: 1.2459, Class Loss: 0.3453\n",
      "Epoch 33/50, Loss: 1.5426, Domain Loss: 1.2322, Class Loss: 0.3104\n",
      "Epoch 34/50, Loss: 1.6016, Domain Loss: 1.2485, Class Loss: 0.3531\n",
      "Epoch 35/50, Loss: 1.4521, Domain Loss: 1.2424, Class Loss: 0.2097\n",
      "Epoch 36/50, Loss: 1.4095, Domain Loss: 1.2064, Class Loss: 0.2031\n",
      "Epoch 37/50, Loss: 1.3831, Domain Loss: 1.2039, Class Loss: 0.1792\n",
      "Epoch 38/50, Loss: 1.5200, Domain Loss: 1.3825, Class Loss: 0.1375\n",
      "Epoch 39/50, Loss: 1.4384, Domain Loss: 1.3334, Class Loss: 0.1050\n",
      "Epoch 40/50, Loss: 1.3683, Domain Loss: 1.2592, Class Loss: 0.1091\n",
      "Epoch 41/50, Loss: 1.2912, Domain Loss: 1.1658, Class Loss: 0.1254\n",
      "Epoch 42/50, Loss: 1.2254, Domain Loss: 1.1111, Class Loss: 0.1143\n",
      "Epoch 43/50, Loss: 1.1520, Domain Loss: 1.0571, Class Loss: 0.0949\n",
      "Epoch 44/50, Loss: 1.1444, Domain Loss: 1.0610, Class Loss: 0.0834\n",
      "Epoch 45/50, Loss: 1.3944, Domain Loss: 1.2697, Class Loss: 0.1247\n",
      "Epoch 46/50, Loss: 1.4673, Domain Loss: 1.1387, Class Loss: 0.3286\n",
      "Epoch 47/50, Loss: 1.6266, Domain Loss: 1.4243, Class Loss: 0.2023\n",
      "Epoch 48/50, Loss: 1.4069, Domain Loss: 1.3054, Class Loss: 0.1015\n",
      "Epoch 49/50, Loss: 1.1670, Domain Loss: 1.0797, Class Loss: 0.0874\n",
      "Epoch 50/50, Loss: 1.2512, Domain Loss: 1.1714, Class Loss: 0.0798\n",
      "68.59\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.6052, Domain Loss: 1.5797, Class Loss: 2.0255\n",
      "Epoch 2/50, Loss: 2.2129, Domain Loss: 1.2281, Class Loss: 0.9849\n",
      "Epoch 3/50, Loss: 2.3583, Domain Loss: 1.4416, Class Loss: 0.9167\n",
      "Epoch 4/50, Loss: 1.8848, Domain Loss: 1.1290, Class Loss: 0.7558\n",
      "Epoch 5/50, Loss: 1.8381, Domain Loss: 1.0685, Class Loss: 0.7696\n",
      "Epoch 6/50, Loss: 1.8930, Domain Loss: 1.1044, Class Loss: 0.7887\n",
      "Epoch 7/50, Loss: 1.8547, Domain Loss: 1.1061, Class Loss: 0.7486\n",
      "Epoch 8/50, Loss: 2.0236, Domain Loss: 1.2350, Class Loss: 0.7885\n",
      "Epoch 9/50, Loss: 2.2294, Domain Loss: 1.4092, Class Loss: 0.8203\n",
      "Epoch 10/50, Loss: 8.7309, Domain Loss: 6.8883, Class Loss: 1.8426\n",
      "Epoch 11/50, Loss: 4.7439, Domain Loss: 3.9614, Class Loss: 0.7825\n",
      "Epoch 12/50, Loss: 9.4916, Domain Loss: 7.5459, Class Loss: 1.9457\n",
      "Epoch 13/50, Loss: 5.6347, Domain Loss: 4.2204, Class Loss: 1.4143\n",
      "Epoch 14/50, Loss: 5.0684, Domain Loss: 3.6819, Class Loss: 1.3865\n",
      "Epoch 15/50, Loss: 5.0624, Domain Loss: 3.6825, Class Loss: 1.3799\n",
      "Epoch 16/50, Loss: 4.7020, Domain Loss: 3.3103, Class Loss: 1.3917\n",
      "Epoch 17/50, Loss: 4.7349, Domain Loss: 3.3463, Class Loss: 1.3886\n",
      "Epoch 18/50, Loss: 6.9110, Domain Loss: 5.5242, Class Loss: 1.3868\n",
      "Epoch 19/50, Loss: 10.0727, Domain Loss: 8.6912, Class Loss: 1.3815\n",
      "Epoch 20/50, Loss: 11.7038, Domain Loss: 10.4839, Class Loss: 1.2199\n",
      "Epoch 21/50, Loss: 10.3273, Domain Loss: 9.4378, Class Loss: 0.8895\n",
      "Epoch 22/50, Loss: 10.9023, Domain Loss: 9.9372, Class Loss: 0.9651\n",
      "Epoch 23/50, Loss: 4.7681, Domain Loss: 3.7190, Class Loss: 1.0491\n",
      "Epoch 24/50, Loss: 4.2618, Domain Loss: 3.4624, Class Loss: 0.7994\n",
      "Epoch 25/50, Loss: 4.0219, Domain Loss: 3.2664, Class Loss: 0.7555\n",
      "Epoch 26/50, Loss: 4.5371, Domain Loss: 3.3354, Class Loss: 1.2016\n",
      "Epoch 27/50, Loss: 4.3588, Domain Loss: 3.3771, Class Loss: 0.9817\n",
      "Epoch 28/50, Loss: 4.4261, Domain Loss: 3.6283, Class Loss: 0.7978\n",
      "Epoch 29/50, Loss: 4.8207, Domain Loss: 3.8199, Class Loss: 1.0008\n",
      "Epoch 30/50, Loss: 4.4168, Domain Loss: 3.4949, Class Loss: 0.9219\n",
      "Epoch 31/50, Loss: 5.5523, Domain Loss: 4.0310, Class Loss: 1.5213\n",
      "Epoch 32/50, Loss: 5.3948, Domain Loss: 4.3520, Class Loss: 1.0428\n",
      "Epoch 33/50, Loss: 6.0300, Domain Loss: 4.8584, Class Loss: 1.1716\n",
      "Epoch 34/50, Loss: 10.0662, Domain Loss: 8.6379, Class Loss: 1.4282\n",
      "Epoch 35/50, Loss: 12.0535, Domain Loss: 10.7760, Class Loss: 1.2776\n",
      "Epoch 36/50, Loss: 6.2201, Domain Loss: 5.0500, Class Loss: 1.1701\n",
      "Epoch 37/50, Loss: 8.9074, Domain Loss: 7.7609, Class Loss: 1.1466\n",
      "Epoch 38/50, Loss: 4.4084, Domain Loss: 3.5374, Class Loss: 0.8709\n",
      "Epoch 39/50, Loss: 4.9756, Domain Loss: 4.2117, Class Loss: 0.7639\n",
      "Epoch 40/50, Loss: 4.8681, Domain Loss: 4.0730, Class Loss: 0.7952\n",
      "Epoch 41/50, Loss: 3.9652, Domain Loss: 3.1729, Class Loss: 0.7923\n",
      "Epoch 42/50, Loss: 3.6807, Domain Loss: 2.9308, Class Loss: 0.7499\n",
      "Epoch 43/50, Loss: 2.5639, Domain Loss: 1.8286, Class Loss: 0.7353\n",
      "Epoch 44/50, Loss: 2.4734, Domain Loss: 1.7117, Class Loss: 0.7617\n",
      "Epoch 45/50, Loss: 2.5805, Domain Loss: 1.7965, Class Loss: 0.7839\n",
      "Epoch 46/50, Loss: 2.3472, Domain Loss: 1.5940, Class Loss: 0.7532\n",
      "Epoch 47/50, Loss: 2.0050, Domain Loss: 1.2456, Class Loss: 0.7594\n",
      "Epoch 48/50, Loss: 1.7953, Domain Loss: 1.0555, Class Loss: 0.7399\n",
      "Epoch 49/50, Loss: 2.1141, Domain Loss: 1.4073, Class Loss: 0.7069\n",
      "Epoch 50/50, Loss: 2.0510, Domain Loss: 1.3334, Class Loss: 0.7177\n",
      "57.13\n",
      "\n",
      "\n",
      "Source performance:\n",
      "59.89 56.26 59.83 52.54 \n",
      "Target performance:\n",
      "47.97 42.59 48.18 38.93 \n",
      "\n",
      "Per-class target performance: 60.00 39.90 49.18 43.65 \n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 3.8699, Discrepancy Loss: 0.1094\n",
      "Epoch [2/50], Class Loss: 1.2589, Discrepancy Loss: 0.1344\n",
      "Epoch [3/50], Class Loss: 0.5673, Discrepancy Loss: 0.0914\n",
      "Epoch [4/50], Class Loss: 0.2168, Discrepancy Loss: 0.0773\n",
      "Epoch [5/50], Class Loss: 0.1597, Discrepancy Loss: 0.0690\n",
      "Epoch [6/50], Class Loss: 0.1418, Discrepancy Loss: 0.0859\n",
      "Epoch [7/50], Class Loss: 0.1068, Discrepancy Loss: 0.0534\n",
      "Epoch [8/50], Class Loss: 0.1218, Discrepancy Loss: 0.0535\n",
      "Epoch [9/50], Class Loss: 0.1338, Discrepancy Loss: 0.0537\n",
      "Epoch [10/50], Class Loss: 0.0692, Discrepancy Loss: 0.0470\n",
      "Epoch [11/50], Class Loss: 0.0719, Discrepancy Loss: 0.0474\n",
      "Epoch [12/50], Class Loss: 0.0348, Discrepancy Loss: 0.0400\n",
      "Epoch [13/50], Class Loss: 0.0557, Discrepancy Loss: 0.0409\n",
      "Epoch [14/50], Class Loss: 0.1386, Discrepancy Loss: 0.0419\n",
      "Epoch [15/50], Class Loss: 0.0458, Discrepancy Loss: 0.0416\n",
      "Epoch [16/50], Class Loss: 0.0709, Discrepancy Loss: 0.0448\n",
      "Epoch [17/50], Class Loss: 0.0951, Discrepancy Loss: 0.0548\n",
      "Epoch [18/50], Class Loss: 0.0570, Discrepancy Loss: 0.0638\n",
      "Epoch [19/50], Class Loss: 0.0526, Discrepancy Loss: 0.0675\n",
      "Epoch [20/50], Class Loss: 0.0556, Discrepancy Loss: 0.0619\n",
      "Epoch [21/50], Class Loss: 0.0325, Discrepancy Loss: 0.0490\n",
      "Epoch [22/50], Class Loss: 0.0339, Discrepancy Loss: 0.0563\n",
      "Epoch [23/50], Class Loss: 0.0347, Discrepancy Loss: 0.0593\n",
      "Epoch [24/50], Class Loss: 0.0275, Discrepancy Loss: 0.0665\n",
      "Epoch [25/50], Class Loss: 0.0406, Discrepancy Loss: 0.0661\n",
      "Epoch [26/50], Class Loss: 0.0476, Discrepancy Loss: 0.0643\n",
      "Epoch [27/50], Class Loss: 0.0275, Discrepancy Loss: 0.0694\n",
      "Epoch [28/50], Class Loss: 0.0329, Discrepancy Loss: 0.0685\n",
      "Epoch [29/50], Class Loss: 0.0251, Discrepancy Loss: 0.0744\n",
      "Epoch [30/50], Class Loss: 0.0234, Discrepancy Loss: 0.0706\n",
      "Epoch [31/50], Class Loss: 0.0213, Discrepancy Loss: 0.0708\n",
      "Epoch [32/50], Class Loss: 0.0213, Discrepancy Loss: 0.0726\n",
      "Epoch [33/50], Class Loss: 0.0195, Discrepancy Loss: 0.0678\n",
      "Epoch [34/50], Class Loss: 0.0235, Discrepancy Loss: 0.0692\n",
      "Epoch [35/50], Class Loss: 0.0300, Discrepancy Loss: 0.0630\n",
      "Epoch [36/50], Class Loss: 0.0277, Discrepancy Loss: 0.0736\n",
      "Epoch [37/50], Class Loss: 0.0279, Discrepancy Loss: 0.0693\n",
      "Epoch [38/50], Class Loss: 0.0287, Discrepancy Loss: 0.0688\n",
      "Epoch [39/50], Class Loss: 0.0315, Discrepancy Loss: 0.0685\n",
      "Epoch [40/50], Class Loss: 0.0248, Discrepancy Loss: 0.0724\n",
      "Epoch [41/50], Class Loss: 0.0373, Discrepancy Loss: 0.0703\n",
      "Epoch [42/50], Class Loss: 0.0256, Discrepancy Loss: 0.0675\n",
      "Epoch [43/50], Class Loss: 0.0214, Discrepancy Loss: 0.0643\n",
      "Epoch [44/50], Class Loss: 0.0280, Discrepancy Loss: 0.0685\n",
      "Epoch [45/50], Class Loss: 0.0279, Discrepancy Loss: 0.0659\n",
      "Epoch [46/50], Class Loss: 0.0263, Discrepancy Loss: 0.0787\n",
      "Epoch [47/50], Class Loss: 0.0189, Discrepancy Loss: 0.0729\n",
      "Epoch [48/50], Class Loss: 0.1283, Discrepancy Loss: 0.0709\n",
      "Epoch [49/50], Class Loss: 0.0325, Discrepancy Loss: 0.0695\n",
      "Epoch [50/50], Class Loss: 0.0264, Discrepancy Loss: 0.0682\n",
      "Source Domain Performance - Accuracy: 90.59%, Precision: 92.75%, Recall: 90.20%, F1 Score: 90.30%\n",
      "Target Domain Performance - Accuracy: 83.93%, Precision: 87.51%, Recall: 83.95%, F1 Score: 83.64%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.8229, Discrepancy Loss: 0.1206\n",
      "Epoch [2/50], Class Loss: 1.6122, Discrepancy Loss: 0.1450\n",
      "Epoch [3/50], Class Loss: 1.2872, Discrepancy Loss: 0.1392\n",
      "Epoch [4/50], Class Loss: 1.2087, Discrepancy Loss: 0.1528\n",
      "Epoch [5/50], Class Loss: 1.0324, Discrepancy Loss: 0.1366\n",
      "Epoch [6/50], Class Loss: 1.0322, Discrepancy Loss: 0.1399\n",
      "Epoch [7/50], Class Loss: 0.4933, Discrepancy Loss: 0.0972\n",
      "Epoch [8/50], Class Loss: 0.1323, Discrepancy Loss: 0.0615\n",
      "Epoch [9/50], Class Loss: 0.1151, Discrepancy Loss: 0.0576\n",
      "Epoch [10/50], Class Loss: 0.1376, Discrepancy Loss: 0.0549\n",
      "Epoch [11/50], Class Loss: 0.1047, Discrepancy Loss: 0.0796\n",
      "Epoch [12/50], Class Loss: 0.0516, Discrepancy Loss: 0.0490\n",
      "Epoch [13/50], Class Loss: 0.0403, Discrepancy Loss: 0.0504\n",
      "Epoch [14/50], Class Loss: 0.0338, Discrepancy Loss: 0.0491\n",
      "Epoch [15/50], Class Loss: 0.0293, Discrepancy Loss: 0.0393\n",
      "Epoch [16/50], Class Loss: 0.0311, Discrepancy Loss: 0.0401\n",
      "Epoch [17/50], Class Loss: 0.0265, Discrepancy Loss: 0.0375\n",
      "Epoch [18/50], Class Loss: 0.0343, Discrepancy Loss: 0.0464\n",
      "Epoch [19/50], Class Loss: 0.0290, Discrepancy Loss: 0.0415\n",
      "Epoch [20/50], Class Loss: 0.0265, Discrepancy Loss: 0.0407\n",
      "Epoch [21/50], Class Loss: 0.0242, Discrepancy Loss: 0.0441\n",
      "Epoch [22/50], Class Loss: 0.0216, Discrepancy Loss: 0.0458\n",
      "Epoch [23/50], Class Loss: 0.0191, Discrepancy Loss: 0.0404\n",
      "Epoch [24/50], Class Loss: 0.0163, Discrepancy Loss: 0.0429\n",
      "Epoch [25/50], Class Loss: 0.0137, Discrepancy Loss: 0.0435\n",
      "Epoch [26/50], Class Loss: 0.0192, Discrepancy Loss: 0.0436\n",
      "Epoch [27/50], Class Loss: 0.0261, Discrepancy Loss: 0.0400\n",
      "Epoch [28/50], Class Loss: 0.0204, Discrepancy Loss: 0.0470\n",
      "Epoch [29/50], Class Loss: 0.0149, Discrepancy Loss: 0.0460\n",
      "Epoch [30/50], Class Loss: 0.0216, Discrepancy Loss: 0.0421\n",
      "Epoch [31/50], Class Loss: 0.0205, Discrepancy Loss: 0.0439\n",
      "Epoch [32/50], Class Loss: 0.0179, Discrepancy Loss: 0.0453\n",
      "Epoch [33/50], Class Loss: 0.0253, Discrepancy Loss: 0.0454\n",
      "Epoch [34/50], Class Loss: 0.0165, Discrepancy Loss: 0.0466\n",
      "Epoch [35/50], Class Loss: 0.0176, Discrepancy Loss: 0.0461\n",
      "Epoch [36/50], Class Loss: 0.0183, Discrepancy Loss: 0.0453\n",
      "Epoch [37/50], Class Loss: 0.0216, Discrepancy Loss: 0.0463\n",
      "Epoch [38/50], Class Loss: 0.0193, Discrepancy Loss: 0.0476\n",
      "Epoch [39/50], Class Loss: 0.0185, Discrepancy Loss: 0.0432\n",
      "Epoch [40/50], Class Loss: 0.0262, Discrepancy Loss: 0.0443\n",
      "Epoch [41/50], Class Loss: 0.0210, Discrepancy Loss: 0.0480\n",
      "Epoch [42/50], Class Loss: 0.0154, Discrepancy Loss: 0.0473\n",
      "Epoch [43/50], Class Loss: 0.0277, Discrepancy Loss: 0.0477\n",
      "Epoch [44/50], Class Loss: 0.0155, Discrepancy Loss: 0.0483\n",
      "Epoch [45/50], Class Loss: 0.0216, Discrepancy Loss: 0.0472\n",
      "Epoch [46/50], Class Loss: 0.0200, Discrepancy Loss: 0.0473\n",
      "Epoch [47/50], Class Loss: 0.0352, Discrepancy Loss: 0.0483\n",
      "Epoch [48/50], Class Loss: 0.0199, Discrepancy Loss: 0.0442\n",
      "Epoch [49/50], Class Loss: 0.0231, Discrepancy Loss: 0.0477\n",
      "Epoch [50/50], Class Loss: 0.0217, Discrepancy Loss: 0.0492\n",
      "Source Domain Performance - Accuracy: 95.68%, Precision: 95.87%, Recall: 95.65%, F1 Score: 95.67%\n",
      "Target Domain Performance - Accuracy: 82.49%, Precision: 87.46%, Recall: 82.54%, F1 Score: 81.86%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 3.3164, Discrepancy Loss: 0.1163\n",
      "Epoch [2/50], Class Loss: 1.4909, Discrepancy Loss: 0.1384\n",
      "Epoch [3/50], Class Loss: 1.3120, Discrepancy Loss: 0.1384\n",
      "Epoch [4/50], Class Loss: 0.7923, Discrepancy Loss: 0.1224\n",
      "Epoch [5/50], Class Loss: 0.2916, Discrepancy Loss: 0.0883\n",
      "Epoch [6/50], Class Loss: 0.1540, Discrepancy Loss: 0.0658\n",
      "Epoch [7/50], Class Loss: 0.1190, Discrepancy Loss: 0.0675\n",
      "Epoch [8/50], Class Loss: 0.1372, Discrepancy Loss: 0.0931\n",
      "Epoch [9/50], Class Loss: 0.1535, Discrepancy Loss: 0.0841\n",
      "Epoch [10/50], Class Loss: 0.1362, Discrepancy Loss: 0.0719\n",
      "Epoch [11/50], Class Loss: 0.1111, Discrepancy Loss: 0.0911\n",
      "Epoch [12/50], Class Loss: 0.0778, Discrepancy Loss: 0.0773\n",
      "Epoch [13/50], Class Loss: 0.0689, Discrepancy Loss: 0.0769\n",
      "Epoch [14/50], Class Loss: 0.0538, Discrepancy Loss: 0.0751\n",
      "Epoch [15/50], Class Loss: 0.0602, Discrepancy Loss: 0.0866\n",
      "Epoch [16/50], Class Loss: 0.0656, Discrepancy Loss: 0.0822\n",
      "Epoch [17/50], Class Loss: 0.0423, Discrepancy Loss: 0.0778\n",
      "Epoch [18/50], Class Loss: 0.0529, Discrepancy Loss: 0.0881\n",
      "Epoch [19/50], Class Loss: 0.0437, Discrepancy Loss: 0.0957\n",
      "Epoch [20/50], Class Loss: 0.0448, Discrepancy Loss: 0.0851\n",
      "Epoch [21/50], Class Loss: 0.0453, Discrepancy Loss: 0.0816\n",
      "Epoch [22/50], Class Loss: 0.0341, Discrepancy Loss: 0.0835\n",
      "Epoch [23/50], Class Loss: 0.0406, Discrepancy Loss: 0.0824\n",
      "Epoch [24/50], Class Loss: 0.0478, Discrepancy Loss: 0.0855\n",
      "Epoch [25/50], Class Loss: 0.0384, Discrepancy Loss: 0.0862\n",
      "Epoch [26/50], Class Loss: 0.0370, Discrepancy Loss: 0.0914\n",
      "Epoch [27/50], Class Loss: 0.0342, Discrepancy Loss: 0.0968\n",
      "Epoch [28/50], Class Loss: 0.0505, Discrepancy Loss: 0.0838\n",
      "Epoch [29/50], Class Loss: 0.0333, Discrepancy Loss: 0.0945\n",
      "Epoch [30/50], Class Loss: 0.0560, Discrepancy Loss: 0.0946\n",
      "Epoch [31/50], Class Loss: 0.0366, Discrepancy Loss: 0.0919\n",
      "Epoch [32/50], Class Loss: 0.0450, Discrepancy Loss: 0.0950\n",
      "Epoch [33/50], Class Loss: 0.0358, Discrepancy Loss: 0.0977\n",
      "Epoch [34/50], Class Loss: 0.0435, Discrepancy Loss: 0.1004\n",
      "Epoch [35/50], Class Loss: 0.0422, Discrepancy Loss: 0.1003\n",
      "Epoch [36/50], Class Loss: 0.0335, Discrepancy Loss: 0.0915\n",
      "Epoch [37/50], Class Loss: 0.0726, Discrepancy Loss: 0.0996\n",
      "Epoch [38/50], Class Loss: 0.0372, Discrepancy Loss: 0.0956\n",
      "Epoch [39/50], Class Loss: 0.0415, Discrepancy Loss: 0.1041\n",
      "Epoch [40/50], Class Loss: 0.0398, Discrepancy Loss: 0.0995\n",
      "Epoch [41/50], Class Loss: 0.0309, Discrepancy Loss: 0.1006\n",
      "Epoch [42/50], Class Loss: 0.0377, Discrepancy Loss: 0.0989\n",
      "Epoch [43/50], Class Loss: 0.0312, Discrepancy Loss: 0.0952\n",
      "Epoch [44/50], Class Loss: 0.0383, Discrepancy Loss: 0.0963\n",
      "Epoch [45/50], Class Loss: 0.0405, Discrepancy Loss: 0.1020\n",
      "Epoch [46/50], Class Loss: 0.0470, Discrepancy Loss: 0.0996\n",
      "Epoch [47/50], Class Loss: 0.0319, Discrepancy Loss: 0.0965\n",
      "Epoch [48/50], Class Loss: 0.0373, Discrepancy Loss: 0.0958\n",
      "Epoch [49/50], Class Loss: 0.0352, Discrepancy Loss: 0.0950\n",
      "Epoch [50/50], Class Loss: 0.0271, Discrepancy Loss: 0.1017\n",
      "Source Domain Performance - Accuracy: 95.26%, Precision: 95.55%, Recall: 95.15%, F1 Score: 95.20%\n",
      "Target Domain Performance - Accuracy: 80.76%, Precision: 86.40%, Recall: 80.80%, F1 Score: 79.77%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 3.1071, Discrepancy Loss: 0.1319\n",
      "Epoch [2/50], Class Loss: 1.5361, Discrepancy Loss: 0.1394\n",
      "Epoch [3/50], Class Loss: 1.4312, Discrepancy Loss: 0.1412\n",
      "Epoch [4/50], Class Loss: 0.7062, Discrepancy Loss: 0.1337\n",
      "Epoch [5/50], Class Loss: 0.2037, Discrepancy Loss: 0.0761\n",
      "Epoch [6/50], Class Loss: 0.1913, Discrepancy Loss: 0.0682\n",
      "Epoch [7/50], Class Loss: 0.1308, Discrepancy Loss: 0.0764\n",
      "Epoch [8/50], Class Loss: 0.0819, Discrepancy Loss: 0.0671\n",
      "Epoch [9/50], Class Loss: 0.1047, Discrepancy Loss: 0.0775\n",
      "Epoch [10/50], Class Loss: 0.1216, Discrepancy Loss: 0.0814\n",
      "Epoch [11/50], Class Loss: 0.0655, Discrepancy Loss: 0.0607\n",
      "Epoch [12/50], Class Loss: 0.0749, Discrepancy Loss: 0.0724\n",
      "Epoch [13/50], Class Loss: 0.0671, Discrepancy Loss: 0.0836\n",
      "Epoch [14/50], Class Loss: 0.0716, Discrepancy Loss: 0.0777\n",
      "Epoch [15/50], Class Loss: 0.0503, Discrepancy Loss: 0.0899\n",
      "Epoch [16/50], Class Loss: 0.0485, Discrepancy Loss: 0.0729\n",
      "Epoch [17/50], Class Loss: 0.0803, Discrepancy Loss: 0.0949\n",
      "Epoch [18/50], Class Loss: 0.0400, Discrepancy Loss: 0.0749\n",
      "Epoch [19/50], Class Loss: 0.0760, Discrepancy Loss: 0.0687\n",
      "Epoch [20/50], Class Loss: 0.0738, Discrepancy Loss: 0.0741\n",
      "Epoch [21/50], Class Loss: 0.0439, Discrepancy Loss: 0.1024\n",
      "Epoch [22/50], Class Loss: 0.0402, Discrepancy Loss: 0.0996\n",
      "Epoch [23/50], Class Loss: 0.0398, Discrepancy Loss: 0.0918\n",
      "Epoch [24/50], Class Loss: 0.0454, Discrepancy Loss: 0.1017\n",
      "Epoch [25/50], Class Loss: 0.0333, Discrepancy Loss: 0.0886\n",
      "Epoch [26/50], Class Loss: 0.0354, Discrepancy Loss: 0.0987\n",
      "Epoch [27/50], Class Loss: 0.0328, Discrepancy Loss: 0.0927\n",
      "Epoch [28/50], Class Loss: 0.0445, Discrepancy Loss: 0.0948\n",
      "Epoch [29/50], Class Loss: 0.0380, Discrepancy Loss: 0.0971\n",
      "Epoch [30/50], Class Loss: 0.0399, Discrepancy Loss: 0.0945\n",
      "Epoch [31/50], Class Loss: 0.0400, Discrepancy Loss: 0.0953\n",
      "Epoch [32/50], Class Loss: 0.0493, Discrepancy Loss: 0.0978\n",
      "Epoch [33/50], Class Loss: 0.0883, Discrepancy Loss: 0.0942\n",
      "Epoch [34/50], Class Loss: 0.0301, Discrepancy Loss: 0.0978\n",
      "Epoch [35/50], Class Loss: 0.0396, Discrepancy Loss: 0.0970\n",
      "Epoch [36/50], Class Loss: 0.0514, Discrepancy Loss: 0.0970\n",
      "Epoch [37/50], Class Loss: 0.0349, Discrepancy Loss: 0.0988\n",
      "Epoch [38/50], Class Loss: 0.0335, Discrepancy Loss: 0.1027\n",
      "Epoch [39/50], Class Loss: 0.0322, Discrepancy Loss: 0.1017\n",
      "Epoch [40/50], Class Loss: 0.0442, Discrepancy Loss: 0.0928\n",
      "Epoch [41/50], Class Loss: 0.0349, Discrepancy Loss: 0.0994\n",
      "Epoch [42/50], Class Loss: 0.0483, Discrepancy Loss: 0.0957\n",
      "Epoch [43/50], Class Loss: 0.0490, Discrepancy Loss: 0.0935\n",
      "Epoch [44/50], Class Loss: 0.0524, Discrepancy Loss: 0.0946\n",
      "Epoch [45/50], Class Loss: 0.0374, Discrepancy Loss: 0.0886\n",
      "Epoch [46/50], Class Loss: 0.0327, Discrepancy Loss: 0.0940\n",
      "Epoch [47/50], Class Loss: 0.0296, Discrepancy Loss: 0.1006\n",
      "Epoch [48/50], Class Loss: 0.0432, Discrepancy Loss: 0.0949\n",
      "Epoch [49/50], Class Loss: 0.0292, Discrepancy Loss: 0.0983\n",
      "Epoch [50/50], Class Loss: 0.0363, Discrepancy Loss: 0.1007\n",
      "Source Domain Performance - Accuracy: 93.59%, Precision: 94.75%, Recall: 93.33%, F1 Score: 93.51%\n",
      "Target Domain Performance - Accuracy: 80.22%, Precision: 86.15%, Recall: 80.20%, F1 Score: 79.42%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 3.1519, Discrepancy Loss: 0.1102\n",
      "Epoch [2/50], Class Loss: 1.7495, Discrepancy Loss: 0.1454\n",
      "Epoch [3/50], Class Loss: 1.3864, Discrepancy Loss: 0.1473\n",
      "Epoch [4/50], Class Loss: 1.2042, Discrepancy Loss: 0.1398\n",
      "Epoch [5/50], Class Loss: 1.0971, Discrepancy Loss: 0.1508\n",
      "Epoch [6/50], Class Loss: 1.0405, Discrepancy Loss: 0.1414\n",
      "Epoch [7/50], Class Loss: 1.0267, Discrepancy Loss: 0.1391\n",
      "Epoch [8/50], Class Loss: 0.9900, Discrepancy Loss: 0.1281\n",
      "Epoch [9/50], Class Loss: 0.9940, Discrepancy Loss: 0.1344\n",
      "Epoch [10/50], Class Loss: 0.9332, Discrepancy Loss: 0.1263\n",
      "Epoch [11/50], Class Loss: 0.9047, Discrepancy Loss: 0.1271\n",
      "Epoch [12/50], Class Loss: 0.8483, Discrepancy Loss: 0.1300\n",
      "Epoch [13/50], Class Loss: 0.8268, Discrepancy Loss: 0.1156\n",
      "Epoch [14/50], Class Loss: 0.7754, Discrepancy Loss: 0.1227\n",
      "Epoch [15/50], Class Loss: 0.7023, Discrepancy Loss: 0.0998\n",
      "Epoch [16/50], Class Loss: 0.5032, Discrepancy Loss: 0.1045\n",
      "Epoch [17/50], Class Loss: 0.3307, Discrepancy Loss: 0.0998\n",
      "Epoch [18/50], Class Loss: 0.2296, Discrepancy Loss: 0.0914\n",
      "Epoch [19/50], Class Loss: 0.1755, Discrepancy Loss: 0.0835\n",
      "Epoch [20/50], Class Loss: 0.1669, Discrepancy Loss: 0.0770\n",
      "Epoch [21/50], Class Loss: 0.1041, Discrepancy Loss: 0.0786\n",
      "Epoch [22/50], Class Loss: 0.1017, Discrepancy Loss: 0.0744\n",
      "Epoch [23/50], Class Loss: 0.0962, Discrepancy Loss: 0.0702\n",
      "Epoch [24/50], Class Loss: 0.0992, Discrepancy Loss: 0.0798\n",
      "Epoch [25/50], Class Loss: 0.1047, Discrepancy Loss: 0.0694\n",
      "Epoch [26/50], Class Loss: 0.1039, Discrepancy Loss: 0.0641\n",
      "Epoch [27/50], Class Loss: 0.1008, Discrepancy Loss: 0.0669\n",
      "Epoch [28/50], Class Loss: 0.1049, Discrepancy Loss: 0.0669\n",
      "Epoch [29/50], Class Loss: 0.0918, Discrepancy Loss: 0.0666\n",
      "Epoch [30/50], Class Loss: 0.0914, Discrepancy Loss: 0.0600\n",
      "Epoch [31/50], Class Loss: 0.1044, Discrepancy Loss: 0.0623\n",
      "Epoch [32/50], Class Loss: 0.0867, Discrepancy Loss: 0.0663\n",
      "Epoch [33/50], Class Loss: 0.1078, Discrepancy Loss: 0.0684\n",
      "Epoch [34/50], Class Loss: 0.0817, Discrepancy Loss: 0.0659\n",
      "Epoch [35/50], Class Loss: 0.0905, Discrepancy Loss: 0.0650\n",
      "Epoch [36/50], Class Loss: 0.1029, Discrepancy Loss: 0.0614\n",
      "Epoch [37/50], Class Loss: 0.1036, Discrepancy Loss: 0.0626\n",
      "Epoch [38/50], Class Loss: 0.0978, Discrepancy Loss: 0.0637\n",
      "Epoch [39/50], Class Loss: 0.1078, Discrepancy Loss: 0.0629\n",
      "Epoch [40/50], Class Loss: 0.0789, Discrepancy Loss: 0.0633\n",
      "Epoch [41/50], Class Loss: 0.1020, Discrepancy Loss: 0.0599\n",
      "Epoch [42/50], Class Loss: 0.0972, Discrepancy Loss: 0.0650\n",
      "Epoch [43/50], Class Loss: 0.0979, Discrepancy Loss: 0.0596\n",
      "Epoch [44/50], Class Loss: 0.1073, Discrepancy Loss: 0.0675\n",
      "Epoch [45/50], Class Loss: 0.0924, Discrepancy Loss: 0.0651\n",
      "Epoch [46/50], Class Loss: 0.0817, Discrepancy Loss: 0.0665\n",
      "Epoch [47/50], Class Loss: 0.1025, Discrepancy Loss: 0.0634\n",
      "Epoch [48/50], Class Loss: 0.1192, Discrepancy Loss: 0.0587\n",
      "Epoch [49/50], Class Loss: 0.0994, Discrepancy Loss: 0.0670\n",
      "Epoch [50/50], Class Loss: 0.0952, Discrepancy Loss: 0.0622\n",
      "Source Domain Performance - Accuracy: 96.28%, Precision: 96.37%, Recall: 96.29%, F1 Score: 96.28%\n",
      "Target Domain Performance - Accuracy: 83.45%, Precision: 83.99%, Recall: 83.73%, F1 Score: 83.78%\n",
      "\n",
      "Source performance: 94.28% 95.06% 94.12% 94.19%\n",
      "Target performance: 82.17% 86.30% 82.24% 81.69%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 98.21%\n",
      "qpsk: 51.33%\n",
      "16qam: 83.82%\n",
      "8apsk: 95.61%\n",
      "\n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 2.4216, Discrepancy Loss: 0.0907\n",
      "Validation Loss: 1.6927\n",
      "Epoch [2/50], Class Loss: 1.5690, Discrepancy Loss: 0.0555\n",
      "Validation Loss: 1.5011\n",
      "Epoch [3/50], Class Loss: 1.3610, Discrepancy Loss: 0.0639\n",
      "Validation Loss: 0.5670\n",
      "Epoch [4/50], Class Loss: 0.3263, Discrepancy Loss: 0.0404\n",
      "Validation Loss: 0.1592\n",
      "Epoch [5/50], Class Loss: 0.1662, Discrepancy Loss: 0.0232\n",
      "Validation Loss: 0.8625\n",
      "Epoch [6/50], Class Loss: 0.2139, Discrepancy Loss: 0.0341\n",
      "Validation Loss: 0.1170\n",
      "Epoch [7/50], Class Loss: 0.2396, Discrepancy Loss: 0.0416\n",
      "Validation Loss: 0.3164\n",
      "Epoch [8/50], Class Loss: 0.2182, Discrepancy Loss: 0.0292\n",
      "Validation Loss: 0.0738\n",
      "Epoch [9/50], Class Loss: 0.1757, Discrepancy Loss: 0.0256\n",
      "Validation Loss: 0.0679\n",
      "Epoch [10/50], Class Loss: 0.1544, Discrepancy Loss: 0.0192\n",
      "Validation Loss: 0.0894\n",
      "Epoch [11/50], Class Loss: 0.0171, Discrepancy Loss: 0.0144\n",
      "Validation Loss: 0.0473\n",
      "Epoch [12/50], Class Loss: 0.0234, Discrepancy Loss: 0.0144\n",
      "Validation Loss: 0.0468\n",
      "Epoch [13/50], Class Loss: 0.0227, Discrepancy Loss: 0.0133\n",
      "Validation Loss: 0.0643\n",
      "Epoch [14/50], Class Loss: 0.0196, Discrepancy Loss: 0.0188\n",
      "Validation Loss: 0.0613\n",
      "Epoch [15/50], Class Loss: 0.0207, Discrepancy Loss: 0.0330\n",
      "Validation Loss: 0.0514\n",
      "Epoch [16/50], Class Loss: 0.0195, Discrepancy Loss: 0.0139\n",
      "Validation Loss: 0.0789\n",
      "Epoch [17/50], Class Loss: 0.0125, Discrepancy Loss: 0.0136\n",
      "Validation Loss: 0.0536\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.34%, Precision: 99.32%, Recall: 99.33%, F1 Score: 99.32%\n",
      "Target Domain Performance - Accuracy: 64.81%, Precision: 75.12%, Recall: 64.99%, F1 Score: 57.28%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.1676, Discrepancy Loss: 0.0675\n",
      "Validation Loss: 1.6170\n",
      "Epoch [2/50], Class Loss: 1.5972, Discrepancy Loss: 0.0407\n",
      "Validation Loss: 1.6613\n",
      "Epoch [3/50], Class Loss: 1.1025, Discrepancy Loss: 0.0595\n",
      "Validation Loss: 0.1589\n",
      "Epoch [4/50], Class Loss: 0.3737, Discrepancy Loss: 0.0372\n",
      "Validation Loss: 1.6018\n",
      "Epoch [5/50], Class Loss: 0.2549, Discrepancy Loss: 0.0209\n",
      "Validation Loss: 0.1070\n",
      "Epoch [6/50], Class Loss: 0.2108, Discrepancy Loss: 0.0252\n",
      "Validation Loss: 0.2168\n",
      "Epoch [7/50], Class Loss: 0.1206, Discrepancy Loss: 0.0268\n",
      "Validation Loss: 0.2294\n",
      "Epoch [8/50], Class Loss: 0.1949, Discrepancy Loss: 0.0318\n",
      "Validation Loss: 0.1704\n",
      "Epoch [9/50], Class Loss: 0.2331, Discrepancy Loss: 0.0407\n",
      "Validation Loss: 1.1787\n",
      "Epoch [10/50], Class Loss: 0.2236, Discrepancy Loss: 0.0363\n",
      "Validation Loss: 0.1881\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.38%, Precision: 98.40%, Recall: 98.34%, F1 Score: 98.35%\n",
      "Target Domain Performance - Accuracy: 73.38%, Precision: 77.07%, Recall: 73.64%, F1 Score: 71.59%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 2.3022, Discrepancy Loss: 0.0737\n",
      "Validation Loss: 1.6121\n",
      "Epoch [2/50], Class Loss: 1.4366, Discrepancy Loss: 0.0490\n",
      "Validation Loss: 2.2178\n",
      "Epoch [3/50], Class Loss: 0.3444, Discrepancy Loss: 0.0211\n",
      "Validation Loss: 0.1281\n",
      "Epoch [4/50], Class Loss: 0.2109, Discrepancy Loss: 0.0186\n",
      "Validation Loss: 0.0644\n",
      "Epoch [5/50], Class Loss: 0.2202, Discrepancy Loss: 0.0195\n",
      "Validation Loss: 0.0986\n",
      "Epoch [6/50], Class Loss: 0.1938, Discrepancy Loss: 0.0205\n",
      "Validation Loss: 0.0667\n",
      "Epoch [7/50], Class Loss: 0.1882, Discrepancy Loss: 0.0283\n",
      "Validation Loss: 17.2839\n",
      "Epoch [8/50], Class Loss: 0.6172, Discrepancy Loss: 0.0283\n",
      "Validation Loss: 0.0621\n",
      "Epoch [9/50], Class Loss: 0.1655, Discrepancy Loss: 0.0363\n",
      "Validation Loss: 0.5883\n",
      "Epoch [10/50], Class Loss: 0.1649, Discrepancy Loss: 0.0377\n",
      "Validation Loss: 0.0821\n",
      "Epoch [11/50], Class Loss: 0.0263, Discrepancy Loss: 0.0149\n",
      "Validation Loss: 0.0705\n",
      "Epoch [12/50], Class Loss: 0.0217, Discrepancy Loss: 0.0138\n",
      "Validation Loss: 0.0542\n",
      "Epoch [13/50], Class Loss: 0.0161, Discrepancy Loss: 0.0151\n",
      "Validation Loss: 0.0668\n",
      "Epoch [14/50], Class Loss: 0.0283, Discrepancy Loss: 0.0172\n",
      "Validation Loss: 0.0918\n",
      "Epoch [15/50], Class Loss: 0.0352, Discrepancy Loss: 0.0192\n",
      "Validation Loss: 0.0792\n",
      "Epoch [16/50], Class Loss: 0.0242, Discrepancy Loss: 0.0193\n",
      "Validation Loss: 0.0951\n",
      "Epoch [17/50], Class Loss: 0.0241, Discrepancy Loss: 0.0222\n",
      "Validation Loss: 0.1185\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.62%, Precision: 98.62%, Recall: 98.58%, F1 Score: 98.59%\n",
      "Target Domain Performance - Accuracy: 56.53%, Precision: 68.92%, Recall: 56.68%, F1 Score: 49.13%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 2.6436, Discrepancy Loss: 0.1021\n",
      "Validation Loss: 1.4510\n",
      "Epoch [2/50], Class Loss: 1.5477, Discrepancy Loss: 0.0653\n",
      "Validation Loss: 1.5810\n",
      "Epoch [3/50], Class Loss: 1.5212, Discrepancy Loss: 0.0738\n",
      "Validation Loss: 1.5447\n",
      "Epoch [4/50], Class Loss: 1.0597, Discrepancy Loss: 0.0667\n",
      "Validation Loss: 0.8372\n",
      "Epoch [5/50], Class Loss: 0.2669, Discrepancy Loss: 0.0325\n",
      "Validation Loss: 0.0499\n",
      "Epoch [6/50], Class Loss: 0.2455, Discrepancy Loss: 0.0230\n",
      "Validation Loss: 0.1089\n",
      "Epoch [7/50], Class Loss: 0.1288, Discrepancy Loss: 0.0174\n",
      "Validation Loss: 0.5894\n",
      "Epoch [8/50], Class Loss: 0.1846, Discrepancy Loss: 0.0208\n",
      "Validation Loss: 0.1600\n",
      "Epoch [9/50], Class Loss: 0.1335, Discrepancy Loss: 0.0183\n",
      "Validation Loss: 0.1762\n",
      "Epoch [10/50], Class Loss: 0.1343, Discrepancy Loss: 0.0236\n",
      "Validation Loss: 0.1590\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.54%, Precision: 97.62%, Recall: 97.45%, F1 Score: 97.46%\n",
      "Target Domain Performance - Accuracy: 66.55%, Precision: 73.89%, Recall: 66.78%, F1 Score: 60.38%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 2.2176, Discrepancy Loss: 0.0806\n",
      "Validation Loss: 1.5035\n",
      "Epoch [2/50], Class Loss: 1.4660, Discrepancy Loss: 0.0312\n",
      "Validation Loss: 1.7087\n",
      "Epoch [3/50], Class Loss: 1.0081, Discrepancy Loss: 0.0389\n",
      "Validation Loss: 0.5568\n",
      "Epoch [4/50], Class Loss: 0.2019, Discrepancy Loss: 0.0193\n",
      "Validation Loss: 0.0519\n",
      "Epoch [5/50], Class Loss: 0.1531, Discrepancy Loss: 0.0152\n",
      "Validation Loss: 0.1031\n",
      "Epoch [6/50], Class Loss: 0.2254, Discrepancy Loss: 0.0146\n",
      "Validation Loss: 0.0863\n",
      "Epoch [7/50], Class Loss: 0.2459, Discrepancy Loss: 0.0195\n",
      "Validation Loss: 0.1210\n",
      "Epoch [8/50], Class Loss: 0.2025, Discrepancy Loss: 0.0210\n",
      "Validation Loss: 0.1002\n",
      "Epoch [9/50], Class Loss: 0.1900, Discrepancy Loss: 0.0237\n",
      "Validation Loss: 0.8726\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 77.76%, Precision: 86.29%, Recall: 76.66%, F1 Score: 72.16%\n",
      "Target Domain Performance - Accuracy: 28.24%, Precision: 62.93%, Recall: 27.26%, F1 Score: 18.64%\n",
      "\n",
      "Source performance: 94.33% 96.05% 94.07% 93.18%\n",
      "Target performance: 57.90% 71.58% 57.87% 51.40%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 77.95%\n",
      "qpsk: 11.37%\n",
      "16qam: 42.94%\n",
      "8apsk: 99.21%\n",
      "\n",
      "Run 1/5\n",
      "Epoch 1/50, Train Loss: 0.9857, Train Acc: 0.5351, Val Loss: 0.7439, Val Acc: 0.6115\n",
      "Epoch 2/50, Train Loss: 0.7137, Train Acc: 0.6438, Val Loss: 0.3592, Val Acc: 0.8615\n",
      "Epoch 3/50, Train Loss: 0.2175, Train Acc: 0.9175, Val Loss: 0.9495, Val Acc: 0.6781\n",
      "Epoch 4/50, Train Loss: 0.0530, Train Acc: 0.9843, Val Loss: 0.1025, Val Acc: 0.9748\n",
      "Epoch 5/50, Train Loss: 0.0626, Train Acc: 0.9829, Val Loss: 0.0424, Val Acc: 0.9898\n",
      "Epoch 6/50, Train Loss: 0.0283, Train Acc: 0.9928, Val Loss: 0.0223, Val Acc: 0.9934\n",
      "Epoch 7/50, Train Loss: 0.0415, Train Acc: 0.9907, Val Loss: 0.0647, Val Acc: 0.9832\n",
      "Epoch 8/50, Train Loss: 0.0120, Train Acc: 0.9966, Val Loss: 0.0172, Val Acc: 0.9970\n",
      "Epoch 9/50, Train Loss: 0.0187, Train Acc: 0.9954, Val Loss: 0.0508, Val Acc: 0.9886\n",
      "Epoch 10/50, Train Loss: 0.0783, Train Acc: 0.9870, Val Loss: 0.1148, Val Acc: 0.9832\n",
      "Epoch 11/50, Train Loss: 0.0046, Train Acc: 0.9987, Val Loss: 0.0218, Val Acc: 0.9952\n",
      "Epoch 12/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0203, Val Acc: 0.9946\n",
      "Epoch 13/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0193, Val Acc: 0.9952\n",
      "Early stopping!\n",
      "\n",
      "Run 2/5\n",
      "Epoch 1/50, Train Loss: 1.0439, Train Acc: 0.5550, Val Loss: 0.7414, Val Acc: 0.6463\n",
      "Epoch 2/50, Train Loss: 0.7587, Train Acc: 0.6197, Val Loss: 0.6458, Val Acc: 0.6637\n",
      "Epoch 3/50, Train Loss: 0.2346, Train Acc: 0.9052, Val Loss: 0.0593, Val Acc: 0.9814\n",
      "Epoch 4/50, Train Loss: 0.0528, Train Acc: 0.9840, Val Loss: 0.0244, Val Acc: 0.9922\n",
      "Epoch 5/50, Train Loss: 0.0437, Train Acc: 0.9892, Val Loss: 0.0297, Val Acc: 0.9928\n",
      "Epoch 6/50, Train Loss: 0.0587, Train Acc: 0.9831, Val Loss: 0.0505, Val Acc: 0.9922\n",
      "Epoch 7/50, Train Loss: 0.0395, Train Acc: 0.9898, Val Loss: 0.0308, Val Acc: 0.9916\n",
      "Epoch 8/50, Train Loss: 0.0172, Train Acc: 0.9957, Val Loss: 0.0167, Val Acc: 0.9952\n",
      "Epoch 9/50, Train Loss: 0.0178, Train Acc: 0.9943, Val Loss: 0.0217, Val Acc: 0.9946\n",
      "Epoch 10/50, Train Loss: 0.0153, Train Acc: 0.9960, Val Loss: 0.0206, Val Acc: 0.9958\n",
      "Epoch 11/50, Train Loss: 0.0032, Train Acc: 0.9993, Val Loss: 0.0167, Val Acc: 0.9964\n",
      "Epoch 12/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0210, Val Acc: 0.9958\n",
      "Epoch 13/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0173, Val Acc: 0.9964\n",
      "Early stopping!\n",
      "\n",
      "Run 3/5\n",
      "Epoch 1/50, Train Loss: 1.1157, Train Acc: 0.5163, Val Loss: 0.7303, Val Acc: 0.6391\n",
      "Epoch 2/50, Train Loss: 0.7705, Train Acc: 0.6207, Val Loss: 0.6923, Val Acc: 0.6481\n",
      "Epoch 3/50, Train Loss: 0.5183, Train Acc: 0.7572, Val Loss: 0.1579, Val Acc: 0.9329\n",
      "Epoch 4/50, Train Loss: 0.0969, Train Acc: 0.9675, Val Loss: 0.3809, Val Acc: 0.9113\n",
      "Epoch 5/50, Train Loss: 0.0685, Train Acc: 0.9814, Val Loss: 0.1141, Val Acc: 0.9670\n",
      "Epoch 6/50, Train Loss: 0.0472, Train Acc: 0.9859, Val Loss: 0.2070, Val Acc: 0.9478\n",
      "Epoch 7/50, Train Loss: 0.0384, Train Acc: 0.9909, Val Loss: 0.0385, Val Acc: 0.9904\n",
      "Epoch 8/50, Train Loss: 0.0173, Train Acc: 0.9952, Val Loss: 0.0753, Val Acc: 0.9874\n",
      "Epoch 9/50, Train Loss: 0.0182, Train Acc: 0.9952, Val Loss: 0.0369, Val Acc: 0.9922\n",
      "Epoch 10/50, Train Loss: 0.0348, Train Acc: 0.9915, Val Loss: 0.0377, Val Acc: 0.9916\n",
      "Epoch 11/50, Train Loss: 0.0056, Train Acc: 0.9984, Val Loss: 0.0098, Val Acc: 0.9970\n",
      "Epoch 12/50, Train Loss: 0.0035, Train Acc: 0.9993, Val Loss: 0.0088, Val Acc: 0.9970\n",
      "Epoch 13/50, Train Loss: 0.0028, Train Acc: 0.9994, Val Loss: 0.0103, Val Acc: 0.9976\n",
      "Epoch 14/50, Train Loss: 0.0030, Train Acc: 0.9994, Val Loss: 0.0092, Val Acc: 0.9970\n",
      "Epoch 15/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0103, Val Acc: 0.9982\n",
      "Epoch 16/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0091, Val Acc: 0.9970\n",
      "Epoch 17/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0087, Val Acc: 0.9976\n",
      "Epoch 18/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0129, Val Acc: 0.9976\n",
      "Epoch 19/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0115, Val Acc: 0.9976\n",
      "Epoch 20/50, Train Loss: 0.0023, Train Acc: 0.9994, Val Loss: 0.0107, Val Acc: 0.9970\n",
      "Epoch 21/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0101, Val Acc: 0.9970\n",
      "Epoch 22/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0095, Val Acc: 0.9970\n",
      "Early stopping!\n",
      "\n",
      "Run 4/5\n",
      "Epoch 1/50, Train Loss: 0.9717, Train Acc: 0.5175, Val Loss: 0.7635, Val Acc: 0.6385\n",
      "Epoch 2/50, Train Loss: 0.7445, Train Acc: 0.6297, Val Loss: 0.7010, Val Acc: 0.6451\n",
      "Epoch 3/50, Train Loss: 0.6055, Train Acc: 0.7224, Val Loss: 0.1534, Val Acc: 0.9394\n",
      "Epoch 4/50, Train Loss: 0.1179, Train Acc: 0.9577, Val Loss: 0.0516, Val Acc: 0.9856\n",
      "Epoch 5/50, Train Loss: 0.0921, Train Acc: 0.9703, Val Loss: 0.0543, Val Acc: 0.9838\n",
      "Epoch 6/50, Train Loss: 0.0623, Train Acc: 0.9823, Val Loss: 0.0390, Val Acc: 0.9898\n",
      "Epoch 7/50, Train Loss: 0.0591, Train Acc: 0.9822, Val Loss: 0.0555, Val Acc: 0.9832\n",
      "Epoch 8/50, Train Loss: 0.0316, Train Acc: 0.9904, Val Loss: 0.0449, Val Acc: 0.9892\n",
      "Epoch 9/50, Train Loss: 0.0231, Train Acc: 0.9939, Val Loss: 0.1681, Val Acc: 0.9580\n",
      "Epoch 10/50, Train Loss: 0.0182, Train Acc: 0.9954, Val Loss: 0.0359, Val Acc: 0.9946\n",
      "Epoch 11/50, Train Loss: 0.0043, Train Acc: 0.9993, Val Loss: 0.0331, Val Acc: 0.9946\n",
      "Epoch 12/50, Train Loss: 0.0025, Train Acc: 0.9993, Val Loss: 0.0267, Val Acc: 0.9964\n",
      "Epoch 13/50, Train Loss: 0.0020, Train Acc: 0.9994, Val Loss: 0.0265, Val Acc: 0.9958\n",
      "Epoch 14/50, Train Loss: 0.0023, Train Acc: 0.9996, Val Loss: 0.0259, Val Acc: 0.9958\n",
      "Epoch 15/50, Train Loss: 0.0017, Train Acc: 0.9994, Val Loss: 0.0296, Val Acc: 0.9952\n",
      "Epoch 16/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0258, Val Acc: 0.9976\n",
      "Epoch 17/50, Train Loss: 0.0011, Train Acc: 0.9997, Val Loss: 0.0281, Val Acc: 0.9958\n",
      "Epoch 18/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0275, Val Acc: 0.9964\n",
      "Epoch 19/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0268, Val Acc: 0.9970\n",
      "Epoch 20/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0333, Val Acc: 0.9946\n",
      "Epoch 21/50, Train Loss: 0.0010, Train Acc: 0.9996, Val Loss: 0.0291, Val Acc: 0.9964\n",
      "Early stopping!\n",
      "\n",
      "Run 5/5\n",
      "Epoch 1/50, Train Loss: 1.0005, Train Acc: 0.5580, Val Loss: 0.7860, Val Acc: 0.6265\n",
      "Epoch 2/50, Train Loss: 0.7427, Train Acc: 0.6309, Val Loss: 0.5913, Val Acc: 0.7074\n",
      "Epoch 3/50, Train Loss: 0.2076, Train Acc: 0.9202, Val Loss: 0.0379, Val Acc: 0.9856\n",
      "Epoch 4/50, Train Loss: 0.1162, Train Acc: 0.9622, Val Loss: 0.0487, Val Acc: 0.9814\n",
      "Epoch 5/50, Train Loss: 0.0352, Train Acc: 0.9906, Val Loss: 0.0356, Val Acc: 0.9868\n",
      "Epoch 6/50, Train Loss: 0.0387, Train Acc: 0.9897, Val Loss: 0.0310, Val Acc: 0.9916\n",
      "Epoch 7/50, Train Loss: 0.0903, Train Acc: 0.9766, Val Loss: 0.0332, Val Acc: 0.9916\n",
      "Epoch 8/50, Train Loss: 0.0218, Train Acc: 0.9934, Val Loss: 0.0324, Val Acc: 0.9952\n",
      "Epoch 9/50, Train Loss: 0.0253, Train Acc: 0.9939, Val Loss: 0.1065, Val Acc: 0.9784\n",
      "Epoch 10/50, Train Loss: 0.0499, Train Acc: 0.9876, Val Loss: 0.0371, Val Acc: 0.9904\n",
      "Epoch 11/50, Train Loss: 0.0063, Train Acc: 0.9984, Val Loss: 0.0149, Val Acc: 0.9952\n",
      "Epoch 12/50, Train Loss: 0.0036, Train Acc: 0.9991, Val Loss: 0.0133, Val Acc: 0.9964\n",
      "Epoch 13/50, Train Loss: 0.0033, Train Acc: 0.9993, Val Loss: 0.0131, Val Acc: 0.9958\n",
      "Epoch 14/50, Train Loss: 0.0031, Train Acc: 0.9996, Val Loss: 0.0153, Val Acc: 0.9958\n",
      "Epoch 15/50, Train Loss: 0.0031, Train Acc: 0.9993, Val Loss: 0.0123, Val Acc: 0.9970\n",
      "Epoch 16/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0144, Val Acc: 0.9964\n",
      "Epoch 17/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0110, Val Acc: 0.9970\n",
      "Epoch 18/50, Train Loss: 0.0028, Train Acc: 0.9994, Val Loss: 0.0142, Val Acc: 0.9970\n",
      "Epoch 19/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0122, Val Acc: 0.9970\n",
      "Epoch 20/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0142, Val Acc: 0.9970\n",
      "Epoch 21/50, Train Loss: 0.0028, Train Acc: 0.9996, Val Loss: 0.0127, Val Acc: 0.9970\n",
      "Epoch 22/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0120, Val Acc: 0.9964\n",
      "Early stopping!\n",
      "\n",
      "Source performance: 99.63 99.63 99.63 99.63\n",
      "Target performance: 81.70 86.00 81.89 81.86\n",
      "\n",
      "bpsk: 87.77\n",
      "qpsk: 58.41\n",
      "16qam: 81.66\n",
      "8apsk: 99.71\n",
      "Epoch 1/50, Loss: 3.2453, Domain Loss: 1.6365, Class Loss: 1.6087\n",
      "Epoch 2/50, Loss: 2.1829, Domain Loss: 1.3502, Class Loss: 0.8327\n",
      "Epoch 3/50, Loss: 2.0928, Domain Loss: 1.3437, Class Loss: 0.7491\n",
      "Epoch 4/50, Loss: 2.0601, Domain Loss: 1.2675, Class Loss: 0.7927\n",
      "Epoch 5/50, Loss: 2.0016, Domain Loss: 1.2706, Class Loss: 0.7310\n",
      "Epoch 6/50, Loss: 2.0290, Domain Loss: 1.2714, Class Loss: 0.7577\n",
      "Epoch 7/50, Loss: 1.9391, Domain Loss: 1.2321, Class Loss: 0.7070\n",
      "Epoch 8/50, Loss: 2.0163, Domain Loss: 1.2759, Class Loss: 0.7405\n",
      "Epoch 9/50, Loss: 2.0836, Domain Loss: 1.3522, Class Loss: 0.7314\n",
      "Epoch 10/50, Loss: 1.8778, Domain Loss: 1.3210, Class Loss: 0.5569\n",
      "Epoch 11/50, Loss: 2.2163, Domain Loss: 1.5735, Class Loss: 0.6429\n",
      "Epoch 12/50, Loss: 1.5594, Domain Loss: 1.2699, Class Loss: 0.2895\n",
      "Epoch 13/50, Loss: 1.2949, Domain Loss: 1.1308, Class Loss: 0.1641\n",
      "Epoch 14/50, Loss: 1.1982, Domain Loss: 1.0705, Class Loss: 0.1277\n",
      "Epoch 15/50, Loss: 1.2903, Domain Loss: 1.1207, Class Loss: 0.1696\n",
      "Epoch 16/50, Loss: 1.4100, Domain Loss: 1.2391, Class Loss: 0.1708\n",
      "Epoch 17/50, Loss: 1.3340, Domain Loss: 1.2247, Class Loss: 0.1093\n",
      "Epoch 18/50, Loss: 1.3024, Domain Loss: 1.2352, Class Loss: 0.0672\n",
      "Epoch 19/50, Loss: 1.3684, Domain Loss: 1.2024, Class Loss: 0.1660\n",
      "Epoch 20/50, Loss: 1.2779, Domain Loss: 1.1555, Class Loss: 0.1224\n",
      "Epoch 21/50, Loss: 1.2040, Domain Loss: 1.1543, Class Loss: 0.0497\n",
      "Epoch 22/50, Loss: 1.3478, Domain Loss: 1.2978, Class Loss: 0.0500\n",
      "Epoch 23/50, Loss: 1.4510, Domain Loss: 1.3779, Class Loss: 0.0731\n",
      "Epoch 24/50, Loss: 1.5016, Domain Loss: 1.3975, Class Loss: 0.1041\n",
      "Epoch 25/50, Loss: 1.4721, Domain Loss: 1.3804, Class Loss: 0.0918\n",
      "Epoch 26/50, Loss: 1.3938, Domain Loss: 1.3701, Class Loss: 0.0237\n",
      "Epoch 27/50, Loss: 1.3325, Domain Loss: 1.3077, Class Loss: 0.0248\n",
      "Epoch 28/50, Loss: 1.1496, Domain Loss: 1.1403, Class Loss: 0.0093\n",
      "Epoch 29/50, Loss: 1.0685, Domain Loss: 1.0385, Class Loss: 0.0300\n",
      "Epoch 30/50, Loss: 1.0688, Domain Loss: 1.0481, Class Loss: 0.0207\n",
      "Epoch 31/50, Loss: 1.3964, Domain Loss: 1.3094, Class Loss: 0.0869\n",
      "Epoch 32/50, Loss: 1.4479, Domain Loss: 1.3856, Class Loss: 0.0623\n",
      "Epoch 33/50, Loss: 1.4104, Domain Loss: 1.3820, Class Loss: 0.0284\n",
      "Epoch 34/50, Loss: 1.4142, Domain Loss: 1.3702, Class Loss: 0.0440\n",
      "Epoch 35/50, Loss: 1.3631, Domain Loss: 1.3371, Class Loss: 0.0260\n",
      "Epoch 36/50, Loss: 1.3533, Domain Loss: 1.3239, Class Loss: 0.0294\n",
      "Epoch 37/50, Loss: 1.3462, Domain Loss: 1.2729, Class Loss: 0.0733\n",
      "Epoch 38/50, Loss: 1.4048, Domain Loss: 1.3570, Class Loss: 0.0478\n",
      "Epoch 39/50, Loss: 1.4147, Domain Loss: 1.3880, Class Loss: 0.0267\n",
      "Epoch 40/50, Loss: 1.4024, Domain Loss: 1.3875, Class Loss: 0.0149\n",
      "Epoch 41/50, Loss: 1.4110, Domain Loss: 1.3871, Class Loss: 0.0239\n",
      "Epoch 42/50, Loss: 1.4000, Domain Loss: 1.3869, Class Loss: 0.0131\n",
      "Epoch 43/50, Loss: 1.3955, Domain Loss: 1.3867, Class Loss: 0.0088\n",
      "Epoch 44/50, Loss: 1.3883, Domain Loss: 1.3863, Class Loss: 0.0019\n",
      "Epoch 45/50, Loss: 1.3887, Domain Loss: 1.3865, Class Loss: 0.0022\n",
      "Epoch 46/50, Loss: 1.3931, Domain Loss: 1.3862, Class Loss: 0.0069\n",
      "Epoch 47/50, Loss: 1.3923, Domain Loss: 1.3864, Class Loss: 0.0059\n",
      "Epoch 48/50, Loss: 1.3893, Domain Loss: 1.3863, Class Loss: 0.0030\n",
      "Epoch 49/50, Loss: 1.3959, Domain Loss: 1.3863, Class Loss: 0.0095\n",
      "Epoch 50/50, Loss: 1.3886, Domain Loss: 1.3860, Class Loss: 0.0026\n",
      "77.82\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.4645, Domain Loss: 1.7337, Class Loss: 1.7308\n",
      "Epoch 2/50, Loss: 2.3146, Domain Loss: 1.4099, Class Loss: 0.9047\n",
      "Epoch 3/50, Loss: 2.0774, Domain Loss: 1.2978, Class Loss: 0.7796\n",
      "Epoch 4/50, Loss: 2.1074, Domain Loss: 1.2994, Class Loss: 0.8080\n",
      "Epoch 5/50, Loss: 2.0944, Domain Loss: 1.2659, Class Loss: 0.8285\n",
      "Epoch 6/50, Loss: 1.9564, Domain Loss: 1.2115, Class Loss: 0.7449\n",
      "Epoch 7/50, Loss: 2.0007, Domain Loss: 1.2678, Class Loss: 0.7329\n",
      "Epoch 8/50, Loss: 2.0266, Domain Loss: 1.2688, Class Loss: 0.7577\n",
      "Epoch 9/50, Loss: 2.1483, Domain Loss: 1.3639, Class Loss: 0.7844\n",
      "Epoch 10/50, Loss: 2.0703, Domain Loss: 1.2994, Class Loss: 0.7709\n",
      "Epoch 11/50, Loss: 2.0329, Domain Loss: 1.3022, Class Loss: 0.7307\n",
      "Epoch 12/50, Loss: 1.9911, Domain Loss: 1.2603, Class Loss: 0.7308\n",
      "Epoch 13/50, Loss: 1.9649, Domain Loss: 1.3085, Class Loss: 0.6564\n",
      "Epoch 14/50, Loss: 1.8477, Domain Loss: 1.2721, Class Loss: 0.5756\n",
      "Epoch 15/50, Loss: 1.7455, Domain Loss: 1.2546, Class Loss: 0.4909\n",
      "Epoch 16/50, Loss: 1.6358, Domain Loss: 1.2235, Class Loss: 0.4123\n",
      "Epoch 17/50, Loss: 2.3232, Domain Loss: 1.7101, Class Loss: 0.6131\n",
      "Epoch 18/50, Loss: 1.8402, Domain Loss: 1.4055, Class Loss: 0.4347\n",
      "Epoch 19/50, Loss: 1.4921, Domain Loss: 1.3254, Class Loss: 0.1667\n",
      "Epoch 20/50, Loss: 1.5853, Domain Loss: 1.4662, Class Loss: 0.1191\n",
      "Epoch 21/50, Loss: 1.4777, Domain Loss: 1.3867, Class Loss: 0.0910\n",
      "Epoch 22/50, Loss: 1.6619, Domain Loss: 1.5698, Class Loss: 0.0922\n",
      "Epoch 23/50, Loss: 1.4758, Domain Loss: 1.3867, Class Loss: 0.0891\n",
      "Epoch 24/50, Loss: 1.4305, Domain Loss: 1.3866, Class Loss: 0.0439\n",
      "Epoch 25/50, Loss: 1.4465, Domain Loss: 1.3865, Class Loss: 0.0600\n",
      "Epoch 26/50, Loss: 1.5804, Domain Loss: 1.5261, Class Loss: 0.0543\n",
      "Epoch 27/50, Loss: 1.4327, Domain Loss: 1.3865, Class Loss: 0.0461\n",
      "Epoch 28/50, Loss: 1.5670, Domain Loss: 1.5127, Class Loss: 0.0543\n",
      "Epoch 29/50, Loss: 1.4248, Domain Loss: 1.3866, Class Loss: 0.0382\n",
      "Epoch 30/50, Loss: 1.4944, Domain Loss: 1.3865, Class Loss: 0.1079\n",
      "Epoch 31/50, Loss: 1.4902, Domain Loss: 1.3864, Class Loss: 0.1038\n",
      "Epoch 32/50, Loss: 1.4257, Domain Loss: 1.3864, Class Loss: 0.0393\n",
      "Epoch 33/50, Loss: 1.6197, Domain Loss: 1.5881, Class Loss: 0.0316\n",
      "Epoch 34/50, Loss: 1.4175, Domain Loss: 1.3864, Class Loss: 0.0311\n",
      "Epoch 35/50, Loss: 1.4146, Domain Loss: 1.3864, Class Loss: 0.0282\n",
      "Epoch 36/50, Loss: 1.4136, Domain Loss: 1.3864, Class Loss: 0.0272\n",
      "Epoch 37/50, Loss: 1.3990, Domain Loss: 1.3863, Class Loss: 0.0126\n",
      "Epoch 38/50, Loss: 1.3980, Domain Loss: 1.3858, Class Loss: 0.0123\n",
      "Epoch 39/50, Loss: 1.3834, Domain Loss: 1.3626, Class Loss: 0.0208\n",
      "Epoch 40/50, Loss: 1.4660, Domain Loss: 1.3859, Class Loss: 0.0801\n",
      "Epoch 41/50, Loss: 1.3776, Domain Loss: 1.3494, Class Loss: 0.0283\n",
      "Epoch 42/50, Loss: 1.4177, Domain Loss: 1.3857, Class Loss: 0.0320\n",
      "Epoch 43/50, Loss: 1.3875, Domain Loss: 1.3816, Class Loss: 0.0059\n",
      "Epoch 44/50, Loss: 1.3814, Domain Loss: 1.3620, Class Loss: 0.0194\n",
      "Epoch 45/50, Loss: 1.4066, Domain Loss: 1.3647, Class Loss: 0.0419\n",
      "Epoch 46/50, Loss: 1.3508, Domain Loss: 1.3335, Class Loss: 0.0172\n",
      "Epoch 47/50, Loss: 1.3986, Domain Loss: 1.3703, Class Loss: 0.0283\n",
      "Epoch 48/50, Loss: 1.4328, Domain Loss: 1.3831, Class Loss: 0.0497\n",
      "Epoch 49/50, Loss: 1.3946, Domain Loss: 1.3881, Class Loss: 0.0065\n",
      "Epoch 50/50, Loss: 1.4007, Domain Loss: 1.3874, Class Loss: 0.0133\n",
      "92.33\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8137, Domain Loss: 1.9054, Class Loss: 1.9083\n",
      "Epoch 2/50, Loss: 2.2694, Domain Loss: 1.3700, Class Loss: 0.8993\n",
      "Epoch 3/50, Loss: 2.1136, Domain Loss: 1.3054, Class Loss: 0.8082\n",
      "Epoch 4/50, Loss: 2.1510, Domain Loss: 1.3531, Class Loss: 0.7979\n",
      "Epoch 5/50, Loss: 2.4360, Domain Loss: 1.5223, Class Loss: 0.9137\n",
      "Epoch 6/50, Loss: 2.0002, Domain Loss: 1.2650, Class Loss: 0.7352\n",
      "Epoch 7/50, Loss: 1.9820, Domain Loss: 1.2260, Class Loss: 0.7560\n",
      "Epoch 8/50, Loss: 1.9747, Domain Loss: 1.2215, Class Loss: 0.7532\n",
      "Epoch 9/50, Loss: 1.8857, Domain Loss: 1.2071, Class Loss: 0.6786\n",
      "Epoch 10/50, Loss: 2.0696, Domain Loss: 1.2810, Class Loss: 0.7887\n",
      "Epoch 11/50, Loss: 2.3991, Domain Loss: 1.5011, Class Loss: 0.8980\n",
      "Epoch 12/50, Loss: 2.1707, Domain Loss: 1.4415, Class Loss: 0.7291\n",
      "Epoch 13/50, Loss: 13.8360, Domain Loss: 11.0014, Class Loss: 2.8345\n",
      "Epoch 14/50, Loss: 20.4251, Domain Loss: 19.0062, Class Loss: 1.4189\n",
      "Epoch 15/50, Loss: 4.5687, Domain Loss: 3.1751, Class Loss: 1.3936\n",
      "Epoch 16/50, Loss: 2.9160, Domain Loss: 1.5238, Class Loss: 1.3922\n",
      "Epoch 17/50, Loss: 2.8991, Domain Loss: 1.5050, Class Loss: 1.3941\n",
      "Epoch 18/50, Loss: 2.9448, Domain Loss: 1.5541, Class Loss: 1.3907\n",
      "Epoch 19/50, Loss: 3.0866, Domain Loss: 1.6992, Class Loss: 1.3874\n",
      "Epoch 20/50, Loss: 5.9398, Domain Loss: 4.5486, Class Loss: 1.3913\n",
      "Epoch 21/50, Loss: 2.9768, Domain Loss: 1.5910, Class Loss: 1.3858\n",
      "Epoch 22/50, Loss: 2.8874, Domain Loss: 1.5129, Class Loss: 1.3745\n",
      "Epoch 23/50, Loss: 2.7627, Domain Loss: 1.4431, Class Loss: 1.3195\n",
      "Epoch 24/50, Loss: 2.7955, Domain Loss: 1.3937, Class Loss: 1.4018\n",
      "Epoch 25/50, Loss: 2.7887, Domain Loss: 1.3732, Class Loss: 1.4155\n",
      "Epoch 26/50, Loss: 2.7565, Domain Loss: 1.3666, Class Loss: 1.3899\n",
      "Epoch 27/50, Loss: 2.9692, Domain Loss: 1.5834, Class Loss: 1.3857\n",
      "Epoch 28/50, Loss: 2.8402, Domain Loss: 1.4557, Class Loss: 1.3845\n",
      "Epoch 29/50, Loss: 2.8047, Domain Loss: 1.4251, Class Loss: 1.3797\n",
      "Epoch 30/50, Loss: 2.7383, Domain Loss: 1.3561, Class Loss: 1.3822\n",
      "Epoch 31/50, Loss: 2.7269, Domain Loss: 1.3496, Class Loss: 1.3773\n",
      "Epoch 32/50, Loss: 2.7342, Domain Loss: 1.3490, Class Loss: 1.3852\n",
      "Epoch 33/50, Loss: 2.7247, Domain Loss: 1.3460, Class Loss: 1.3786\n",
      "Epoch 34/50, Loss: 2.7357, Domain Loss: 1.3691, Class Loss: 1.3666\n",
      "Epoch 35/50, Loss: 2.7190, Domain Loss: 1.3558, Class Loss: 1.3632\n",
      "Epoch 36/50, Loss: 2.7383, Domain Loss: 1.3772, Class Loss: 1.3611\n",
      "Epoch 37/50, Loss: 2.6902, Domain Loss: 1.3740, Class Loss: 1.3162\n",
      "Epoch 38/50, Loss: 2.8426, Domain Loss: 1.4011, Class Loss: 1.4416\n",
      "Epoch 39/50, Loss: 2.7557, Domain Loss: 1.3692, Class Loss: 1.3865\n",
      "Epoch 40/50, Loss: 2.7606, Domain Loss: 1.3732, Class Loss: 1.3874\n",
      "Epoch 41/50, Loss: 2.7549, Domain Loss: 1.3735, Class Loss: 1.3814\n",
      "Epoch 42/50, Loss: 2.7718, Domain Loss: 1.3958, Class Loss: 1.3760\n",
      "Epoch 43/50, Loss: 2.7368, Domain Loss: 1.3789, Class Loss: 1.3579\n",
      "Epoch 44/50, Loss: 2.7057, Domain Loss: 1.3886, Class Loss: 1.3171\n",
      "Epoch 45/50, Loss: 2.7011, Domain Loss: 1.3926, Class Loss: 1.3085\n",
      "Epoch 46/50, Loss: 2.6552, Domain Loss: 1.3755, Class Loss: 1.2797\n",
      "Epoch 47/50, Loss: 2.6096, Domain Loss: 1.3712, Class Loss: 1.2384\n",
      "Epoch 48/50, Loss: 2.5686, Domain Loss: 1.3721, Class Loss: 1.1965\n",
      "Epoch 49/50, Loss: 2.5872, Domain Loss: 1.3770, Class Loss: 1.2103\n",
      "Epoch 50/50, Loss: 2.5484, Domain Loss: 1.3763, Class Loss: 1.1721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.30\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.1274, Domain Loss: 1.8369, Class Loss: 2.2905\n",
      "Epoch 2/50, Loss: 2.5109, Domain Loss: 1.3915, Class Loss: 1.1195\n",
      "Epoch 3/50, Loss: 2.1676, Domain Loss: 1.3631, Class Loss: 0.8045\n",
      "Epoch 4/50, Loss: 2.1423, Domain Loss: 1.3962, Class Loss: 0.7461\n",
      "Epoch 5/50, Loss: 2.0907, Domain Loss: 1.3417, Class Loss: 0.7490\n",
      "Epoch 6/50, Loss: 2.0512, Domain Loss: 1.3235, Class Loss: 0.7277\n",
      "Epoch 7/50, Loss: 2.0581, Domain Loss: 1.2830, Class Loss: 0.7751\n",
      "Epoch 8/50, Loss: 1.9688, Domain Loss: 1.2051, Class Loss: 0.7636\n",
      "Epoch 9/50, Loss: 1.9654, Domain Loss: 1.2053, Class Loss: 0.7601\n",
      "Epoch 10/50, Loss: 2.1792, Domain Loss: 1.3712, Class Loss: 0.8080\n",
      "Epoch 11/50, Loss: 3.6680, Domain Loss: 2.3855, Class Loss: 1.2825\n",
      "Epoch 12/50, Loss: 10.7009, Domain Loss: 8.5842, Class Loss: 2.1167\n",
      "Epoch 13/50, Loss: 3.4585, Domain Loss: 2.0090, Class Loss: 1.4495\n",
      "Epoch 14/50, Loss: 2.8295, Domain Loss: 1.4212, Class Loss: 1.4083\n",
      "Epoch 15/50, Loss: 2.8057, Domain Loss: 1.4049, Class Loss: 1.4008\n",
      "Epoch 16/50, Loss: 2.7963, Domain Loss: 1.4075, Class Loss: 1.3888\n",
      "Epoch 17/50, Loss: 2.7987, Domain Loss: 1.4083, Class Loss: 1.3904\n",
      "Epoch 18/50, Loss: 2.7956, Domain Loss: 1.4080, Class Loss: 1.3876\n",
      "Epoch 19/50, Loss: 2.7766, Domain Loss: 1.3891, Class Loss: 1.3875\n",
      "Epoch 20/50, Loss: 2.7772, Domain Loss: 1.3867, Class Loss: 1.3905\n",
      "Epoch 21/50, Loss: 2.7705, Domain Loss: 1.3865, Class Loss: 1.3840\n",
      "Epoch 22/50, Loss: 2.7672, Domain Loss: 1.3863, Class Loss: 1.3809\n",
      "Epoch 23/50, Loss: 2.7640, Domain Loss: 1.3862, Class Loss: 1.3778\n",
      "Epoch 24/50, Loss: 2.7606, Domain Loss: 1.3861, Class Loss: 1.3745\n",
      "Epoch 25/50, Loss: 2.7263, Domain Loss: 1.3859, Class Loss: 1.3404\n",
      "Epoch 26/50, Loss: 2.6784, Domain Loss: 1.3856, Class Loss: 1.2928\n",
      "Epoch 27/50, Loss: 2.4594, Domain Loss: 1.3850, Class Loss: 1.0744\n",
      "Epoch 28/50, Loss: 2.2197, Domain Loss: 1.3839, Class Loss: 0.8359\n",
      "Epoch 29/50, Loss: 2.1720, Domain Loss: 1.3823, Class Loss: 0.7898\n",
      "Epoch 30/50, Loss: 2.1167, Domain Loss: 1.3807, Class Loss: 0.7360\n",
      "Epoch 31/50, Loss: 2.1795, Domain Loss: 1.3786, Class Loss: 0.8009\n",
      "Epoch 32/50, Loss: 2.0917, Domain Loss: 1.3767, Class Loss: 0.7150\n",
      "Epoch 33/50, Loss: 2.1676, Domain Loss: 1.3730, Class Loss: 0.7945\n",
      "Epoch 34/50, Loss: 2.0940, Domain Loss: 1.3709, Class Loss: 0.7232\n",
      "Epoch 35/50, Loss: 1.9965, Domain Loss: 1.3680, Class Loss: 0.6285\n",
      "Epoch 36/50, Loss: 1.9085, Domain Loss: 1.3565, Class Loss: 0.5520\n",
      "Epoch 37/50, Loss: 1.8685, Domain Loss: 1.3574, Class Loss: 0.5111\n",
      "Epoch 38/50, Loss: 1.8187, Domain Loss: 1.3466, Class Loss: 0.4720\n",
      "Epoch 39/50, Loss: 1.9112, Domain Loss: 1.3457, Class Loss: 0.5656\n",
      "Epoch 40/50, Loss: 1.7606, Domain Loss: 1.3468, Class Loss: 0.4138\n",
      "Epoch 41/50, Loss: 1.7068, Domain Loss: 1.3379, Class Loss: 0.3690\n",
      "Epoch 42/50, Loss: 1.7130, Domain Loss: 1.3518, Class Loss: 0.3612\n",
      "Epoch 43/50, Loss: 1.9122, Domain Loss: 1.3486, Class Loss: 0.5636\n",
      "Epoch 44/50, Loss: 1.7265, Domain Loss: 1.3404, Class Loss: 0.3862\n",
      "Epoch 45/50, Loss: 1.6401, Domain Loss: 1.3406, Class Loss: 0.2996\n",
      "Epoch 46/50, Loss: 1.6259, Domain Loss: 1.3418, Class Loss: 0.2841\n",
      "Epoch 47/50, Loss: 1.6529, Domain Loss: 1.3450, Class Loss: 0.3079\n",
      "Epoch 48/50, Loss: 1.6194, Domain Loss: 1.3327, Class Loss: 0.2867\n",
      "Epoch 49/50, Loss: 1.7383, Domain Loss: 1.3307, Class Loss: 0.4076\n",
      "Epoch 50/50, Loss: 1.6657, Domain Loss: 1.3838, Class Loss: 0.2818\n",
      "77.46\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.0243, Domain Loss: 2.0426, Class Loss: 1.9817\n",
      "Epoch 2/50, Loss: 2.3439, Domain Loss: 1.3794, Class Loss: 0.9645\n",
      "Epoch 3/50, Loss: 2.1616, Domain Loss: 1.3667, Class Loss: 0.7948\n",
      "Epoch 4/50, Loss: 2.0490, Domain Loss: 1.3074, Class Loss: 0.7416\n",
      "Epoch 5/50, Loss: 1.9669, Domain Loss: 1.2282, Class Loss: 0.7387\n",
      "Epoch 6/50, Loss: 2.2576, Domain Loss: 1.4310, Class Loss: 0.8267\n",
      "Epoch 7/50, Loss: 2.6511, Domain Loss: 1.7446, Class Loss: 0.9065\n",
      "Epoch 8/50, Loss: 2.2150, Domain Loss: 1.3936, Class Loss: 0.8213\n",
      "Epoch 9/50, Loss: 2.0929, Domain Loss: 1.3010, Class Loss: 0.7919\n",
      "Epoch 10/50, Loss: 2.3103, Domain Loss: 1.4468, Class Loss: 0.8635\n",
      "Epoch 11/50, Loss: 2.1888, Domain Loss: 1.3686, Class Loss: 0.8202\n",
      "Epoch 12/50, Loss: 1.9935, Domain Loss: 1.2782, Class Loss: 0.7152\n",
      "Epoch 13/50, Loss: 1.9906, Domain Loss: 1.2986, Class Loss: 0.6920\n",
      "Epoch 14/50, Loss: 1.9569, Domain Loss: 1.3094, Class Loss: 0.6475\n",
      "Epoch 15/50, Loss: 1.9151, Domain Loss: 1.4257, Class Loss: 0.4894\n",
      "Epoch 16/50, Loss: 2.0286, Domain Loss: 1.3727, Class Loss: 0.6559\n",
      "Epoch 17/50, Loss: 1.7276, Domain Loss: 1.3443, Class Loss: 0.3833\n",
      "Epoch 18/50, Loss: 1.5932, Domain Loss: 1.3718, Class Loss: 0.2214\n",
      "Epoch 19/50, Loss: 1.6660, Domain Loss: 1.3810, Class Loss: 0.2850\n",
      "Epoch 20/50, Loss: 1.5309, Domain Loss: 1.3818, Class Loss: 0.1491\n",
      "Epoch 21/50, Loss: 1.4897, Domain Loss: 1.3835, Class Loss: 0.1063\n",
      "Epoch 22/50, Loss: 1.6411, Domain Loss: 1.4913, Class Loss: 0.1498\n",
      "Epoch 23/50, Loss: 1.4875, Domain Loss: 1.3818, Class Loss: 0.1057\n",
      "Epoch 24/50, Loss: 1.3773, Domain Loss: 1.3166, Class Loss: 0.0606\n",
      "Epoch 25/50, Loss: 1.4216, Domain Loss: 1.3577, Class Loss: 0.0639\n",
      "Epoch 26/50, Loss: 1.2958, Domain Loss: 1.2600, Class Loss: 0.0358\n",
      "Epoch 27/50, Loss: 1.4831, Domain Loss: 1.3441, Class Loss: 0.1390\n",
      "Epoch 28/50, Loss: 1.4560, Domain Loss: 1.3062, Class Loss: 0.1498\n",
      "Epoch 29/50, Loss: 1.3875, Domain Loss: 1.3155, Class Loss: 0.0720\n",
      "Epoch 30/50, Loss: 1.3515, Domain Loss: 1.3140, Class Loss: 0.0374\n",
      "Epoch 31/50, Loss: 1.3444, Domain Loss: 1.3230, Class Loss: 0.0213\n",
      "Epoch 32/50, Loss: 1.4323, Domain Loss: 1.3232, Class Loss: 0.1092\n",
      "Epoch 33/50, Loss: 1.3441, Domain Loss: 1.3074, Class Loss: 0.0368\n",
      "Epoch 34/50, Loss: 1.4053, Domain Loss: 1.3582, Class Loss: 0.0472\n",
      "Epoch 35/50, Loss: 1.4058, Domain Loss: 1.3688, Class Loss: 0.0370\n",
      "Epoch 36/50, Loss: 1.3762, Domain Loss: 1.3398, Class Loss: 0.0364\n",
      "Epoch 37/50, Loss: 1.4328, Domain Loss: 1.3466, Class Loss: 0.0862\n",
      "Epoch 38/50, Loss: 1.4287, Domain Loss: 1.3624, Class Loss: 0.0663\n",
      "Epoch 39/50, Loss: 1.4138, Domain Loss: 1.3784, Class Loss: 0.0354\n",
      "Epoch 40/50, Loss: 1.3565, Domain Loss: 1.3307, Class Loss: 0.0258\n",
      "Epoch 41/50, Loss: 1.3914, Domain Loss: 1.3574, Class Loss: 0.0340\n",
      "Epoch 42/50, Loss: 1.4957, Domain Loss: 1.4030, Class Loss: 0.0927\n",
      "Epoch 43/50, Loss: 1.4039, Domain Loss: 1.3801, Class Loss: 0.0238\n",
      "Epoch 44/50, Loss: 1.3836, Domain Loss: 1.3747, Class Loss: 0.0089\n",
      "Epoch 45/50, Loss: 1.3852, Domain Loss: 1.3721, Class Loss: 0.0131\n",
      "Epoch 46/50, Loss: 1.3972, Domain Loss: 1.3795, Class Loss: 0.0176\n",
      "Epoch 47/50, Loss: 1.4093, Domain Loss: 1.3705, Class Loss: 0.0388\n",
      "Epoch 48/50, Loss: 1.4085, Domain Loss: 1.3833, Class Loss: 0.0252\n",
      "Epoch 49/50, Loss: 1.3983, Domain Loss: 1.3786, Class Loss: 0.0197\n",
      "Epoch 50/50, Loss: 1.3922, Domain Loss: 1.3724, Class Loss: 0.0198\n",
      "58.87\n",
      "\n",
      "\n",
      "Source performance:\n",
      "87.41 84.70 87.42 84.86 \n",
      "Target performance:\n",
      "71.35 74.32 71.57 68.39 \n",
      "\n",
      "Per-class target performance: 93.93 40.51 53.41 98.42 \n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 3.3204, Discrepancy Loss: 0.1076\n",
      "Epoch [2/50], Class Loss: 1.5307, Discrepancy Loss: 0.1568\n",
      "Epoch [3/50], Class Loss: 1.2362, Discrepancy Loss: 0.1436\n",
      "Epoch [4/50], Class Loss: 0.3806, Discrepancy Loss: 0.0660\n",
      "Epoch [5/50], Class Loss: 0.2150, Discrepancy Loss: 0.0392\n",
      "Epoch [6/50], Class Loss: 0.1770, Discrepancy Loss: 0.0339\n",
      "Epoch [7/50], Class Loss: 0.0876, Discrepancy Loss: 0.0235\n",
      "Epoch [8/50], Class Loss: 0.0780, Discrepancy Loss: 0.0279\n",
      "Epoch [9/50], Class Loss: 0.0740, Discrepancy Loss: 0.0211\n",
      "Epoch [10/50], Class Loss: 0.0389, Discrepancy Loss: 0.0166\n",
      "Epoch [11/50], Class Loss: 0.0524, Discrepancy Loss: 0.0148\n",
      "Epoch [12/50], Class Loss: 0.0336, Discrepancy Loss: 0.0143\n",
      "Epoch [13/50], Class Loss: 0.0291, Discrepancy Loss: 0.0171\n",
      "Epoch [14/50], Class Loss: 0.0308, Discrepancy Loss: 0.0175\n",
      "Epoch [15/50], Class Loss: 0.0549, Discrepancy Loss: 0.0159\n",
      "Epoch [16/50], Class Loss: 0.0207, Discrepancy Loss: 0.0173\n",
      "Epoch [17/50], Class Loss: 0.0193, Discrepancy Loss: 0.0156\n",
      "Epoch [18/50], Class Loss: 0.0148, Discrepancy Loss: 0.0149\n",
      "Epoch [19/50], Class Loss: 0.0248, Discrepancy Loss: 0.0169\n",
      "Epoch [20/50], Class Loss: 0.0123, Discrepancy Loss: 0.0152\n",
      "Epoch [21/50], Class Loss: 0.0185, Discrepancy Loss: 0.0168\n",
      "Epoch [22/50], Class Loss: 0.0137, Discrepancy Loss: 0.0171\n",
      "Epoch [23/50], Class Loss: 0.0134, Discrepancy Loss: 0.0161\n",
      "Epoch [24/50], Class Loss: 0.0153, Discrepancy Loss: 0.0166\n",
      "Epoch [25/50], Class Loss: 0.0129, Discrepancy Loss: 0.0161\n",
      "Epoch [26/50], Class Loss: 0.0117, Discrepancy Loss: 0.0161\n",
      "Epoch [27/50], Class Loss: 0.0122, Discrepancy Loss: 0.0149\n",
      "Epoch [28/50], Class Loss: 0.0176, Discrepancy Loss: 0.0159\n",
      "Epoch [29/50], Class Loss: 0.0141, Discrepancy Loss: 0.0146\n",
      "Epoch [30/50], Class Loss: 0.0191, Discrepancy Loss: 0.0159\n",
      "Epoch [31/50], Class Loss: 0.0192, Discrepancy Loss: 0.0162\n",
      "Epoch [32/50], Class Loss: 0.0129, Discrepancy Loss: 0.0169\n",
      "Epoch [33/50], Class Loss: 0.0139, Discrepancy Loss: 0.0177\n",
      "Epoch [34/50], Class Loss: 0.0134, Discrepancy Loss: 0.0177\n",
      "Epoch [35/50], Class Loss: 0.0172, Discrepancy Loss: 0.0162\n",
      "Epoch [36/50], Class Loss: 0.0118, Discrepancy Loss: 0.0180\n",
      "Epoch [37/50], Class Loss: 0.0141, Discrepancy Loss: 0.0175\n",
      "Epoch [38/50], Class Loss: 0.0189, Discrepancy Loss: 0.0173\n",
      "Epoch [39/50], Class Loss: 0.0161, Discrepancy Loss: 0.0152\n",
      "Epoch [40/50], Class Loss: 0.0169, Discrepancy Loss: 0.0157\n",
      "Epoch [41/50], Class Loss: 0.0099, Discrepancy Loss: 0.0153\n",
      "Epoch [42/50], Class Loss: 0.0093, Discrepancy Loss: 0.0164\n",
      "Epoch [43/50], Class Loss: 0.0143, Discrepancy Loss: 0.0182\n",
      "Epoch [44/50], Class Loss: 0.0139, Discrepancy Loss: 0.0174\n",
      "Epoch [45/50], Class Loss: 0.0193, Discrepancy Loss: 0.0164\n",
      "Epoch [46/50], Class Loss: 0.0179, Discrepancy Loss: 0.0167\n",
      "Epoch [47/50], Class Loss: 0.0114, Discrepancy Loss: 0.0185\n",
      "Epoch [48/50], Class Loss: 0.0154, Discrepancy Loss: 0.0167\n",
      "Epoch [49/50], Class Loss: 0.0100, Discrepancy Loss: 0.0168\n",
      "Epoch [50/50], Class Loss: 0.0097, Discrepancy Loss: 0.0172\n",
      "Source Domain Performance - Accuracy: 99.52%, Precision: 99.53%, Recall: 99.51%, F1 Score: 99.52%\n",
      "Target Domain Performance - Accuracy: 93.76%, Precision: 94.16%, Recall: 93.83%, F1 Score: 93.78%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 3.4740, Discrepancy Loss: 0.1127\n",
      "Epoch [2/50], Class Loss: 1.3319, Discrepancy Loss: 0.1488\n",
      "Epoch [3/50], Class Loss: 0.2887, Discrepancy Loss: 0.0719\n",
      "Epoch [4/50], Class Loss: 0.1985, Discrepancy Loss: 0.0493\n",
      "Epoch [5/50], Class Loss: 0.1541, Discrepancy Loss: 0.0443\n",
      "Epoch [6/50], Class Loss: 0.0931, Discrepancy Loss: 0.0298\n",
      "Epoch [7/50], Class Loss: 0.1207, Discrepancy Loss: 0.0417\n",
      "Epoch [8/50], Class Loss: 0.1022, Discrepancy Loss: 0.0299\n",
      "Epoch [9/50], Class Loss: 0.0528, Discrepancy Loss: 0.0257\n",
      "Epoch [10/50], Class Loss: 0.0463, Discrepancy Loss: 0.0249\n",
      "Epoch [11/50], Class Loss: 0.0258, Discrepancy Loss: 0.0208\n",
      "Epoch [12/50], Class Loss: 0.0213, Discrepancy Loss: 0.0209\n",
      "Epoch [13/50], Class Loss: 0.0136, Discrepancy Loss: 0.0218\n",
      "Epoch [14/50], Class Loss: 0.0155, Discrepancy Loss: 0.0193\n",
      "Epoch [15/50], Class Loss: 0.0280, Discrepancy Loss: 0.0227\n",
      "Epoch [16/50], Class Loss: 0.0233, Discrepancy Loss: 0.0182\n",
      "Epoch [17/50], Class Loss: 0.0129, Discrepancy Loss: 0.0206\n",
      "Epoch [18/50], Class Loss: 0.0108, Discrepancy Loss: 0.0180\n",
      "Epoch [19/50], Class Loss: 0.0172, Discrepancy Loss: 0.0194\n",
      "Epoch [20/50], Class Loss: 0.0241, Discrepancy Loss: 0.0206\n",
      "Epoch [21/50], Class Loss: 0.0130, Discrepancy Loss: 0.0240\n",
      "Epoch [22/50], Class Loss: 0.0157, Discrepancy Loss: 0.0232\n",
      "Epoch [23/50], Class Loss: 0.0117, Discrepancy Loss: 0.0215\n",
      "Epoch [24/50], Class Loss: 0.0162, Discrepancy Loss: 0.0202\n",
      "Epoch [25/50], Class Loss: 0.0153, Discrepancy Loss: 0.0224\n",
      "Epoch [26/50], Class Loss: 0.0204, Discrepancy Loss: 0.0222\n",
      "Epoch [27/50], Class Loss: 0.0119, Discrepancy Loss: 0.0207\n",
      "Epoch [28/50], Class Loss: 0.0119, Discrepancy Loss: 0.0213\n",
      "Epoch [29/50], Class Loss: 0.0197, Discrepancy Loss: 0.0254\n",
      "Epoch [30/50], Class Loss: 0.0141, Discrepancy Loss: 0.0208\n",
      "Epoch [31/50], Class Loss: 0.0101, Discrepancy Loss: 0.0218\n",
      "Epoch [32/50], Class Loss: 0.0113, Discrepancy Loss: 0.0241\n",
      "Epoch [33/50], Class Loss: 0.0139, Discrepancy Loss: 0.0241\n",
      "Epoch [34/50], Class Loss: 0.0162, Discrepancy Loss: 0.0209\n",
      "Epoch [35/50], Class Loss: 0.0110, Discrepancy Loss: 0.0237\n",
      "Epoch [36/50], Class Loss: 0.0147, Discrepancy Loss: 0.0228\n",
      "Epoch [37/50], Class Loss: 0.0196, Discrepancy Loss: 0.0223\n",
      "Epoch [38/50], Class Loss: 0.0126, Discrepancy Loss: 0.0218\n",
      "Epoch [39/50], Class Loss: 0.0158, Discrepancy Loss: 0.0243\n",
      "Epoch [40/50], Class Loss: 0.0188, Discrepancy Loss: 0.0236\n",
      "Epoch [41/50], Class Loss: 0.0282, Discrepancy Loss: 0.0234\n",
      "Epoch [42/50], Class Loss: 0.0129, Discrepancy Loss: 0.0235\n",
      "Epoch [43/50], Class Loss: 0.0159, Discrepancy Loss: 0.0246\n",
      "Epoch [44/50], Class Loss: 0.0195, Discrepancy Loss: 0.0230\n",
      "Epoch [45/50], Class Loss: 0.0100, Discrepancy Loss: 0.0232\n",
      "Epoch [46/50], Class Loss: 0.0146, Discrepancy Loss: 0.0243\n",
      "Epoch [47/50], Class Loss: 0.0094, Discrepancy Loss: 0.0244\n",
      "Epoch [48/50], Class Loss: 0.0160, Discrepancy Loss: 0.0235\n",
      "Epoch [49/50], Class Loss: 0.0133, Discrepancy Loss: 0.0212\n",
      "Epoch [50/50], Class Loss: 0.0157, Discrepancy Loss: 0.0220\n",
      "Source Domain Performance - Accuracy: 99.16%, Precision: 99.18%, Recall: 99.15%, F1 Score: 99.16%\n",
      "Target Domain Performance - Accuracy: 94.18%, Precision: 94.51%, Recall: 94.25%, F1 Score: 94.20%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 3.3753, Discrepancy Loss: 0.1310\n",
      "Epoch [2/50], Class Loss: 1.3466, Discrepancy Loss: 0.1618\n",
      "Epoch [3/50], Class Loss: 1.2406, Discrepancy Loss: 0.1379\n",
      "Epoch [4/50], Class Loss: 1.0923, Discrepancy Loss: 0.1281\n",
      "Epoch [5/50], Class Loss: 0.4412, Discrepancy Loss: 0.0977\n",
      "Epoch [6/50], Class Loss: 0.1858, Discrepancy Loss: 0.0512\n",
      "Epoch [7/50], Class Loss: 0.0942, Discrepancy Loss: 0.0418\n",
      "Epoch [8/50], Class Loss: 0.0920, Discrepancy Loss: 0.0291\n",
      "Epoch [9/50], Class Loss: 0.0734, Discrepancy Loss: 0.0273\n",
      "Epoch [10/50], Class Loss: 0.0591, Discrepancy Loss: 0.0240\n",
      "Epoch [11/50], Class Loss: 0.0549, Discrepancy Loss: 0.0215\n",
      "Epoch [12/50], Class Loss: 0.0238, Discrepancy Loss: 0.0192\n",
      "Epoch [13/50], Class Loss: 0.0313, Discrepancy Loss: 0.0204\n",
      "Epoch [14/50], Class Loss: 0.0257, Discrepancy Loss: 0.0207\n",
      "Epoch [15/50], Class Loss: 0.0192, Discrepancy Loss: 0.0174\n",
      "Epoch [16/50], Class Loss: 0.0220, Discrepancy Loss: 0.0198\n",
      "Epoch [17/50], Class Loss: 0.0176, Discrepancy Loss: 0.0207\n",
      "Epoch [18/50], Class Loss: 0.0311, Discrepancy Loss: 0.0177\n",
      "Epoch [19/50], Class Loss: 0.0178, Discrepancy Loss: 0.0192\n",
      "Epoch [20/50], Class Loss: 0.0161, Discrepancy Loss: 0.0205\n",
      "Epoch [21/50], Class Loss: 0.0215, Discrepancy Loss: 0.0183\n",
      "Epoch [22/50], Class Loss: 0.0132, Discrepancy Loss: 0.0201\n",
      "Epoch [23/50], Class Loss: 0.0133, Discrepancy Loss: 0.0197\n",
      "Epoch [24/50], Class Loss: 0.0308, Discrepancy Loss: 0.0212\n",
      "Epoch [25/50], Class Loss: 0.0160, Discrepancy Loss: 0.0188\n",
      "Epoch [26/50], Class Loss: 0.0183, Discrepancy Loss: 0.0213\n",
      "Epoch [27/50], Class Loss: 0.0120, Discrepancy Loss: 0.0197\n",
      "Epoch [28/50], Class Loss: 0.0150, Discrepancy Loss: 0.0211\n",
      "Epoch [29/50], Class Loss: 0.0121, Discrepancy Loss: 0.0215\n",
      "Epoch [30/50], Class Loss: 0.0184, Discrepancy Loss: 0.0205\n",
      "Epoch [31/50], Class Loss: 0.0148, Discrepancy Loss: 0.0210\n",
      "Epoch [32/50], Class Loss: 0.0131, Discrepancy Loss: 0.0203\n",
      "Epoch [33/50], Class Loss: 0.0088, Discrepancy Loss: 0.0192\n",
      "Epoch [34/50], Class Loss: 0.0148, Discrepancy Loss: 0.0193\n",
      "Epoch [35/50], Class Loss: 0.0172, Discrepancy Loss: 0.0200\n",
      "Epoch [36/50], Class Loss: 0.0147, Discrepancy Loss: 0.0174\n",
      "Epoch [37/50], Class Loss: 0.0147, Discrepancy Loss: 0.0190\n",
      "Epoch [38/50], Class Loss: 0.0126, Discrepancy Loss: 0.0186\n",
      "Epoch [39/50], Class Loss: 0.0102, Discrepancy Loss: 0.0216\n",
      "Epoch [40/50], Class Loss: 0.0143, Discrepancy Loss: 0.0197\n",
      "Epoch [41/50], Class Loss: 0.0162, Discrepancy Loss: 0.0214\n",
      "Epoch [42/50], Class Loss: 0.0136, Discrepancy Loss: 0.0193\n",
      "Epoch [43/50], Class Loss: 0.0177, Discrepancy Loss: 0.0208\n",
      "Epoch [44/50], Class Loss: 0.0220, Discrepancy Loss: 0.0220\n",
      "Epoch [45/50], Class Loss: 0.0121, Discrepancy Loss: 0.0187\n",
      "Epoch [46/50], Class Loss: 0.0132, Discrepancy Loss: 0.0203\n",
      "Epoch [47/50], Class Loss: 0.0161, Discrepancy Loss: 0.0207\n",
      "Epoch [48/50], Class Loss: 0.0195, Discrepancy Loss: 0.0226\n",
      "Epoch [49/50], Class Loss: 0.0151, Discrepancy Loss: 0.0224\n",
      "Epoch [50/50], Class Loss: 0.0133, Discrepancy Loss: 0.0218\n",
      "Source Domain Performance - Accuracy: 98.86%, Precision: 98.91%, Recall: 98.84%, F1 Score: 98.86%\n",
      "Target Domain Performance - Accuracy: 95.56%, Precision: 95.67%, Recall: 95.58%, F1 Score: 95.57%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 3.0841, Discrepancy Loss: 0.1198\n",
      "Epoch [2/50], Class Loss: 1.5466, Discrepancy Loss: 0.1482\n",
      "Epoch [3/50], Class Loss: 1.3326, Discrepancy Loss: 0.1660\n",
      "Epoch [4/50], Class Loss: 1.1169, Discrepancy Loss: 0.1397\n",
      "Epoch [5/50], Class Loss: 1.0376, Discrepancy Loss: 0.1432\n",
      "Epoch [6/50], Class Loss: 0.2875, Discrepancy Loss: 0.0686\n",
      "Epoch [7/50], Class Loss: 0.1485, Discrepancy Loss: 0.0534\n",
      "Epoch [8/50], Class Loss: 0.0817, Discrepancy Loss: 0.0338\n",
      "Epoch [9/50], Class Loss: 0.0757, Discrepancy Loss: 0.0281\n",
      "Epoch [10/50], Class Loss: 0.1224, Discrepancy Loss: 0.0372\n",
      "Epoch [11/50], Class Loss: 0.0462, Discrepancy Loss: 0.0316\n",
      "Epoch [12/50], Class Loss: 0.0449, Discrepancy Loss: 0.0273\n",
      "Epoch [13/50], Class Loss: 0.0241, Discrepancy Loss: 0.0247\n",
      "Epoch [14/50], Class Loss: 0.0294, Discrepancy Loss: 0.0252\n",
      "Epoch [15/50], Class Loss: 0.0320, Discrepancy Loss: 0.0228\n",
      "Epoch [16/50], Class Loss: 0.0248, Discrepancy Loss: 0.0217\n",
      "Epoch [17/50], Class Loss: 0.0359, Discrepancy Loss: 0.0237\n",
      "Epoch [18/50], Class Loss: 0.0212, Discrepancy Loss: 0.0226\n",
      "Epoch [19/50], Class Loss: 0.0321, Discrepancy Loss: 0.0220\n",
      "Epoch [20/50], Class Loss: 0.0353, Discrepancy Loss: 0.0188\n",
      "Epoch [21/50], Class Loss: 0.0189, Discrepancy Loss: 0.0200\n",
      "Epoch [22/50], Class Loss: 0.0229, Discrepancy Loss: 0.0189\n",
      "Epoch [23/50], Class Loss: 0.0137, Discrepancy Loss: 0.0177\n",
      "Epoch [24/50], Class Loss: 0.0137, Discrepancy Loss: 0.0198\n",
      "Epoch [25/50], Class Loss: 0.0189, Discrepancy Loss: 0.0211\n",
      "Epoch [26/50], Class Loss: 0.0149, Discrepancy Loss: 0.0176\n",
      "Epoch [27/50], Class Loss: 0.0152, Discrepancy Loss: 0.0187\n",
      "Epoch [28/50], Class Loss: 0.0121, Discrepancy Loss: 0.0224\n",
      "Epoch [29/50], Class Loss: 0.0139, Discrepancy Loss: 0.0205\n",
      "Epoch [30/50], Class Loss: 0.0160, Discrepancy Loss: 0.0199\n",
      "Epoch [31/50], Class Loss: 0.0127, Discrepancy Loss: 0.0240\n",
      "Epoch [32/50], Class Loss: 0.0162, Discrepancy Loss: 0.0204\n",
      "Epoch [33/50], Class Loss: 0.0132, Discrepancy Loss: 0.0213\n",
      "Epoch [34/50], Class Loss: 0.0186, Discrepancy Loss: 0.0198\n",
      "Epoch [35/50], Class Loss: 0.0140, Discrepancy Loss: 0.0205\n",
      "Epoch [36/50], Class Loss: 0.0129, Discrepancy Loss: 0.0210\n",
      "Epoch [37/50], Class Loss: 0.0144, Discrepancy Loss: 0.0196\n",
      "Epoch [38/50], Class Loss: 0.0142, Discrepancy Loss: 0.0198\n",
      "Epoch [39/50], Class Loss: 0.0111, Discrepancy Loss: 0.0230\n",
      "Epoch [40/50], Class Loss: 0.0102, Discrepancy Loss: 0.0198\n",
      "Epoch [41/50], Class Loss: 0.0134, Discrepancy Loss: 0.0206\n",
      "Epoch [42/50], Class Loss: 0.0121, Discrepancy Loss: 0.0195\n",
      "Epoch [43/50], Class Loss: 0.0092, Discrepancy Loss: 0.0215\n",
      "Epoch [44/50], Class Loss: 0.0096, Discrepancy Loss: 0.0199\n",
      "Epoch [45/50], Class Loss: 0.0156, Discrepancy Loss: 0.0207\n",
      "Epoch [46/50], Class Loss: 0.0150, Discrepancy Loss: 0.0207\n",
      "Epoch [47/50], Class Loss: 0.0127, Discrepancy Loss: 0.0191\n",
      "Epoch [48/50], Class Loss: 0.0444, Discrepancy Loss: 0.0200\n",
      "Epoch [49/50], Class Loss: 0.0138, Discrepancy Loss: 0.0213\n",
      "Epoch [50/50], Class Loss: 0.0130, Discrepancy Loss: 0.0226\n",
      "Source Domain Performance - Accuracy: 98.74%, Precision: 98.78%, Recall: 98.71%, F1 Score: 98.74%\n",
      "Target Domain Performance - Accuracy: 95.32%, Precision: 95.57%, Recall: 95.38%, F1 Score: 95.35%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 4.0994, Discrepancy Loss: 0.1180\n",
      "Epoch [2/50], Class Loss: 1.4641, Discrepancy Loss: 0.1525\n",
      "Epoch [3/50], Class Loss: 0.8948, Discrepancy Loss: 0.1264\n",
      "Epoch [4/50], Class Loss: 0.4109, Discrepancy Loss: 0.0876\n",
      "Epoch [5/50], Class Loss: 0.2066, Discrepancy Loss: 0.0491\n",
      "Epoch [6/50], Class Loss: 0.1692, Discrepancy Loss: 0.0415\n",
      "Epoch [7/50], Class Loss: 0.0940, Discrepancy Loss: 0.0340\n",
      "Epoch [8/50], Class Loss: 0.1236, Discrepancy Loss: 0.0370\n",
      "Epoch [9/50], Class Loss: 0.0746, Discrepancy Loss: 0.0323\n",
      "Epoch [10/50], Class Loss: 0.0749, Discrepancy Loss: 0.0272\n",
      "Epoch [11/50], Class Loss: 0.0473, Discrepancy Loss: 0.0258\n",
      "Epoch [12/50], Class Loss: 0.0295, Discrepancy Loss: 0.0243\n",
      "Epoch [13/50], Class Loss: 0.0458, Discrepancy Loss: 0.0222\n",
      "Epoch [14/50], Class Loss: 0.0317, Discrepancy Loss: 0.0260\n",
      "Epoch [15/50], Class Loss: 0.0215, Discrepancy Loss: 0.0249\n",
      "Epoch [16/50], Class Loss: 0.0295, Discrepancy Loss: 0.0264\n",
      "Epoch [17/50], Class Loss: 0.0344, Discrepancy Loss: 0.0245\n",
      "Epoch [18/50], Class Loss: 0.0284, Discrepancy Loss: 0.0209\n",
      "Epoch [19/50], Class Loss: 0.0151, Discrepancy Loss: 0.0226\n",
      "Epoch [20/50], Class Loss: 0.0240, Discrepancy Loss: 0.0237\n",
      "Epoch [21/50], Class Loss: 0.0243, Discrepancy Loss: 0.0278\n",
      "Epoch [22/50], Class Loss: 0.0176, Discrepancy Loss: 0.0245\n",
      "Epoch [23/50], Class Loss: 0.0245, Discrepancy Loss: 0.0267\n",
      "Epoch [24/50], Class Loss: 0.0331, Discrepancy Loss: 0.0252\n",
      "Epoch [25/50], Class Loss: 0.0373, Discrepancy Loss: 0.0246\n",
      "Epoch [26/50], Class Loss: 0.0243, Discrepancy Loss: 0.0287\n",
      "Epoch [27/50], Class Loss: 0.0234, Discrepancy Loss: 0.0306\n",
      "Epoch [28/50], Class Loss: 0.0264, Discrepancy Loss: 0.0281\n",
      "Epoch [29/50], Class Loss: 0.0230, Discrepancy Loss: 0.0254\n",
      "Epoch [30/50], Class Loss: 0.0343, Discrepancy Loss: 0.0274\n",
      "Epoch [31/50], Class Loss: 0.0301, Discrepancy Loss: 0.0258\n",
      "Epoch [32/50], Class Loss: 0.0318, Discrepancy Loss: 0.0269\n",
      "Epoch [33/50], Class Loss: 0.0270, Discrepancy Loss: 0.0236\n",
      "Epoch [34/50], Class Loss: 0.0203, Discrepancy Loss: 0.0242\n",
      "Epoch [35/50], Class Loss: 0.0169, Discrepancy Loss: 0.0265\n",
      "Epoch [36/50], Class Loss: 0.0199, Discrepancy Loss: 0.0277\n",
      "Epoch [37/50], Class Loss: 0.0237, Discrepancy Loss: 0.0264\n",
      "Epoch [38/50], Class Loss: 0.0150, Discrepancy Loss: 0.0239\n",
      "Epoch [39/50], Class Loss: 0.0199, Discrepancy Loss: 0.0301\n",
      "Epoch [40/50], Class Loss: 0.0251, Discrepancy Loss: 0.0232\n",
      "Epoch [41/50], Class Loss: 0.0226, Discrepancy Loss: 0.0257\n",
      "Epoch [42/50], Class Loss: 0.0185, Discrepancy Loss: 0.0280\n",
      "Epoch [43/50], Class Loss: 0.0218, Discrepancy Loss: 0.0228\n",
      "Epoch [44/50], Class Loss: 0.0217, Discrepancy Loss: 0.0283\n",
      "Epoch [45/50], Class Loss: 0.0278, Discrepancy Loss: 0.0248\n",
      "Epoch [46/50], Class Loss: 0.0149, Discrepancy Loss: 0.0257\n",
      "Epoch [47/50], Class Loss: 0.0212, Discrepancy Loss: 0.0258\n",
      "Epoch [48/50], Class Loss: 0.0172, Discrepancy Loss: 0.0241\n",
      "Epoch [49/50], Class Loss: 0.0186, Discrepancy Loss: 0.0293\n",
      "Epoch [50/50], Class Loss: 0.0247, Discrepancy Loss: 0.0277\n",
      "Source Domain Performance - Accuracy: 99.10%, Precision: 99.12%, Recall: 99.08%, F1 Score: 99.10%\n",
      "Target Domain Performance - Accuracy: 93.59%, Precision: 94.15%, Recall: 93.66%, F1 Score: 93.63%\n",
      "\n",
      "Source performance: 99.08% 99.10% 99.06% 99.07%\n",
      "Target performance: 94.48% 94.81% 94.54% 94.51%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 98.93%\n",
      "qpsk: 87.37%\n",
      "16qam: 92.63%\n",
      "8apsk: 99.23%\n",
      "\n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 2.1754, Discrepancy Loss: 0.0841\n",
      "Validation Loss: 1.9250\n",
      "Epoch [2/50], Class Loss: 1.3487, Discrepancy Loss: 0.0512\n",
      "Validation Loss: 0.7420\n",
      "Epoch [3/50], Class Loss: 0.3263, Discrepancy Loss: 0.0432\n",
      "Validation Loss: 0.8254\n",
      "Epoch [4/50], Class Loss: 0.4771, Discrepancy Loss: 0.0383\n",
      "Validation Loss: 0.3840\n",
      "Epoch [5/50], Class Loss: 0.1975, Discrepancy Loss: 0.0380\n",
      "Validation Loss: 0.1101\n",
      "Epoch [6/50], Class Loss: 0.1305, Discrepancy Loss: 0.0368\n",
      "Validation Loss: 0.1018\n",
      "Epoch [7/50], Class Loss: 0.2500, Discrepancy Loss: 0.0375\n",
      "Validation Loss: 0.3606\n",
      "Epoch [8/50], Class Loss: 0.1435, Discrepancy Loss: 0.0344\n",
      "Validation Loss: 0.0907\n",
      "Epoch [9/50], Class Loss: 0.1279, Discrepancy Loss: 0.0510\n",
      "Validation Loss: 0.0584\n",
      "Epoch [10/50], Class Loss: 0.3321, Discrepancy Loss: 0.0437\n",
      "Validation Loss: 0.3589\n",
      "Epoch [11/50], Class Loss: 0.0363, Discrepancy Loss: 0.0323\n",
      "Validation Loss: 0.0426\n",
      "Epoch [12/50], Class Loss: 0.0164, Discrepancy Loss: 0.0265\n",
      "Validation Loss: 0.0380\n",
      "Epoch [13/50], Class Loss: 0.0190, Discrepancy Loss: 0.0263\n",
      "Validation Loss: 0.0541\n",
      "Epoch [14/50], Class Loss: 0.0123, Discrepancy Loss: 0.0279\n",
      "Validation Loss: 0.0676\n",
      "Epoch [15/50], Class Loss: 0.0150, Discrepancy Loss: 0.0340\n",
      "Validation Loss: 0.0971\n",
      "Epoch [16/50], Class Loss: 0.0144, Discrepancy Loss: 0.0393\n",
      "Validation Loss: 0.0570\n",
      "Epoch [17/50], Class Loss: 0.0176, Discrepancy Loss: 0.0372\n",
      "Validation Loss: 0.0703\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.40%, Precision: 99.41%, Recall: 99.40%, F1 Score: 99.40%\n",
      "Target Domain Performance - Accuracy: 71.70%, Precision: 76.79%, Recall: 71.94%, F1 Score: 70.59%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.3744, Discrepancy Loss: 0.0765\n",
      "Validation Loss: 2.1311\n",
      "Epoch [2/50], Class Loss: 1.5194, Discrepancy Loss: 0.0370\n",
      "Validation Loss: 1.5548\n",
      "Epoch [3/50], Class Loss: 1.3943, Discrepancy Loss: 0.0345\n",
      "Validation Loss: 0.7933\n",
      "Epoch [4/50], Class Loss: 0.2951, Discrepancy Loss: 0.0273\n",
      "Validation Loss: 1.1475\n",
      "Epoch [5/50], Class Loss: 0.1559, Discrepancy Loss: 0.0263\n",
      "Validation Loss: 0.0548\n",
      "Epoch [6/50], Class Loss: 0.1746, Discrepancy Loss: 0.0253\n",
      "Validation Loss: 0.1642\n",
      "Epoch [7/50], Class Loss: 0.1605, Discrepancy Loss: 0.0273\n",
      "Validation Loss: 0.1020\n",
      "Epoch [8/50], Class Loss: 0.1903, Discrepancy Loss: 0.0327\n",
      "Validation Loss: 0.1434\n",
      "Epoch [9/50], Class Loss: 0.1032, Discrepancy Loss: 0.0222\n",
      "Validation Loss: 0.0826\n",
      "Epoch [10/50], Class Loss: 0.1011, Discrepancy Loss: 0.0245\n",
      "Validation Loss: 0.0373\n",
      "Epoch [11/50], Class Loss: 0.0145, Discrepancy Loss: 0.0186\n",
      "Validation Loss: 0.0406\n",
      "Epoch [12/50], Class Loss: 0.0121, Discrepancy Loss: 0.0156\n",
      "Validation Loss: 0.0416\n",
      "Epoch [13/50], Class Loss: 0.0114, Discrepancy Loss: 0.0136\n",
      "Validation Loss: 0.0537\n",
      "Epoch [14/50], Class Loss: 0.0120, Discrepancy Loss: 0.0131\n",
      "Validation Loss: 0.0473\n",
      "Epoch [15/50], Class Loss: 0.0083, Discrepancy Loss: 0.0129\n",
      "Validation Loss: 0.0658\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.10%, Precision: 99.11%, Recall: 99.08%, F1 Score: 99.09%\n",
      "Target Domain Performance - Accuracy: 79.02%, Precision: 81.91%, Recall: 79.06%, F1 Score: 79.07%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 2.1394, Discrepancy Loss: 0.0665\n",
      "Validation Loss: 1.5646\n",
      "Epoch [2/50], Class Loss: 1.5112, Discrepancy Loss: 0.0334\n",
      "Validation Loss: 1.4579\n",
      "Epoch [3/50], Class Loss: 0.8539, Discrepancy Loss: 0.0307\n",
      "Validation Loss: 0.1397\n",
      "Epoch [4/50], Class Loss: 0.1790, Discrepancy Loss: 0.0237\n",
      "Validation Loss: 0.1180\n",
      "Epoch [5/50], Class Loss: 0.0955, Discrepancy Loss: 0.0220\n",
      "Validation Loss: 0.1060\n",
      "Epoch [6/50], Class Loss: 0.1145, Discrepancy Loss: 0.0270\n",
      "Validation Loss: 1.0557\n",
      "Epoch [7/50], Class Loss: 0.1715, Discrepancy Loss: 0.0240\n",
      "Validation Loss: 0.6423\n",
      "Epoch [8/50], Class Loss: 0.1625, Discrepancy Loss: 0.0292\n",
      "Validation Loss: 0.0835\n",
      "Epoch [9/50], Class Loss: 0.0992, Discrepancy Loss: 0.0365\n",
      "Validation Loss: 0.4685\n",
      "Epoch [10/50], Class Loss: 0.2607, Discrepancy Loss: 0.0366\n",
      "Validation Loss: 0.1759\n",
      "Epoch [11/50], Class Loss: 0.0268, Discrepancy Loss: 0.0258\n",
      "Validation Loss: 0.0486\n",
      "Epoch [12/50], Class Loss: 0.0180, Discrepancy Loss: 0.0218\n",
      "Validation Loss: 0.0573\n",
      "Epoch [13/50], Class Loss: 0.0178, Discrepancy Loss: 0.0247\n",
      "Validation Loss: 0.0799\n",
      "Epoch [14/50], Class Loss: 0.0169, Discrepancy Loss: 0.0262\n",
      "Validation Loss: 0.0730\n",
      "Epoch [15/50], Class Loss: 0.0185, Discrepancy Loss: 0.0269\n",
      "Validation Loss: 0.0789\n",
      "Epoch [16/50], Class Loss: 0.0114, Discrepancy Loss: 0.0264\n",
      "Validation Loss: 0.0967\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.10%, Precision: 99.11%, Recall: 99.09%, F1 Score: 99.10%\n",
      "Target Domain Performance - Accuracy: 75.42%, Precision: 79.71%, Recall: 75.78%, F1 Score: 72.98%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 2.2200, Discrepancy Loss: 0.0750\n",
      "Validation Loss: 1.7699\n",
      "Epoch [2/50], Class Loss: 1.5812, Discrepancy Loss: 0.0757\n",
      "Validation Loss: 1.4710\n",
      "Epoch [3/50], Class Loss: 0.7905, Discrepancy Loss: 0.0455\n",
      "Validation Loss: 0.2643\n",
      "Epoch [4/50], Class Loss: 0.1622, Discrepancy Loss: 0.0208\n",
      "Validation Loss: 0.4721\n",
      "Epoch [5/50], Class Loss: 0.1296, Discrepancy Loss: 0.0235\n",
      "Validation Loss: 0.1278\n",
      "Epoch [6/50], Class Loss: 0.1838, Discrepancy Loss: 0.0224\n",
      "Validation Loss: 0.8209\n",
      "Epoch [7/50], Class Loss: 0.1726, Discrepancy Loss: 0.0313\n",
      "Validation Loss: 0.0466\n",
      "Epoch [8/50], Class Loss: 0.2366, Discrepancy Loss: 0.0413\n",
      "Validation Loss: 0.1206\n",
      "Epoch [9/50], Class Loss: 0.2557, Discrepancy Loss: 0.0400\n",
      "Validation Loss: 0.2215\n",
      "Epoch [10/50], Class Loss: 0.1198, Discrepancy Loss: 0.0453\n",
      "Validation Loss: 0.2213\n",
      "Epoch [11/50], Class Loss: 0.0362, Discrepancy Loss: 0.0312\n",
      "Validation Loss: 0.0551\n",
      "Epoch [12/50], Class Loss: 0.0188, Discrepancy Loss: 0.0224\n",
      "Validation Loss: 0.0557\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.34%, Precision: 99.34%, Recall: 99.34%, F1 Score: 99.34%\n",
      "Target Domain Performance - Accuracy: 66.61%, Precision: 77.13%, Recall: 66.88%, F1 Score: 65.83%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 2.2151, Discrepancy Loss: 0.0651\n",
      "Validation Loss: 1.4984\n",
      "Epoch [2/50], Class Loss: 1.5375, Discrepancy Loss: 0.0198\n",
      "Validation Loss: 1.3727\n",
      "Epoch [3/50], Class Loss: 0.7208, Discrepancy Loss: 0.0297\n",
      "Validation Loss: 0.2051\n",
      "Epoch [4/50], Class Loss: 0.3802, Discrepancy Loss: 0.0206\n",
      "Validation Loss: 0.7395\n",
      "Epoch [5/50], Class Loss: 0.2154, Discrepancy Loss: 0.0224\n",
      "Validation Loss: 0.0754\n",
      "Epoch [6/50], Class Loss: 0.1759, Discrepancy Loss: 0.0324\n",
      "Validation Loss: 0.0858\n",
      "Epoch [7/50], Class Loss: 0.1114, Discrepancy Loss: 0.0342\n",
      "Validation Loss: 0.1733\n",
      "Epoch [8/50], Class Loss: 0.1537, Discrepancy Loss: 0.0306\n",
      "Validation Loss: 0.1343\n",
      "Epoch [9/50], Class Loss: 0.0989, Discrepancy Loss: 0.0395\n",
      "Validation Loss: 0.1634\n",
      "Epoch [10/50], Class Loss: 0.1378, Discrepancy Loss: 0.0288\n",
      "Validation Loss: 0.0918\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.28%, Precision: 99.27%, Recall: 99.29%, F1 Score: 99.28%\n",
      "Target Domain Performance - Accuracy: 61.21%, Precision: 77.72%, Recall: 61.48%, F1 Score: 60.41%\n",
      "\n",
      "Source performance: 99.24% 99.25% 99.24% 99.24%\n",
      "Target performance: 70.79% 78.65% 71.02% 69.78%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 77.18%\n",
      "qpsk: 39.25%\n",
      "16qam: 67.80%\n",
      "8apsk: 99.86%\n",
      "\n",
      "Run 1/5\n",
      "Epoch 1/50, Train Loss: 1.0429, Train Acc: 0.5439, Val Loss: 0.7606, Val Acc: 0.6205\n",
      "Epoch 2/50, Train Loss: 0.7574, Train Acc: 0.6243, Val Loss: 0.7008, Val Acc: 0.6193\n",
      "Epoch 3/50, Train Loss: 0.3461, Train Acc: 0.8529, Val Loss: 0.4080, Val Acc: 0.8705\n",
      "Epoch 4/50, Train Loss: 0.1289, Train Acc: 0.9598, Val Loss: 0.0165, Val Acc: 0.9958\n",
      "Epoch 5/50, Train Loss: 0.0382, Train Acc: 0.9904, Val Loss: 0.0906, Val Acc: 0.9730\n",
      "Epoch 6/50, Train Loss: 0.0451, Train Acc: 0.9882, Val Loss: 0.0536, Val Acc: 0.9862\n",
      "Epoch 7/50, Train Loss: 0.0243, Train Acc: 0.9930, Val Loss: 0.0271, Val Acc: 0.9934\n",
      "Epoch 8/50, Train Loss: 0.0211, Train Acc: 0.9936, Val Loss: 0.0996, Val Acc: 0.9700\n",
      "Epoch 9/50, Train Loss: 0.0419, Train Acc: 0.9898, Val Loss: 0.0492, Val Acc: 0.9898\n",
      "Early stopping!\n",
      "\n",
      "Run 2/5\n",
      "Epoch 1/50, Train Loss: 1.1569, Train Acc: 0.5525, Val Loss: 0.7733, Val Acc: 0.5935\n",
      "Epoch 2/50, Train Loss: 0.7541, Train Acc: 0.6167, Val Loss: 0.6162, Val Acc: 0.6661\n",
      "Epoch 3/50, Train Loss: 0.2635, Train Acc: 0.8893, Val Loss: 0.1851, Val Acc: 0.9239\n",
      "Epoch 4/50, Train Loss: 0.0861, Train Acc: 0.9736, Val Loss: 0.0282, Val Acc: 0.9898\n",
      "Epoch 5/50, Train Loss: 0.0974, Train Acc: 0.9750, Val Loss: 0.0737, Val Acc: 0.9772\n",
      "Epoch 6/50, Train Loss: 0.0459, Train Acc: 0.9859, Val Loss: 0.0190, Val Acc: 0.9940\n",
      "Epoch 7/50, Train Loss: 0.0466, Train Acc: 0.9882, Val Loss: 0.0572, Val Acc: 0.9790\n",
      "Epoch 8/50, Train Loss: 0.0873, Train Acc: 0.9816, Val Loss: 0.0311, Val Acc: 0.9874\n",
      "Epoch 9/50, Train Loss: 0.0322, Train Acc: 0.9913, Val Loss: 0.0132, Val Acc: 0.9964\n",
      "Epoch 10/50, Train Loss: 0.0274, Train Acc: 0.9922, Val Loss: 0.0663, Val Acc: 0.9844\n",
      "Epoch 11/50, Train Loss: 0.0073, Train Acc: 0.9982, Val Loss: 0.0148, Val Acc: 0.9952\n",
      "Epoch 12/50, Train Loss: 0.0032, Train Acc: 0.9993, Val Loss: 0.0095, Val Acc: 0.9976\n",
      "Epoch 13/50, Train Loss: 0.0028, Train Acc: 0.9994, Val Loss: 0.0052, Val Acc: 0.9970\n",
      "Epoch 14/50, Train Loss: 0.0027, Train Acc: 0.9994, Val Loss: 0.0034, Val Acc: 0.9982\n",
      "Epoch 15/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0077, Val Acc: 0.9970\n",
      "Epoch 16/50, Train Loss: 0.0022, Train Acc: 0.9994, Val Loss: 0.0032, Val Acc: 0.9988\n",
      "Epoch 17/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0131, Val Acc: 0.9946\n",
      "Epoch 18/50, Train Loss: 0.0027, Train Acc: 0.9994, Val Loss: 0.0037, Val Acc: 0.9976\n",
      "Epoch 19/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0030, Val Acc: 0.9988\n",
      "Epoch 20/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0047, Val Acc: 0.9976\n",
      "Epoch 21/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9988\n",
      "Epoch 22/50, Train Loss: 0.0012, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9988\n",
      "Epoch 23/50, Train Loss: 0.0012, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9988\n",
      "Epoch 24/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 25/50, Train Loss: 0.0013, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9994\n",
      "Epoch 26/50, Train Loss: 0.0013, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9988\n",
      "Epoch 27/50, Train Loss: 0.0013, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9988\n",
      "Epoch 28/50, Train Loss: 0.0011, Train Acc: 0.9996, Val Loss: 0.0028, Val Acc: 0.9988\n",
      "Epoch 29/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9988\n",
      "Early stopping!\n",
      "\n",
      "Run 3/5\n",
      "Epoch 1/50, Train Loss: 1.0181, Train Acc: 0.5585, Val Loss: 0.7097, Val Acc: 0.6133\n",
      "Epoch 2/50, Train Loss: 0.6507, Train Acc: 0.6786, Val Loss: 0.2204, Val Acc: 0.8969\n",
      "Epoch 3/50, Train Loss: 0.1365, Train Acc: 0.9556, Val Loss: 0.1787, Val Acc: 0.9454\n",
      "Epoch 4/50, Train Loss: 0.0804, Train Acc: 0.9769, Val Loss: 0.1837, Val Acc: 0.9514\n",
      "Epoch 5/50, Train Loss: 0.0874, Train Acc: 0.9777, Val Loss: 0.0297, Val Acc: 0.9904\n",
      "Epoch 6/50, Train Loss: 0.0645, Train Acc: 0.9822, Val Loss: 0.0880, Val Acc: 0.9742\n",
      "Epoch 7/50, Train Loss: 0.0300, Train Acc: 0.9916, Val Loss: 0.3536, Val Acc: 0.9347\n",
      "Epoch 8/50, Train Loss: 0.0439, Train Acc: 0.9895, Val Loss: 0.0280, Val Acc: 0.9922\n",
      "Epoch 9/50, Train Loss: 0.0352, Train Acc: 0.9897, Val Loss: 0.0147, Val Acc: 0.9940\n",
      "Epoch 10/50, Train Loss: 0.0199, Train Acc: 0.9955, Val Loss: 0.0700, Val Acc: 0.9796\n",
      "Epoch 11/50, Train Loss: 0.0040, Train Acc: 0.9990, Val Loss: 0.0079, Val Acc: 0.9976\n",
      "Epoch 12/50, Train Loss: 0.0033, Train Acc: 0.9994, Val Loss: 0.0074, Val Acc: 0.9970\n",
      "Epoch 13/50, Train Loss: 0.0028, Train Acc: 0.9994, Val Loss: 0.0072, Val Acc: 0.9976\n",
      "Epoch 14/50, Train Loss: 0.0027, Train Acc: 0.9996, Val Loss: 0.0074, Val Acc: 0.9970\n",
      "Epoch 15/50, Train Loss: 0.0030, Train Acc: 0.9996, Val Loss: 0.0098, Val Acc: 0.9976\n",
      "Epoch 16/50, Train Loss: 0.0024, Train Acc: 0.9994, Val Loss: 0.0054, Val Acc: 0.9982\n",
      "Epoch 17/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0070, Val Acc: 0.9976\n",
      "Epoch 18/50, Train Loss: 0.0020, Train Acc: 0.9994, Val Loss: 0.0044, Val Acc: 0.9982\n",
      "Epoch 19/50, Train Loss: 0.0026, Train Acc: 0.9994, Val Loss: 0.0045, Val Acc: 0.9982\n",
      "Epoch 20/50, Train Loss: 0.0026, Train Acc: 0.9996, Val Loss: 0.0029, Val Acc: 0.9994\n",
      "Epoch 21/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0029, Val Acc: 0.9994\n",
      "Epoch 22/50, Train Loss: 0.0016, Train Acc: 0.9996, Val Loss: 0.0030, Val Acc: 0.9994\n",
      "Epoch 23/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0028, Val Acc: 0.9994\n",
      "Epoch 24/50, Train Loss: 0.0016, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9994\n",
      "Epoch 25/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9994\n",
      "Epoch 26/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9994\n",
      "Epoch 27/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9994\n",
      "Epoch 28/50, Train Loss: 0.0016, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9994\n",
      "Epoch 29/50, Train Loss: 0.0017, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9994\n",
      "Epoch 30/50, Train Loss: 0.0016, Train Acc: 0.9996, Val Loss: 0.0026, Val Acc: 0.9994\n",
      "Epoch 31/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 32/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 33/50, Train Loss: 0.0013, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 34/50, Train Loss: 0.0013, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 35/50, Train Loss: 0.0012, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 36/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 37/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 38/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 39/50, Train Loss: 0.0016, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 40/50, Train Loss: 0.0013, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 41/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 42/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 43/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Epoch 44/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0025, Val Acc: 0.9994\n",
      "Early stopping!\n",
      "\n",
      "Run 4/5\n",
      "Epoch 1/50, Train Loss: 1.0433, Train Acc: 0.5186, Val Loss: 0.8266, Val Acc: 0.5911\n",
      "Epoch 2/50, Train Loss: 0.4329, Train Acc: 0.7857, Val Loss: 0.1791, Val Acc: 0.9508\n",
      "Epoch 3/50, Train Loss: 0.1027, Train Acc: 0.9724, Val Loss: 0.1911, Val Acc: 0.9454\n",
      "Epoch 4/50, Train Loss: 0.0861, Train Acc: 0.9759, Val Loss: 0.0491, Val Acc: 0.9814\n",
      "Epoch 5/50, Train Loss: 0.0417, Train Acc: 0.9885, Val Loss: 0.0980, Val Acc: 0.9748\n",
      "Epoch 6/50, Train Loss: 0.1264, Train Acc: 0.9708, Val Loss: 0.0243, Val Acc: 0.9910\n",
      "Epoch 7/50, Train Loss: 0.0289, Train Acc: 0.9919, Val Loss: 0.1518, Val Acc: 0.9682\n",
      "Epoch 8/50, Train Loss: 0.0378, Train Acc: 0.9904, Val Loss: 0.0178, Val Acc: 0.9964\n",
      "Epoch 9/50, Train Loss: 0.0155, Train Acc: 0.9958, Val Loss: 0.0100, Val Acc: 0.9958\n",
      "Epoch 10/50, Train Loss: 0.0115, Train Acc: 0.9970, Val Loss: 0.0186, Val Acc: 0.9958\n",
      "Epoch 11/50, Train Loss: 0.0033, Train Acc: 0.9994, Val Loss: 0.0098, Val Acc: 0.9976\n",
      "Epoch 12/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0083, Val Acc: 0.9988\n",
      "Epoch 13/50, Train Loss: 0.0029, Train Acc: 0.9996, Val Loss: 0.0089, Val Acc: 0.9970\n",
      "Epoch 14/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0104, Val Acc: 0.9964\n",
      "Epoch 15/50, Train Loss: 0.0022, Train Acc: 0.9994, Val Loss: 0.0078, Val Acc: 0.9988\n",
      "Epoch 16/50, Train Loss: 0.0018, Train Acc: 0.9994, Val Loss: 0.0077, Val Acc: 0.9988\n",
      "Epoch 17/50, Train Loss: 0.0020, Train Acc: 0.9993, Val Loss: 0.0234, Val Acc: 0.9940\n",
      "Epoch 18/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0095, Val Acc: 0.9970\n",
      "Epoch 19/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0080, Val Acc: 0.9982\n",
      "Epoch 20/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0091, Val Acc: 0.9976\n",
      "Epoch 21/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0083, Val Acc: 0.9976\n",
      "Early stopping!\n",
      "\n",
      "Run 5/5\n",
      "Epoch 1/50, Train Loss: 1.0405, Train Acc: 0.5318, Val Loss: 0.7284, Val Acc: 0.6451\n",
      "Epoch 2/50, Train Loss: 0.7167, Train Acc: 0.6437, Val Loss: 0.3604, Val Acc: 0.8609\n",
      "Epoch 3/50, Train Loss: 0.2059, Train Acc: 0.9162, Val Loss: 0.0683, Val Acc: 0.9730\n",
      "Epoch 4/50, Train Loss: 0.1019, Train Acc: 0.9700, Val Loss: 0.0152, Val Acc: 0.9922\n",
      "Epoch 5/50, Train Loss: 0.1365, Train Acc: 0.9607, Val Loss: 0.0275, Val Acc: 0.9928\n",
      "Epoch 6/50, Train Loss: 0.0708, Train Acc: 0.9804, Val Loss: 0.0701, Val Acc: 0.9826\n",
      "Epoch 7/50, Train Loss: 0.0455, Train Acc: 0.9883, Val Loss: 0.0222, Val Acc: 0.9952\n",
      "Epoch 8/50, Train Loss: 0.0382, Train Acc: 0.9892, Val Loss: 0.0198, Val Acc: 0.9958\n",
      "Epoch 9/50, Train Loss: 0.0610, Train Acc: 0.9847, Val Loss: 0.1042, Val Acc: 0.9760\n",
      "Early stopping!\n",
      "\n",
      "Source performance: 99.23 99.27 99.21 99.23\n",
      "Target performance: 97.03 97.14 96.97 96.88\n",
      "\n",
      "bpsk: 99.48\n",
      "qpsk: 97.78\n",
      "16qam: 90.83\n",
      "8apsk: 99.80\n",
      "Epoch 1/50, Loss: 3.1187, Domain Loss: 1.6012, Class Loss: 1.5175\n",
      "Epoch 2/50, Loss: 2.2125, Domain Loss: 1.4127, Class Loss: 0.7998\n",
      "Epoch 3/50, Loss: 2.1672, Domain Loss: 1.3792, Class Loss: 0.7880\n",
      "Epoch 4/50, Loss: 2.1280, Domain Loss: 1.3706, Class Loss: 0.7574\n",
      "Epoch 5/50, Loss: 2.0610, Domain Loss: 1.3230, Class Loss: 0.7380\n",
      "Epoch 6/50, Loss: 2.0642, Domain Loss: 1.3222, Class Loss: 0.7419\n",
      "Epoch 7/50, Loss: 2.0405, Domain Loss: 1.3396, Class Loss: 0.7008\n",
      "Epoch 8/50, Loss: 2.0477, Domain Loss: 1.3794, Class Loss: 0.6682\n",
      "Epoch 9/50, Loss: 2.1982, Domain Loss: 1.6445, Class Loss: 0.5537\n",
      "Epoch 10/50, Loss: 1.8733, Domain Loss: 1.4307, Class Loss: 0.4427\n",
      "Epoch 11/50, Loss: 1.4633, Domain Loss: 1.3177, Class Loss: 0.1457\n",
      "Epoch 12/50, Loss: 1.4725, Domain Loss: 1.3354, Class Loss: 0.1371\n",
      "Epoch 13/50, Loss: 1.5216, Domain Loss: 1.3791, Class Loss: 0.1425\n",
      "Epoch 14/50, Loss: 1.3845, Domain Loss: 1.3443, Class Loss: 0.0401\n",
      "Epoch 15/50, Loss: 1.3633, Domain Loss: 1.3145, Class Loss: 0.0488\n",
      "Epoch 16/50, Loss: 1.3766, Domain Loss: 1.3018, Class Loss: 0.0747\n",
      "Epoch 17/50, Loss: 1.3317, Domain Loss: 1.2835, Class Loss: 0.0482\n",
      "Epoch 18/50, Loss: 1.2712, Domain Loss: 1.2588, Class Loss: 0.0123\n",
      "Epoch 19/50, Loss: 1.3704, Domain Loss: 1.2769, Class Loss: 0.0936\n",
      "Epoch 20/50, Loss: 1.2968, Domain Loss: 1.2193, Class Loss: 0.0774\n",
      "Epoch 21/50, Loss: 1.2566, Domain Loss: 1.2217, Class Loss: 0.0349\n",
      "Epoch 22/50, Loss: 1.2776, Domain Loss: 1.2313, Class Loss: 0.0463\n",
      "Epoch 23/50, Loss: 1.3381, Domain Loss: 1.2584, Class Loss: 0.0797\n",
      "Epoch 24/50, Loss: 1.5811, Domain Loss: 1.2402, Class Loss: 0.3409\n",
      "Epoch 25/50, Loss: 1.2739, Domain Loss: 1.1824, Class Loss: 0.0915\n",
      "Epoch 26/50, Loss: 1.1631, Domain Loss: 1.1330, Class Loss: 0.0300\n",
      "Epoch 27/50, Loss: 1.1370, Domain Loss: 1.1142, Class Loss: 0.0227\n",
      "Epoch 28/50, Loss: 1.1741, Domain Loss: 1.1163, Class Loss: 0.0578\n",
      "Epoch 29/50, Loss: 1.1716, Domain Loss: 1.1204, Class Loss: 0.0512\n",
      "Epoch 30/50, Loss: 1.2019, Domain Loss: 1.1027, Class Loss: 0.0992\n",
      "Epoch 31/50, Loss: 1.2300, Domain Loss: 1.1368, Class Loss: 0.0932\n",
      "Epoch 32/50, Loss: 1.2178, Domain Loss: 1.1503, Class Loss: 0.0675\n",
      "Epoch 33/50, Loss: 1.2065, Domain Loss: 1.1240, Class Loss: 0.0825\n",
      "Epoch 34/50, Loss: 1.1101, Domain Loss: 1.0693, Class Loss: 0.0408\n",
      "Epoch 35/50, Loss: 1.0917, Domain Loss: 1.0590, Class Loss: 0.0326\n",
      "Epoch 36/50, Loss: 1.2905, Domain Loss: 1.2177, Class Loss: 0.0728\n",
      "Epoch 37/50, Loss: 1.4276, Domain Loss: 1.1750, Class Loss: 0.2526\n",
      "Epoch 38/50, Loss: 1.2039, Domain Loss: 1.1312, Class Loss: 0.0727\n",
      "Epoch 39/50, Loss: 1.1811, Domain Loss: 1.1375, Class Loss: 0.0436\n",
      "Epoch 40/50, Loss: 1.1750, Domain Loss: 1.1359, Class Loss: 0.0390\n",
      "Epoch 41/50, Loss: 1.2238, Domain Loss: 1.1623, Class Loss: 0.0614\n",
      "Epoch 42/50, Loss: 1.4024, Domain Loss: 1.2581, Class Loss: 0.1443\n",
      "Epoch 43/50, Loss: 1.3268, Domain Loss: 1.2734, Class Loss: 0.0534\n",
      "Epoch 44/50, Loss: 1.3361, Domain Loss: 1.2998, Class Loss: 0.0363\n",
      "Epoch 45/50, Loss: 1.3377, Domain Loss: 1.3141, Class Loss: 0.0236\n",
      "Epoch 46/50, Loss: 1.3360, Domain Loss: 1.3211, Class Loss: 0.0149\n",
      "Epoch 47/50, Loss: 1.3684, Domain Loss: 1.3257, Class Loss: 0.0427\n",
      "Epoch 48/50, Loss: 1.3432, Domain Loss: 1.3003, Class Loss: 0.0429\n",
      "Epoch 49/50, Loss: 1.3178, Domain Loss: 1.2870, Class Loss: 0.0309\n",
      "Epoch 50/50, Loss: 1.3744, Domain Loss: 1.3146, Class Loss: 0.0598\n",
      "95.50\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.9807, Domain Loss: 2.1936, Class Loss: 1.7871\n",
      "Epoch 2/50, Loss: 2.1762, Domain Loss: 1.3888, Class Loss: 0.7875\n",
      "Epoch 3/50, Loss: 2.1577, Domain Loss: 1.3958, Class Loss: 0.7619\n",
      "Epoch 4/50, Loss: 2.1215, Domain Loss: 1.3854, Class Loss: 0.7361\n",
      "Epoch 5/50, Loss: 2.1214, Domain Loss: 1.3693, Class Loss: 0.7522\n",
      "Epoch 6/50, Loss: 2.1795, Domain Loss: 1.3817, Class Loss: 0.7978\n",
      "Epoch 7/50, Loss: 2.0630, Domain Loss: 1.3608, Class Loss: 0.7022\n",
      "Epoch 8/50, Loss: 2.0625, Domain Loss: 1.3497, Class Loss: 0.7127\n",
      "Epoch 9/50, Loss: 2.0186, Domain Loss: 1.3496, Class Loss: 0.6691\n",
      "Epoch 10/50, Loss: 1.8697, Domain Loss: 1.3400, Class Loss: 0.5297\n",
      "Epoch 11/50, Loss: 2.5929, Domain Loss: 2.0237, Class Loss: 0.5692\n",
      "Epoch 12/50, Loss: 1.9173, Domain Loss: 1.5589, Class Loss: 0.3584\n",
      "Epoch 13/50, Loss: 1.6694, Domain Loss: 1.4146, Class Loss: 0.2548\n",
      "Epoch 14/50, Loss: 1.4858, Domain Loss: 1.4056, Class Loss: 0.0802\n",
      "Epoch 15/50, Loss: 1.3961, Domain Loss: 1.3673, Class Loss: 0.0288\n",
      "Epoch 16/50, Loss: 1.4527, Domain Loss: 1.3723, Class Loss: 0.0803\n",
      "Epoch 17/50, Loss: 1.4383, Domain Loss: 1.3713, Class Loss: 0.0670\n",
      "Epoch 18/50, Loss: 1.4639, Domain Loss: 1.4108, Class Loss: 0.0531\n",
      "Epoch 19/50, Loss: 1.3966, Domain Loss: 1.3835, Class Loss: 0.0131\n",
      "Epoch 20/50, Loss: 1.3981, Domain Loss: 1.3714, Class Loss: 0.0267\n",
      "Epoch 21/50, Loss: 1.4067, Domain Loss: 1.3787, Class Loss: 0.0280\n",
      "Epoch 22/50, Loss: 1.3759, Domain Loss: 1.3573, Class Loss: 0.0186\n",
      "Epoch 23/50, Loss: 1.3863, Domain Loss: 1.3534, Class Loss: 0.0329\n",
      "Epoch 24/50, Loss: 1.3865, Domain Loss: 1.3397, Class Loss: 0.0468\n",
      "Epoch 25/50, Loss: 1.3834, Domain Loss: 1.3418, Class Loss: 0.0416\n",
      "Epoch 26/50, Loss: 1.3551, Domain Loss: 1.3355, Class Loss: 0.0196\n",
      "Epoch 27/50, Loss: 1.3755, Domain Loss: 1.3221, Class Loss: 0.0534\n",
      "Epoch 28/50, Loss: 1.3939, Domain Loss: 1.3364, Class Loss: 0.0575\n",
      "Epoch 29/50, Loss: 1.5049, Domain Loss: 1.2983, Class Loss: 0.2066\n",
      "Epoch 30/50, Loss: 1.3282, Domain Loss: 1.2935, Class Loss: 0.0347\n",
      "Epoch 31/50, Loss: 1.3182, Domain Loss: 1.2822, Class Loss: 0.0360\n",
      "Epoch 32/50, Loss: 1.3316, Domain Loss: 1.3028, Class Loss: 0.0287\n",
      "Epoch 33/50, Loss: 1.3429, Domain Loss: 1.3062, Class Loss: 0.0367\n",
      "Epoch 34/50, Loss: 1.3750, Domain Loss: 1.3428, Class Loss: 0.0323\n",
      "Epoch 35/50, Loss: 1.5779, Domain Loss: 1.3400, Class Loss: 0.2379\n",
      "Epoch 36/50, Loss: 1.3439, Domain Loss: 1.3013, Class Loss: 0.0427\n",
      "Epoch 37/50, Loss: 1.3030, Domain Loss: 1.2937, Class Loss: 0.0093\n",
      "Epoch 38/50, Loss: 1.3180, Domain Loss: 1.3061, Class Loss: 0.0119\n",
      "Epoch 39/50, Loss: 1.3423, Domain Loss: 1.3356, Class Loss: 0.0067\n",
      "Epoch 40/50, Loss: 1.3778, Domain Loss: 1.3379, Class Loss: 0.0399\n",
      "Epoch 41/50, Loss: 1.3337, Domain Loss: 1.3152, Class Loss: 0.0184\n",
      "Epoch 42/50, Loss: 1.3097, Domain Loss: 1.3036, Class Loss: 0.0061\n",
      "Epoch 43/50, Loss: 1.3216, Domain Loss: 1.3057, Class Loss: 0.0158\n",
      "Epoch 44/50, Loss: 1.3908, Domain Loss: 1.3572, Class Loss: 0.0336\n",
      "Epoch 45/50, Loss: 2.2297, Domain Loss: 1.5988, Class Loss: 0.6308\n",
      "Epoch 46/50, Loss: 4.5960, Domain Loss: 3.5170, Class Loss: 1.0791\n",
      "Epoch 47/50, Loss: 2.4968, Domain Loss: 2.2816, Class Loss: 0.2151\n",
      "Epoch 48/50, Loss: 1.8158, Domain Loss: 1.6904, Class Loss: 0.1254\n",
      "Epoch 49/50, Loss: 2.5895, Domain Loss: 2.2963, Class Loss: 0.2932\n",
      "Epoch 50/50, Loss: 1.9306, Domain Loss: 1.8662, Class Loss: 0.0644\n",
      "95.86\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.3463, Domain Loss: 2.3919, Class Loss: 1.9544\n",
      "Epoch 2/50, Loss: 2.3215, Domain Loss: 1.4074, Class Loss: 0.9141\n",
      "Epoch 3/50, Loss: 2.1589, Domain Loss: 1.3834, Class Loss: 0.7755\n",
      "Epoch 4/50, Loss: 2.0901, Domain Loss: 1.3760, Class Loss: 0.7141\n",
      "Epoch 5/50, Loss: 2.0897, Domain Loss: 1.3570, Class Loss: 0.7327\n",
      "Epoch 6/50, Loss: 2.1183, Domain Loss: 1.3893, Class Loss: 0.7290\n",
      "Epoch 7/50, Loss: 2.1193, Domain Loss: 1.3766, Class Loss: 0.7426\n",
      "Epoch 8/50, Loss: 2.0666, Domain Loss: 1.3218, Class Loss: 0.7448\n",
      "Epoch 9/50, Loss: 2.0747, Domain Loss: 1.3419, Class Loss: 0.7328\n",
      "Epoch 10/50, Loss: 2.0321, Domain Loss: 1.2947, Class Loss: 0.7374\n",
      "Epoch 11/50, Loss: 1.9515, Domain Loss: 1.3480, Class Loss: 0.6035\n",
      "Epoch 12/50, Loss: 3.8112, Domain Loss: 2.7086, Class Loss: 1.1026\n",
      "Epoch 13/50, Loss: 2.3495, Domain Loss: 1.5247, Class Loss: 0.8248\n",
      "Epoch 14/50, Loss: 2.0667, Domain Loss: 1.3497, Class Loss: 0.7171\n",
      "Epoch 15/50, Loss: 2.0950, Domain Loss: 1.3977, Class Loss: 0.6973\n",
      "Epoch 16/50, Loss: 2.0228, Domain Loss: 1.3870, Class Loss: 0.6357\n",
      "Epoch 17/50, Loss: 1.9727, Domain Loss: 1.3867, Class Loss: 0.5860\n",
      "Epoch 18/50, Loss: 1.7959, Domain Loss: 1.3866, Class Loss: 0.4093\n",
      "Epoch 19/50, Loss: 1.7278, Domain Loss: 1.3866, Class Loss: 0.3412\n",
      "Epoch 20/50, Loss: 1.5313, Domain Loss: 1.3862, Class Loss: 0.1451\n",
      "Epoch 21/50, Loss: 1.5619, Domain Loss: 1.3848, Class Loss: 0.1770\n",
      "Epoch 22/50, Loss: 1.5081, Domain Loss: 1.3823, Class Loss: 0.1259\n",
      "Epoch 23/50, Loss: 1.4836, Domain Loss: 1.3788, Class Loss: 0.1048\n",
      "Epoch 24/50, Loss: 1.4263, Domain Loss: 1.3776, Class Loss: 0.0487\n",
      "Epoch 25/50, Loss: 1.4053, Domain Loss: 1.3732, Class Loss: 0.0321\n",
      "Epoch 26/50, Loss: 1.3900, Domain Loss: 1.3610, Class Loss: 0.0290\n",
      "Epoch 27/50, Loss: 1.3800, Domain Loss: 1.3513, Class Loss: 0.0287\n",
      "Epoch 28/50, Loss: 1.3710, Domain Loss: 1.3394, Class Loss: 0.0317\n",
      "Epoch 29/50, Loss: 1.3441, Domain Loss: 1.3156, Class Loss: 0.0285\n",
      "Epoch 30/50, Loss: 1.3512, Domain Loss: 1.2961, Class Loss: 0.0552\n",
      "Epoch 31/50, Loss: 1.3399, Domain Loss: 1.3032, Class Loss: 0.0367\n",
      "Epoch 32/50, Loss: 1.4243, Domain Loss: 1.3366, Class Loss: 0.0877\n",
      "Epoch 33/50, Loss: 1.3327, Domain Loss: 1.2701, Class Loss: 0.0626\n",
      "Epoch 34/50, Loss: 1.3139, Domain Loss: 1.2748, Class Loss: 0.0391\n",
      "Epoch 35/50, Loss: 1.3004, Domain Loss: 1.2544, Class Loss: 0.0460\n",
      "Epoch 36/50, Loss: 1.6246, Domain Loss: 1.4082, Class Loss: 0.2164\n",
      "Epoch 37/50, Loss: 1.5729, Domain Loss: 1.3106, Class Loss: 0.2623\n",
      "Epoch 38/50, Loss: 1.2918, Domain Loss: 1.2519, Class Loss: 0.0400\n",
      "Epoch 39/50, Loss: 1.3386, Domain Loss: 1.2915, Class Loss: 0.0471\n",
      "Epoch 40/50, Loss: 1.2908, Domain Loss: 1.2547, Class Loss: 0.0361\n",
      "Epoch 41/50, Loss: 1.2761, Domain Loss: 1.2509, Class Loss: 0.0253\n",
      "Epoch 42/50, Loss: 1.3006, Domain Loss: 1.2642, Class Loss: 0.0364\n",
      "Epoch 43/50, Loss: 1.4036, Domain Loss: 1.3332, Class Loss: 0.0705\n",
      "Epoch 44/50, Loss: 1.4575, Domain Loss: 1.3555, Class Loss: 0.1019\n",
      "Epoch 45/50, Loss: 1.3401, Domain Loss: 1.3072, Class Loss: 0.0329\n",
      "Epoch 46/50, Loss: 1.2918, Domain Loss: 1.2481, Class Loss: 0.0436\n",
      "Epoch 47/50, Loss: 1.2974, Domain Loss: 1.2561, Class Loss: 0.0412\n",
      "Epoch 48/50, Loss: 1.3339, Domain Loss: 1.3111, Class Loss: 0.0228\n",
      "Epoch 49/50, Loss: 1.3684, Domain Loss: 1.3143, Class Loss: 0.0541\n",
      "Epoch 50/50, Loss: 1.3868, Domain Loss: 1.3189, Class Loss: 0.0680\n",
      "96.58\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.6099, Domain Loss: 1.7817, Class Loss: 1.8282\n",
      "Epoch 2/50, Loss: 2.4477, Domain Loss: 1.3811, Class Loss: 1.0666\n",
      "Epoch 3/50, Loss: 2.1808, Domain Loss: 1.3758, Class Loss: 0.8050\n",
      "Epoch 4/50, Loss: 2.1355, Domain Loss: 1.3678, Class Loss: 0.7677\n",
      "Epoch 5/50, Loss: 2.1109, Domain Loss: 1.3513, Class Loss: 0.7596\n",
      "Epoch 6/50, Loss: 2.0727, Domain Loss: 1.3497, Class Loss: 0.7230\n",
      "Epoch 7/50, Loss: 2.0534, Domain Loss: 1.3447, Class Loss: 0.7086\n",
      "Epoch 8/50, Loss: 2.0193, Domain Loss: 1.3558, Class Loss: 0.6635\n",
      "Epoch 9/50, Loss: 1.7020, Domain Loss: 1.3494, Class Loss: 0.3526\n",
      "Epoch 10/50, Loss: 1.6708, Domain Loss: 1.3745, Class Loss: 0.2963\n",
      "Epoch 11/50, Loss: 1.4232, Domain Loss: 1.3487, Class Loss: 0.0745\n",
      "Epoch 12/50, Loss: 1.3693, Domain Loss: 1.3074, Class Loss: 0.0619\n",
      "Epoch 13/50, Loss: 1.4606, Domain Loss: 1.3402, Class Loss: 0.1204\n",
      "Epoch 14/50, Loss: 4.7619, Domain Loss: 3.3931, Class Loss: 1.3688\n",
      "Epoch 15/50, Loss: 17.0890, Domain Loss: 15.3596, Class Loss: 1.7295\n",
      "Epoch 16/50, Loss: 9.5704, Domain Loss: 8.1821, Class Loss: 1.3883\n",
      "Epoch 17/50, Loss: 9.0906, Domain Loss: 7.6874, Class Loss: 1.4031\n",
      "Epoch 18/50, Loss: 7.4280, Domain Loss: 6.0406, Class Loss: 1.3874\n",
      "Epoch 19/50, Loss: 5.9875, Domain Loss: 4.6028, Class Loss: 1.3847\n",
      "Epoch 20/50, Loss: 5.0680, Domain Loss: 3.6901, Class Loss: 1.3778\n",
      "Epoch 21/50, Loss: 3.5325, Domain Loss: 2.1565, Class Loss: 1.3760\n",
      "Epoch 22/50, Loss: 3.3077, Domain Loss: 1.9301, Class Loss: 1.3776\n",
      "Epoch 23/50, Loss: 3.5099, Domain Loss: 2.1981, Class Loss: 1.3118\n",
      "Epoch 24/50, Loss: 3.7524, Domain Loss: 2.5627, Class Loss: 1.1896\n",
      "Epoch 25/50, Loss: 3.3268, Domain Loss: 2.4789, Class Loss: 0.8479\n",
      "Epoch 26/50, Loss: 2.7511, Domain Loss: 1.9858, Class Loss: 0.7653\n",
      "Epoch 27/50, Loss: 2.1940, Domain Loss: 1.4177, Class Loss: 0.7763\n",
      "Epoch 28/50, Loss: 2.0542, Domain Loss: 1.3468, Class Loss: 0.7074\n",
      "Epoch 29/50, Loss: 1.9924, Domain Loss: 1.3460, Class Loss: 0.6464\n",
      "Epoch 30/50, Loss: 1.9476, Domain Loss: 1.3611, Class Loss: 0.5864\n",
      "Epoch 31/50, Loss: 1.9339, Domain Loss: 1.3834, Class Loss: 0.5505\n",
      "Epoch 32/50, Loss: 1.9156, Domain Loss: 1.3336, Class Loss: 0.5820\n",
      "Epoch 33/50, Loss: 1.8424, Domain Loss: 1.3564, Class Loss: 0.4860\n",
      "Epoch 34/50, Loss: 1.8142, Domain Loss: 1.3930, Class Loss: 0.4212\n",
      "Epoch 35/50, Loss: 1.7491, Domain Loss: 1.3760, Class Loss: 0.3731\n",
      "Epoch 36/50, Loss: 3.0011, Domain Loss: 1.3722, Class Loss: 1.6289\n",
      "Epoch 37/50, Loss: 3.4041, Domain Loss: 1.9855, Class Loss: 1.4186\n",
      "Epoch 38/50, Loss: 2.7041, Domain Loss: 1.3365, Class Loss: 1.3676\n",
      "Epoch 39/50, Loss: 2.6683, Domain Loss: 1.3456, Class Loss: 1.3227\n",
      "Epoch 40/50, Loss: 2.6275, Domain Loss: 1.3705, Class Loss: 1.2570\n",
      "Epoch 41/50, Loss: 2.4960, Domain Loss: 1.3489, Class Loss: 1.1471\n",
      "Epoch 42/50, Loss: 2.2592, Domain Loss: 1.3585, Class Loss: 0.9008\n",
      "Epoch 43/50, Loss: 2.1654, Domain Loss: 1.3981, Class Loss: 0.7672\n",
      "Epoch 44/50, Loss: 1.9179, Domain Loss: 1.3513, Class Loss: 0.5665\n",
      "Epoch 45/50, Loss: 1.8259, Domain Loss: 1.3940, Class Loss: 0.4319\n",
      "Epoch 46/50, Loss: 1.7310, Domain Loss: 1.3775, Class Loss: 0.3534\n",
      "Epoch 47/50, Loss: 1.8038, Domain Loss: 1.3723, Class Loss: 0.4315\n",
      "Epoch 48/50, Loss: 1.7265, Domain Loss: 1.3642, Class Loss: 0.3623\n",
      "Epoch 49/50, Loss: 1.6406, Domain Loss: 1.3337, Class Loss: 0.3069\n",
      "Epoch 50/50, Loss: 1.6064, Domain Loss: 1.3473, Class Loss: 0.2591\n",
      "86.21\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8462, Domain Loss: 2.1677, Class Loss: 1.6785\n",
      "Epoch 2/50, Loss: 2.2772, Domain Loss: 1.3826, Class Loss: 0.8946\n",
      "Epoch 3/50, Loss: 2.1478, Domain Loss: 1.3756, Class Loss: 0.7721\n",
      "Epoch 4/50, Loss: 2.1340, Domain Loss: 1.3811, Class Loss: 0.7529\n",
      "Epoch 5/50, Loss: 2.1491, Domain Loss: 1.3677, Class Loss: 0.7815\n",
      "Epoch 6/50, Loss: 2.1209, Domain Loss: 1.3770, Class Loss: 0.7439\n",
      "Epoch 7/50, Loss: 2.1049, Domain Loss: 1.3725, Class Loss: 0.7324\n",
      "Epoch 8/50, Loss: 2.0827, Domain Loss: 1.3726, Class Loss: 0.7101\n",
      "Epoch 9/50, Loss: 2.0971, Domain Loss: 1.3813, Class Loss: 0.7157\n",
      "Epoch 10/50, Loss: 2.0821, Domain Loss: 1.3710, Class Loss: 0.7110\n",
      "Epoch 11/50, Loss: 2.0454, Domain Loss: 1.3675, Class Loss: 0.6779\n",
      "Epoch 12/50, Loss: 1.9425, Domain Loss: 1.3673, Class Loss: 0.5752\n",
      "Epoch 13/50, Loss: 1.9600, Domain Loss: 1.3602, Class Loss: 0.5998\n",
      "Epoch 14/50, Loss: 1.5849, Domain Loss: 1.3159, Class Loss: 0.2690\n",
      "Epoch 15/50, Loss: 1.3711, Domain Loss: 1.2620, Class Loss: 0.1091\n",
      "Epoch 16/50, Loss: 1.3371, Domain Loss: 1.2615, Class Loss: 0.0757\n",
      "Epoch 17/50, Loss: 1.3216, Domain Loss: 1.2350, Class Loss: 0.0865\n",
      "Epoch 18/50, Loss: 1.3569, Domain Loss: 1.2499, Class Loss: 0.1070\n",
      "Epoch 19/50, Loss: 1.2687, Domain Loss: 1.2226, Class Loss: 0.0461\n",
      "Epoch 20/50, Loss: 1.4492, Domain Loss: 1.2262, Class Loss: 0.2231\n",
      "Epoch 21/50, Loss: 1.3179, Domain Loss: 1.2235, Class Loss: 0.0945\n",
      "Epoch 22/50, Loss: 1.1863, Domain Loss: 1.1581, Class Loss: 0.0281\n",
      "Epoch 23/50, Loss: 1.1882, Domain Loss: 1.1634, Class Loss: 0.0248\n",
      "Epoch 24/50, Loss: 1.2221, Domain Loss: 1.1905, Class Loss: 0.0316\n",
      "Epoch 25/50, Loss: 1.2179, Domain Loss: 1.1817, Class Loss: 0.0362\n",
      "Epoch 26/50, Loss: 1.2707, Domain Loss: 1.2367, Class Loss: 0.0340\n",
      "Epoch 27/50, Loss: 1.7264, Domain Loss: 1.3225, Class Loss: 0.4039\n",
      "Epoch 28/50, Loss: 1.4235, Domain Loss: 1.3408, Class Loss: 0.0827\n",
      "Epoch 29/50, Loss: 1.3254, Domain Loss: 1.2611, Class Loss: 0.0643\n",
      "Epoch 30/50, Loss: 1.2357, Domain Loss: 1.2109, Class Loss: 0.0248\n",
      "Epoch 31/50, Loss: 1.3267, Domain Loss: 1.2507, Class Loss: 0.0759\n",
      "Epoch 32/50, Loss: 1.3862, Domain Loss: 1.2451, Class Loss: 0.1411\n",
      "Epoch 33/50, Loss: 1.2311, Domain Loss: 1.2056, Class Loss: 0.0255\n",
      "Epoch 34/50, Loss: 1.2387, Domain Loss: 1.2030, Class Loss: 0.0357\n",
      "Epoch 35/50, Loss: 1.2774, Domain Loss: 1.2169, Class Loss: 0.0605\n",
      "Epoch 36/50, Loss: 1.2967, Domain Loss: 1.2182, Class Loss: 0.0785\n",
      "Epoch 37/50, Loss: 1.2276, Domain Loss: 1.1634, Class Loss: 0.0642\n",
      "Epoch 38/50, Loss: 1.1730, Domain Loss: 1.1360, Class Loss: 0.0370\n",
      "Epoch 39/50, Loss: 1.3472, Domain Loss: 1.1844, Class Loss: 0.1628\n",
      "Epoch 40/50, Loss: 1.3229, Domain Loss: 1.1514, Class Loss: 0.1715\n",
      "Epoch 41/50, Loss: 1.1667, Domain Loss: 1.1122, Class Loss: 0.0545\n",
      "Epoch 42/50, Loss: 1.1530, Domain Loss: 1.1233, Class Loss: 0.0297\n",
      "Epoch 43/50, Loss: 1.2673, Domain Loss: 1.2189, Class Loss: 0.0484\n",
      "Epoch 44/50, Loss: 7.9748, Domain Loss: 5.9248, Class Loss: 2.0500\n",
      "Epoch 45/50, Loss: 8.0622, Domain Loss: 5.4823, Class Loss: 2.5799\n",
      "Epoch 46/50, Loss: 3.4472, Domain Loss: 2.0531, Class Loss: 1.3941\n",
      "Epoch 47/50, Loss: 8.4052, Domain Loss: 7.0687, Class Loss: 1.3365\n",
      "Epoch 48/50, Loss: 14.2689, Domain Loss: 12.4859, Class Loss: 1.7830\n",
      "Epoch 49/50, Loss: 4.6284, Domain Loss: 3.2618, Class Loss: 1.3666\n",
      "Epoch 50/50, Loss: 2.8655, Domain Loss: 1.5604, Class Loss: 1.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.80\n",
      "\n",
      "\n",
      "Source performance:\n",
      "81.99 80.25 82.12 79.70 \n",
      "Target performance:\n",
      "80.19 78.58 80.03 77.27 \n",
      "\n",
      "Per-class target performance: 98.88 74.55 69.17 77.54 \n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 3.6033, Discrepancy Loss: 0.1172\n",
      "Epoch [2/50], Class Loss: 1.4806, Discrepancy Loss: 0.1444\n",
      "Epoch [3/50], Class Loss: 1.2414, Discrepancy Loss: 0.1405\n",
      "Epoch [4/50], Class Loss: 1.1977, Discrepancy Loss: 0.1404\n",
      "Epoch [5/50], Class Loss: 1.0007, Discrepancy Loss: 0.1363\n",
      "Epoch [6/50], Class Loss: 0.3304, Discrepancy Loss: 0.0545\n",
      "Epoch [7/50], Class Loss: 0.1201, Discrepancy Loss: 0.0310\n",
      "Epoch [8/50], Class Loss: 0.0834, Discrepancy Loss: 0.0241\n",
      "Epoch [9/50], Class Loss: 0.1009, Discrepancy Loss: 0.0235\n",
      "Epoch [10/50], Class Loss: 0.1056, Discrepancy Loss: 0.0222\n",
      "Epoch [11/50], Class Loss: 0.0435, Discrepancy Loss: 0.0148\n",
      "Epoch [12/50], Class Loss: 0.0426, Discrepancy Loss: 0.0143\n",
      "Epoch [13/50], Class Loss: 0.0424, Discrepancy Loss: 0.0132\n",
      "Epoch [14/50], Class Loss: 0.0406, Discrepancy Loss: 0.0176\n",
      "Epoch [15/50], Class Loss: 0.0321, Discrepancy Loss: 0.0116\n",
      "Epoch [16/50], Class Loss: 0.0286, Discrepancy Loss: 0.0146\n",
      "Epoch [17/50], Class Loss: 0.0340, Discrepancy Loss: 0.0121\n",
      "Epoch [18/50], Class Loss: 0.0294, Discrepancy Loss: 0.0123\n",
      "Epoch [19/50], Class Loss: 0.0303, Discrepancy Loss: 0.0102\n",
      "Epoch [20/50], Class Loss: 0.0551, Discrepancy Loss: 0.0105\n",
      "Epoch [21/50], Class Loss: 0.0290, Discrepancy Loss: 0.0099\n",
      "Epoch [22/50], Class Loss: 0.0279, Discrepancy Loss: 0.0093\n",
      "Epoch [23/50], Class Loss: 0.0292, Discrepancy Loss: 0.0102\n",
      "Epoch [24/50], Class Loss: 0.0234, Discrepancy Loss: 0.0095\n",
      "Epoch [25/50], Class Loss: 0.0223, Discrepancy Loss: 0.0105\n",
      "Epoch [26/50], Class Loss: 0.0202, Discrepancy Loss: 0.0091\n",
      "Epoch [27/50], Class Loss: 0.0257, Discrepancy Loss: 0.0111\n",
      "Epoch [28/50], Class Loss: 0.0192, Discrepancy Loss: 0.0100\n",
      "Epoch [29/50], Class Loss: 0.0160, Discrepancy Loss: 0.0099\n",
      "Epoch [30/50], Class Loss: 0.0435, Discrepancy Loss: 0.0103\n",
      "Epoch [31/50], Class Loss: 0.0241, Discrepancy Loss: 0.0100\n",
      "Epoch [32/50], Class Loss: 0.0194, Discrepancy Loss: 0.0097\n",
      "Epoch [33/50], Class Loss: 0.0211, Discrepancy Loss: 0.0095\n",
      "Epoch [34/50], Class Loss: 0.0190, Discrepancy Loss: 0.0093\n",
      "Epoch [35/50], Class Loss: 0.0177, Discrepancy Loss: 0.0101\n",
      "Epoch [36/50], Class Loss: 0.0145, Discrepancy Loss: 0.0118\n",
      "Epoch [37/50], Class Loss: 0.0167, Discrepancy Loss: 0.0088\n",
      "Epoch [38/50], Class Loss: 0.0201, Discrepancy Loss: 0.0098\n",
      "Epoch [39/50], Class Loss: 0.0290, Discrepancy Loss: 0.0101\n",
      "Epoch [40/50], Class Loss: 0.0197, Discrepancy Loss: 0.0108\n",
      "Epoch [41/50], Class Loss: 0.0260, Discrepancy Loss: 0.0082\n",
      "Epoch [42/50], Class Loss: 0.0167, Discrepancy Loss: 0.0108\n",
      "Epoch [43/50], Class Loss: 0.0158, Discrepancy Loss: 0.0095\n",
      "Epoch [44/50], Class Loss: 0.0189, Discrepancy Loss: 0.0089\n",
      "Epoch [45/50], Class Loss: 0.0177, Discrepancy Loss: 0.0094\n",
      "Epoch [46/50], Class Loss: 0.0174, Discrepancy Loss: 0.0089\n",
      "Epoch [47/50], Class Loss: 0.0178, Discrepancy Loss: 0.0095\n",
      "Epoch [48/50], Class Loss: 0.0155, Discrepancy Loss: 0.0108\n",
      "Epoch [49/50], Class Loss: 0.0166, Discrepancy Loss: 0.0103\n",
      "Epoch [50/50], Class Loss: 0.0199, Discrepancy Loss: 0.0101\n",
      "Source Domain Performance - Accuracy: 99.58%, Precision: 99.58%, Recall: 99.57%, F1 Score: 99.57%\n",
      "Target Domain Performance - Accuracy: 98.98%, Precision: 98.95%, Recall: 98.95%, F1 Score: 98.94%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 3.2932, Discrepancy Loss: 0.1141\n",
      "Epoch [2/50], Class Loss: 1.2889, Discrepancy Loss: 0.1510\n",
      "Epoch [3/50], Class Loss: 1.0963, Discrepancy Loss: 0.1423\n",
      "Epoch [4/50], Class Loss: 0.3818, Discrepancy Loss: 0.0538\n",
      "Epoch [5/50], Class Loss: 0.1761, Discrepancy Loss: 0.0323\n",
      "Epoch [6/50], Class Loss: 0.1139, Discrepancy Loss: 0.0289\n",
      "Epoch [7/50], Class Loss: 0.1565, Discrepancy Loss: 0.0286\n",
      "Epoch [8/50], Class Loss: 0.0619, Discrepancy Loss: 0.0166\n",
      "Epoch [9/50], Class Loss: 0.1023, Discrepancy Loss: 0.0198\n",
      "Epoch [10/50], Class Loss: 0.1059, Discrepancy Loss: 0.0177\n",
      "Epoch [11/50], Class Loss: 0.0392, Discrepancy Loss: 0.0140\n",
      "Epoch [12/50], Class Loss: 0.0312, Discrepancy Loss: 0.0125\n",
      "Epoch [13/50], Class Loss: 0.0256, Discrepancy Loss: 0.0129\n",
      "Epoch [14/50], Class Loss: 0.0285, Discrepancy Loss: 0.0108\n",
      "Epoch [15/50], Class Loss: 0.0277, Discrepancy Loss: 0.0100\n",
      "Epoch [16/50], Class Loss: 0.0192, Discrepancy Loss: 0.0104\n",
      "Epoch [17/50], Class Loss: 0.0186, Discrepancy Loss: 0.0085\n",
      "Epoch [18/50], Class Loss: 0.0175, Discrepancy Loss: 0.0107\n",
      "Epoch [19/50], Class Loss: 0.0199, Discrepancy Loss: 0.0102\n",
      "Epoch [20/50], Class Loss: 0.0170, Discrepancy Loss: 0.0098\n",
      "Epoch [21/50], Class Loss: 0.0122, Discrepancy Loss: 0.0098\n",
      "Epoch [22/50], Class Loss: 0.0149, Discrepancy Loss: 0.0101\n",
      "Epoch [23/50], Class Loss: 0.0308, Discrepancy Loss: 0.0109\n",
      "Epoch [24/50], Class Loss: 0.0138, Discrepancy Loss: 0.0112\n",
      "Epoch [25/50], Class Loss: 0.0105, Discrepancy Loss: 0.0114\n",
      "Epoch [26/50], Class Loss: 0.0136, Discrepancy Loss: 0.0082\n",
      "Epoch [27/50], Class Loss: 0.0219, Discrepancy Loss: 0.0098\n",
      "Epoch [28/50], Class Loss: 0.0144, Discrepancy Loss: 0.0102\n",
      "Epoch [29/50], Class Loss: 0.0114, Discrepancy Loss: 0.0091\n",
      "Epoch [30/50], Class Loss: 0.0116, Discrepancy Loss: 0.0094\n",
      "Epoch [31/50], Class Loss: 0.0140, Discrepancy Loss: 0.0096\n",
      "Epoch [32/50], Class Loss: 0.0104, Discrepancy Loss: 0.0092\n",
      "Epoch [33/50], Class Loss: 0.0122, Discrepancy Loss: 0.0087\n",
      "Epoch [34/50], Class Loss: 0.0193, Discrepancy Loss: 0.0110\n",
      "Epoch [35/50], Class Loss: 0.0105, Discrepancy Loss: 0.0110\n",
      "Epoch [36/50], Class Loss: 0.0144, Discrepancy Loss: 0.0094\n",
      "Epoch [37/50], Class Loss: 0.0262, Discrepancy Loss: 0.0103\n",
      "Epoch [38/50], Class Loss: 0.0094, Discrepancy Loss: 0.0088\n",
      "Epoch [39/50], Class Loss: 0.0137, Discrepancy Loss: 0.0099\n",
      "Epoch [40/50], Class Loss: 0.0239, Discrepancy Loss: 0.0109\n",
      "Epoch [41/50], Class Loss: 0.0117, Discrepancy Loss: 0.0097\n",
      "Epoch [42/50], Class Loss: 0.0683, Discrepancy Loss: 0.0095\n",
      "Epoch [43/50], Class Loss: 0.0138, Discrepancy Loss: 0.0094\n",
      "Epoch [44/50], Class Loss: 0.0364, Discrepancy Loss: 0.0096\n",
      "Epoch [45/50], Class Loss: 0.0242, Discrepancy Loss: 0.0098\n",
      "Epoch [46/50], Class Loss: 0.0123, Discrepancy Loss: 0.0087\n",
      "Epoch [47/50], Class Loss: 0.0122, Discrepancy Loss: 0.0097\n",
      "Epoch [48/50], Class Loss: 0.0148, Discrepancy Loss: 0.0111\n",
      "Epoch [49/50], Class Loss: 0.0145, Discrepancy Loss: 0.0095\n",
      "Epoch [50/50], Class Loss: 0.0098, Discrepancy Loss: 0.0103\n",
      "Source Domain Performance - Accuracy: 99.64%, Precision: 99.65%, Recall: 99.63%, F1 Score: 99.64%\n",
      "Target Domain Performance - Accuracy: 98.86%, Precision: 98.81%, Recall: 98.86%, F1 Score: 98.83%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 3.2124, Discrepancy Loss: 0.1250\n",
      "Epoch [2/50], Class Loss: 1.3753, Discrepancy Loss: 0.1619\n",
      "Epoch [3/50], Class Loss: 1.2472, Discrepancy Loss: 0.1487\n",
      "Epoch [4/50], Class Loss: 0.4565, Discrepancy Loss: 0.0795\n",
      "Epoch [5/50], Class Loss: 0.1538, Discrepancy Loss: 0.0267\n",
      "Epoch [6/50], Class Loss: 0.1248, Discrepancy Loss: 0.0280\n",
      "Epoch [7/50], Class Loss: 0.0856, Discrepancy Loss: 0.0234\n",
      "Epoch [8/50], Class Loss: 0.0856, Discrepancy Loss: 0.0216\n",
      "Epoch [9/50], Class Loss: 0.0835, Discrepancy Loss: 0.0214\n",
      "Epoch [10/50], Class Loss: 0.0438, Discrepancy Loss: 0.0155\n",
      "Epoch [11/50], Class Loss: 0.0241, Discrepancy Loss: 0.0122\n",
      "Epoch [12/50], Class Loss: 0.0176, Discrepancy Loss: 0.0107\n",
      "Epoch [13/50], Class Loss: 0.0194, Discrepancy Loss: 0.0141\n",
      "Epoch [14/50], Class Loss: 0.0179, Discrepancy Loss: 0.0105\n",
      "Epoch [15/50], Class Loss: 0.0497, Discrepancy Loss: 0.0118\n",
      "Epoch [16/50], Class Loss: 0.0239, Discrepancy Loss: 0.0119\n",
      "Epoch [17/50], Class Loss: 0.0102, Discrepancy Loss: 0.0083\n",
      "Epoch [18/50], Class Loss: 0.0160, Discrepancy Loss: 0.0139\n",
      "Epoch [19/50], Class Loss: 0.0202, Discrepancy Loss: 0.0099\n",
      "Epoch [20/50], Class Loss: 0.0185, Discrepancy Loss: 0.0123\n",
      "Epoch [21/50], Class Loss: 0.0086, Discrepancy Loss: 0.0100\n",
      "Epoch [22/50], Class Loss: 0.0208, Discrepancy Loss: 0.0104\n",
      "Epoch [23/50], Class Loss: 0.0189, Discrepancy Loss: 0.0101\n",
      "Epoch [24/50], Class Loss: 0.0139, Discrepancy Loss: 0.0115\n",
      "Epoch [25/50], Class Loss: 0.0120, Discrepancy Loss: 0.0100\n",
      "Epoch [26/50], Class Loss: 0.0134, Discrepancy Loss: 0.0090\n",
      "Epoch [27/50], Class Loss: 0.0170, Discrepancy Loss: 0.0096\n",
      "Epoch [28/50], Class Loss: 0.0093, Discrepancy Loss: 0.0091\n",
      "Epoch [29/50], Class Loss: 0.0102, Discrepancy Loss: 0.0108\n",
      "Epoch [30/50], Class Loss: 0.0126, Discrepancy Loss: 0.0103\n",
      "Epoch [31/50], Class Loss: 0.0125, Discrepancy Loss: 0.0114\n",
      "Epoch [32/50], Class Loss: 0.0205, Discrepancy Loss: 0.0110\n",
      "Epoch [33/50], Class Loss: 0.0106, Discrepancy Loss: 0.0112\n",
      "Epoch [34/50], Class Loss: 0.0124, Discrepancy Loss: 0.0099\n",
      "Epoch [35/50], Class Loss: 0.0149, Discrepancy Loss: 0.0111\n",
      "Epoch [36/50], Class Loss: 0.0139, Discrepancy Loss: 0.0095\n",
      "Epoch [37/50], Class Loss: 0.0094, Discrepancy Loss: 0.0101\n",
      "Epoch [38/50], Class Loss: 0.0101, Discrepancy Loss: 0.0079\n",
      "Epoch [39/50], Class Loss: 0.0115, Discrepancy Loss: 0.0090\n",
      "Epoch [40/50], Class Loss: 0.0164, Discrepancy Loss: 0.0081\n",
      "Epoch [41/50], Class Loss: 0.0161, Discrepancy Loss: 0.0113\n",
      "Epoch [42/50], Class Loss: 0.0184, Discrepancy Loss: 0.0093\n",
      "Epoch [43/50], Class Loss: 0.0086, Discrepancy Loss: 0.0094\n",
      "Epoch [44/50], Class Loss: 0.0147, Discrepancy Loss: 0.0092\n",
      "Epoch [45/50], Class Loss: 0.0112, Discrepancy Loss: 0.0085\n",
      "Epoch [46/50], Class Loss: 0.0111, Discrepancy Loss: 0.0097\n",
      "Epoch [47/50], Class Loss: 0.0118, Discrepancy Loss: 0.0088\n",
      "Epoch [48/50], Class Loss: 0.0203, Discrepancy Loss: 0.0093\n",
      "Epoch [49/50], Class Loss: 0.0178, Discrepancy Loss: 0.0085\n",
      "Epoch [50/50], Class Loss: 0.0145, Discrepancy Loss: 0.0091\n",
      "Source Domain Performance - Accuracy: 99.64%, Precision: 99.64%, Recall: 99.63%, F1 Score: 99.63%\n",
      "Target Domain Performance - Accuracy: 99.46%, Precision: 99.43%, Recall: 99.45%, F1 Score: 99.44%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 3.0002, Discrepancy Loss: 0.1220\n",
      "Epoch [2/50], Class Loss: 1.4416, Discrepancy Loss: 0.1438\n",
      "Epoch [3/50], Class Loss: 1.1406, Discrepancy Loss: 0.1580\n",
      "Epoch [4/50], Class Loss: 0.2974, Discrepancy Loss: 0.0418\n",
      "Epoch [5/50], Class Loss: 0.1566, Discrepancy Loss: 0.0276\n",
      "Epoch [6/50], Class Loss: 0.0703, Discrepancy Loss: 0.0168\n",
      "Epoch [7/50], Class Loss: 0.0697, Discrepancy Loss: 0.0214\n",
      "Epoch [8/50], Class Loss: 0.1293, Discrepancy Loss: 0.0252\n",
      "Epoch [9/50], Class Loss: 0.0961, Discrepancy Loss: 0.0162\n",
      "Epoch [10/50], Class Loss: 0.0968, Discrepancy Loss: 0.0222\n",
      "Epoch [11/50], Class Loss: 0.0345, Discrepancy Loss: 0.0120\n",
      "Epoch [12/50], Class Loss: 0.0288, Discrepancy Loss: 0.0128\n",
      "Epoch [13/50], Class Loss: 0.0271, Discrepancy Loss: 0.0137\n",
      "Epoch [14/50], Class Loss: 0.0265, Discrepancy Loss: 0.0134\n",
      "Epoch [15/50], Class Loss: 0.0270, Discrepancy Loss: 0.0108\n",
      "Epoch [16/50], Class Loss: 0.0299, Discrepancy Loss: 0.0110\n",
      "Epoch [17/50], Class Loss: 0.0301, Discrepancy Loss: 0.0137\n",
      "Epoch [18/50], Class Loss: 0.0177, Discrepancy Loss: 0.0109\n",
      "Epoch [19/50], Class Loss: 0.0178, Discrepancy Loss: 0.0100\n",
      "Epoch [20/50], Class Loss: 0.0172, Discrepancy Loss: 0.0104\n",
      "Epoch [21/50], Class Loss: 0.0153, Discrepancy Loss: 0.0118\n",
      "Epoch [22/50], Class Loss: 0.0135, Discrepancy Loss: 0.0101\n",
      "Epoch [23/50], Class Loss: 0.0179, Discrepancy Loss: 0.0114\n",
      "Epoch [24/50], Class Loss: 0.0175, Discrepancy Loss: 0.0115\n",
      "Epoch [25/50], Class Loss: 0.0112, Discrepancy Loss: 0.0099\n",
      "Epoch [26/50], Class Loss: 0.0159, Discrepancy Loss: 0.0105\n",
      "Epoch [27/50], Class Loss: 0.0204, Discrepancy Loss: 0.0093\n",
      "Epoch [28/50], Class Loss: 0.0185, Discrepancy Loss: 0.0109\n",
      "Epoch [29/50], Class Loss: 0.0157, Discrepancy Loss: 0.0089\n",
      "Epoch [30/50], Class Loss: 0.0182, Discrepancy Loss: 0.0100\n",
      "Epoch [31/50], Class Loss: 0.0121, Discrepancy Loss: 0.0090\n",
      "Epoch [32/50], Class Loss: 0.0155, Discrepancy Loss: 0.0118\n",
      "Epoch [33/50], Class Loss: 0.0149, Discrepancy Loss: 0.0105\n",
      "Epoch [34/50], Class Loss: 0.0182, Discrepancy Loss: 0.0124\n",
      "Epoch [35/50], Class Loss: 0.0132, Discrepancy Loss: 0.0088\n",
      "Epoch [36/50], Class Loss: 0.0142, Discrepancy Loss: 0.0092\n",
      "Epoch [37/50], Class Loss: 0.0144, Discrepancy Loss: 0.0111\n",
      "Epoch [38/50], Class Loss: 0.0118, Discrepancy Loss: 0.0097\n",
      "Epoch [39/50], Class Loss: 0.0110, Discrepancy Loss: 0.0106\n",
      "Epoch [40/50], Class Loss: 0.0157, Discrepancy Loss: 0.0089\n",
      "Epoch [41/50], Class Loss: 0.0115, Discrepancy Loss: 0.0098\n",
      "Epoch [42/50], Class Loss: 0.0168, Discrepancy Loss: 0.0085\n",
      "Epoch [43/50], Class Loss: 0.0113, Discrepancy Loss: 0.0078\n",
      "Epoch [44/50], Class Loss: 0.0174, Discrepancy Loss: 0.0093\n",
      "Epoch [45/50], Class Loss: 0.0106, Discrepancy Loss: 0.0092\n",
      "Epoch [46/50], Class Loss: 0.0103, Discrepancy Loss: 0.0104\n",
      "Epoch [47/50], Class Loss: 0.0244, Discrepancy Loss: 0.0107\n",
      "Epoch [48/50], Class Loss: 0.0161, Discrepancy Loss: 0.0095\n",
      "Epoch [49/50], Class Loss: 0.0222, Discrepancy Loss: 0.0088\n",
      "Epoch [50/50], Class Loss: 0.0141, Discrepancy Loss: 0.0095\n",
      "Source Domain Performance - Accuracy: 99.70%, Precision: 99.69%, Recall: 99.69%, F1 Score: 99.69%\n",
      "Target Domain Performance - Accuracy: 99.16%, Precision: 99.13%, Recall: 99.17%, F1 Score: 99.15%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 3.4155, Discrepancy Loss: 0.1203\n",
      "Epoch [2/50], Class Loss: 1.5197, Discrepancy Loss: 0.1509\n",
      "Epoch [3/50], Class Loss: 1.2953, Discrepancy Loss: 0.1447\n",
      "Epoch [4/50], Class Loss: 0.7032, Discrepancy Loss: 0.1116\n",
      "Epoch [5/50], Class Loss: 0.2322, Discrepancy Loss: 0.0457\n",
      "Epoch [6/50], Class Loss: 0.1229, Discrepancy Loss: 0.0355\n",
      "Epoch [7/50], Class Loss: 0.0986, Discrepancy Loss: 0.0224\n",
      "Epoch [8/50], Class Loss: 0.0993, Discrepancy Loss: 0.0217\n",
      "Epoch [9/50], Class Loss: 0.0771, Discrepancy Loss: 0.0228\n",
      "Epoch [10/50], Class Loss: 0.0799, Discrepancy Loss: 0.0190\n",
      "Epoch [11/50], Class Loss: 0.0436, Discrepancy Loss: 0.0120\n",
      "Epoch [12/50], Class Loss: 0.0411, Discrepancy Loss: 0.0126\n",
      "Epoch [13/50], Class Loss: 0.0340, Discrepancy Loss: 0.0122\n",
      "Epoch [14/50], Class Loss: 0.0303, Discrepancy Loss: 0.0108\n",
      "Epoch [15/50], Class Loss: 0.0277, Discrepancy Loss: 0.0110\n",
      "Epoch [16/50], Class Loss: 0.0201, Discrepancy Loss: 0.0115\n",
      "Epoch [17/50], Class Loss: 0.0331, Discrepancy Loss: 0.0096\n",
      "Epoch [18/50], Class Loss: 0.0565, Discrepancy Loss: 0.0104\n",
      "Epoch [19/50], Class Loss: 0.0275, Discrepancy Loss: 0.0101\n",
      "Epoch [20/50], Class Loss: 0.0205, Discrepancy Loss: 0.0093\n",
      "Epoch [21/50], Class Loss: 0.0589, Discrepancy Loss: 0.0087\n",
      "Epoch [22/50], Class Loss: 0.0171, Discrepancy Loss: 0.0096\n",
      "Epoch [23/50], Class Loss: 0.0205, Discrepancy Loss: 0.0083\n",
      "Epoch [24/50], Class Loss: 0.0119, Discrepancy Loss: 0.0102\n",
      "Epoch [25/50], Class Loss: 0.0186, Discrepancy Loss: 0.0086\n",
      "Epoch [26/50], Class Loss: 0.0188, Discrepancy Loss: 0.0076\n",
      "Epoch [27/50], Class Loss: 0.0110, Discrepancy Loss: 0.0076\n",
      "Epoch [28/50], Class Loss: 0.0090, Discrepancy Loss: 0.0104\n",
      "Epoch [29/50], Class Loss: 0.0136, Discrepancy Loss: 0.0090\n",
      "Epoch [30/50], Class Loss: 0.0157, Discrepancy Loss: 0.0081\n",
      "Epoch [31/50], Class Loss: 0.0158, Discrepancy Loss: 0.0071\n",
      "Epoch [32/50], Class Loss: 0.0215, Discrepancy Loss: 0.0109\n",
      "Epoch [33/50], Class Loss: 0.0158, Discrepancy Loss: 0.0092\n",
      "Epoch [34/50], Class Loss: 0.0199, Discrepancy Loss: 0.0081\n",
      "Epoch [35/50], Class Loss: 0.0152, Discrepancy Loss: 0.0090\n",
      "Epoch [36/50], Class Loss: 0.0137, Discrepancy Loss: 0.0076\n",
      "Epoch [37/50], Class Loss: 0.0091, Discrepancy Loss: 0.0090\n",
      "Epoch [38/50], Class Loss: 0.0288, Discrepancy Loss: 0.0082\n",
      "Epoch [39/50], Class Loss: 0.0163, Discrepancy Loss: 0.0083\n",
      "Epoch [40/50], Class Loss: 0.0157, Discrepancy Loss: 0.0082\n",
      "Epoch [41/50], Class Loss: 0.0105, Discrepancy Loss: 0.0085\n",
      "Epoch [42/50], Class Loss: 0.0149, Discrepancy Loss: 0.0071\n",
      "Epoch [43/50], Class Loss: 0.0113, Discrepancy Loss: 0.0080\n",
      "Epoch [44/50], Class Loss: 0.0134, Discrepancy Loss: 0.0080\n",
      "Epoch [45/50], Class Loss: 0.0161, Discrepancy Loss: 0.0076\n",
      "Epoch [46/50], Class Loss: 0.0102, Discrepancy Loss: 0.0087\n",
      "Epoch [47/50], Class Loss: 0.0182, Discrepancy Loss: 0.0085\n",
      "Epoch [48/50], Class Loss: 0.0144, Discrepancy Loss: 0.0076\n",
      "Epoch [49/50], Class Loss: 0.0124, Discrepancy Loss: 0.0087\n",
      "Epoch [50/50], Class Loss: 0.0143, Discrepancy Loss: 0.0084\n",
      "Source Domain Performance - Accuracy: 99.28%, Precision: 99.32%, Recall: 99.26%, F1 Score: 99.29%\n",
      "Target Domain Performance - Accuracy: 98.08%, Precision: 98.03%, Recall: 98.05%, F1 Score: 98.01%\n",
      "\n",
      "Source performance: 99.57% 99.58% 99.56% 99.56%\n",
      "Target performance: 98.91% 98.87% 98.90% 98.87%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 100.00%\n",
      "qpsk: 98.85%\n",
      "16qam: 96.94%\n",
      "8apsk: 99.80%\n",
      "\n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 2.2749, Discrepancy Loss: 0.0751\n",
      "Validation Loss: 1.5394\n",
      "Epoch [2/50], Class Loss: 1.4449, Discrepancy Loss: 0.0379\n",
      "Validation Loss: 0.9975\n",
      "Epoch [3/50], Class Loss: 0.6278, Discrepancy Loss: 0.0317\n",
      "Validation Loss: 0.0882\n",
      "Epoch [4/50], Class Loss: 0.3910, Discrepancy Loss: 0.0278\n",
      "Validation Loss: 0.4383\n",
      "Epoch [5/50], Class Loss: 0.3335, Discrepancy Loss: 0.0222\n",
      "Validation Loss: 0.0762\n",
      "Epoch [6/50], Class Loss: 0.1957, Discrepancy Loss: 0.0162\n",
      "Validation Loss: 0.9146\n",
      "Epoch [7/50], Class Loss: 0.2389, Discrepancy Loss: 0.0243\n",
      "Validation Loss: 0.1699\n",
      "Epoch [8/50], Class Loss: 0.2364, Discrepancy Loss: 0.0379\n",
      "Validation Loss: 0.5315\n",
      "Epoch [9/50], Class Loss: 0.2447, Discrepancy Loss: 0.0200\n",
      "Validation Loss: 0.0521\n",
      "Epoch [10/50], Class Loss: 0.1860, Discrepancy Loss: 0.0241\n",
      "Validation Loss: 0.1598\n",
      "Epoch [11/50], Class Loss: 0.0310, Discrepancy Loss: 0.0123\n",
      "Validation Loss: 0.1254\n",
      "Epoch [12/50], Class Loss: 0.0199, Discrepancy Loss: 0.0100\n",
      "Validation Loss: 0.0612\n",
      "Epoch [13/50], Class Loss: 0.0191, Discrepancy Loss: 0.0094\n",
      "Validation Loss: 0.0769\n",
      "Epoch [14/50], Class Loss: 0.0175, Discrepancy Loss: 0.0101\n",
      "Validation Loss: 0.0800\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.80%, Precision: 98.80%, Recall: 98.78%, F1 Score: 98.79%\n",
      "Target Domain Performance - Accuracy: 90.59%, Precision: 91.28%, Recall: 90.90%, F1 Score: 90.61%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.0183, Discrepancy Loss: 0.0756\n",
      "Validation Loss: 1.4256\n",
      "Epoch [2/50], Class Loss: 1.0562, Discrepancy Loss: 0.0463\n",
      "Validation Loss: 0.1413\n",
      "Epoch [3/50], Class Loss: 0.2559, Discrepancy Loss: 0.0289\n",
      "Validation Loss: 0.3897\n",
      "Epoch [4/50], Class Loss: 0.1963, Discrepancy Loss: 0.0245\n",
      "Validation Loss: 0.5648\n",
      "Epoch [5/50], Class Loss: 0.1358, Discrepancy Loss: 0.0216\n",
      "Validation Loss: 0.2872\n",
      "Epoch [6/50], Class Loss: 0.1593, Discrepancy Loss: 0.0222\n",
      "Validation Loss: 1.5900\n",
      "Epoch [7/50], Class Loss: 0.1625, Discrepancy Loss: 0.0199\n",
      "Validation Loss: 0.0448\n",
      "Epoch [8/50], Class Loss: 0.1943, Discrepancy Loss: 0.0233\n",
      "Validation Loss: 0.0429\n",
      "Epoch [9/50], Class Loss: 0.1536, Discrepancy Loss: 0.0260\n",
      "Validation Loss: 0.2688\n",
      "Epoch [10/50], Class Loss: 0.2217, Discrepancy Loss: 0.0332\n",
      "Validation Loss: 0.3243\n",
      "Epoch [11/50], Class Loss: 0.0460, Discrepancy Loss: 0.0204\n",
      "Validation Loss: 0.0282\n",
      "Epoch [12/50], Class Loss: 0.0242, Discrepancy Loss: 0.0144\n",
      "Validation Loss: 0.0783\n",
      "Epoch [13/50], Class Loss: 0.0293, Discrepancy Loss: 0.0167\n",
      "Validation Loss: 0.0595\n",
      "Epoch [14/50], Class Loss: 0.0277, Discrepancy Loss: 0.0160\n",
      "Validation Loss: 0.0343\n",
      "Epoch [15/50], Class Loss: 0.0256, Discrepancy Loss: 0.0158\n",
      "Validation Loss: 0.0486\n",
      "Epoch [16/50], Class Loss: 0.0255, Discrepancy Loss: 0.0175\n",
      "Validation Loss: 0.0625\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.16%, Precision: 99.18%, Recall: 99.14%, F1 Score: 99.15%\n",
      "Target Domain Performance - Accuracy: 94.54%, Precision: 94.61%, Recall: 94.69%, F1 Score: 94.52%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 2.2869, Discrepancy Loss: 0.0790\n",
      "Validation Loss: 1.5699\n",
      "Epoch [2/50], Class Loss: 1.3479, Discrepancy Loss: 0.0255\n",
      "Validation Loss: 0.6554\n",
      "Epoch [3/50], Class Loss: 0.2141, Discrepancy Loss: 0.0197\n",
      "Validation Loss: 0.1536\n",
      "Epoch [4/50], Class Loss: 0.2342, Discrepancy Loss: 0.0152\n",
      "Validation Loss: 0.1806\n",
      "Epoch [5/50], Class Loss: 0.2120, Discrepancy Loss: 0.0210\n",
      "Validation Loss: 0.1330\n",
      "Epoch [6/50], Class Loss: 0.3508, Discrepancy Loss: 0.0275\n",
      "Validation Loss: 0.0638\n",
      "Epoch [7/50], Class Loss: 0.2505, Discrepancy Loss: 0.0309\n",
      "Validation Loss: 0.2000\n",
      "Epoch [8/50], Class Loss: 0.1464, Discrepancy Loss: 0.0313\n",
      "Validation Loss: 0.1557\n",
      "Epoch [9/50], Class Loss: 0.1980, Discrepancy Loss: 0.0305\n",
      "Validation Loss: 0.1208\n",
      "Epoch [10/50], Class Loss: 0.4369, Discrepancy Loss: 0.0299\n",
      "Validation Loss: 0.2770\n",
      "Epoch [11/50], Class Loss: 0.0599, Discrepancy Loss: 0.0196\n",
      "Validation Loss: 0.0532\n",
      "Epoch [12/50], Class Loss: 0.0306, Discrepancy Loss: 0.0140\n",
      "Validation Loss: 0.0608\n",
      "Epoch [13/50], Class Loss: 0.0314, Discrepancy Loss: 0.0135\n",
      "Validation Loss: 0.0519\n",
      "Epoch [14/50], Class Loss: 0.0241, Discrepancy Loss: 0.0118\n",
      "Validation Loss: 0.0550\n",
      "Epoch [15/50], Class Loss: 0.0221, Discrepancy Loss: 0.0122\n",
      "Validation Loss: 0.1069\n",
      "Epoch [16/50], Class Loss: 0.0309, Discrepancy Loss: 0.0155\n",
      "Validation Loss: 0.0994\n",
      "Epoch [17/50], Class Loss: 0.0237, Discrepancy Loss: 0.0165\n",
      "Validation Loss: 0.1111\n",
      "Epoch [18/50], Class Loss: 0.0212, Discrepancy Loss: 0.0209\n",
      "Validation Loss: 0.1055\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.56%, Precision: 98.61%, Recall: 98.53%, F1 Score: 98.56%\n",
      "Target Domain Performance - Accuracy: 91.01%, Precision: 91.16%, Recall: 91.11%, F1 Score: 90.87%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 2.0958, Discrepancy Loss: 0.0660\n",
      "Validation Loss: 1.5302\n",
      "Epoch [2/50], Class Loss: 1.4755, Discrepancy Loss: 0.0465\n",
      "Validation Loss: 1.8541\n",
      "Epoch [3/50], Class Loss: 0.6827, Discrepancy Loss: 0.0358\n",
      "Validation Loss: 0.6058\n",
      "Epoch [4/50], Class Loss: 0.3221, Discrepancy Loss: 0.0175\n",
      "Validation Loss: 0.1756\n",
      "Epoch [5/50], Class Loss: 0.1243, Discrepancy Loss: 0.0250\n",
      "Validation Loss: 0.1787\n",
      "Epoch [6/50], Class Loss: 0.1754, Discrepancy Loss: 0.0420\n",
      "Validation Loss: 0.1570\n",
      "Epoch [7/50], Class Loss: 0.1758, Discrepancy Loss: 0.0350\n",
      "Validation Loss: 0.2280\n",
      "Epoch [8/50], Class Loss: 0.2163, Discrepancy Loss: 0.0325\n",
      "Validation Loss: 0.3432\n",
      "Epoch [9/50], Class Loss: 0.3036, Discrepancy Loss: 0.0462\n",
      "Validation Loss: 0.0679\n",
      "Epoch [10/50], Class Loss: 0.4186, Discrepancy Loss: 0.0356\n",
      "Validation Loss: 1.7980\n",
      "Epoch [11/50], Class Loss: 0.1807, Discrepancy Loss: 0.0392\n",
      "Validation Loss: 0.0718\n",
      "Epoch [12/50], Class Loss: 0.0274, Discrepancy Loss: 0.0243\n",
      "Validation Loss: 0.0839\n",
      "Epoch [13/50], Class Loss: 0.0285, Discrepancy Loss: 0.0223\n",
      "Validation Loss: 0.0625\n",
      "Epoch [14/50], Class Loss: 0.0285, Discrepancy Loss: 0.0248\n",
      "Validation Loss: 0.0947\n",
      "Epoch [15/50], Class Loss: 0.0274, Discrepancy Loss: 0.0239\n",
      "Validation Loss: 0.0786\n",
      "Epoch [16/50], Class Loss: 0.0343, Discrepancy Loss: 0.0244\n",
      "Validation Loss: 0.1701\n",
      "Epoch [17/50], Class Loss: 0.0352, Discrepancy Loss: 0.0242\n",
      "Validation Loss: 0.1309\n",
      "Epoch [18/50], Class Loss: 0.0261, Discrepancy Loss: 0.0218\n",
      "Validation Loss: 0.1053\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.50%, Precision: 98.55%, Recall: 98.47%, F1 Score: 98.49%\n",
      "Target Domain Performance - Accuracy: 93.23%, Precision: 93.29%, Recall: 93.37%, F1 Score: 93.13%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 2.0345, Discrepancy Loss: 0.0733\n",
      "Validation Loss: 1.8707\n",
      "Epoch [2/50], Class Loss: 1.5270, Discrepancy Loss: 0.0353\n",
      "Validation Loss: 1.4287\n",
      "Epoch [3/50], Class Loss: 1.0072, Discrepancy Loss: 0.0339\n",
      "Validation Loss: 0.1250\n",
      "Epoch [4/50], Class Loss: 0.2107, Discrepancy Loss: 0.0249\n",
      "Validation Loss: 0.6190\n",
      "Epoch [5/50], Class Loss: 0.2267, Discrepancy Loss: 0.0244\n",
      "Validation Loss: 0.1090\n",
      "Epoch [6/50], Class Loss: 0.3254, Discrepancy Loss: 0.0221\n",
      "Validation Loss: 0.4313\n",
      "Epoch [7/50], Class Loss: 0.2253, Discrepancy Loss: 0.0293\n",
      "Validation Loss: 0.3435\n",
      "Epoch [8/50], Class Loss: 0.1547, Discrepancy Loss: 0.0258\n",
      "Validation Loss: 1.7185\n",
      "Epoch [9/50], Class Loss: 0.1403, Discrepancy Loss: 0.0242\n",
      "Validation Loss: 0.1185\n",
      "Epoch [10/50], Class Loss: 0.1618, Discrepancy Loss: 0.0373\n",
      "Validation Loss: 0.1352\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.14%, Precision: 98.27%, Recall: 98.09%, F1 Score: 98.14%\n",
      "Target Domain Performance - Accuracy: 92.57%, Precision: 92.65%, Recall: 92.53%, F1 Score: 92.30%\n",
      "\n",
      "Source performance: 98.63% 98.68% 98.60% 98.63%\n",
      "Target performance: 92.39% 92.60% 92.52% 92.29%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 98.03%\n",
      "qpsk: 86.43%\n",
      "16qam: 85.71%\n",
      "8apsk: 99.90%\n",
      "\n",
      "Run 1/5\n",
      "Epoch 1/50, Train Loss: 1.2852, Train Acc: 0.4916, Val Loss: 0.9107, Val Acc: 0.5677\n",
      "Epoch 2/50, Train Loss: 0.7923, Train Acc: 0.5990, Val Loss: 0.7820, Val Acc: 0.5989\n",
      "Epoch 3/50, Train Loss: 0.6485, Train Acc: 0.6836, Val Loss: 0.2776, Val Acc: 0.8687\n",
      "Epoch 4/50, Train Loss: 0.1114, Train Acc: 0.9595, Val Loss: 0.0744, Val Acc: 0.9670\n",
      "Epoch 5/50, Train Loss: 0.0820, Train Acc: 0.9736, Val Loss: 0.0117, Val Acc: 0.9964\n",
      "Epoch 6/50, Train Loss: 0.0416, Train Acc: 0.9882, Val Loss: 0.0125, Val Acc: 0.9964\n",
      "Epoch 7/50, Train Loss: 0.0524, Train Acc: 0.9864, Val Loss: 0.0729, Val Acc: 0.9838\n",
      "Epoch 8/50, Train Loss: 0.0351, Train Acc: 0.9898, Val Loss: 0.0443, Val Acc: 0.9856\n",
      "Epoch 9/50, Train Loss: 0.0262, Train Acc: 0.9928, Val Loss: 0.5974, Val Acc: 0.8849\n",
      "Epoch 10/50, Train Loss: 0.0476, Train Acc: 0.9874, Val Loss: 0.0086, Val Acc: 0.9982\n",
      "Epoch 11/50, Train Loss: 0.0035, Train Acc: 0.9991, Val Loss: 0.0021, Val Acc: 0.9994\n",
      "Epoch 12/50, Train Loss: 0.0030, Train Acc: 0.9994, Val Loss: 0.0029, Val Acc: 0.9988\n",
      "Epoch 13/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0043, Val Acc: 0.9988\n",
      "Epoch 14/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0028, Val Acc: 0.9988\n",
      "Epoch 15/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0037, Val Acc: 0.9988\n",
      "Epoch 16/50, Train Loss: 0.0013, Train Acc: 0.9996, Val Loss: 0.0084, Val Acc: 0.9982\n",
      "Early stopping!\n",
      "\n",
      "Run 2/5\n",
      "Epoch 1/50, Train Loss: 0.9796, Train Acc: 0.5475, Val Loss: 0.7592, Val Acc: 0.5995\n",
      "Epoch 2/50, Train Loss: 0.7498, Train Acc: 0.6189, Val Loss: 0.7053, Val Acc: 0.6343\n",
      "Epoch 3/50, Train Loss: 0.3457, Train Acc: 0.8484, Val Loss: 0.6453, Val Acc: 0.7806\n",
      "Epoch 4/50, Train Loss: 0.1117, Train Acc: 0.9663, Val Loss: 0.2925, Val Acc: 0.9209\n",
      "Epoch 5/50, Train Loss: 0.0586, Train Acc: 0.9817, Val Loss: 0.0324, Val Acc: 0.9904\n",
      "Epoch 6/50, Train Loss: 0.0728, Train Acc: 0.9823, Val Loss: 0.0163, Val Acc: 0.9934\n",
      "Epoch 7/50, Train Loss: 0.0418, Train Acc: 0.9892, Val Loss: 0.0145, Val Acc: 0.9958\n",
      "Epoch 8/50, Train Loss: 0.0336, Train Acc: 0.9912, Val Loss: 0.0408, Val Acc: 0.9898\n",
      "Epoch 9/50, Train Loss: 0.0617, Train Acc: 0.9879, Val Loss: 0.0380, Val Acc: 0.9904\n",
      "Epoch 10/50, Train Loss: 0.0299, Train Acc: 0.9931, Val Loss: 0.0146, Val Acc: 0.9970\n",
      "Epoch 11/50, Train Loss: 0.0067, Train Acc: 0.9984, Val Loss: 0.0042, Val Acc: 0.9982\n",
      "Epoch 12/50, Train Loss: 0.0039, Train Acc: 0.9990, Val Loss: 0.0043, Val Acc: 0.9982\n",
      "Epoch 13/50, Train Loss: 0.0032, Train Acc: 0.9993, Val Loss: 0.0060, Val Acc: 0.9982\n",
      "Epoch 14/50, Train Loss: 0.0035, Train Acc: 0.9994, Val Loss: 0.0039, Val Acc: 0.9994\n",
      "Epoch 15/50, Train Loss: 0.0029, Train Acc: 0.9994, Val Loss: 0.0039, Val Acc: 0.9994\n",
      "Epoch 16/50, Train Loss: 0.0032, Train Acc: 0.9993, Val Loss: 0.0053, Val Acc: 0.9988\n",
      "Epoch 17/50, Train Loss: 0.0023, Train Acc: 0.9994, Val Loss: 0.0035, Val Acc: 0.9988\n",
      "Epoch 18/50, Train Loss: 0.0028, Train Acc: 0.9993, Val Loss: 0.0043, Val Acc: 0.9982\n",
      "Epoch 19/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0027, Val Acc: 0.9982\n",
      "Epoch 20/50, Train Loss: 0.0026, Train Acc: 0.9994, Val Loss: 0.0022, Val Acc: 0.9994\n",
      "Epoch 21/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0021, Val Acc: 0.9994\n",
      "Epoch 22/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0022, Val Acc: 0.9994\n",
      "Epoch 23/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0023, Val Acc: 0.9994\n",
      "Epoch 24/50, Train Loss: 0.0020, Train Acc: 0.9996, Val Loss: 0.0022, Val Acc: 0.9994\n",
      "Epoch 25/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0022, Val Acc: 0.9994\n",
      "Epoch 26/50, Train Loss: 0.0017, Train Acc: 0.9996, Val Loss: 0.0022, Val Acc: 0.9994\n",
      "Early stopping!\n",
      "\n",
      "Run 3/5\n",
      "Epoch 1/50, Train Loss: 1.0402, Train Acc: 0.5427, Val Loss: 0.9824, Val Acc: 0.5498\n",
      "Epoch 2/50, Train Loss: 0.7595, Train Acc: 0.6260, Val Loss: 0.7883, Val Acc: 0.5719\n",
      "Epoch 3/50, Train Loss: 0.5376, Train Acc: 0.7413, Val Loss: 0.3005, Val Acc: 0.8927\n",
      "Epoch 4/50, Train Loss: 0.2313, Train Acc: 0.9364, Val Loss: 0.0655, Val Acc: 0.9694\n",
      "Epoch 5/50, Train Loss: 0.0759, Train Acc: 0.9795, Val Loss: 0.1711, Val Acc: 0.9466\n",
      "Epoch 6/50, Train Loss: 0.0456, Train Acc: 0.9867, Val Loss: 0.0174, Val Acc: 0.9934\n",
      "Epoch 7/50, Train Loss: 0.0345, Train Acc: 0.9903, Val Loss: 0.0252, Val Acc: 0.9946\n",
      "Epoch 8/50, Train Loss: 0.0184, Train Acc: 0.9958, Val Loss: 0.0153, Val Acc: 0.9964\n",
      "Epoch 9/50, Train Loss: 0.0511, Train Acc: 0.9873, Val Loss: 0.0162, Val Acc: 0.9958\n",
      "Epoch 10/50, Train Loss: 0.0458, Train Acc: 0.9894, Val Loss: 0.0086, Val Acc: 0.9976\n",
      "Epoch 11/50, Train Loss: 0.0053, Train Acc: 0.9985, Val Loss: 0.0071, Val Acc: 0.9988\n",
      "Epoch 12/50, Train Loss: 0.0040, Train Acc: 0.9991, Val Loss: 0.0080, Val Acc: 0.9988\n",
      "Epoch 13/50, Train Loss: 0.0022, Train Acc: 0.9993, Val Loss: 0.0097, Val Acc: 0.9976\n",
      "Epoch 14/50, Train Loss: 0.0027, Train Acc: 0.9994, Val Loss: 0.0070, Val Acc: 0.9982\n",
      "Epoch 15/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0073, Val Acc: 0.9988\n",
      "Epoch 16/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0080, Val Acc: 0.9988\n",
      "Epoch 17/50, Train Loss: 0.0017, Train Acc: 0.9996, Val Loss: 0.0073, Val Acc: 0.9988\n",
      "Epoch 18/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0092, Val Acc: 0.9982\n",
      "Epoch 19/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0111, Val Acc: 0.9976\n",
      "Early stopping!\n",
      "\n",
      "Run 4/5\n",
      "Epoch 1/50, Train Loss: 1.0159, Train Acc: 0.5202, Val Loss: 0.7509, Val Acc: 0.6133\n",
      "Epoch 2/50, Train Loss: 0.7916, Train Acc: 0.6039, Val Loss: 0.7398, Val Acc: 0.6085\n",
      "Epoch 3/50, Train Loss: 0.3731, Train Acc: 0.8310, Val Loss: 0.0197, Val Acc: 0.9928\n",
      "Epoch 4/50, Train Loss: 0.1111, Train Acc: 0.9670, Val Loss: 0.0542, Val Acc: 0.9844\n",
      "Epoch 5/50, Train Loss: 0.0571, Train Acc: 0.9835, Val Loss: 0.0462, Val Acc: 0.9862\n",
      "Epoch 6/50, Train Loss: 0.1093, Train Acc: 0.9711, Val Loss: 0.0510, Val Acc: 0.9844\n",
      "Epoch 7/50, Train Loss: 0.0327, Train Acc: 0.9876, Val Loss: 0.0176, Val Acc: 0.9934\n",
      "Epoch 8/50, Train Loss: 0.0793, Train Acc: 0.9835, Val Loss: 0.2975, Val Acc: 0.9418\n",
      "Epoch 9/50, Train Loss: 0.0289, Train Acc: 0.9919, Val Loss: 0.1605, Val Acc: 0.9676\n",
      "Epoch 10/50, Train Loss: 0.0440, Train Acc: 0.9895, Val Loss: 0.0115, Val Acc: 0.9976\n",
      "Epoch 11/50, Train Loss: 0.0034, Train Acc: 0.9991, Val Loss: 0.0080, Val Acc: 0.9982\n",
      "Epoch 12/50, Train Loss: 0.0021, Train Acc: 0.9993, Val Loss: 0.0063, Val Acc: 0.9988\n",
      "Epoch 13/50, Train Loss: 0.0020, Train Acc: 0.9993, Val Loss: 0.0054, Val Acc: 0.9988\n",
      "Epoch 14/50, Train Loss: 0.0017, Train Acc: 0.9996, Val Loss: 0.0065, Val Acc: 0.9988\n",
      "Epoch 15/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0055, Val Acc: 0.9988\n",
      "Epoch 16/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0054, Val Acc: 0.9988\n",
      "Epoch 17/50, Train Loss: 0.0013, Train Acc: 0.9994, Val Loss: 0.0069, Val Acc: 0.9988\n",
      "Epoch 18/50, Train Loss: 0.0013, Train Acc: 0.9996, Val Loss: 0.0109, Val Acc: 0.9982\n",
      "Epoch 19/50, Train Loss: 0.0015, Train Acc: 0.9994, Val Loss: 0.0076, Val Acc: 0.9988\n",
      "Epoch 20/50, Train Loss: 0.0008, Train Acc: 0.9997, Val Loss: 0.0077, Val Acc: 0.9988\n",
      "Epoch 21/50, Train Loss: 0.0008, Train Acc: 0.9996, Val Loss: 0.0069, Val Acc: 0.9982\n",
      "Early stopping!\n",
      "\n",
      "Run 5/5\n",
      "Epoch 1/50, Train Loss: 1.1642, Train Acc: 0.5459, Val Loss: 0.7336, Val Acc: 0.6211\n",
      "Epoch 2/50, Train Loss: 0.7343, Train Acc: 0.6446, Val Loss: 0.5218, Val Acc: 0.7590\n",
      "Epoch 3/50, Train Loss: 0.2645, Train Acc: 0.9009, Val Loss: 0.0769, Val Acc: 0.9790\n",
      "Epoch 4/50, Train Loss: 0.1445, Train Acc: 0.9607, Val Loss: 0.0071, Val Acc: 0.9970\n",
      "Epoch 5/50, Train Loss: 0.1126, Train Acc: 0.9697, Val Loss: 0.0237, Val Acc: 0.9910\n",
      "Epoch 6/50, Train Loss: 0.0528, Train Acc: 0.9843, Val Loss: 0.0297, Val Acc: 0.9898\n",
      "Epoch 7/50, Train Loss: 0.0333, Train Acc: 0.9903, Val Loss: 0.0008, Val Acc: 0.9994\n",
      "Epoch 8/50, Train Loss: 0.0270, Train Acc: 0.9910, Val Loss: 0.0321, Val Acc: 0.9904\n",
      "Epoch 9/50, Train Loss: 0.0166, Train Acc: 0.9964, Val Loss: 0.0139, Val Acc: 0.9982\n",
      "Epoch 10/50, Train Loss: 0.0572, Train Acc: 0.9852, Val Loss: 0.1977, Val Acc: 0.9568\n",
      "Epoch 11/50, Train Loss: 0.0133, Train Acc: 0.9963, Val Loss: 0.0051, Val Acc: 0.9988\n",
      "Epoch 12/50, Train Loss: 0.0031, Train Acc: 0.9993, Val Loss: 0.0035, Val Acc: 0.9982\n",
      "Early stopping!\n",
      "\n",
      "Source performance: 99.83 99.83 99.83 99.83\n",
      "Target performance: 99.41 99.40 99.43 99.41\n",
      "\n",
      "bpsk: 99.75\n",
      "qpsk: 98.88\n",
      "16qam: 99.08\n",
      "8apsk: 100.00\n",
      "Epoch 1/50, Loss: 3.6760, Domain Loss: 2.2202, Class Loss: 1.4559\n",
      "Epoch 2/50, Loss: 2.2821, Domain Loss: 1.5003, Class Loss: 0.7818\n",
      "Epoch 3/50, Loss: 2.1676, Domain Loss: 1.3984, Class Loss: 0.7692\n",
      "Epoch 4/50, Loss: 2.0718, Domain Loss: 1.3667, Class Loss: 0.7051\n",
      "Epoch 5/50, Loss: 2.1118, Domain Loss: 1.3742, Class Loss: 0.7376\n",
      "Epoch 6/50, Loss: 2.1983, Domain Loss: 1.4744, Class Loss: 0.7239\n",
      "Epoch 7/50, Loss: 2.3446, Domain Loss: 1.6169, Class Loss: 0.7277\n",
      "Epoch 8/50, Loss: 3.6165, Domain Loss: 2.5821, Class Loss: 1.0344\n",
      "Epoch 9/50, Loss: 2.1832, Domain Loss: 1.4183, Class Loss: 0.7649\n",
      "Epoch 10/50, Loss: 2.1076, Domain Loss: 1.3826, Class Loss: 0.7250\n",
      "Epoch 11/50, Loss: 2.1342, Domain Loss: 1.3892, Class Loss: 0.7450\n",
      "Epoch 12/50, Loss: 2.1108, Domain Loss: 1.3854, Class Loss: 0.7255\n",
      "Epoch 13/50, Loss: 2.0468, Domain Loss: 1.3940, Class Loss: 0.6528\n",
      "Epoch 14/50, Loss: 1.9970, Domain Loss: 1.3917, Class Loss: 0.6053\n",
      "Epoch 15/50, Loss: 1.9489, Domain Loss: 1.3800, Class Loss: 0.5689\n",
      "Epoch 16/50, Loss: 1.8874, Domain Loss: 1.3705, Class Loss: 0.5170\n",
      "Epoch 17/50, Loss: 1.7959, Domain Loss: 1.3533, Class Loss: 0.4426\n",
      "Epoch 18/50, Loss: 1.7187, Domain Loss: 1.3465, Class Loss: 0.3722\n",
      "Epoch 19/50, Loss: 1.6787, Domain Loss: 1.3455, Class Loss: 0.3332\n",
      "Epoch 20/50, Loss: 1.8673, Domain Loss: 1.6054, Class Loss: 0.2619\n",
      "Epoch 21/50, Loss: 1.5465, Domain Loss: 1.3828, Class Loss: 0.1637\n",
      "Epoch 22/50, Loss: 1.4237, Domain Loss: 1.3593, Class Loss: 0.0644\n",
      "Epoch 23/50, Loss: 1.4069, Domain Loss: 1.3516, Class Loss: 0.0553\n",
      "Epoch 24/50, Loss: 1.4037, Domain Loss: 1.3393, Class Loss: 0.0644\n",
      "Epoch 25/50, Loss: 1.3936, Domain Loss: 1.3446, Class Loss: 0.0491\n",
      "Epoch 26/50, Loss: 1.3984, Domain Loss: 1.3391, Class Loss: 0.0593\n",
      "Epoch 27/50, Loss: 1.4684, Domain Loss: 1.3281, Class Loss: 0.1403\n",
      "Epoch 28/50, Loss: 1.3627, Domain Loss: 1.3243, Class Loss: 0.0384\n",
      "Epoch 29/50, Loss: 1.3725, Domain Loss: 1.3329, Class Loss: 0.0396\n",
      "Epoch 30/50, Loss: 1.3554, Domain Loss: 1.3329, Class Loss: 0.0225\n",
      "Epoch 31/50, Loss: 1.3387, Domain Loss: 1.3113, Class Loss: 0.0274\n",
      "Epoch 32/50, Loss: 1.3250, Domain Loss: 1.3080, Class Loss: 0.0171\n",
      "Epoch 33/50, Loss: 1.3307, Domain Loss: 1.3227, Class Loss: 0.0081\n",
      "Epoch 34/50, Loss: 1.3912, Domain Loss: 1.3296, Class Loss: 0.0616\n",
      "Epoch 35/50, Loss: 1.5384, Domain Loss: 1.3338, Class Loss: 0.2045\n",
      "Epoch 36/50, Loss: 1.3549, Domain Loss: 1.3139, Class Loss: 0.0410\n",
      "Epoch 37/50, Loss: 1.3381, Domain Loss: 1.3011, Class Loss: 0.0370\n",
      "Epoch 38/50, Loss: 1.3377, Domain Loss: 1.3059, Class Loss: 0.0317\n",
      "Epoch 39/50, Loss: 1.3100, Domain Loss: 1.2931, Class Loss: 0.0169\n",
      "Epoch 40/50, Loss: 1.3188, Domain Loss: 1.3037, Class Loss: 0.0151\n",
      "Epoch 41/50, Loss: 1.3694, Domain Loss: 1.3132, Class Loss: 0.0562\n",
      "Epoch 42/50, Loss: 1.3231, Domain Loss: 1.3059, Class Loss: 0.0172\n",
      "Epoch 43/50, Loss: 1.3178, Domain Loss: 1.3067, Class Loss: 0.0111\n",
      "Epoch 44/50, Loss: 1.4013, Domain Loss: 1.3084, Class Loss: 0.0928\n",
      "Epoch 45/50, Loss: 1.4453, Domain Loss: 1.3181, Class Loss: 0.1272\n",
      "Epoch 46/50, Loss: 1.3202, Domain Loss: 1.2862, Class Loss: 0.0341\n",
      "Epoch 47/50, Loss: 1.2957, Domain Loss: 1.2757, Class Loss: 0.0200\n",
      "Epoch 48/50, Loss: 1.3041, Domain Loss: 1.2876, Class Loss: 0.0165\n",
      "Epoch 49/50, Loss: 1.3141, Domain Loss: 1.3013, Class Loss: 0.0128\n",
      "Epoch 50/50, Loss: 1.3358, Domain Loss: 1.3153, Class Loss: 0.0205\n",
      "95.38\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8422, Domain Loss: 2.0488, Class Loss: 1.7935\n",
      "Epoch 2/50, Loss: 2.3255, Domain Loss: 1.4124, Class Loss: 0.9132\n",
      "Epoch 3/50, Loss: 2.2001, Domain Loss: 1.4185, Class Loss: 0.7816\n",
      "Epoch 4/50, Loss: 2.1231, Domain Loss: 1.3748, Class Loss: 0.7483\n",
      "Epoch 5/50, Loss: 2.1427, Domain Loss: 1.3612, Class Loss: 0.7815\n",
      "Epoch 6/50, Loss: 2.0775, Domain Loss: 1.3577, Class Loss: 0.7198\n",
      "Epoch 7/50, Loss: 2.0797, Domain Loss: 1.3505, Class Loss: 0.7292\n",
      "Epoch 8/50, Loss: 2.0519, Domain Loss: 1.3511, Class Loss: 0.7009\n",
      "Epoch 9/50, Loss: 2.0455, Domain Loss: 1.3730, Class Loss: 0.6724\n",
      "Epoch 10/50, Loss: 2.0021, Domain Loss: 1.4514, Class Loss: 0.5506\n",
      "Epoch 11/50, Loss: 1.6840, Domain Loss: 1.4213, Class Loss: 0.2627\n",
      "Epoch 12/50, Loss: 1.4940, Domain Loss: 1.3581, Class Loss: 0.1359\n",
      "Epoch 13/50, Loss: 1.3769, Domain Loss: 1.3404, Class Loss: 0.0365\n",
      "Epoch 14/50, Loss: 1.3635, Domain Loss: 1.3121, Class Loss: 0.0514\n",
      "Epoch 15/50, Loss: 1.3869, Domain Loss: 1.3405, Class Loss: 0.0464\n",
      "Epoch 16/50, Loss: 1.3982, Domain Loss: 1.3364, Class Loss: 0.0618\n",
      "Epoch 17/50, Loss: 1.3978, Domain Loss: 1.3332, Class Loss: 0.0646\n",
      "Epoch 18/50, Loss: 1.4776, Domain Loss: 1.3624, Class Loss: 0.1152\n",
      "Epoch 19/50, Loss: 1.4122, Domain Loss: 1.3070, Class Loss: 0.1052\n",
      "Epoch 20/50, Loss: 1.4221, Domain Loss: 1.3032, Class Loss: 0.1189\n",
      "Epoch 21/50, Loss: 1.3790, Domain Loss: 1.2845, Class Loss: 0.0945\n",
      "Epoch 22/50, Loss: 1.3183, Domain Loss: 1.2787, Class Loss: 0.0396\n",
      "Epoch 23/50, Loss: 1.3270, Domain Loss: 1.3037, Class Loss: 0.0234\n",
      "Epoch 24/50, Loss: 1.3228, Domain Loss: 1.2966, Class Loss: 0.0262\n",
      "Epoch 25/50, Loss: 1.2900, Domain Loss: 1.2691, Class Loss: 0.0210\n",
      "Epoch 26/50, Loss: 1.4219, Domain Loss: 1.3473, Class Loss: 0.0746\n",
      "Epoch 27/50, Loss: 1.3971, Domain Loss: 1.3551, Class Loss: 0.0420\n",
      "Epoch 28/50, Loss: 1.3304, Domain Loss: 1.2952, Class Loss: 0.0352\n",
      "Epoch 29/50, Loss: 1.3719, Domain Loss: 1.2998, Class Loss: 0.0721\n",
      "Epoch 30/50, Loss: 1.3323, Domain Loss: 1.2936, Class Loss: 0.0387\n",
      "Epoch 31/50, Loss: 1.3732, Domain Loss: 1.2802, Class Loss: 0.0930\n",
      "Epoch 32/50, Loss: 1.3174, Domain Loss: 1.2542, Class Loss: 0.0632\n",
      "Epoch 33/50, Loss: 1.3054, Domain Loss: 1.2842, Class Loss: 0.0212\n",
      "Epoch 34/50, Loss: 1.3119, Domain Loss: 1.2874, Class Loss: 0.0245\n",
      "Epoch 35/50, Loss: 1.3675, Domain Loss: 1.3059, Class Loss: 0.0616\n",
      "Epoch 36/50, Loss: 1.4429, Domain Loss: 1.3524, Class Loss: 0.0905\n",
      "Epoch 37/50, Loss: 1.4437, Domain Loss: 1.3611, Class Loss: 0.0826\n",
      "Epoch 38/50, Loss: 1.3462, Domain Loss: 1.3164, Class Loss: 0.0298\n",
      "Epoch 39/50, Loss: 1.3699, Domain Loss: 1.3270, Class Loss: 0.0429\n",
      "Epoch 40/50, Loss: 1.3728, Domain Loss: 1.3272, Class Loss: 0.0455\n",
      "Epoch 41/50, Loss: 1.3870, Domain Loss: 1.3114, Class Loss: 0.0756\n",
      "Epoch 42/50, Loss: 1.3364, Domain Loss: 1.3084, Class Loss: 0.0280\n",
      "Epoch 43/50, Loss: 1.3304, Domain Loss: 1.2964, Class Loss: 0.0340\n",
      "Epoch 44/50, Loss: 1.4049, Domain Loss: 1.3041, Class Loss: 0.1008\n",
      "Epoch 45/50, Loss: 1.4593, Domain Loss: 1.3451, Class Loss: 0.1142\n",
      "Epoch 46/50, Loss: 1.3171, Domain Loss: 1.2847, Class Loss: 0.0323\n",
      "Epoch 47/50, Loss: 1.3513, Domain Loss: 1.3282, Class Loss: 0.0231\n",
      "Epoch 48/50, Loss: 1.3126, Domain Loss: 1.2951, Class Loss: 0.0175\n",
      "Epoch 49/50, Loss: 1.3099, Domain Loss: 1.2837, Class Loss: 0.0261\n",
      "Epoch 50/50, Loss: 1.3461, Domain Loss: 1.3120, Class Loss: 0.0342\n",
      "95.74\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.4011, Domain Loss: 1.8998, Class Loss: 1.5013\n",
      "Epoch 2/50, Loss: 2.2775, Domain Loss: 1.4197, Class Loss: 0.8579\n",
      "Epoch 3/50, Loss: 2.1640, Domain Loss: 1.3739, Class Loss: 0.7901\n",
      "Epoch 4/50, Loss: 2.0949, Domain Loss: 1.3707, Class Loss: 0.7241\n",
      "Epoch 5/50, Loss: 2.1160, Domain Loss: 1.3906, Class Loss: 0.7254\n",
      "Epoch 6/50, Loss: 2.1160, Domain Loss: 1.3749, Class Loss: 0.7411\n",
      "Epoch 7/50, Loss: 2.1063, Domain Loss: 1.3903, Class Loss: 0.7160\n",
      "Epoch 8/50, Loss: 2.2658, Domain Loss: 1.6397, Class Loss: 0.6261\n",
      "Epoch 9/50, Loss: 2.6159, Domain Loss: 1.5947, Class Loss: 1.0213\n",
      "Epoch 10/50, Loss: 1.9918, Domain Loss: 1.4019, Class Loss: 0.5899\n",
      "Epoch 11/50, Loss: 1.7685, Domain Loss: 1.3599, Class Loss: 0.4086\n",
      "Epoch 12/50, Loss: 1.5375, Domain Loss: 1.3612, Class Loss: 0.1763\n",
      "Epoch 13/50, Loss: 1.4768, Domain Loss: 1.3861, Class Loss: 0.0907\n",
      "Epoch 14/50, Loss: 1.5416, Domain Loss: 1.3608, Class Loss: 0.1809\n",
      "Epoch 15/50, Loss: 1.3868, Domain Loss: 1.3420, Class Loss: 0.0448\n",
      "Epoch 16/50, Loss: 1.3738, Domain Loss: 1.3485, Class Loss: 0.0253\n",
      "Epoch 17/50, Loss: 1.4375, Domain Loss: 1.3652, Class Loss: 0.0723\n",
      "Epoch 18/50, Loss: 1.4230, Domain Loss: 1.3700, Class Loss: 0.0530\n",
      "Epoch 19/50, Loss: 2.3432, Domain Loss: 1.4098, Class Loss: 0.9333\n",
      "Epoch 20/50, Loss: 1.5269, Domain Loss: 1.3430, Class Loss: 0.1839\n",
      "Epoch 21/50, Loss: 1.3876, Domain Loss: 1.3112, Class Loss: 0.0764\n",
      "Epoch 22/50, Loss: 1.3495, Domain Loss: 1.3006, Class Loss: 0.0489\n",
      "Epoch 23/50, Loss: 1.3340, Domain Loss: 1.3027, Class Loss: 0.0312\n",
      "Epoch 24/50, Loss: 1.3068, Domain Loss: 1.2756, Class Loss: 0.0311\n",
      "Epoch 25/50, Loss: 1.2894, Domain Loss: 1.2773, Class Loss: 0.0122\n",
      "Epoch 26/50, Loss: 1.3031, Domain Loss: 1.2827, Class Loss: 0.0204\n",
      "Epoch 27/50, Loss: 1.3086, Domain Loss: 1.2900, Class Loss: 0.0186\n",
      "Epoch 28/50, Loss: 1.3223, Domain Loss: 1.2804, Class Loss: 0.0419\n",
      "Epoch 29/50, Loss: 1.2739, Domain Loss: 1.2455, Class Loss: 0.0284\n",
      "Epoch 30/50, Loss: 1.2707, Domain Loss: 1.2572, Class Loss: 0.0135\n",
      "Epoch 31/50, Loss: 1.2698, Domain Loss: 1.2497, Class Loss: 0.0201\n",
      "Epoch 32/50, Loss: 1.2682, Domain Loss: 1.2423, Class Loss: 0.0259\n",
      "Epoch 33/50, Loss: 1.4360, Domain Loss: 1.2961, Class Loss: 0.1399\n",
      "Epoch 34/50, Loss: 1.5518, Domain Loss: 1.2876, Class Loss: 0.2642\n",
      "Epoch 35/50, Loss: 1.3397, Domain Loss: 1.2872, Class Loss: 0.0525\n",
      "Epoch 36/50, Loss: 1.3006, Domain Loss: 1.2640, Class Loss: 0.0366\n",
      "Epoch 37/50, Loss: 1.2767, Domain Loss: 1.2596, Class Loss: 0.0171\n",
      "Epoch 38/50, Loss: 1.2739, Domain Loss: 1.2367, Class Loss: 0.0372\n",
      "Epoch 39/50, Loss: 1.3757, Domain Loss: 1.2976, Class Loss: 0.0780\n",
      "Epoch 40/50, Loss: 1.4325, Domain Loss: 1.3225, Class Loss: 0.1100\n",
      "Epoch 41/50, Loss: 1.3687, Domain Loss: 1.3101, Class Loss: 0.0585\n",
      "Epoch 42/50, Loss: 1.3496, Domain Loss: 1.3220, Class Loss: 0.0276\n",
      "Epoch 43/50, Loss: 1.9260, Domain Loss: 1.3259, Class Loss: 0.6001\n",
      "Epoch 44/50, Loss: 1.5117, Domain Loss: 1.2866, Class Loss: 0.2251\n",
      "Epoch 45/50, Loss: 1.2914, Domain Loss: 1.2374, Class Loss: 0.0540\n",
      "Epoch 46/50, Loss: 1.2749, Domain Loss: 1.2275, Class Loss: 0.0474\n",
      "Epoch 47/50, Loss: 1.2430, Domain Loss: 1.2224, Class Loss: 0.0206\n",
      "Epoch 48/50, Loss: 1.2437, Domain Loss: 1.2213, Class Loss: 0.0224\n",
      "Epoch 49/50, Loss: 1.2565, Domain Loss: 1.2373, Class Loss: 0.0192\n",
      "Epoch 50/50, Loss: 1.2630, Domain Loss: 1.2515, Class Loss: 0.0115\n",
      "99.34\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8689, Domain Loss: 1.9138, Class Loss: 1.9551\n",
      "Epoch 2/50, Loss: 2.3656, Domain Loss: 1.4003, Class Loss: 0.9654\n",
      "Epoch 3/50, Loss: 2.1678, Domain Loss: 1.3973, Class Loss: 0.7705\n",
      "Epoch 4/50, Loss: 2.1150, Domain Loss: 1.3893, Class Loss: 0.7257\n",
      "Epoch 5/50, Loss: 2.1114, Domain Loss: 1.3916, Class Loss: 0.7198\n",
      "Epoch 6/50, Loss: 2.0981, Domain Loss: 1.3749, Class Loss: 0.7232\n",
      "Epoch 7/50, Loss: 2.1144, Domain Loss: 1.3942, Class Loss: 0.7202\n",
      "Epoch 8/50, Loss: 2.0985, Domain Loss: 1.3637, Class Loss: 0.7349\n",
      "Epoch 9/50, Loss: 2.0530, Domain Loss: 1.3607, Class Loss: 0.6923\n",
      "Epoch 10/50, Loss: 2.1399, Domain Loss: 1.4250, Class Loss: 0.7149\n",
      "Epoch 11/50, Loss: 2.1384, Domain Loss: 1.3553, Class Loss: 0.7831\n",
      "Epoch 12/50, Loss: 2.0738, Domain Loss: 1.3545, Class Loss: 0.7192\n",
      "Epoch 13/50, Loss: 2.0767, Domain Loss: 1.3514, Class Loss: 0.7252\n",
      "Epoch 14/50, Loss: 2.0365, Domain Loss: 1.3519, Class Loss: 0.6846\n",
      "Epoch 15/50, Loss: 2.0625, Domain Loss: 1.3428, Class Loss: 0.7197\n",
      "Epoch 16/50, Loss: 2.0221, Domain Loss: 1.3420, Class Loss: 0.6801\n",
      "Epoch 17/50, Loss: 2.0139, Domain Loss: 1.3440, Class Loss: 0.6699\n",
      "Epoch 18/50, Loss: 1.9396, Domain Loss: 1.3460, Class Loss: 0.5936\n",
      "Epoch 19/50, Loss: 1.8885, Domain Loss: 1.4990, Class Loss: 0.3895\n",
      "Epoch 20/50, Loss: 2.0116, Domain Loss: 1.6357, Class Loss: 0.3758\n",
      "Epoch 21/50, Loss: 1.4796, Domain Loss: 1.3847, Class Loss: 0.0949\n",
      "Epoch 22/50, Loss: 1.4493, Domain Loss: 1.3831, Class Loss: 0.0662\n",
      "Epoch 23/50, Loss: 1.4399, Domain Loss: 1.3803, Class Loss: 0.0596\n",
      "Epoch 24/50, Loss: 1.4249, Domain Loss: 1.3763, Class Loss: 0.0485\n",
      "Epoch 25/50, Loss: 1.4692, Domain Loss: 1.3700, Class Loss: 0.0992\n",
      "Epoch 26/50, Loss: 1.3870, Domain Loss: 1.3654, Class Loss: 0.0216\n",
      "Epoch 27/50, Loss: 1.3711, Domain Loss: 1.3572, Class Loss: 0.0139\n",
      "Epoch 28/50, Loss: 1.3825, Domain Loss: 1.3523, Class Loss: 0.0302\n",
      "Epoch 29/50, Loss: 1.3845, Domain Loss: 1.3514, Class Loss: 0.0331\n",
      "Epoch 30/50, Loss: 1.4708, Domain Loss: 1.3464, Class Loss: 0.1244\n",
      "Epoch 31/50, Loss: 1.4242, Domain Loss: 1.3356, Class Loss: 0.0886\n",
      "Epoch 32/50, Loss: 1.3921, Domain Loss: 1.3302, Class Loss: 0.0618\n",
      "Epoch 33/50, Loss: 1.3591, Domain Loss: 1.3299, Class Loss: 0.0292\n",
      "Epoch 34/50, Loss: 1.3452, Domain Loss: 1.3280, Class Loss: 0.0172\n",
      "Epoch 35/50, Loss: 1.3358, Domain Loss: 1.3193, Class Loss: 0.0165\n",
      "Epoch 36/50, Loss: 1.3907, Domain Loss: 1.3481, Class Loss: 0.0427\n",
      "Epoch 37/50, Loss: 1.5483, Domain Loss: 1.3419, Class Loss: 0.2064\n",
      "Epoch 38/50, Loss: 1.4788, Domain Loss: 1.3255, Class Loss: 0.1533\n",
      "Epoch 39/50, Loss: 1.3523, Domain Loss: 1.3255, Class Loss: 0.0268\n",
      "Epoch 40/50, Loss: 1.3579, Domain Loss: 1.3330, Class Loss: 0.0249\n",
      "Epoch 41/50, Loss: 1.3377, Domain Loss: 1.3204, Class Loss: 0.0173\n",
      "Epoch 42/50, Loss: 1.3329, Domain Loss: 1.3191, Class Loss: 0.0139\n",
      "Epoch 43/50, Loss: 1.3121, Domain Loss: 1.3011, Class Loss: 0.0111\n",
      "Epoch 44/50, Loss: 1.3186, Domain Loss: 1.2979, Class Loss: 0.0207\n",
      "Epoch 45/50, Loss: 1.3139, Domain Loss: 1.3018, Class Loss: 0.0121\n",
      "Epoch 46/50, Loss: 1.3348, Domain Loss: 1.3249, Class Loss: 0.0098\n",
      "Epoch 47/50, Loss: 1.3473, Domain Loss: 1.3156, Class Loss: 0.0318\n",
      "Epoch 48/50, Loss: 1.3347, Domain Loss: 1.3001, Class Loss: 0.0346\n",
      "Epoch 49/50, Loss: 1.3245, Domain Loss: 1.3060, Class Loss: 0.0185\n",
      "Epoch 50/50, Loss: 1.3221, Domain Loss: 1.3039, Class Loss: 0.0182\n",
      "97.72\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.6913, Domain Loss: 1.9918, Class Loss: 1.6995\n",
      "Epoch 2/50, Loss: 2.3601, Domain Loss: 1.3943, Class Loss: 0.9658\n",
      "Epoch 3/50, Loss: 2.1789, Domain Loss: 1.3937, Class Loss: 0.7852\n",
      "Epoch 4/50, Loss: 2.1547, Domain Loss: 1.3824, Class Loss: 0.7723\n",
      "Epoch 5/50, Loss: 2.1120, Domain Loss: 1.3775, Class Loss: 0.7345\n",
      "Epoch 6/50, Loss: 2.1248, Domain Loss: 1.3734, Class Loss: 0.7514\n",
      "Epoch 7/50, Loss: 2.1153, Domain Loss: 1.3740, Class Loss: 0.7413\n",
      "Epoch 8/50, Loss: 2.0860, Domain Loss: 1.3671, Class Loss: 0.7189\n",
      "Epoch 9/50, Loss: 2.0599, Domain Loss: 1.3612, Class Loss: 0.6988\n",
      "Epoch 10/50, Loss: 2.0272, Domain Loss: 1.3555, Class Loss: 0.6717\n",
      "Epoch 11/50, Loss: 2.0346, Domain Loss: 1.3742, Class Loss: 0.6604\n",
      "Epoch 12/50, Loss: 1.9902, Domain Loss: 1.3932, Class Loss: 0.5971\n",
      "Epoch 13/50, Loss: 1.9828, Domain Loss: 1.4278, Class Loss: 0.5550\n",
      "Epoch 14/50, Loss: 1.5322, Domain Loss: 1.3879, Class Loss: 0.1443\n",
      "Epoch 15/50, Loss: 1.4553, Domain Loss: 1.3866, Class Loss: 0.0687\n",
      "Epoch 16/50, Loss: 1.4346, Domain Loss: 1.3844, Class Loss: 0.0502\n",
      "Epoch 17/50, Loss: 1.4545, Domain Loss: 1.3743, Class Loss: 0.0802\n",
      "Epoch 18/50, Loss: 1.4015, Domain Loss: 1.3681, Class Loss: 0.0334\n",
      "Epoch 19/50, Loss: 1.3854, Domain Loss: 1.3615, Class Loss: 0.0240\n",
      "Epoch 20/50, Loss: 1.3820, Domain Loss: 1.3526, Class Loss: 0.0295\n",
      "Epoch 21/50, Loss: 1.3824, Domain Loss: 1.3475, Class Loss: 0.0349\n",
      "Epoch 22/50, Loss: 1.3962, Domain Loss: 1.3509, Class Loss: 0.0453\n",
      "Epoch 23/50, Loss: 1.3525, Domain Loss: 1.3397, Class Loss: 0.0128\n",
      "Epoch 24/50, Loss: 1.3601, Domain Loss: 1.3328, Class Loss: 0.0273\n",
      "Epoch 25/50, Loss: 1.4147, Domain Loss: 1.3416, Class Loss: 0.0730\n",
      "Epoch 26/50, Loss: 1.3973, Domain Loss: 1.3393, Class Loss: 0.0581\n",
      "Epoch 27/50, Loss: 1.3502, Domain Loss: 1.3118, Class Loss: 0.0383\n",
      "Epoch 28/50, Loss: 1.3675, Domain Loss: 1.3044, Class Loss: 0.0631\n",
      "Epoch 29/50, Loss: 1.4649, Domain Loss: 1.3244, Class Loss: 0.1405\n",
      "Epoch 30/50, Loss: 1.4474, Domain Loss: 1.3666, Class Loss: 0.0808\n",
      "Epoch 31/50, Loss: 1.3947, Domain Loss: 1.3652, Class Loss: 0.0296\n",
      "Epoch 32/50, Loss: 1.5158, Domain Loss: 1.3853, Class Loss: 0.1304\n",
      "Epoch 33/50, Loss: 1.4464, Domain Loss: 1.3802, Class Loss: 0.0662\n",
      "Epoch 34/50, Loss: 1.3828, Domain Loss: 1.3570, Class Loss: 0.0258\n",
      "Epoch 35/50, Loss: 5.4597, Domain Loss: 3.7893, Class Loss: 1.6703\n",
      "Epoch 36/50, Loss: 8.3860, Domain Loss: 4.9289, Class Loss: 3.4571\n",
      "Epoch 37/50, Loss: 2.9529, Domain Loss: 1.5262, Class Loss: 1.4267\n",
      "Epoch 38/50, Loss: 2.7777, Domain Loss: 1.3885, Class Loss: 1.3892\n",
      "Epoch 39/50, Loss: 2.7770, Domain Loss: 1.3880, Class Loss: 1.3890\n",
      "Epoch 40/50, Loss: 2.7762, Domain Loss: 1.3876, Class Loss: 1.3886\n",
      "Epoch 41/50, Loss: 2.7771, Domain Loss: 1.3872, Class Loss: 1.3899\n",
      "Epoch 42/50, Loss: 2.7744, Domain Loss: 1.3870, Class Loss: 1.3874\n",
      "Epoch 43/50, Loss: 2.7773, Domain Loss: 1.3868, Class Loss: 1.3905\n",
      "Epoch 44/50, Loss: 2.7749, Domain Loss: 1.3867, Class Loss: 1.3882\n",
      "Epoch 45/50, Loss: 2.7743, Domain Loss: 1.3866, Class Loss: 1.3877\n",
      "Epoch 46/50, Loss: 2.7752, Domain Loss: 1.3865, Class Loss: 1.3887\n",
      "Epoch 47/50, Loss: 2.7768, Domain Loss: 1.3864, Class Loss: 1.3904\n",
      "Epoch 48/50, Loss: 2.7757, Domain Loss: 1.3864, Class Loss: 1.3892\n",
      "Epoch 49/50, Loss: 2.7745, Domain Loss: 1.3864, Class Loss: 1.3882\n",
      "Epoch 50/50, Loss: 2.7741, Domain Loss: 1.3864, Class Loss: 1.3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.86\n",
      "\n",
      "\n",
      "Source performance:\n",
      "82.54 79.04 82.46 79.45 \n",
      "Target performance:\n",
      "82.41 78.98 82.63 79.55 \n",
      "\n",
      "Per-class target performance: 98.39 78.38 76.79 76.96 \n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 2.6151, Discrepancy Loss: 0.1399\n",
      "Epoch [2/50], Class Loss: 1.2629, Discrepancy Loss: 0.1518\n",
      "Epoch [3/50], Class Loss: 1.0643, Discrepancy Loss: 0.1400\n",
      "Epoch [4/50], Class Loss: 0.3291, Discrepancy Loss: 0.0526\n",
      "Epoch [5/50], Class Loss: 0.2920, Discrepancy Loss: 0.0428\n",
      "Epoch [6/50], Class Loss: 0.3269, Discrepancy Loss: 0.0560\n",
      "Epoch [7/50], Class Loss: 0.1333, Discrepancy Loss: 0.0291\n",
      "Epoch [8/50], Class Loss: 0.0955, Discrepancy Loss: 0.0215\n",
      "Epoch [9/50], Class Loss: 0.0961, Discrepancy Loss: 0.0158\n",
      "Epoch [10/50], Class Loss: 0.1133, Discrepancy Loss: 0.0207\n",
      "Epoch [11/50], Class Loss: 0.0476, Discrepancy Loss: 0.0111\n",
      "Epoch [12/50], Class Loss: 0.0374, Discrepancy Loss: 0.0117\n",
      "Epoch [13/50], Class Loss: 0.0582, Discrepancy Loss: 0.0131\n",
      "Epoch [14/50], Class Loss: 0.0424, Discrepancy Loss: 0.0142\n",
      "Epoch [15/50], Class Loss: 0.0381, Discrepancy Loss: 0.0129\n",
      "Epoch [16/50], Class Loss: 0.0305, Discrepancy Loss: 0.0111\n",
      "Epoch [17/50], Class Loss: 0.0329, Discrepancy Loss: 0.0093\n",
      "Epoch [18/50], Class Loss: 0.0333, Discrepancy Loss: 0.0084\n",
      "Epoch [19/50], Class Loss: 0.0230, Discrepancy Loss: 0.0106\n",
      "Epoch [20/50], Class Loss: 0.0268, Discrepancy Loss: 0.0114\n",
      "Epoch [21/50], Class Loss: 0.0209, Discrepancy Loss: 0.0105\n",
      "Epoch [22/50], Class Loss: 0.0230, Discrepancy Loss: 0.0090\n",
      "Epoch [23/50], Class Loss: 0.0262, Discrepancy Loss: 0.0097\n",
      "Epoch [24/50], Class Loss: 0.0251, Discrepancy Loss: 0.0120\n",
      "Epoch [25/50], Class Loss: 0.0250, Discrepancy Loss: 0.0096\n",
      "Epoch [26/50], Class Loss: 0.0236, Discrepancy Loss: 0.0084\n",
      "Epoch [27/50], Class Loss: 0.0268, Discrepancy Loss: 0.0083\n",
      "Epoch [28/50], Class Loss: 0.0232, Discrepancy Loss: 0.0068\n",
      "Epoch [29/50], Class Loss: 0.0228, Discrepancy Loss: 0.0091\n",
      "Epoch [30/50], Class Loss: 0.0267, Discrepancy Loss: 0.0088\n",
      "Epoch [31/50], Class Loss: 0.0158, Discrepancy Loss: 0.0099\n",
      "Epoch [32/50], Class Loss: 0.0210, Discrepancy Loss: 0.0080\n",
      "Epoch [33/50], Class Loss: 0.0243, Discrepancy Loss: 0.0080\n",
      "Epoch [34/50], Class Loss: 0.0227, Discrepancy Loss: 0.0083\n",
      "Epoch [35/50], Class Loss: 0.0248, Discrepancy Loss: 0.0076\n",
      "Epoch [36/50], Class Loss: 0.0142, Discrepancy Loss: 0.0073\n",
      "Epoch [37/50], Class Loss: 0.0177, Discrepancy Loss: 0.0082\n",
      "Epoch [38/50], Class Loss: 0.0191, Discrepancy Loss: 0.0078\n",
      "Epoch [39/50], Class Loss: 0.0168, Discrepancy Loss: 0.0080\n",
      "Epoch [40/50], Class Loss: 0.0208, Discrepancy Loss: 0.0082\n",
      "Epoch [41/50], Class Loss: 0.0195, Discrepancy Loss: 0.0086\n",
      "Epoch [42/50], Class Loss: 0.0158, Discrepancy Loss: 0.0103\n",
      "Epoch [43/50], Class Loss: 0.0208, Discrepancy Loss: 0.0091\n",
      "Epoch [44/50], Class Loss: 0.0218, Discrepancy Loss: 0.0084\n",
      "Epoch [45/50], Class Loss: 0.0461, Discrepancy Loss: 0.0080\n",
      "Epoch [46/50], Class Loss: 0.0189, Discrepancy Loss: 0.0093\n",
      "Epoch [47/50], Class Loss: 0.0235, Discrepancy Loss: 0.0080\n",
      "Epoch [48/50], Class Loss: 0.0232, Discrepancy Loss: 0.0080\n",
      "Epoch [49/50], Class Loss: 0.0232, Discrepancy Loss: 0.0089\n",
      "Epoch [50/50], Class Loss: 0.0376, Discrepancy Loss: 0.0081\n",
      "Source Domain Performance - Accuracy: 99.94%, Precision: 99.94%, Recall: 99.94%, F1 Score: 99.94%\n",
      "Target Domain Performance - Accuracy: 99.40%, Precision: 99.40%, Recall: 99.40%, F1 Score: 99.40%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.9559, Discrepancy Loss: 0.1290\n",
      "Epoch [2/50], Class Loss: 1.3298, Discrepancy Loss: 0.1614\n",
      "Epoch [3/50], Class Loss: 0.9710, Discrepancy Loss: 0.1285\n",
      "Epoch [4/50], Class Loss: 0.3069, Discrepancy Loss: 0.0421\n",
      "Epoch [5/50], Class Loss: 0.1663, Discrepancy Loss: 0.0269\n",
      "Epoch [6/50], Class Loss: 0.0811, Discrepancy Loss: 0.0160\n",
      "Epoch [7/50], Class Loss: 0.0945, Discrepancy Loss: 0.0144\n",
      "Epoch [8/50], Class Loss: 0.0572, Discrepancy Loss: 0.0141\n",
      "Epoch [9/50], Class Loss: 0.0754, Discrepancy Loss: 0.0142\n",
      "Epoch [10/50], Class Loss: 0.1006, Discrepancy Loss: 0.0178\n",
      "Epoch [11/50], Class Loss: 0.0319, Discrepancy Loss: 0.0092\n",
      "Epoch [12/50], Class Loss: 0.0278, Discrepancy Loss: 0.0061\n",
      "Epoch [13/50], Class Loss: 0.0225, Discrepancy Loss: 0.0072\n",
      "Epoch [14/50], Class Loss: 0.0228, Discrepancy Loss: 0.0064\n",
      "Epoch [15/50], Class Loss: 0.0165, Discrepancy Loss: 0.0070\n",
      "Epoch [16/50], Class Loss: 0.0256, Discrepancy Loss: 0.0051\n",
      "Epoch [17/50], Class Loss: 0.0241, Discrepancy Loss: 0.0058\n",
      "Epoch [18/50], Class Loss: 0.0183, Discrepancy Loss: 0.0072\n",
      "Epoch [19/50], Class Loss: 0.0295, Discrepancy Loss: 0.0058\n",
      "Epoch [20/50], Class Loss: 0.0192, Discrepancy Loss: 0.0063\n",
      "Epoch [21/50], Class Loss: 0.0104, Discrepancy Loss: 0.0069\n",
      "Epoch [22/50], Class Loss: 0.0144, Discrepancy Loss: 0.0044\n",
      "Epoch [23/50], Class Loss: 0.0111, Discrepancy Loss: 0.0048\n",
      "Epoch [24/50], Class Loss: 0.0092, Discrepancy Loss: 0.0049\n",
      "Epoch [25/50], Class Loss: 0.0100, Discrepancy Loss: 0.0052\n",
      "Epoch [26/50], Class Loss: 0.0145, Discrepancy Loss: 0.0051\n",
      "Epoch [27/50], Class Loss: 0.0130, Discrepancy Loss: 0.0050\n",
      "Epoch [28/50], Class Loss: 0.0136, Discrepancy Loss: 0.0049\n",
      "Epoch [29/50], Class Loss: 0.0126, Discrepancy Loss: 0.0041\n",
      "Epoch [30/50], Class Loss: 0.0111, Discrepancy Loss: 0.0057\n",
      "Epoch [31/50], Class Loss: 0.0096, Discrepancy Loss: 0.0049\n",
      "Epoch [32/50], Class Loss: 0.0096, Discrepancy Loss: 0.0048\n",
      "Epoch [33/50], Class Loss: 0.0100, Discrepancy Loss: 0.0051\n",
      "Epoch [34/50], Class Loss: 0.0119, Discrepancy Loss: 0.0060\n",
      "Epoch [35/50], Class Loss: 0.0125, Discrepancy Loss: 0.0068\n",
      "Epoch [36/50], Class Loss: 0.0089, Discrepancy Loss: 0.0052\n",
      "Epoch [37/50], Class Loss: 0.0105, Discrepancy Loss: 0.0052\n",
      "Epoch [38/50], Class Loss: 0.0113, Discrepancy Loss: 0.0054\n",
      "Epoch [39/50], Class Loss: 0.0135, Discrepancy Loss: 0.0061\n",
      "Epoch [40/50], Class Loss: 0.0106, Discrepancy Loss: 0.0057\n",
      "Epoch [41/50], Class Loss: 0.0091, Discrepancy Loss: 0.0045\n",
      "Epoch [42/50], Class Loss: 0.0117, Discrepancy Loss: 0.0057\n",
      "Epoch [43/50], Class Loss: 0.0064, Discrepancy Loss: 0.0048\n",
      "Epoch [44/50], Class Loss: 0.0270, Discrepancy Loss: 0.0050\n",
      "Epoch [45/50], Class Loss: 0.0090, Discrepancy Loss: 0.0048\n",
      "Epoch [46/50], Class Loss: 0.0147, Discrepancy Loss: 0.0049\n",
      "Epoch [47/50], Class Loss: 0.0139, Discrepancy Loss: 0.0056\n",
      "Epoch [48/50], Class Loss: 0.0105, Discrepancy Loss: 0.0072\n",
      "Epoch [49/50], Class Loss: 0.0253, Discrepancy Loss: 0.0049\n",
      "Epoch [50/50], Class Loss: 0.0073, Discrepancy Loss: 0.0049\n",
      "Source Domain Performance - Accuracy: 99.82%, Precision: 99.82%, Recall: 99.82%, F1 Score: 99.82%\n",
      "Target Domain Performance - Accuracy: 99.70%, Precision: 99.69%, Recall: 99.70%, F1 Score: 99.70%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 3.2855, Discrepancy Loss: 0.1365\n",
      "Epoch [2/50], Class Loss: 1.3671, Discrepancy Loss: 0.1649\n",
      "Epoch [3/50], Class Loss: 1.3941, Discrepancy Loss: 0.1467\n",
      "Epoch [4/50], Class Loss: 1.2140, Discrepancy Loss: 0.1519\n",
      "Epoch [5/50], Class Loss: 1.0985, Discrepancy Loss: 0.1348\n",
      "Epoch [6/50], Class Loss: 0.5880, Discrepancy Loss: 0.0863\n",
      "Epoch [7/50], Class Loss: 0.1411, Discrepancy Loss: 0.0257\n",
      "Epoch [8/50], Class Loss: 0.0881, Discrepancy Loss: 0.0212\n",
      "Epoch [9/50], Class Loss: 0.0701, Discrepancy Loss: 0.0145\n",
      "Epoch [10/50], Class Loss: 0.0376, Discrepancy Loss: 0.0105\n",
      "Epoch [11/50], Class Loss: 0.0236, Discrepancy Loss: 0.0066\n",
      "Epoch [12/50], Class Loss: 0.0231, Discrepancy Loss: 0.0051\n",
      "Epoch [13/50], Class Loss: 0.0191, Discrepancy Loss: 0.0047\n",
      "Epoch [14/50], Class Loss: 0.0126, Discrepancy Loss: 0.0053\n",
      "Epoch [15/50], Class Loss: 0.0143, Discrepancy Loss: 0.0047\n",
      "Epoch [16/50], Class Loss: 0.0162, Discrepancy Loss: 0.0055\n",
      "Epoch [17/50], Class Loss: 0.0139, Discrepancy Loss: 0.0057\n",
      "Epoch [18/50], Class Loss: 0.0199, Discrepancy Loss: 0.0062\n",
      "Epoch [19/50], Class Loss: 0.0231, Discrepancy Loss: 0.0056\n",
      "Epoch [20/50], Class Loss: 0.0177, Discrepancy Loss: 0.0047\n",
      "Epoch [21/50], Class Loss: 0.0161, Discrepancy Loss: 0.0055\n",
      "Epoch [22/50], Class Loss: 0.0103, Discrepancy Loss: 0.0050\n",
      "Epoch [23/50], Class Loss: 0.0084, Discrepancy Loss: 0.0038\n",
      "Epoch [24/50], Class Loss: 0.0106, Discrepancy Loss: 0.0054\n",
      "Epoch [25/50], Class Loss: 0.0093, Discrepancy Loss: 0.0043\n",
      "Epoch [26/50], Class Loss: 0.0126, Discrepancy Loss: 0.0045\n",
      "Epoch [27/50], Class Loss: 0.0080, Discrepancy Loss: 0.0045\n",
      "Epoch [28/50], Class Loss: 0.0083, Discrepancy Loss: 0.0043\n",
      "Epoch [29/50], Class Loss: 0.0088, Discrepancy Loss: 0.0053\n",
      "Epoch [30/50], Class Loss: 0.0091, Discrepancy Loss: 0.0053\n",
      "Epoch [31/50], Class Loss: 0.0322, Discrepancy Loss: 0.0055\n",
      "Epoch [32/50], Class Loss: 0.0098, Discrepancy Loss: 0.0053\n",
      "Epoch [33/50], Class Loss: 0.0101, Discrepancy Loss: 0.0074\n",
      "Epoch [34/50], Class Loss: 0.0177, Discrepancy Loss: 0.0044\n",
      "Epoch [35/50], Class Loss: 0.0094, Discrepancy Loss: 0.0040\n",
      "Epoch [36/50], Class Loss: 0.0074, Discrepancy Loss: 0.0043\n",
      "Epoch [37/50], Class Loss: 0.0117, Discrepancy Loss: 0.0041\n",
      "Epoch [38/50], Class Loss: 0.0084, Discrepancy Loss: 0.0058\n",
      "Epoch [39/50], Class Loss: 0.0122, Discrepancy Loss: 0.0042\n",
      "Epoch [40/50], Class Loss: 0.0101, Discrepancy Loss: 0.0053\n",
      "Epoch [41/50], Class Loss: 0.0079, Discrepancy Loss: 0.0059\n",
      "Epoch [42/50], Class Loss: 0.0185, Discrepancy Loss: 0.0045\n",
      "Epoch [43/50], Class Loss: 0.0136, Discrepancy Loss: 0.0046\n",
      "Epoch [44/50], Class Loss: 0.0066, Discrepancy Loss: 0.0051\n",
      "Epoch [45/50], Class Loss: 0.0195, Discrepancy Loss: 0.0043\n",
      "Epoch [46/50], Class Loss: 0.0134, Discrepancy Loss: 0.0045\n",
      "Epoch [47/50], Class Loss: 0.0066, Discrepancy Loss: 0.0062\n",
      "Epoch [48/50], Class Loss: 0.0131, Discrepancy Loss: 0.0046\n",
      "Epoch [49/50], Class Loss: 0.0097, Discrepancy Loss: 0.0050\n",
      "Epoch [50/50], Class Loss: 0.0114, Discrepancy Loss: 0.0045\n",
      "Source Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.88%, F1 Score: 99.88%\n",
      "Target Domain Performance - Accuracy: 99.58%, Precision: 99.57%, Recall: 99.59%, F1 Score: 99.58%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 3.1513, Discrepancy Loss: 0.1374\n",
      "Epoch [2/50], Class Loss: 1.4600, Discrepancy Loss: 0.1600\n",
      "Epoch [3/50], Class Loss: 1.3578, Discrepancy Loss: 0.1600\n",
      "Epoch [4/50], Class Loss: 0.7273, Discrepancy Loss: 0.0962\n",
      "Epoch [5/50], Class Loss: 0.1633, Discrepancy Loss: 0.0308\n",
      "Epoch [6/50], Class Loss: 0.1819, Discrepancy Loss: 0.0209\n",
      "Epoch [7/50], Class Loss: 0.1022, Discrepancy Loss: 0.0196\n",
      "Epoch [8/50], Class Loss: 0.1059, Discrepancy Loss: 0.0198\n",
      "Epoch [9/50], Class Loss: 0.0557, Discrepancy Loss: 0.0160\n",
      "Epoch [10/50], Class Loss: 0.0627, Discrepancy Loss: 0.0111\n",
      "Epoch [11/50], Class Loss: 0.0307, Discrepancy Loss: 0.0069\n",
      "Epoch [12/50], Class Loss: 0.0193, Discrepancy Loss: 0.0073\n",
      "Epoch [13/50], Class Loss: 0.0201, Discrepancy Loss: 0.0080\n",
      "Epoch [14/50], Class Loss: 0.0229, Discrepancy Loss: 0.0094\n",
      "Epoch [15/50], Class Loss: 0.0165, Discrepancy Loss: 0.0068\n",
      "Epoch [16/50], Class Loss: 0.0256, Discrepancy Loss: 0.0059\n",
      "Epoch [17/50], Class Loss: 0.0198, Discrepancy Loss: 0.0080\n",
      "Epoch [18/50], Class Loss: 0.0183, Discrepancy Loss: 0.0068\n",
      "Epoch [19/50], Class Loss: 0.0112, Discrepancy Loss: 0.0059\n",
      "Epoch [20/50], Class Loss: 0.0150, Discrepancy Loss: 0.0055\n",
      "Epoch [21/50], Class Loss: 0.0122, Discrepancy Loss: 0.0066\n",
      "Epoch [22/50], Class Loss: 0.0198, Discrepancy Loss: 0.0054\n",
      "Epoch [23/50], Class Loss: 0.0132, Discrepancy Loss: 0.0068\n",
      "Epoch [24/50], Class Loss: 0.0174, Discrepancy Loss: 0.0064\n",
      "Epoch [25/50], Class Loss: 0.0128, Discrepancy Loss: 0.0070\n",
      "Epoch [26/50], Class Loss: 0.0170, Discrepancy Loss: 0.0067\n",
      "Epoch [27/50], Class Loss: 0.0110, Discrepancy Loss: 0.0059\n",
      "Epoch [28/50], Class Loss: 0.0114, Discrepancy Loss: 0.0055\n",
      "Epoch [29/50], Class Loss: 0.0145, Discrepancy Loss: 0.0057\n",
      "Epoch [30/50], Class Loss: 0.0252, Discrepancy Loss: 0.0060\n",
      "Epoch [31/50], Class Loss: 0.0123, Discrepancy Loss: 0.0050\n",
      "Epoch [32/50], Class Loss: 0.0083, Discrepancy Loss: 0.0051\n",
      "Epoch [33/50], Class Loss: 0.0186, Discrepancy Loss: 0.0069\n",
      "Epoch [34/50], Class Loss: 0.0134, Discrepancy Loss: 0.0066\n",
      "Epoch [35/50], Class Loss: 0.0128, Discrepancy Loss: 0.0050\n",
      "Epoch [36/50], Class Loss: 0.0263, Discrepancy Loss: 0.0063\n",
      "Epoch [37/50], Class Loss: 0.0160, Discrepancy Loss: 0.0057\n",
      "Epoch [38/50], Class Loss: 0.0135, Discrepancy Loss: 0.0069\n",
      "Epoch [39/50], Class Loss: 0.0091, Discrepancy Loss: 0.0052\n",
      "Epoch [40/50], Class Loss: 0.0121, Discrepancy Loss: 0.0049\n",
      "Epoch [41/50], Class Loss: 0.0101, Discrepancy Loss: 0.0047\n",
      "Epoch [42/50], Class Loss: 0.0327, Discrepancy Loss: 0.0061\n",
      "Epoch [43/50], Class Loss: 0.0089, Discrepancy Loss: 0.0058\n",
      "Epoch [44/50], Class Loss: 0.0121, Discrepancy Loss: 0.0081\n",
      "Epoch [45/50], Class Loss: 0.0155, Discrepancy Loss: 0.0068\n",
      "Epoch [46/50], Class Loss: 0.0101, Discrepancy Loss: 0.0053\n",
      "Epoch [47/50], Class Loss: 0.0136, Discrepancy Loss: 0.0060\n",
      "Epoch [48/50], Class Loss: 0.0126, Discrepancy Loss: 0.0053\n",
      "Epoch [49/50], Class Loss: 0.0182, Discrepancy Loss: 0.0058\n",
      "Epoch [50/50], Class Loss: 0.0138, Discrepancy Loss: 0.0059\n",
      "Source Domain Performance - Accuracy: 99.82%, Precision: 99.83%, Recall: 99.81%, F1 Score: 99.82%\n",
      "Target Domain Performance - Accuracy: 98.98%, Precision: 98.98%, Recall: 98.98%, F1 Score: 98.97%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 3.1664, Discrepancy Loss: 0.1243\n",
      "Epoch [2/50], Class Loss: 1.5555, Discrepancy Loss: 0.1482\n",
      "Epoch [3/50], Class Loss: 1.3828, Discrepancy Loss: 0.1621\n",
      "Epoch [4/50], Class Loss: 0.8957, Discrepancy Loss: 0.1135\n",
      "Epoch [5/50], Class Loss: 0.1820, Discrepancy Loss: 0.0335\n",
      "Epoch [6/50], Class Loss: 0.0933, Discrepancy Loss: 0.0235\n",
      "Epoch [7/50], Class Loss: 0.1353, Discrepancy Loss: 0.0194\n",
      "Epoch [8/50], Class Loss: 0.0570, Discrepancy Loss: 0.0113\n",
      "Epoch [9/50], Class Loss: 0.0456, Discrepancy Loss: 0.0108\n",
      "Epoch [10/50], Class Loss: 0.0697, Discrepancy Loss: 0.0144\n",
      "Epoch [11/50], Class Loss: 0.0338, Discrepancy Loss: 0.0100\n",
      "Epoch [12/50], Class Loss: 0.0247, Discrepancy Loss: 0.0080\n",
      "Epoch [13/50], Class Loss: 0.0294, Discrepancy Loss: 0.0090\n",
      "Epoch [14/50], Class Loss: 0.0289, Discrepancy Loss: 0.0074\n",
      "Epoch [15/50], Class Loss: 0.0230, Discrepancy Loss: 0.0088\n",
      "Epoch [16/50], Class Loss: 0.0679, Discrepancy Loss: 0.0061\n",
      "Epoch [17/50], Class Loss: 0.0371, Discrepancy Loss: 0.0073\n",
      "Epoch [18/50], Class Loss: 0.0256, Discrepancy Loss: 0.0062\n",
      "Epoch [19/50], Class Loss: 0.0148, Discrepancy Loss: 0.0054\n",
      "Epoch [20/50], Class Loss: 0.0205, Discrepancy Loss: 0.0066\n",
      "Epoch [21/50], Class Loss: 0.0116, Discrepancy Loss: 0.0056\n",
      "Epoch [22/50], Class Loss: 0.0094, Discrepancy Loss: 0.0062\n",
      "Epoch [23/50], Class Loss: 0.0134, Discrepancy Loss: 0.0054\n",
      "Epoch [24/50], Class Loss: 0.0124, Discrepancy Loss: 0.0052\n",
      "Epoch [25/50], Class Loss: 0.0151, Discrepancy Loss: 0.0047\n",
      "Epoch [26/50], Class Loss: 0.0129, Discrepancy Loss: 0.0056\n",
      "Epoch [27/50], Class Loss: 0.0102, Discrepancy Loss: 0.0065\n",
      "Epoch [28/50], Class Loss: 0.0097, Discrepancy Loss: 0.0046\n",
      "Epoch [29/50], Class Loss: 0.0143, Discrepancy Loss: 0.0056\n",
      "Epoch [30/50], Class Loss: 0.0104, Discrepancy Loss: 0.0073\n",
      "Epoch [31/50], Class Loss: 0.0268, Discrepancy Loss: 0.0076\n",
      "Epoch [32/50], Class Loss: 0.0190, Discrepancy Loss: 0.0047\n",
      "Epoch [33/50], Class Loss: 0.0140, Discrepancy Loss: 0.0056\n",
      "Epoch [34/50], Class Loss: 0.0149, Discrepancy Loss: 0.0052\n",
      "Epoch [35/50], Class Loss: 0.0145, Discrepancy Loss: 0.0062\n",
      "Epoch [36/50], Class Loss: 0.0130, Discrepancy Loss: 0.0057\n",
      "Epoch [37/50], Class Loss: 0.0084, Discrepancy Loss: 0.0068\n",
      "Epoch [38/50], Class Loss: 0.0062, Discrepancy Loss: 0.0059\n",
      "Epoch [39/50], Class Loss: 0.0111, Discrepancy Loss: 0.0051\n",
      "Epoch [40/50], Class Loss: 0.0114, Discrepancy Loss: 0.0056\n",
      "Epoch [41/50], Class Loss: 0.0162, Discrepancy Loss: 0.0057\n",
      "Epoch [42/50], Class Loss: 0.0088, Discrepancy Loss: 0.0045\n",
      "Epoch [43/50], Class Loss: 0.0139, Discrepancy Loss: 0.0051\n",
      "Epoch [44/50], Class Loss: 0.0150, Discrepancy Loss: 0.0057\n",
      "Epoch [45/50], Class Loss: 0.0168, Discrepancy Loss: 0.0053\n",
      "Epoch [46/50], Class Loss: 0.0115, Discrepancy Loss: 0.0054\n",
      "Epoch [47/50], Class Loss: 0.0133, Discrepancy Loss: 0.0068\n",
      "Epoch [48/50], Class Loss: 0.0104, Discrepancy Loss: 0.0052\n",
      "Epoch [49/50], Class Loss: 0.0143, Discrepancy Loss: 0.0055\n",
      "Epoch [50/50], Class Loss: 0.0112, Discrepancy Loss: 0.0059\n",
      "Source Domain Performance - Accuracy: 100.00%, Precision: 100.00%, Recall: 100.00%, F1 Score: 100.00%\n",
      "Target Domain Performance - Accuracy: 99.52%, Precision: 99.51%, Recall: 99.53%, F1 Score: 99.52%\n",
      "\n",
      "Source performance: 99.89% 99.89% 99.89% 99.89%\n",
      "Target performance: 99.44% 99.43% 99.44% 99.43%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.75%\n",
      "qpsk: 99.28%\n",
      "16qam: 98.73%\n",
      "8apsk: 100.00%\n",
      "\n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 1.9872, Discrepancy Loss: 0.0669\n",
      "Validation Loss: 1.4451\n",
      "Epoch [2/50], Class Loss: 1.2154, Discrepancy Loss: 0.0291\n",
      "Validation Loss: 0.3100\n",
      "Epoch [3/50], Class Loss: 0.2829, Discrepancy Loss: 0.0109\n",
      "Validation Loss: 0.1050\n",
      "Epoch [4/50], Class Loss: 0.1575, Discrepancy Loss: 0.0058\n",
      "Validation Loss: 0.0238\n",
      "Epoch [5/50], Class Loss: 0.0984, Discrepancy Loss: 0.0061\n",
      "Validation Loss: 0.0844\n",
      "Epoch [6/50], Class Loss: 0.1284, Discrepancy Loss: 0.0101\n",
      "Validation Loss: 0.1751\n",
      "Epoch [7/50], Class Loss: 0.1614, Discrepancy Loss: 0.0111\n",
      "Validation Loss: 0.7238\n",
      "Epoch [8/50], Class Loss: 0.2997, Discrepancy Loss: 0.0125\n",
      "Validation Loss: 0.1195\n",
      "Epoch [9/50], Class Loss: 0.1254, Discrepancy Loss: 0.0093\n",
      "Validation Loss: 0.0172\n",
      "Epoch [10/50], Class Loss: 0.1742, Discrepancy Loss: 0.0136\n",
      "Validation Loss: 0.0625\n",
      "Epoch [11/50], Class Loss: 0.0208, Discrepancy Loss: 0.0061\n",
      "Validation Loss: 0.0924\n",
      "Epoch [12/50], Class Loss: 0.0191, Discrepancy Loss: 0.0046\n",
      "Validation Loss: 0.0244\n",
      "Epoch [13/50], Class Loss: 0.0083, Discrepancy Loss: 0.0033\n",
      "Validation Loss: 0.0989\n",
      "Epoch [14/50], Class Loss: 0.0148, Discrepancy Loss: 0.0047\n",
      "Validation Loss: 0.0756\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.68%, Precision: 98.75%, Recall: 98.64%, F1 Score: 98.67%\n",
      "Target Domain Performance - Accuracy: 98.08%, Precision: 98.12%, Recall: 98.09%, F1 Score: 98.07%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.3375, Discrepancy Loss: 0.1055\n",
      "Validation Loss: 1.8649\n",
      "Epoch [2/50], Class Loss: 1.5406, Discrepancy Loss: 0.0597\n",
      "Validation Loss: 1.4412\n",
      "Epoch [3/50], Class Loss: 0.9926, Discrepancy Loss: 0.0485\n",
      "Validation Loss: 0.1770\n",
      "Epoch [4/50], Class Loss: 0.1829, Discrepancy Loss: 0.0110\n",
      "Validation Loss: 1.2866\n",
      "Epoch [5/50], Class Loss: 0.2198, Discrepancy Loss: 0.0080\n",
      "Validation Loss: 0.3163\n",
      "Epoch [6/50], Class Loss: 0.4388, Discrepancy Loss: 0.0124\n",
      "Validation Loss: 0.3162\n",
      "Epoch [7/50], Class Loss: 0.1079, Discrepancy Loss: 0.0063\n",
      "Validation Loss: 0.0359\n",
      "Epoch [8/50], Class Loss: 0.1407, Discrepancy Loss: 0.0077\n",
      "Validation Loss: 0.5170\n",
      "Epoch [9/50], Class Loss: 0.1063, Discrepancy Loss: 0.0071\n",
      "Validation Loss: 0.0397\n",
      "Epoch [10/50], Class Loss: 0.1961, Discrepancy Loss: 0.0112\n",
      "Validation Loss: 0.7015\n",
      "Epoch [11/50], Class Loss: 0.0255, Discrepancy Loss: 0.0040\n",
      "Validation Loss: 0.0049\n",
      "Epoch [12/50], Class Loss: 0.0132, Discrepancy Loss: 0.0038\n",
      "Validation Loss: 0.0182\n",
      "Epoch [13/50], Class Loss: 0.0120, Discrepancy Loss: 0.0032\n",
      "Validation Loss: 0.0276\n",
      "Epoch [14/50], Class Loss: 0.0102, Discrepancy Loss: 0.0033\n",
      "Validation Loss: 0.0249\n",
      "Epoch [15/50], Class Loss: 0.0083, Discrepancy Loss: 0.0030\n",
      "Validation Loss: 0.0454\n",
      "Epoch [16/50], Class Loss: 0.0112, Discrepancy Loss: 0.0043\n",
      "Validation Loss: 0.0427\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.46%, Precision: 99.48%, Recall: 99.44%, F1 Score: 99.45%\n",
      "Target Domain Performance - Accuracy: 98.62%, Precision: 98.64%, Recall: 98.61%, F1 Score: 98.61%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 2.1831, Discrepancy Loss: 0.0897\n",
      "Validation Loss: 1.5039\n",
      "Epoch [2/50], Class Loss: 1.4562, Discrepancy Loss: 0.0422\n",
      "Validation Loss: 1.5960\n",
      "Epoch [3/50], Class Loss: 0.6245, Discrepancy Loss: 0.0234\n",
      "Validation Loss: 0.0925\n",
      "Epoch [4/50], Class Loss: 0.1724, Discrepancy Loss: 0.0109\n",
      "Validation Loss: 0.0362\n",
      "Epoch [5/50], Class Loss: 0.1750, Discrepancy Loss: 0.0063\n",
      "Validation Loss: 0.0279\n",
      "Epoch [6/50], Class Loss: 0.1255, Discrepancy Loss: 0.0081\n",
      "Validation Loss: 1.1914\n",
      "Epoch [7/50], Class Loss: 0.1578, Discrepancy Loss: 0.0102\n",
      "Validation Loss: 0.0469\n",
      "Epoch [8/50], Class Loss: 0.1534, Discrepancy Loss: 0.0108\n",
      "Validation Loss: 0.0653\n",
      "Epoch [9/50], Class Loss: 0.0874, Discrepancy Loss: 0.0114\n",
      "Validation Loss: 0.0291\n",
      "Epoch [10/50], Class Loss: 0.0734, Discrepancy Loss: 0.0086\n",
      "Validation Loss: 0.0320\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.46%, Precision: 99.46%, Recall: 99.45%, F1 Score: 99.45%\n",
      "Target Domain Performance - Accuracy: 99.28%, Precision: 99.29%, Recall: 99.29%, F1 Score: 99.28%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 1.9906, Discrepancy Loss: 0.0653\n",
      "Validation Loss: 1.6672\n",
      "Epoch [2/50], Class Loss: 1.4811, Discrepancy Loss: 0.0249\n",
      "Validation Loss: 1.3566\n",
      "Epoch [3/50], Class Loss: 0.5943, Discrepancy Loss: 0.0276\n",
      "Validation Loss: 0.2834\n",
      "Epoch [4/50], Class Loss: 0.2639, Discrepancy Loss: 0.0117\n",
      "Validation Loss: 0.0557\n",
      "Epoch [5/50], Class Loss: 0.2730, Discrepancy Loss: 0.0086\n",
      "Validation Loss: 0.0452\n",
      "Epoch [6/50], Class Loss: 0.2162, Discrepancy Loss: 0.0090\n",
      "Validation Loss: 0.3890\n",
      "Epoch [7/50], Class Loss: 0.1137, Discrepancy Loss: 0.0050\n",
      "Validation Loss: 0.0907\n",
      "Epoch [8/50], Class Loss: 0.0914, Discrepancy Loss: 0.0050\n",
      "Validation Loss: 0.0244\n",
      "Epoch [9/50], Class Loss: 0.1947, Discrepancy Loss: 0.0105\n",
      "Validation Loss: 0.0851\n",
      "Epoch [10/50], Class Loss: 0.1603, Discrepancy Loss: 0.0144\n",
      "Validation Loss: 4.0783\n",
      "Epoch [11/50], Class Loss: 0.2395, Discrepancy Loss: 0.0085\n",
      "Validation Loss: 0.0327\n",
      "Epoch [12/50], Class Loss: 0.0132, Discrepancy Loss: 0.0034\n",
      "Validation Loss: 0.0185\n",
      "Epoch [13/50], Class Loss: 0.0073, Discrepancy Loss: 0.0027\n",
      "Validation Loss: 0.0107\n",
      "Epoch [14/50], Class Loss: 0.0068, Discrepancy Loss: 0.0023\n",
      "Validation Loss: 0.0134\n",
      "Epoch [15/50], Class Loss: 0.0089, Discrepancy Loss: 0.0033\n",
      "Validation Loss: 0.0264\n",
      "Epoch [16/50], Class Loss: 0.0091, Discrepancy Loss: 0.0034\n",
      "Validation Loss: 0.0232\n",
      "Epoch [17/50], Class Loss: 0.0050, Discrepancy Loss: 0.0037\n",
      "Validation Loss: 0.0257\n",
      "Epoch [18/50], Class Loss: 0.0083, Discrepancy Loss: 0.0031\n",
      "Validation Loss: 0.0251\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.46%, Precision: 99.48%, Recall: 99.44%, F1 Score: 99.46%\n",
      "Target Domain Performance - Accuracy: 98.86%, Precision: 98.86%, Recall: 98.87%, F1 Score: 98.86%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 2.2431, Discrepancy Loss: 0.0713\n",
      "Validation Loss: 1.6041\n",
      "Epoch [2/50], Class Loss: 1.5656, Discrepancy Loss: 0.0360\n",
      "Validation Loss: 1.4723\n",
      "Epoch [3/50], Class Loss: 1.2103, Discrepancy Loss: 0.0402\n",
      "Validation Loss: 0.2372\n",
      "Epoch [4/50], Class Loss: 0.4631, Discrepancy Loss: 0.0158\n",
      "Validation Loss: 0.1465\n",
      "Epoch [5/50], Class Loss: 0.2065, Discrepancy Loss: 0.0089\n",
      "Validation Loss: 0.1554\n",
      "Epoch [6/50], Class Loss: 0.3598, Discrepancy Loss: 0.0132\n",
      "Validation Loss: 0.1126\n",
      "Epoch [7/50], Class Loss: 0.2011, Discrepancy Loss: 0.0113\n",
      "Validation Loss: 0.0256\n",
      "Epoch [8/50], Class Loss: 0.1869, Discrepancy Loss: 0.0069\n",
      "Validation Loss: 0.1180\n",
      "Epoch [9/50], Class Loss: 0.1284, Discrepancy Loss: 0.0079\n",
      "Validation Loss: 0.0207\n",
      "Epoch [10/50], Class Loss: 0.0735, Discrepancy Loss: 0.0095\n",
      "Validation Loss: 0.1944\n",
      "Epoch [11/50], Class Loss: 0.0355, Discrepancy Loss: 0.0061\n",
      "Validation Loss: 0.0126\n",
      "Epoch [12/50], Class Loss: 0.0131, Discrepancy Loss: 0.0041\n",
      "Validation Loss: 0.0122\n",
      "Epoch [13/50], Class Loss: 0.0111, Discrepancy Loss: 0.0036\n",
      "Validation Loss: 0.0080\n",
      "Epoch [14/50], Class Loss: 0.0120, Discrepancy Loss: 0.0032\n",
      "Validation Loss: 0.0084\n",
      "Epoch [15/50], Class Loss: 0.0085, Discrepancy Loss: 0.0030\n",
      "Validation Loss: 0.0556\n",
      "Epoch [16/50], Class Loss: 0.0126, Discrepancy Loss: 0.0043\n",
      "Validation Loss: 0.0144\n",
      "Epoch [17/50], Class Loss: 0.0112, Discrepancy Loss: 0.0037\n",
      "Validation Loss: 0.0846\n",
      "Epoch [18/50], Class Loss: 0.0131, Discrepancy Loss: 0.0038\n",
      "Validation Loss: 0.0288\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.58%, Precision: 99.58%, Recall: 99.57%, F1 Score: 99.58%\n",
      "Target Domain Performance - Accuracy: 99.04%, Precision: 99.03%, Recall: 99.06%, F1 Score: 99.04%\n",
      "\n",
      "Source performance: 99.33% 99.35% 99.31% 99.32%\n",
      "Target performance: 98.78% 98.79% 98.78% 98.77%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.75%\n",
      "qpsk: 98.70%\n",
      "16qam: 96.69%\n",
      "8apsk: 100.00%\n",
      "\n",
      "Run 1/5\n",
      "Epoch 1/50, Train Loss: 0.9853, Train Acc: 0.5352, Val Loss: 0.8152, Val Acc: 0.6019\n",
      "Epoch 2/50, Train Loss: 0.7313, Train Acc: 0.6335, Val Loss: 0.7629, Val Acc: 0.6139\n",
      "Epoch 3/50, Train Loss: 0.3486, Train Acc: 0.8580, Val Loss: 1.3363, Val Acc: 0.7602\n",
      "Epoch 4/50, Train Loss: 0.2729, Train Acc: 0.9327, Val Loss: 0.0538, Val Acc: 0.9796\n",
      "Epoch 5/50, Train Loss: 0.0843, Train Acc: 0.9760, Val Loss: 0.0892, Val Acc: 0.9760\n",
      "Epoch 6/50, Train Loss: 0.0439, Train Acc: 0.9858, Val Loss: 0.0341, Val Acc: 0.9940\n",
      "Epoch 7/50, Train Loss: 0.0500, Train Acc: 0.9880, Val Loss: 0.0610, Val Acc: 0.9850\n",
      "Epoch 8/50, Train Loss: 0.0512, Train Acc: 0.9876, Val Loss: 0.0644, Val Acc: 0.9874\n",
      "Epoch 9/50, Train Loss: 0.0162, Train Acc: 0.9951, Val Loss: 0.0600, Val Acc: 0.9916\n",
      "Epoch 10/50, Train Loss: 0.0224, Train Acc: 0.9940, Val Loss: 0.1114, Val Acc: 0.9784\n",
      "Epoch 11/50, Train Loss: 0.0042, Train Acc: 0.9988, Val Loss: 0.0367, Val Acc: 0.9934\n",
      "Early stopping!\n",
      "\n",
      "Run 2/5\n",
      "Epoch 1/50, Train Loss: 0.9400, Train Acc: 0.5693, Val Loss: 0.8590, Val Acc: 0.5719\n",
      "Epoch 2/50, Train Loss: 0.7241, Train Acc: 0.6438, Val Loss: 0.5507, Val Acc: 0.7530\n",
      "Epoch 3/50, Train Loss: 0.1305, Train Acc: 0.9514, Val Loss: 0.0785, Val Acc: 0.9718\n",
      "Epoch 4/50, Train Loss: 0.0614, Train Acc: 0.9804, Val Loss: 0.0591, Val Acc: 0.9838\n",
      "Epoch 5/50, Train Loss: 0.0480, Train Acc: 0.9852, Val Loss: 0.0365, Val Acc: 0.9940\n",
      "Epoch 6/50, Train Loss: 0.0467, Train Acc: 0.9874, Val Loss: 0.0838, Val Acc: 0.9802\n",
      "Epoch 7/50, Train Loss: 0.0392, Train Acc: 0.9891, Val Loss: 0.0307, Val Acc: 0.9946\n",
      "Epoch 8/50, Train Loss: 0.0186, Train Acc: 0.9954, Val Loss: 0.0351, Val Acc: 0.9940\n",
      "Epoch 9/50, Train Loss: 0.0227, Train Acc: 0.9937, Val Loss: 0.0859, Val Acc: 0.9808\n",
      "Epoch 10/50, Train Loss: 0.0308, Train Acc: 0.9919, Val Loss: 0.2197, Val Acc: 0.9442\n",
      "Epoch 11/50, Train Loss: 0.0124, Train Acc: 0.9966, Val Loss: 0.0320, Val Acc: 0.9958\n",
      "Epoch 12/50, Train Loss: 0.0023, Train Acc: 0.9997, Val Loss: 0.0318, Val Acc: 0.9946\n",
      "Early stopping!\n",
      "\n",
      "Run 3/5\n",
      "Epoch 1/50, Train Loss: 1.0782, Train Acc: 0.5331, Val Loss: 0.9298, Val Acc: 0.5689\n",
      "Epoch 2/50, Train Loss: 0.5863, Train Acc: 0.7302, Val Loss: 0.9404, Val Acc: 0.7548\n",
      "Epoch 3/50, Train Loss: 0.1624, Train Acc: 0.9436, Val Loss: 0.3895, Val Acc: 0.8711\n",
      "Epoch 4/50, Train Loss: 0.0584, Train Acc: 0.9832, Val Loss: 0.0767, Val Acc: 0.9772\n",
      "Epoch 5/50, Train Loss: 0.0461, Train Acc: 0.9861, Val Loss: 0.1235, Val Acc: 0.9658\n",
      "Epoch 6/50, Train Loss: 0.0530, Train Acc: 0.9858, Val Loss: 0.1206, Val Acc: 0.9682\n",
      "Epoch 7/50, Train Loss: 0.0294, Train Acc: 0.9913, Val Loss: 0.0680, Val Acc: 0.9880\n",
      "Epoch 8/50, Train Loss: 0.0296, Train Acc: 0.9931, Val Loss: 0.1840, Val Acc: 0.9640\n",
      "Epoch 9/50, Train Loss: 0.0396, Train Acc: 0.9897, Val Loss: 0.0342, Val Acc: 0.9958\n",
      "Epoch 10/50, Train Loss: 0.0254, Train Acc: 0.9948, Val Loss: 0.0469, Val Acc: 0.9928\n",
      "Epoch 11/50, Train Loss: 0.0035, Train Acc: 0.9991, Val Loss: 0.0318, Val Acc: 0.9946\n",
      "Epoch 12/50, Train Loss: 0.0030, Train Acc: 0.9994, Val Loss: 0.0303, Val Acc: 0.9952\n",
      "Epoch 13/50, Train Loss: 0.0029, Train Acc: 0.9994, Val Loss: 0.0274, Val Acc: 0.9958\n",
      "Epoch 14/50, Train Loss: 0.0024, Train Acc: 0.9996, Val Loss: 0.0290, Val Acc: 0.9946\n",
      "Epoch 15/50, Train Loss: 0.0018, Train Acc: 0.9996, Val Loss: 0.0251, Val Acc: 0.9964\n",
      "Epoch 16/50, Train Loss: 0.0022, Train Acc: 0.9996, Val Loss: 0.0230, Val Acc: 0.9958\n",
      "Epoch 17/50, Train Loss: 0.0023, Train Acc: 0.9994, Val Loss: 0.0226, Val Acc: 0.9964\n",
      "Epoch 18/50, Train Loss: 0.0018, Train Acc: 0.9997, Val Loss: 0.0234, Val Acc: 0.9970\n",
      "Epoch 19/50, Train Loss: 0.0024, Train Acc: 0.9997, Val Loss: 0.0244, Val Acc: 0.9964\n",
      "Epoch 20/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0255, Val Acc: 0.9964\n",
      "Epoch 21/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0219, Val Acc: 0.9970\n",
      "Epoch 22/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0218, Val Acc: 0.9970\n",
      "Epoch 23/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0215, Val Acc: 0.9964\n",
      "Epoch 24/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0213, Val Acc: 0.9964\n",
      "Epoch 25/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0216, Val Acc: 0.9970\n",
      "Epoch 26/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0212, Val Acc: 0.9964\n",
      "Epoch 27/50, Train Loss: 0.0017, Train Acc: 0.9997, Val Loss: 0.0211, Val Acc: 0.9970\n",
      "Epoch 28/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0216, Val Acc: 0.9970\n",
      "Epoch 29/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0214, Val Acc: 0.9970\n",
      "Epoch 30/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0214, Val Acc: 0.9970\n",
      "Epoch 31/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0215, Val Acc: 0.9970\n",
      "Epoch 32/50, Train Loss: 0.0014, Train Acc: 0.9997, Val Loss: 0.0214, Val Acc: 0.9970\n",
      "Early stopping!\n",
      "\n",
      "Run 4/5\n",
      "Epoch 1/50, Train Loss: 0.9479, Train Acc: 0.5433, Val Loss: 0.7844, Val Acc: 0.6097\n",
      "Epoch 2/50, Train Loss: 0.6612, Train Acc: 0.6822, Val Loss: 0.1778, Val Acc: 0.9436\n",
      "Epoch 3/50, Train Loss: 0.1126, Train Acc: 0.9592, Val Loss: 0.0439, Val Acc: 0.9868\n",
      "Epoch 4/50, Train Loss: 0.1125, Train Acc: 0.9702, Val Loss: 0.1707, Val Acc: 0.9580\n",
      "Epoch 5/50, Train Loss: 0.0395, Train Acc: 0.9880, Val Loss: 0.0453, Val Acc: 0.9886\n",
      "Epoch 6/50, Train Loss: 0.0297, Train Acc: 0.9928, Val Loss: 0.0352, Val Acc: 0.9958\n",
      "Epoch 7/50, Train Loss: 0.0586, Train Acc: 0.9864, Val Loss: 0.0695, Val Acc: 0.9814\n",
      "Epoch 8/50, Train Loss: 0.0195, Train Acc: 0.9955, Val Loss: 0.0328, Val Acc: 0.9940\n",
      "Epoch 9/50, Train Loss: 0.0309, Train Acc: 0.9930, Val Loss: 0.0304, Val Acc: 0.9928\n",
      "Epoch 10/50, Train Loss: 0.0132, Train Acc: 0.9961, Val Loss: 0.0321, Val Acc: 0.9940\n",
      "Epoch 11/50, Train Loss: 0.0025, Train Acc: 0.9996, Val Loss: 0.0255, Val Acc: 0.9964\n",
      "Epoch 12/50, Train Loss: 0.0021, Train Acc: 0.9996, Val Loss: 0.0262, Val Acc: 0.9946\n",
      "Epoch 13/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0244, Val Acc: 0.9964\n",
      "Epoch 14/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0242, Val Acc: 0.9964\n",
      "Epoch 15/50, Train Loss: 0.0019, Train Acc: 0.9997, Val Loss: 0.0236, Val Acc: 0.9970\n",
      "Epoch 16/50, Train Loss: 0.0017, Train Acc: 0.9996, Val Loss: 0.0248, Val Acc: 0.9952\n",
      "Epoch 17/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0228, Val Acc: 0.9964\n",
      "Epoch 18/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0230, Val Acc: 0.9964\n",
      "Epoch 19/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0229, Val Acc: 0.9970\n",
      "Epoch 20/50, Train Loss: 0.0016, Train Acc: 0.9997, Val Loss: 0.0229, Val Acc: 0.9964\n",
      "Epoch 21/50, Train Loss: 0.0015, Train Acc: 0.9997, Val Loss: 0.0226, Val Acc: 0.9970\n",
      "Epoch 22/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0227, Val Acc: 0.9964\n",
      "Epoch 23/50, Train Loss: 0.0012, Train Acc: 0.9997, Val Loss: 0.0229, Val Acc: 0.9964\n",
      "Epoch 24/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0226, Val Acc: 0.9964\n",
      "Epoch 25/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0224, Val Acc: 0.9970\n",
      "Epoch 26/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0228, Val Acc: 0.9964\n",
      "Epoch 27/50, Train Loss: 0.0011, Train Acc: 0.9997, Val Loss: 0.0224, Val Acc: 0.9964\n",
      "Epoch 28/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0225, Val Acc: 0.9970\n",
      "Epoch 29/50, Train Loss: 0.0012, Train Acc: 0.9997, Val Loss: 0.0229, Val Acc: 0.9964\n",
      "Epoch 30/50, Train Loss: 0.0012, Train Acc: 0.9997, Val Loss: 0.0225, Val Acc: 0.9970\n",
      "Epoch 31/50, Train Loss: 0.0011, Train Acc: 0.9997, Val Loss: 0.0224, Val Acc: 0.9970\n",
      "Epoch 32/50, Train Loss: 0.0011, Train Acc: 0.9997, Val Loss: 0.0225, Val Acc: 0.9970\n",
      "Early stopping!\n",
      "\n",
      "Run 5/5\n",
      "Epoch 1/50, Train Loss: 0.9674, Train Acc: 0.5445, Val Loss: 0.7562, Val Acc: 0.6175\n",
      "Epoch 2/50, Train Loss: 0.7470, Train Acc: 0.6194, Val Loss: 0.7877, Val Acc: 0.6067\n",
      "Epoch 3/50, Train Loss: 0.3264, Train Acc: 0.8449, Val Loss: 0.1252, Val Acc: 0.9664\n",
      "Epoch 4/50, Train Loss: 0.0795, Train Acc: 0.9753, Val Loss: 0.0821, Val Acc: 0.9826\n",
      "Epoch 5/50, Train Loss: 0.0664, Train Acc: 0.9813, Val Loss: 0.0303, Val Acc: 0.9916\n",
      "Epoch 6/50, Train Loss: 0.0259, Train Acc: 0.9928, Val Loss: 0.0313, Val Acc: 0.9946\n",
      "Epoch 7/50, Train Loss: 0.0199, Train Acc: 0.9951, Val Loss: 0.0724, Val Acc: 0.9820\n",
      "Epoch 8/50, Train Loss: 0.0228, Train Acc: 0.9942, Val Loss: 0.0430, Val Acc: 0.9934\n",
      "Epoch 9/50, Train Loss: 0.0513, Train Acc: 0.9849, Val Loss: 0.0924, Val Acc: 0.9772\n",
      "Epoch 10/50, Train Loss: 0.0428, Train Acc: 0.9901, Val Loss: 0.2703, Val Acc: 0.9418\n",
      "Early stopping!\n",
      "\n",
      "Source performance: 98.48 98.56 98.51 98.51\n",
      "Target performance: 99.09 99.10 99.06 99.07\n",
      "\n",
      "bpsk: 100.00\n",
      "qpsk: 99.95\n",
      "16qam: 97.72\n",
      "8apsk: 98.59\n",
      "Epoch 1/50, Loss: 3.9514, Domain Loss: 2.3986, Class Loss: 1.5527\n",
      "Epoch 2/50, Loss: 2.2143, Domain Loss: 1.3935, Class Loss: 0.8207\n",
      "Epoch 3/50, Loss: 2.1374, Domain Loss: 1.3868, Class Loss: 0.7507\n",
      "Epoch 4/50, Loss: 2.1513, Domain Loss: 1.3920, Class Loss: 0.7593\n",
      "Epoch 5/50, Loss: 2.0777, Domain Loss: 1.3877, Class Loss: 0.6900\n",
      "Epoch 6/50, Loss: 2.1354, Domain Loss: 1.3874, Class Loss: 0.7480\n",
      "Epoch 7/50, Loss: 2.0900, Domain Loss: 1.3907, Class Loss: 0.6993\n",
      "Epoch 8/50, Loss: 2.0298, Domain Loss: 1.4391, Class Loss: 0.5908\n",
      "Epoch 9/50, Loss: 1.7093, Domain Loss: 1.3871, Class Loss: 0.3222\n",
      "Epoch 10/50, Loss: 1.5660, Domain Loss: 1.3866, Class Loss: 0.1794\n",
      "Epoch 11/50, Loss: 1.5005, Domain Loss: 1.3865, Class Loss: 0.1140\n",
      "Epoch 12/50, Loss: 1.4320, Domain Loss: 1.3864, Class Loss: 0.0456\n",
      "Epoch 13/50, Loss: 1.4307, Domain Loss: 1.3864, Class Loss: 0.0443\n",
      "Epoch 14/50, Loss: 1.4080, Domain Loss: 1.3864, Class Loss: 0.0217\n",
      "Epoch 15/50, Loss: 1.4139, Domain Loss: 1.3863, Class Loss: 0.0276\n",
      "Epoch 16/50, Loss: 1.4242, Domain Loss: 1.3863, Class Loss: 0.0379\n",
      "Epoch 17/50, Loss: 1.4101, Domain Loss: 1.3863, Class Loss: 0.0238\n",
      "Epoch 18/50, Loss: 1.4217, Domain Loss: 1.3863, Class Loss: 0.0354\n",
      "Epoch 19/50, Loss: 1.4041, Domain Loss: 1.3863, Class Loss: 0.0178\n",
      "Epoch 20/50, Loss: 1.4374, Domain Loss: 1.3863, Class Loss: 0.0511\n",
      "Epoch 21/50, Loss: 1.4015, Domain Loss: 1.3863, Class Loss: 0.0152\n",
      "Epoch 22/50, Loss: 1.4041, Domain Loss: 1.3863, Class Loss: 0.0179\n",
      "Epoch 23/50, Loss: 1.4040, Domain Loss: 1.3863, Class Loss: 0.0177\n",
      "Epoch 24/50, Loss: 1.4280, Domain Loss: 1.3863, Class Loss: 0.0417\n",
      "Epoch 25/50, Loss: 1.4474, Domain Loss: 1.3863, Class Loss: 0.0611\n",
      "Epoch 26/50, Loss: 1.4017, Domain Loss: 1.3863, Class Loss: 0.0154\n",
      "Epoch 27/50, Loss: 1.3954, Domain Loss: 1.3863, Class Loss: 0.0091\n",
      "Epoch 28/50, Loss: 1.3932, Domain Loss: 1.3863, Class Loss: 0.0070\n",
      "Epoch 29/50, Loss: 1.3958, Domain Loss: 1.3863, Class Loss: 0.0095\n",
      "Epoch 30/50, Loss: 1.3976, Domain Loss: 1.3863, Class Loss: 0.0113\n",
      "Epoch 31/50, Loss: 1.3937, Domain Loss: 1.3863, Class Loss: 0.0074\n",
      "Epoch 32/50, Loss: 1.4011, Domain Loss: 1.3863, Class Loss: 0.0148\n",
      "Epoch 33/50, Loss: 1.3986, Domain Loss: 1.3863, Class Loss: 0.0123\n",
      "Epoch 34/50, Loss: 1.4096, Domain Loss: 1.3863, Class Loss: 0.0233\n",
      "Epoch 35/50, Loss: 1.4017, Domain Loss: 1.3863, Class Loss: 0.0154\n",
      "Epoch 36/50, Loss: 1.3915, Domain Loss: 1.3863, Class Loss: 0.0052\n",
      "Epoch 37/50, Loss: 1.3983, Domain Loss: 1.3863, Class Loss: 0.0120\n",
      "Epoch 38/50, Loss: 1.4123, Domain Loss: 1.3863, Class Loss: 0.0260\n",
      "Epoch 39/50, Loss: 1.9657, Domain Loss: 1.3871, Class Loss: 0.5786\n",
      "Epoch 40/50, Loss: 1.4325, Domain Loss: 1.3863, Class Loss: 0.0462\n",
      "Epoch 41/50, Loss: 1.4135, Domain Loss: 1.3863, Class Loss: 0.0272\n",
      "Epoch 42/50, Loss: 1.3953, Domain Loss: 1.3863, Class Loss: 0.0090\n",
      "Epoch 43/50, Loss: 1.3939, Domain Loss: 1.3863, Class Loss: 0.0076\n",
      "Epoch 44/50, Loss: 1.3911, Domain Loss: 1.3863, Class Loss: 0.0048\n",
      "Epoch 45/50, Loss: 1.3966, Domain Loss: 1.3863, Class Loss: 0.0103\n",
      "Epoch 46/50, Loss: 1.4015, Domain Loss: 1.3863, Class Loss: 0.0151\n",
      "Epoch 47/50, Loss: 1.3946, Domain Loss: 1.3863, Class Loss: 0.0083\n",
      "Epoch 48/50, Loss: 1.3901, Domain Loss: 1.3863, Class Loss: 0.0038\n",
      "Epoch 49/50, Loss: 1.3871, Domain Loss: 1.3863, Class Loss: 0.0008\n",
      "Epoch 50/50, Loss: 1.3879, Domain Loss: 1.3863, Class Loss: 0.0016\n",
      "99.70\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.5718, Domain Loss: 1.7552, Class Loss: 1.8166\n",
      "Epoch 2/50, Loss: 2.2707, Domain Loss: 1.3880, Class Loss: 0.8826\n",
      "Epoch 3/50, Loss: 2.1333, Domain Loss: 1.3980, Class Loss: 0.7353\n",
      "Epoch 4/50, Loss: 2.1565, Domain Loss: 1.3873, Class Loss: 0.7692\n",
      "Epoch 5/50, Loss: 2.1138, Domain Loss: 1.3871, Class Loss: 0.7267\n",
      "Epoch 6/50, Loss: 2.1113, Domain Loss: 1.3867, Class Loss: 0.7246\n",
      "Epoch 7/50, Loss: 2.1055, Domain Loss: 1.3860, Class Loss: 0.7195\n",
      "Epoch 8/50, Loss: 2.0545, Domain Loss: 1.3858, Class Loss: 0.6688\n",
      "Epoch 9/50, Loss: 1.7966, Domain Loss: 1.3893, Class Loss: 0.4073\n",
      "Epoch 10/50, Loss: 1.5807, Domain Loss: 1.3694, Class Loss: 0.2113\n",
      "Epoch 11/50, Loss: 1.4907, Domain Loss: 1.3707, Class Loss: 0.1200\n",
      "Epoch 12/50, Loss: 1.3977, Domain Loss: 1.3555, Class Loss: 0.0422\n",
      "Epoch 13/50, Loss: 1.3945, Domain Loss: 1.3651, Class Loss: 0.0293\n",
      "Epoch 14/50, Loss: 1.3725, Domain Loss: 1.3424, Class Loss: 0.0300\n",
      "Epoch 15/50, Loss: 2.2149, Domain Loss: 1.3532, Class Loss: 0.8617\n",
      "Epoch 16/50, Loss: 1.5219, Domain Loss: 1.3391, Class Loss: 0.1828\n",
      "Epoch 17/50, Loss: 1.3633, Domain Loss: 1.3194, Class Loss: 0.0439\n",
      "Epoch 18/50, Loss: 1.3519, Domain Loss: 1.3272, Class Loss: 0.0247\n",
      "Epoch 19/50, Loss: 1.3294, Domain Loss: 1.3094, Class Loss: 0.0200\n",
      "Epoch 20/50, Loss: 1.3402, Domain Loss: 1.3228, Class Loss: 0.0174\n",
      "Epoch 21/50, Loss: 1.3071, Domain Loss: 1.2959, Class Loss: 0.0112\n",
      "Epoch 22/50, Loss: 1.3274, Domain Loss: 1.2992, Class Loss: 0.0282\n",
      "Epoch 23/50, Loss: 1.4187, Domain Loss: 1.2767, Class Loss: 0.1419\n",
      "Epoch 24/50, Loss: 1.3136, Domain Loss: 1.2734, Class Loss: 0.0402\n",
      "Epoch 25/50, Loss: 1.2826, Domain Loss: 1.2711, Class Loss: 0.0115\n",
      "Epoch 26/50, Loss: 1.2826, Domain Loss: 1.2696, Class Loss: 0.0129\n",
      "Epoch 27/50, Loss: 1.3116, Domain Loss: 1.2860, Class Loss: 0.0257\n",
      "Epoch 28/50, Loss: 1.3304, Domain Loss: 1.3051, Class Loss: 0.0253\n",
      "Epoch 29/50, Loss: 1.3059, Domain Loss: 1.2935, Class Loss: 0.0124\n",
      "Epoch 30/50, Loss: 2.0000, Domain Loss: 1.3069, Class Loss: 0.6931\n",
      "Epoch 31/50, Loss: 1.3979, Domain Loss: 1.2847, Class Loss: 0.1133\n",
      "Epoch 32/50, Loss: 1.3190, Domain Loss: 1.2649, Class Loss: 0.0541\n",
      "Epoch 33/50, Loss: 1.2971, Domain Loss: 1.2498, Class Loss: 0.0473\n",
      "Epoch 34/50, Loss: 1.2819, Domain Loss: 1.2502, Class Loss: 0.0317\n",
      "Epoch 35/50, Loss: 1.2691, Domain Loss: 1.2311, Class Loss: 0.0381\n",
      "Epoch 36/50, Loss: 1.2399, Domain Loss: 1.2237, Class Loss: 0.0162\n",
      "Epoch 37/50, Loss: 1.2770, Domain Loss: 1.2470, Class Loss: 0.0300\n",
      "Epoch 38/50, Loss: 1.2433, Domain Loss: 1.2276, Class Loss: 0.0157\n",
      "Epoch 39/50, Loss: 1.2648, Domain Loss: 1.2463, Class Loss: 0.0185\n",
      "Epoch 40/50, Loss: 1.2479, Domain Loss: 1.2247, Class Loss: 0.0231\n",
      "Epoch 41/50, Loss: 1.2822, Domain Loss: 1.2412, Class Loss: 0.0410\n",
      "Epoch 42/50, Loss: 1.2807, Domain Loss: 1.2567, Class Loss: 0.0240\n",
      "Epoch 43/50, Loss: 1.2710, Domain Loss: 1.2455, Class Loss: 0.0255\n",
      "Epoch 44/50, Loss: 1.3068, Domain Loss: 1.2673, Class Loss: 0.0395\n",
      "Epoch 45/50, Loss: 1.2764, Domain Loss: 1.2521, Class Loss: 0.0243\n",
      "Epoch 46/50, Loss: 1.2757, Domain Loss: 1.2461, Class Loss: 0.0296\n",
      "Epoch 47/50, Loss: 1.2911, Domain Loss: 1.2570, Class Loss: 0.0341\n",
      "Epoch 48/50, Loss: 1.2944, Domain Loss: 1.2557, Class Loss: 0.0387\n",
      "Epoch 49/50, Loss: 1.3014, Domain Loss: 1.2587, Class Loss: 0.0427\n",
      "Epoch 50/50, Loss: 1.3385, Domain Loss: 1.2843, Class Loss: 0.0543\n",
      "98.38\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.9165, Domain Loss: 2.2671, Class Loss: 1.6494\n",
      "Epoch 2/50, Loss: 2.3295, Domain Loss: 1.4177, Class Loss: 0.9119\n",
      "Epoch 3/50, Loss: 2.2221, Domain Loss: 1.4278, Class Loss: 0.7943\n",
      "Epoch 4/50, Loss: 2.1533, Domain Loss: 1.3888, Class Loss: 0.7645\n",
      "Epoch 5/50, Loss: 2.1334, Domain Loss: 1.4089, Class Loss: 0.7245\n",
      "Epoch 6/50, Loss: 2.0576, Domain Loss: 1.3755, Class Loss: 0.6822\n",
      "Epoch 7/50, Loss: 2.1129, Domain Loss: 1.4195, Class Loss: 0.6934\n",
      "Epoch 8/50, Loss: 2.6250, Domain Loss: 1.8662, Class Loss: 0.7589\n",
      "Epoch 9/50, Loss: 2.4176, Domain Loss: 1.7840, Class Loss: 0.6336\n",
      "Epoch 10/50, Loss: 3.4729, Domain Loss: 2.5713, Class Loss: 0.9016\n",
      "Epoch 11/50, Loss: 2.0776, Domain Loss: 1.4908, Class Loss: 0.5869\n",
      "Epoch 12/50, Loss: 1.7341, Domain Loss: 1.3863, Class Loss: 0.3478\n",
      "Epoch 13/50, Loss: 1.5654, Domain Loss: 1.3845, Class Loss: 0.1808\n",
      "Epoch 14/50, Loss: 1.5368, Domain Loss: 1.3831, Class Loss: 0.1538\n",
      "Epoch 15/50, Loss: 1.6359, Domain Loss: 1.5805, Class Loss: 0.0554\n",
      "Epoch 16/50, Loss: 1.4393, Domain Loss: 1.3894, Class Loss: 0.0499\n",
      "Epoch 17/50, Loss: 1.4303, Domain Loss: 1.3890, Class Loss: 0.0413\n",
      "Epoch 18/50, Loss: 1.4159, Domain Loss: 1.3885, Class Loss: 0.0274\n",
      "Epoch 19/50, Loss: 1.4138, Domain Loss: 1.3881, Class Loss: 0.0257\n",
      "Epoch 20/50, Loss: 1.4186, Domain Loss: 1.3879, Class Loss: 0.0308\n",
      "Epoch 21/50, Loss: 1.4026, Domain Loss: 1.3875, Class Loss: 0.0151\n",
      "Epoch 22/50, Loss: 1.4172, Domain Loss: 1.3873, Class Loss: 0.0299\n",
      "Epoch 23/50, Loss: 1.4259, Domain Loss: 1.3871, Class Loss: 0.0388\n",
      "Epoch 24/50, Loss: 1.4180, Domain Loss: 1.3869, Class Loss: 0.0311\n",
      "Epoch 25/50, Loss: 1.7447, Domain Loss: 1.4873, Class Loss: 0.2573\n",
      "Epoch 26/50, Loss: 1.5280, Domain Loss: 1.3866, Class Loss: 0.1414\n",
      "Epoch 27/50, Loss: 1.4269, Domain Loss: 1.3864, Class Loss: 0.0405\n",
      "Epoch 28/50, Loss: 1.6131, Domain Loss: 1.5727, Class Loss: 0.0404\n",
      "Epoch 29/50, Loss: 1.4187, Domain Loss: 1.3868, Class Loss: 0.0319\n",
      "Epoch 30/50, Loss: 1.4005, Domain Loss: 1.3864, Class Loss: 0.0141\n",
      "Epoch 31/50, Loss: 1.4021, Domain Loss: 1.3863, Class Loss: 0.0158\n",
      "Epoch 32/50, Loss: 1.3931, Domain Loss: 1.3863, Class Loss: 0.0068\n",
      "Epoch 33/50, Loss: 1.3951, Domain Loss: 1.3862, Class Loss: 0.0089\n",
      "Epoch 34/50, Loss: 1.3991, Domain Loss: 1.3851, Class Loss: 0.0140\n",
      "Epoch 35/50, Loss: 1.3991, Domain Loss: 1.3854, Class Loss: 0.0137\n",
      "Epoch 36/50, Loss: 1.4667, Domain Loss: 1.4512, Class Loss: 0.0155\n",
      "Epoch 37/50, Loss: 1.4124, Domain Loss: 1.3860, Class Loss: 0.0264\n",
      "Epoch 38/50, Loss: 1.3914, Domain Loss: 1.3862, Class Loss: 0.0052\n",
      "Epoch 39/50, Loss: 1.3933, Domain Loss: 1.3841, Class Loss: 0.0092\n",
      "Epoch 40/50, Loss: 1.4572, Domain Loss: 1.3826, Class Loss: 0.0746\n",
      "Epoch 41/50, Loss: 1.6115, Domain Loss: 1.4061, Class Loss: 0.2053\n",
      "Epoch 42/50, Loss: 1.4546, Domain Loss: 1.3814, Class Loss: 0.0732\n",
      "Epoch 43/50, Loss: 1.3933, Domain Loss: 1.3800, Class Loss: 0.0133\n",
      "Epoch 44/50, Loss: 1.3852, Domain Loss: 1.3776, Class Loss: 0.0076\n",
      "Epoch 45/50, Loss: 1.3792, Domain Loss: 1.3732, Class Loss: 0.0060\n",
      "Epoch 46/50, Loss: 1.3816, Domain Loss: 1.3741, Class Loss: 0.0075\n",
      "Epoch 47/50, Loss: 1.3720, Domain Loss: 1.3669, Class Loss: 0.0051\n",
      "Epoch 48/50, Loss: 1.3778, Domain Loss: 1.3709, Class Loss: 0.0069\n",
      "Epoch 49/50, Loss: 1.3670, Domain Loss: 1.3644, Class Loss: 0.0026\n",
      "Epoch 50/50, Loss: 1.3673, Domain Loss: 1.3631, Class Loss: 0.0042\n",
      "99.82\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.1609, Domain Loss: 2.1812, Class Loss: 1.9798\n",
      "Epoch 2/50, Loss: 2.6232, Domain Loss: 1.4131, Class Loss: 1.2101\n",
      "Epoch 3/50, Loss: 2.2021, Domain Loss: 1.4003, Class Loss: 0.8019\n",
      "Epoch 4/50, Loss: 2.1839, Domain Loss: 1.3820, Class Loss: 0.8019\n",
      "Epoch 5/50, Loss: 2.1237, Domain Loss: 1.3742, Class Loss: 0.7495\n",
      "Epoch 6/50, Loss: 2.1236, Domain Loss: 1.3925, Class Loss: 0.7311\n",
      "Epoch 7/50, Loss: 2.0938, Domain Loss: 1.3741, Class Loss: 0.7197\n",
      "Epoch 8/50, Loss: 2.0968, Domain Loss: 1.3830, Class Loss: 0.7138\n",
      "Epoch 9/50, Loss: 2.0650, Domain Loss: 1.3615, Class Loss: 0.7035\n",
      "Epoch 10/50, Loss: 2.1209, Domain Loss: 1.3640, Class Loss: 0.7569\n",
      "Epoch 11/50, Loss: 2.0679, Domain Loss: 1.3658, Class Loss: 0.7020\n",
      "Epoch 12/50, Loss: 2.0512, Domain Loss: 1.3610, Class Loss: 0.6902\n",
      "Epoch 13/50, Loss: 2.0379, Domain Loss: 1.3439, Class Loss: 0.6939\n",
      "Epoch 14/50, Loss: 1.9991, Domain Loss: 1.3433, Class Loss: 0.6558\n",
      "Epoch 15/50, Loss: 1.9975, Domain Loss: 1.3476, Class Loss: 0.6499\n",
      "Epoch 16/50, Loss: 2.3165, Domain Loss: 1.6633, Class Loss: 0.6532\n",
      "Epoch 17/50, Loss: 27.9582, Domain Loss: 25.7617, Class Loss: 2.1965\n",
      "Epoch 18/50, Loss: 13.7199, Domain Loss: 12.3376, Class Loss: 1.3823\n",
      "Epoch 19/50, Loss: 6.3280, Domain Loss: 4.9474, Class Loss: 1.3806\n",
      "Epoch 20/50, Loss: 3.6389, Domain Loss: 2.3002, Class Loss: 1.3387\n",
      "Epoch 21/50, Loss: 2.7737, Domain Loss: 1.4665, Class Loss: 1.3072\n",
      "Epoch 22/50, Loss: 2.6789, Domain Loss: 1.4142, Class Loss: 1.2647\n",
      "Epoch 23/50, Loss: 3.9366, Domain Loss: 2.8326, Class Loss: 1.1040\n",
      "Epoch 24/50, Loss: 3.6138, Domain Loss: 2.5497, Class Loss: 1.0641\n",
      "Epoch 25/50, Loss: 2.3444, Domain Loss: 1.5774, Class Loss: 0.7670\n",
      "Epoch 26/50, Loss: 2.3128, Domain Loss: 1.4981, Class Loss: 0.8147\n",
      "Epoch 27/50, Loss: 2.1817, Domain Loss: 1.4443, Class Loss: 0.7374\n",
      "Epoch 28/50, Loss: 2.0530, Domain Loss: 1.3863, Class Loss: 0.6667\n",
      "Epoch 29/50, Loss: 2.0541, Domain Loss: 1.3835, Class Loss: 0.6707\n",
      "Epoch 30/50, Loss: 1.9581, Domain Loss: 1.3829, Class Loss: 0.5752\n",
      "Epoch 31/50, Loss: 1.9466, Domain Loss: 1.3812, Class Loss: 0.5654\n",
      "Epoch 32/50, Loss: 1.9269, Domain Loss: 1.3887, Class Loss: 0.5382\n",
      "Epoch 33/50, Loss: 1.8700, Domain Loss: 1.3840, Class Loss: 0.4861\n",
      "Epoch 34/50, Loss: 1.8184, Domain Loss: 1.3797, Class Loss: 0.4387\n",
      "Epoch 35/50, Loss: 1.8355, Domain Loss: 1.3834, Class Loss: 0.4521\n",
      "Epoch 36/50, Loss: 1.8623, Domain Loss: 1.3835, Class Loss: 0.4787\n",
      "Epoch 37/50, Loss: 1.7989, Domain Loss: 1.3758, Class Loss: 0.4232\n",
      "Epoch 38/50, Loss: 1.7892, Domain Loss: 1.3796, Class Loss: 0.4096\n",
      "Epoch 39/50, Loss: 1.7504, Domain Loss: 1.3789, Class Loss: 0.3715\n",
      "Epoch 40/50, Loss: 1.7704, Domain Loss: 1.3829, Class Loss: 0.3875\n",
      "Epoch 41/50, Loss: 1.7746, Domain Loss: 1.3750, Class Loss: 0.3996\n",
      "Epoch 42/50, Loss: 1.7781, Domain Loss: 1.3787, Class Loss: 0.3994\n",
      "Epoch 43/50, Loss: 1.7746, Domain Loss: 1.3822, Class Loss: 0.3924\n",
      "Epoch 44/50, Loss: 1.7694, Domain Loss: 1.3805, Class Loss: 0.3888\n",
      "Epoch 45/50, Loss: 1.7885, Domain Loss: 1.3867, Class Loss: 0.4019\n",
      "Epoch 46/50, Loss: 1.7362, Domain Loss: 1.3824, Class Loss: 0.3538\n",
      "Epoch 47/50, Loss: 1.7655, Domain Loss: 1.3818, Class Loss: 0.3837\n",
      "Epoch 48/50, Loss: 1.7584, Domain Loss: 1.3806, Class Loss: 0.3778\n",
      "Epoch 49/50, Loss: 1.7501, Domain Loss: 1.3864, Class Loss: 0.3637\n",
      "Epoch 50/50, Loss: 1.7203, Domain Loss: 1.3788, Class Loss: 0.3415\n",
      "86.15\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.7938, Domain Loss: 1.8125, Class Loss: 1.9813\n",
      "Epoch 2/50, Loss: 2.4740, Domain Loss: 1.3890, Class Loss: 1.0849\n",
      "Epoch 3/50, Loss: 2.1548, Domain Loss: 1.3904, Class Loss: 0.7644\n",
      "Epoch 4/50, Loss: 2.1187, Domain Loss: 1.3814, Class Loss: 0.7373\n",
      "Epoch 5/50, Loss: 2.0867, Domain Loss: 1.3764, Class Loss: 0.7103\n",
      "Epoch 6/50, Loss: 2.0827, Domain Loss: 1.3787, Class Loss: 0.7040\n",
      "Epoch 7/50, Loss: 2.1014, Domain Loss: 1.4097, Class Loss: 0.6917\n",
      "Epoch 8/50, Loss: 2.0857, Domain Loss: 1.3727, Class Loss: 0.7130\n",
      "Epoch 9/50, Loss: 2.0484, Domain Loss: 1.3637, Class Loss: 0.6847\n",
      "Epoch 10/50, Loss: 1.9956, Domain Loss: 1.3717, Class Loss: 0.6239\n",
      "Epoch 11/50, Loss: 2.1246, Domain Loss: 1.4743, Class Loss: 0.6503\n",
      "Epoch 12/50, Loss: 2.0802, Domain Loss: 1.4002, Class Loss: 0.6800\n",
      "Epoch 13/50, Loss: 1.6554, Domain Loss: 1.3869, Class Loss: 0.2685\n",
      "Epoch 14/50, Loss: 1.4672, Domain Loss: 1.3868, Class Loss: 0.0805\n",
      "Epoch 15/50, Loss: 1.5016, Domain Loss: 1.3866, Class Loss: 0.1150\n",
      "Epoch 16/50, Loss: 1.4700, Domain Loss: 1.3863, Class Loss: 0.0837\n",
      "Epoch 17/50, Loss: 1.4202, Domain Loss: 1.3863, Class Loss: 0.0339\n",
      "Epoch 18/50, Loss: 1.4002, Domain Loss: 1.3861, Class Loss: 0.0141\n",
      "Epoch 19/50, Loss: 1.4012, Domain Loss: 1.3845, Class Loss: 0.0167\n",
      "Epoch 20/50, Loss: 1.3953, Domain Loss: 1.3854, Class Loss: 0.0099\n",
      "Epoch 21/50, Loss: 1.4024, Domain Loss: 1.3835, Class Loss: 0.0189\n",
      "Epoch 22/50, Loss: 1.4014, Domain Loss: 1.3839, Class Loss: 0.0175\n",
      "Epoch 23/50, Loss: 1.4075, Domain Loss: 1.3808, Class Loss: 0.0267\n",
      "Epoch 24/50, Loss: 1.4233, Domain Loss: 1.3757, Class Loss: 0.0476\n",
      "Epoch 25/50, Loss: 1.3919, Domain Loss: 1.3829, Class Loss: 0.0090\n",
      "Epoch 26/50, Loss: 1.3808, Domain Loss: 1.3752, Class Loss: 0.0056\n",
      "Epoch 27/50, Loss: 1.3798, Domain Loss: 1.3643, Class Loss: 0.0155\n",
      "Epoch 28/50, Loss: 1.3816, Domain Loss: 1.3632, Class Loss: 0.0184\n",
      "Epoch 29/50, Loss: 1.3620, Domain Loss: 1.3569, Class Loss: 0.0052\n",
      "Epoch 30/50, Loss: 1.3660, Domain Loss: 1.3555, Class Loss: 0.0105\n",
      "Epoch 31/50, Loss: 1.3547, Domain Loss: 1.3408, Class Loss: 0.0139\n",
      "Epoch 32/50, Loss: 1.3579, Domain Loss: 1.3440, Class Loss: 0.0139\n",
      "Epoch 33/50, Loss: 1.3740, Domain Loss: 1.3484, Class Loss: 0.0256\n",
      "Epoch 34/50, Loss: 1.3384, Domain Loss: 1.3292, Class Loss: 0.0092\n",
      "Epoch 35/50, Loss: 1.3408, Domain Loss: 1.3321, Class Loss: 0.0088\n",
      "Epoch 36/50, Loss: 1.3498, Domain Loss: 1.3352, Class Loss: 0.0146\n",
      "Epoch 37/50, Loss: 1.3522, Domain Loss: 1.3373, Class Loss: 0.0149\n",
      "Epoch 38/50, Loss: 1.4104, Domain Loss: 1.3667, Class Loss: 0.0436\n",
      "Epoch 39/50, Loss: 1.4089, Domain Loss: 1.3906, Class Loss: 0.0183\n",
      "Epoch 40/50, Loss: 1.3935, Domain Loss: 1.3879, Class Loss: 0.0056\n",
      "Epoch 41/50, Loss: 1.3884, Domain Loss: 1.3831, Class Loss: 0.0052\n",
      "Epoch 42/50, Loss: 1.3922, Domain Loss: 1.3865, Class Loss: 0.0057\n",
      "Epoch 43/50, Loss: 1.4022, Domain Loss: 1.3883, Class Loss: 0.0139\n",
      "Epoch 44/50, Loss: 1.3943, Domain Loss: 1.3872, Class Loss: 0.0071\n",
      "Epoch 45/50, Loss: 1.3933, Domain Loss: 1.3865, Class Loss: 0.0068\n",
      "Epoch 46/50, Loss: 1.3885, Domain Loss: 1.3864, Class Loss: 0.0021\n",
      "Epoch 47/50, Loss: 1.3871, Domain Loss: 1.3861, Class Loss: 0.0010\n",
      "Epoch 48/50, Loss: 1.3868, Domain Loss: 1.3855, Class Loss: 0.0013\n",
      "Epoch 49/50, Loss: 1.3910, Domain Loss: 1.3832, Class Loss: 0.0078\n",
      "Epoch 50/50, Loss: 1.4470, Domain Loss: 1.3800, Class Loss: 0.0669\n",
      "99.64\n",
      "\n",
      "\n",
      "Source performance:\n",
      "95.41 95.65 95.49 95.47 \n",
      "Target performance:\n",
      "96.74 96.99 96.71 96.78 \n",
      "\n",
      "Per-class target performance: 100.00 97.07 94.06 95.72 \n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 3.2711, Discrepancy Loss: 0.1243\n",
      "Epoch [2/50], Class Loss: 1.5940, Discrepancy Loss: 0.1460\n",
      "Epoch [3/50], Class Loss: 1.2314, Discrepancy Loss: 0.1556\n",
      "Epoch [4/50], Class Loss: 1.1241, Discrepancy Loss: 0.1570\n",
      "Epoch [5/50], Class Loss: 1.0474, Discrepancy Loss: 0.1384\n",
      "Epoch [6/50], Class Loss: 0.3888, Discrepancy Loss: 0.0534\n",
      "Epoch [7/50], Class Loss: 0.1618, Discrepancy Loss: 0.0249\n",
      "Epoch [8/50], Class Loss: 0.1002, Discrepancy Loss: 0.0258\n",
      "Epoch [9/50], Class Loss: 0.0785, Discrepancy Loss: 0.0162\n",
      "Epoch [10/50], Class Loss: 0.0513, Discrepancy Loss: 0.0171\n",
      "Epoch [11/50], Class Loss: 0.0528, Discrepancy Loss: 0.0094\n",
      "Epoch [12/50], Class Loss: 0.0285, Discrepancy Loss: 0.0089\n",
      "Epoch [13/50], Class Loss: 0.0342, Discrepancy Loss: 0.0068\n",
      "Epoch [14/50], Class Loss: 0.0212, Discrepancy Loss: 0.0099\n",
      "Epoch [15/50], Class Loss: 0.0260, Discrepancy Loss: 0.0079\n",
      "Epoch [16/50], Class Loss: 0.0248, Discrepancy Loss: 0.0075\n",
      "Epoch [17/50], Class Loss: 0.0615, Discrepancy Loss: 0.0068\n",
      "Epoch [18/50], Class Loss: 0.0326, Discrepancy Loss: 0.0086\n",
      "Epoch [19/50], Class Loss: 0.0182, Discrepancy Loss: 0.0069\n",
      "Epoch [20/50], Class Loss: 0.0203, Discrepancy Loss: 0.0060\n",
      "Epoch [21/50], Class Loss: 0.0219, Discrepancy Loss: 0.0067\n",
      "Epoch [22/50], Class Loss: 0.0209, Discrepancy Loss: 0.0065\n",
      "Epoch [23/50], Class Loss: 0.0127, Discrepancy Loss: 0.0050\n",
      "Epoch [24/50], Class Loss: 0.0152, Discrepancy Loss: 0.0050\n",
      "Epoch [25/50], Class Loss: 0.0174, Discrepancy Loss: 0.0047\n",
      "Epoch [26/50], Class Loss: 0.0159, Discrepancy Loss: 0.0049\n",
      "Epoch [27/50], Class Loss: 0.0126, Discrepancy Loss: 0.0077\n",
      "Epoch [28/50], Class Loss: 0.0140, Discrepancy Loss: 0.0068\n",
      "Epoch [29/50], Class Loss: 0.0168, Discrepancy Loss: 0.0058\n",
      "Epoch [30/50], Class Loss: 0.0195, Discrepancy Loss: 0.0061\n",
      "Epoch [31/50], Class Loss: 0.0253, Discrepancy Loss: 0.0042\n",
      "Epoch [32/50], Class Loss: 0.0147, Discrepancy Loss: 0.0062\n",
      "Epoch [33/50], Class Loss: 0.0236, Discrepancy Loss: 0.0065\n",
      "Epoch [34/50], Class Loss: 0.0122, Discrepancy Loss: 0.0057\n",
      "Epoch [35/50], Class Loss: 0.0127, Discrepancy Loss: 0.0041\n",
      "Epoch [36/50], Class Loss: 0.0121, Discrepancy Loss: 0.0046\n",
      "Epoch [37/50], Class Loss: 0.0181, Discrepancy Loss: 0.0054\n",
      "Epoch [38/50], Class Loss: 0.0215, Discrepancy Loss: 0.0070\n",
      "Epoch [39/50], Class Loss: 0.0150, Discrepancy Loss: 0.0056\n",
      "Epoch [40/50], Class Loss: 0.0123, Discrepancy Loss: 0.0061\n",
      "Epoch [41/50], Class Loss: 0.0169, Discrepancy Loss: 0.0058\n",
      "Epoch [42/50], Class Loss: 0.0140, Discrepancy Loss: 0.0058\n",
      "Epoch [43/50], Class Loss: 0.0179, Discrepancy Loss: 0.0044\n",
      "Epoch [44/50], Class Loss: 0.0150, Discrepancy Loss: 0.0060\n",
      "Epoch [45/50], Class Loss: 0.0143, Discrepancy Loss: 0.0052\n",
      "Epoch [46/50], Class Loss: 0.0140, Discrepancy Loss: 0.0066\n",
      "Epoch [47/50], Class Loss: 0.0160, Discrepancy Loss: 0.0061\n",
      "Epoch [48/50], Class Loss: 0.0124, Discrepancy Loss: 0.0048\n",
      "Epoch [49/50], Class Loss: 0.0159, Discrepancy Loss: 0.0053\n",
      "Epoch [50/50], Class Loss: 0.0154, Discrepancy Loss: 0.0063\n",
      "Source Domain Performance - Accuracy: 99.58%, Precision: 99.60%, Recall: 99.58%, F1 Score: 99.59%\n",
      "Target Domain Performance - Accuracy: 99.94%, Precision: 99.94%, Recall: 99.94%, F1 Score: 99.94%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.7966, Discrepancy Loss: 0.1400\n",
      "Epoch [2/50], Class Loss: 1.5213, Discrepancy Loss: 0.1729\n",
      "Epoch [3/50], Class Loss: 1.3416, Discrepancy Loss: 0.1651\n",
      "Epoch [4/50], Class Loss: 1.2122, Discrepancy Loss: 0.1596\n",
      "Epoch [5/50], Class Loss: 0.5487, Discrepancy Loss: 0.0811\n",
      "Epoch [6/50], Class Loss: 0.2065, Discrepancy Loss: 0.0291\n",
      "Epoch [7/50], Class Loss: 0.0907, Discrepancy Loss: 0.0206\n",
      "Epoch [8/50], Class Loss: 0.0811, Discrepancy Loss: 0.0175\n",
      "Epoch [9/50], Class Loss: 0.0543, Discrepancy Loss: 0.0111\n",
      "Epoch [10/50], Class Loss: 0.0441, Discrepancy Loss: 0.0093\n",
      "Epoch [11/50], Class Loss: 0.0250, Discrepancy Loss: 0.0065\n",
      "Epoch [12/50], Class Loss: 0.0267, Discrepancy Loss: 0.0063\n",
      "Epoch [13/50], Class Loss: 0.0204, Discrepancy Loss: 0.0059\n",
      "Epoch [14/50], Class Loss: 0.0217, Discrepancy Loss: 0.0068\n",
      "Epoch [15/50], Class Loss: 0.0259, Discrepancy Loss: 0.0075\n",
      "Epoch [16/50], Class Loss: 0.0204, Discrepancy Loss: 0.0066\n",
      "Epoch [17/50], Class Loss: 0.0180, Discrepancy Loss: 0.0064\n",
      "Epoch [18/50], Class Loss: 0.0204, Discrepancy Loss: 0.0041\n",
      "Epoch [19/50], Class Loss: 0.0127, Discrepancy Loss: 0.0085\n",
      "Epoch [20/50], Class Loss: 0.0276, Discrepancy Loss: 0.0054\n",
      "Epoch [21/50], Class Loss: 0.0145, Discrepancy Loss: 0.0044\n",
      "Epoch [22/50], Class Loss: 0.0260, Discrepancy Loss: 0.0050\n",
      "Epoch [23/50], Class Loss: 0.0124, Discrepancy Loss: 0.0042\n",
      "Epoch [24/50], Class Loss: 0.0152, Discrepancy Loss: 0.0038\n",
      "Epoch [25/50], Class Loss: 0.0082, Discrepancy Loss: 0.0038\n",
      "Epoch [26/50], Class Loss: 0.0114, Discrepancy Loss: 0.0045\n",
      "Epoch [27/50], Class Loss: 0.0190, Discrepancy Loss: 0.0040\n",
      "Epoch [28/50], Class Loss: 0.0113, Discrepancy Loss: 0.0049\n",
      "Epoch [29/50], Class Loss: 0.0070, Discrepancy Loss: 0.0047\n",
      "Epoch [30/50], Class Loss: 0.0120, Discrepancy Loss: 0.0052\n",
      "Epoch [31/50], Class Loss: 0.0128, Discrepancy Loss: 0.0045\n",
      "Epoch [32/50], Class Loss: 0.0132, Discrepancy Loss: 0.0056\n",
      "Epoch [33/50], Class Loss: 0.0319, Discrepancy Loss: 0.0047\n",
      "Epoch [34/50], Class Loss: 0.0101, Discrepancy Loss: 0.0046\n",
      "Epoch [35/50], Class Loss: 0.0141, Discrepancy Loss: 0.0044\n",
      "Epoch [36/50], Class Loss: 0.0156, Discrepancy Loss: 0.0050\n",
      "Epoch [37/50], Class Loss: 0.0148, Discrepancy Loss: 0.0052\n",
      "Epoch [38/50], Class Loss: 0.0095, Discrepancy Loss: 0.0040\n",
      "Epoch [39/50], Class Loss: 0.0072, Discrepancy Loss: 0.0055\n",
      "Epoch [40/50], Class Loss: 0.0130, Discrepancy Loss: 0.0048\n",
      "Epoch [41/50], Class Loss: 0.0489, Discrepancy Loss: 0.0045\n",
      "Epoch [42/50], Class Loss: 0.0121, Discrepancy Loss: 0.0034\n",
      "Epoch [43/50], Class Loss: 0.0121, Discrepancy Loss: 0.0043\n",
      "Epoch [44/50], Class Loss: 0.0129, Discrepancy Loss: 0.0033\n",
      "Epoch [45/50], Class Loss: 0.0158, Discrepancy Loss: 0.0043\n",
      "Epoch [46/50], Class Loss: 0.0101, Discrepancy Loss: 0.0049\n",
      "Epoch [47/50], Class Loss: 0.0119, Discrepancy Loss: 0.0037\n",
      "Epoch [48/50], Class Loss: 0.0112, Discrepancy Loss: 0.0046\n",
      "Epoch [49/50], Class Loss: 0.0151, Discrepancy Loss: 0.0056\n",
      "Epoch [50/50], Class Loss: 0.0152, Discrepancy Loss: 0.0040\n",
      "Source Domain Performance - Accuracy: 99.46%, Precision: 99.46%, Recall: 99.48%, F1 Score: 99.47%\n",
      "Target Domain Performance - Accuracy: 100.00%, Precision: 100.00%, Recall: 100.00%, F1 Score: 100.00%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 3.1717, Discrepancy Loss: 0.1302\n",
      "Epoch [2/50], Class Loss: 1.4379, Discrepancy Loss: 0.1643\n",
      "Epoch [3/50], Class Loss: 1.1358, Discrepancy Loss: 0.1526\n",
      "Epoch [4/50], Class Loss: 0.8236, Discrepancy Loss: 0.0905\n",
      "Epoch [5/50], Class Loss: 0.1793, Discrepancy Loss: 0.0371\n",
      "Epoch [6/50], Class Loss: 0.1109, Discrepancy Loss: 0.0211\n",
      "Epoch [7/50], Class Loss: 0.1178, Discrepancy Loss: 0.0182\n",
      "Epoch [8/50], Class Loss: 0.0495, Discrepancy Loss: 0.0115\n",
      "Epoch [9/50], Class Loss: 0.1103, Discrepancy Loss: 0.0152\n",
      "Epoch [10/50], Class Loss: 0.0423, Discrepancy Loss: 0.0094\n",
      "Epoch [11/50], Class Loss: 0.0237, Discrepancy Loss: 0.0055\n",
      "Epoch [12/50], Class Loss: 0.0183, Discrepancy Loss: 0.0057\n",
      "Epoch [13/50], Class Loss: 0.0209, Discrepancy Loss: 0.0056\n",
      "Epoch [14/50], Class Loss: 0.0183, Discrepancy Loss: 0.0045\n",
      "Epoch [15/50], Class Loss: 0.0182, Discrepancy Loss: 0.0054\n",
      "Epoch [16/50], Class Loss: 0.0216, Discrepancy Loss: 0.0040\n",
      "Epoch [17/50], Class Loss: 0.0131, Discrepancy Loss: 0.0046\n",
      "Epoch [18/50], Class Loss: 0.0228, Discrepancy Loss: 0.0044\n",
      "Epoch [19/50], Class Loss: 0.0147, Discrepancy Loss: 0.0038\n",
      "Epoch [20/50], Class Loss: 0.0147, Discrepancy Loss: 0.0039\n",
      "Epoch [21/50], Class Loss: 0.0129, Discrepancy Loss: 0.0035\n",
      "Epoch [22/50], Class Loss: 0.0167, Discrepancy Loss: 0.0033\n",
      "Epoch [23/50], Class Loss: 0.0081, Discrepancy Loss: 0.0034\n",
      "Epoch [24/50], Class Loss: 0.0137, Discrepancy Loss: 0.0051\n",
      "Epoch [25/50], Class Loss: 0.0140, Discrepancy Loss: 0.0042\n",
      "Epoch [26/50], Class Loss: 0.0128, Discrepancy Loss: 0.0046\n",
      "Epoch [27/50], Class Loss: 0.0132, Discrepancy Loss: 0.0037\n",
      "Epoch [28/50], Class Loss: 0.0082, Discrepancy Loss: 0.0027\n",
      "Epoch [29/50], Class Loss: 0.0111, Discrepancy Loss: 0.0051\n",
      "Epoch [30/50], Class Loss: 0.0102, Discrepancy Loss: 0.0048\n",
      "Epoch [31/50], Class Loss: 0.0100, Discrepancy Loss: 0.0039\n",
      "Epoch [32/50], Class Loss: 0.0092, Discrepancy Loss: 0.0039\n",
      "Epoch [33/50], Class Loss: 0.0114, Discrepancy Loss: 0.0026\n",
      "Epoch [34/50], Class Loss: 0.0133, Discrepancy Loss: 0.0049\n",
      "Epoch [35/50], Class Loss: 0.0104, Discrepancy Loss: 0.0036\n",
      "Epoch [36/50], Class Loss: 0.0082, Discrepancy Loss: 0.0028\n",
      "Epoch [37/50], Class Loss: 0.0175, Discrepancy Loss: 0.0043\n",
      "Epoch [38/50], Class Loss: 0.0078, Discrepancy Loss: 0.0036\n",
      "Epoch [39/50], Class Loss: 0.0113, Discrepancy Loss: 0.0033\n",
      "Epoch [40/50], Class Loss: 0.0416, Discrepancy Loss: 0.0030\n",
      "Epoch [41/50], Class Loss: 0.0246, Discrepancy Loss: 0.0037\n",
      "Epoch [42/50], Class Loss: 0.0089, Discrepancy Loss: 0.0039\n",
      "Epoch [43/50], Class Loss: 0.0089, Discrepancy Loss: 0.0043\n",
      "Epoch [44/50], Class Loss: 0.0095, Discrepancy Loss: 0.0033\n",
      "Epoch [45/50], Class Loss: 0.0080, Discrepancy Loss: 0.0036\n",
      "Epoch [46/50], Class Loss: 0.0082, Discrepancy Loss: 0.0031\n",
      "Epoch [47/50], Class Loss: 0.0132, Discrepancy Loss: 0.0042\n",
      "Epoch [48/50], Class Loss: 0.0105, Discrepancy Loss: 0.0038\n",
      "Epoch [49/50], Class Loss: 0.0132, Discrepancy Loss: 0.0038\n",
      "Epoch [50/50], Class Loss: 0.0106, Discrepancy Loss: 0.0030\n",
      "Source Domain Performance - Accuracy: 99.58%, Precision: 99.58%, Recall: 99.59%, F1 Score: 99.59%\n",
      "Target Domain Performance - Accuracy: 100.00%, Precision: 100.00%, Recall: 100.00%, F1 Score: 100.00%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 3.2890, Discrepancy Loss: 0.1173\n",
      "Epoch [2/50], Class Loss: 1.4476, Discrepancy Loss: 0.1573\n",
      "Epoch [3/50], Class Loss: 1.3400, Discrepancy Loss: 0.1566\n",
      "Epoch [4/50], Class Loss: 0.9576, Discrepancy Loss: 0.1288\n",
      "Epoch [5/50], Class Loss: 0.2451, Discrepancy Loss: 0.0436\n",
      "Epoch [6/50], Class Loss: 0.1342, Discrepancy Loss: 0.0341\n",
      "Epoch [7/50], Class Loss: 0.1131, Discrepancy Loss: 0.0209\n",
      "Epoch [8/50], Class Loss: 0.1058, Discrepancy Loss: 0.0196\n",
      "Epoch [9/50], Class Loss: 0.0852, Discrepancy Loss: 0.0154\n",
      "Epoch [10/50], Class Loss: 0.0721, Discrepancy Loss: 0.0131\n",
      "Epoch [11/50], Class Loss: 0.0431, Discrepancy Loss: 0.0090\n",
      "Epoch [12/50], Class Loss: 0.0333, Discrepancy Loss: 0.0084\n",
      "Epoch [13/50], Class Loss: 0.0354, Discrepancy Loss: 0.0081\n",
      "Epoch [14/50], Class Loss: 0.0192, Discrepancy Loss: 0.0088\n",
      "Epoch [15/50], Class Loss: 0.0289, Discrepancy Loss: 0.0068\n",
      "Epoch [16/50], Class Loss: 0.0337, Discrepancy Loss: 0.0089\n",
      "Epoch [17/50], Class Loss: 0.0219, Discrepancy Loss: 0.0067\n",
      "Epoch [18/50], Class Loss: 0.0361, Discrepancy Loss: 0.0060\n",
      "Epoch [19/50], Class Loss: 0.0321, Discrepancy Loss: 0.0062\n",
      "Epoch [20/50], Class Loss: 0.0193, Discrepancy Loss: 0.0049\n",
      "Epoch [21/50], Class Loss: 0.0190, Discrepancy Loss: 0.0050\n",
      "Epoch [22/50], Class Loss: 0.0143, Discrepancy Loss: 0.0052\n",
      "Epoch [23/50], Class Loss: 0.0203, Discrepancy Loss: 0.0048\n",
      "Epoch [24/50], Class Loss: 0.0150, Discrepancy Loss: 0.0045\n",
      "Epoch [25/50], Class Loss: 0.0103, Discrepancy Loss: 0.0056\n",
      "Epoch [26/50], Class Loss: 0.0120, Discrepancy Loss: 0.0049\n",
      "Epoch [27/50], Class Loss: 0.0244, Discrepancy Loss: 0.0052\n",
      "Epoch [28/50], Class Loss: 0.0159, Discrepancy Loss: 0.0040\n",
      "Epoch [29/50], Class Loss: 0.0162, Discrepancy Loss: 0.0050\n",
      "Epoch [30/50], Class Loss: 0.0217, Discrepancy Loss: 0.0050\n",
      "Epoch [31/50], Class Loss: 0.0130, Discrepancy Loss: 0.0039\n",
      "Epoch [32/50], Class Loss: 0.0180, Discrepancy Loss: 0.0039\n",
      "Epoch [33/50], Class Loss: 0.0170, Discrepancy Loss: 0.0052\n",
      "Epoch [34/50], Class Loss: 0.0120, Discrepancy Loss: 0.0057\n",
      "Epoch [35/50], Class Loss: 0.0194, Discrepancy Loss: 0.0043\n",
      "Epoch [36/50], Class Loss: 0.0226, Discrepancy Loss: 0.0032\n",
      "Epoch [37/50], Class Loss: 0.0230, Discrepancy Loss: 0.0057\n",
      "Epoch [38/50], Class Loss: 0.0126, Discrepancy Loss: 0.0058\n",
      "Epoch [39/50], Class Loss: 0.0136, Discrepancy Loss: 0.0045\n",
      "Epoch [40/50], Class Loss: 0.0225, Discrepancy Loss: 0.0056\n",
      "Epoch [41/50], Class Loss: 0.0135, Discrepancy Loss: 0.0049\n",
      "Epoch [42/50], Class Loss: 0.0272, Discrepancy Loss: 0.0048\n",
      "Epoch [43/50], Class Loss: 0.0200, Discrepancy Loss: 0.0041\n",
      "Epoch [44/50], Class Loss: 0.0145, Discrepancy Loss: 0.0044\n",
      "Epoch [45/50], Class Loss: 0.0134, Discrepancy Loss: 0.0044\n",
      "Epoch [46/50], Class Loss: 0.0211, Discrepancy Loss: 0.0037\n",
      "Epoch [47/50], Class Loss: 0.0185, Discrepancy Loss: 0.0047\n",
      "Epoch [48/50], Class Loss: 0.0118, Discrepancy Loss: 0.0042\n",
      "Epoch [49/50], Class Loss: 0.0147, Discrepancy Loss: 0.0040\n",
      "Epoch [50/50], Class Loss: 0.0138, Discrepancy Loss: 0.0060\n",
      "Source Domain Performance - Accuracy: 99.10%, Precision: 99.10%, Recall: 99.14%, F1 Score: 99.12%\n",
      "Target Domain Performance - Accuracy: 100.00%, Precision: 100.00%, Recall: 100.00%, F1 Score: 100.00%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 3.5967, Discrepancy Loss: 0.1188\n",
      "Epoch [2/50], Class Loss: 1.5240, Discrepancy Loss: 0.1554\n",
      "Epoch [3/50], Class Loss: 1.2868, Discrepancy Loss: 0.1566\n",
      "Epoch [4/50], Class Loss: 1.2464, Discrepancy Loss: 0.1436\n",
      "Epoch [5/50], Class Loss: 1.1522, Discrepancy Loss: 0.1457\n",
      "Epoch [6/50], Class Loss: 1.0975, Discrepancy Loss: 0.1367\n",
      "Epoch [7/50], Class Loss: 1.0696, Discrepancy Loss: 0.1416\n",
      "Epoch [8/50], Class Loss: 1.0164, Discrepancy Loss: 0.1399\n",
      "Epoch [9/50], Class Loss: 0.7221, Discrepancy Loss: 0.0977\n",
      "Epoch [10/50], Class Loss: 0.3955, Discrepancy Loss: 0.0629\n",
      "Epoch [11/50], Class Loss: 0.1343, Discrepancy Loss: 0.0242\n",
      "Epoch [12/50], Class Loss: 0.1288, Discrepancy Loss: 0.0236\n",
      "Epoch [13/50], Class Loss: 0.1023, Discrepancy Loss: 0.0200\n",
      "Epoch [14/50], Class Loss: 0.0778, Discrepancy Loss: 0.0172\n",
      "Epoch [15/50], Class Loss: 0.0651, Discrepancy Loss: 0.0142\n",
      "Epoch [16/50], Class Loss: 0.0667, Discrepancy Loss: 0.0133\n",
      "Epoch [17/50], Class Loss: 0.0548, Discrepancy Loss: 0.0111\n",
      "Epoch [18/50], Class Loss: 0.0512, Discrepancy Loss: 0.0120\n",
      "Epoch [19/50], Class Loss: 0.0454, Discrepancy Loss: 0.0118\n",
      "Epoch [20/50], Class Loss: 0.0506, Discrepancy Loss: 0.0112\n",
      "Epoch [21/50], Class Loss: 0.0556, Discrepancy Loss: 0.0074\n",
      "Epoch [22/50], Class Loss: 0.0315, Discrepancy Loss: 0.0084\n",
      "Epoch [23/50], Class Loss: 0.0265, Discrepancy Loss: 0.0093\n",
      "Epoch [24/50], Class Loss: 0.0259, Discrepancy Loss: 0.0081\n",
      "Epoch [25/50], Class Loss: 0.0318, Discrepancy Loss: 0.0068\n",
      "Epoch [26/50], Class Loss: 0.0396, Discrepancy Loss: 0.0080\n",
      "Epoch [27/50], Class Loss: 0.0369, Discrepancy Loss: 0.0092\n",
      "Epoch [28/50], Class Loss: 0.0487, Discrepancy Loss: 0.0085\n",
      "Epoch [29/50], Class Loss: 0.0279, Discrepancy Loss: 0.0086\n",
      "Epoch [30/50], Class Loss: 0.0262, Discrepancy Loss: 0.0078\n",
      "Epoch [31/50], Class Loss: 0.0284, Discrepancy Loss: 0.0094\n",
      "Epoch [32/50], Class Loss: 0.0292, Discrepancy Loss: 0.0072\n",
      "Epoch [33/50], Class Loss: 0.0299, Discrepancy Loss: 0.0088\n",
      "Epoch [34/50], Class Loss: 0.0234, Discrepancy Loss: 0.0084\n",
      "Epoch [35/50], Class Loss: 0.0305, Discrepancy Loss: 0.0072\n",
      "Epoch [36/50], Class Loss: 0.0323, Discrepancy Loss: 0.0071\n",
      "Epoch [37/50], Class Loss: 0.0506, Discrepancy Loss: 0.0094\n",
      "Epoch [38/50], Class Loss: 0.0255, Discrepancy Loss: 0.0075\n",
      "Epoch [39/50], Class Loss: 0.0263, Discrepancy Loss: 0.0064\n",
      "Epoch [40/50], Class Loss: 0.0210, Discrepancy Loss: 0.0076\n",
      "Epoch [41/50], Class Loss: 0.0242, Discrepancy Loss: 0.0066\n",
      "Epoch [42/50], Class Loss: 0.0256, Discrepancy Loss: 0.0080\n",
      "Epoch [43/50], Class Loss: 0.0261, Discrepancy Loss: 0.0067\n",
      "Epoch [44/50], Class Loss: 0.0235, Discrepancy Loss: 0.0084\n",
      "Epoch [45/50], Class Loss: 0.0350, Discrepancy Loss: 0.0077\n",
      "Epoch [46/50], Class Loss: 0.0257, Discrepancy Loss: 0.0081\n",
      "Epoch [47/50], Class Loss: 0.0289, Discrepancy Loss: 0.0077\n",
      "Epoch [48/50], Class Loss: 0.0292, Discrepancy Loss: 0.0079\n",
      "Epoch [49/50], Class Loss: 0.0286, Discrepancy Loss: 0.0076\n",
      "Epoch [50/50], Class Loss: 0.0283, Discrepancy Loss: 0.0074\n",
      "Source Domain Performance - Accuracy: 99.28%, Precision: 99.27%, Recall: 99.32%, F1 Score: 99.29%\n",
      "Target Domain Performance - Accuracy: 99.88%, Precision: 99.88%, Recall: 99.87%, F1 Score: 99.88%\n",
      "\n",
      "Source performance: 99.40% 99.40% 99.42% 99.41%\n",
      "Target performance: 99.96% 99.96% 99.96% 99.96%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 100.00%\n",
      "qpsk: 99.95%\n",
      "16qam: 99.90%\n",
      "8apsk: 100.00%\n",
      "\n",
      "Run 1/5\n",
      "Epoch [1/50], Class Loss: 2.0794, Discrepancy Loss: 0.0702\n",
      "Validation Loss: 1.7346\n",
      "Epoch [2/50], Class Loss: 1.4892, Discrepancy Loss: 0.0443\n",
      "Validation Loss: 1.5198\n",
      "Epoch [3/50], Class Loss: 0.8841, Discrepancy Loss: 0.0436\n",
      "Validation Loss: 0.2620\n",
      "Epoch [4/50], Class Loss: 0.2028, Discrepancy Loss: 0.0090\n",
      "Validation Loss: 0.3622\n",
      "Epoch [5/50], Class Loss: 0.1725, Discrepancy Loss: 0.0065\n",
      "Validation Loss: 0.1161\n",
      "Epoch [6/50], Class Loss: 0.1535, Discrepancy Loss: 0.0059\n",
      "Validation Loss: 0.3093\n",
      "Epoch [7/50], Class Loss: 0.1217, Discrepancy Loss: 0.0042\n",
      "Validation Loss: 0.3522\n",
      "Epoch [8/50], Class Loss: 0.1939, Discrepancy Loss: 0.0062\n",
      "Validation Loss: 0.1610\n",
      "Epoch [9/50], Class Loss: 0.1330, Discrepancy Loss: 0.0032\n",
      "Validation Loss: 0.9004\n",
      "Epoch [10/50], Class Loss: 0.1032, Discrepancy Loss: 0.0040\n",
      "Validation Loss: 0.3119\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.18%, Precision: 97.27%, Recall: 97.26%, F1 Score: 97.23%\n",
      "Target Domain Performance - Accuracy: 97.96%, Precision: 97.99%, Recall: 97.88%, F1 Score: 97.91%\n",
      "\n",
      "Run 2/5\n",
      "Epoch [1/50], Class Loss: 2.1015, Discrepancy Loss: 0.0678\n",
      "Validation Loss: 1.6039\n",
      "Epoch [2/50], Class Loss: 1.6222, Discrepancy Loss: 0.0424\n",
      "Validation Loss: 1.4959\n",
      "Epoch [3/50], Class Loss: 1.2059, Discrepancy Loss: 0.0414\n",
      "Validation Loss: 0.2533\n",
      "Epoch [4/50], Class Loss: 0.3022, Discrepancy Loss: 0.0123\n",
      "Validation Loss: 0.2110\n",
      "Epoch [5/50], Class Loss: 0.1426, Discrepancy Loss: 0.0066\n",
      "Validation Loss: 0.1290\n",
      "Epoch [6/50], Class Loss: 0.2038, Discrepancy Loss: 0.0094\n",
      "Validation Loss: 0.5336\n",
      "Epoch [7/50], Class Loss: 0.1437, Discrepancy Loss: 0.0062\n",
      "Validation Loss: 0.0561\n",
      "Epoch [8/50], Class Loss: 0.2121, Discrepancy Loss: 0.0074\n",
      "Validation Loss: 0.1045\n",
      "Epoch [9/50], Class Loss: 0.1733, Discrepancy Loss: 0.0097\n",
      "Validation Loss: 0.2132\n",
      "Epoch [10/50], Class Loss: 0.1414, Discrepancy Loss: 0.0107\n",
      "Validation Loss: 0.1344\n",
      "Epoch [11/50], Class Loss: 0.0129, Discrepancy Loss: 0.0022\n",
      "Validation Loss: 0.0718\n",
      "Epoch [12/50], Class Loss: 0.0082, Discrepancy Loss: 0.0010\n",
      "Validation Loss: 0.0631\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.40%, Precision: 99.40%, Recall: 99.43%, F1 Score: 99.41%\n",
      "Target Domain Performance - Accuracy: 99.82%, Precision: 99.82%, Recall: 99.81%, F1 Score: 99.82%\n",
      "\n",
      "Run 3/5\n",
      "Epoch [1/50], Class Loss: 2.0364, Discrepancy Loss: 0.0670\n",
      "Validation Loss: 1.5701\n",
      "Epoch [2/50], Class Loss: 1.4401, Discrepancy Loss: 0.0261\n",
      "Validation Loss: 1.1604\n",
      "Epoch [3/50], Class Loss: 0.4154, Discrepancy Loss: 0.0250\n",
      "Validation Loss: 1.4045\n",
      "Epoch [4/50], Class Loss: 0.3048, Discrepancy Loss: 0.0091\n",
      "Validation Loss: 0.6589\n",
      "Epoch [5/50], Class Loss: 0.1747, Discrepancy Loss: 0.0080\n",
      "Validation Loss: 0.3676\n",
      "Epoch [6/50], Class Loss: 0.1714, Discrepancy Loss: 0.0064\n",
      "Validation Loss: 0.0721\n",
      "Epoch [7/50], Class Loss: 0.1480, Discrepancy Loss: 0.0052\n",
      "Validation Loss: 0.6129\n",
      "Epoch [8/50], Class Loss: 0.1495, Discrepancy Loss: 0.0056\n",
      "Validation Loss: 0.1723\n",
      "Epoch [9/50], Class Loss: 0.0979, Discrepancy Loss: 0.0080\n",
      "Validation Loss: 0.3065\n",
      "Epoch [10/50], Class Loss: 0.0747, Discrepancy Loss: 0.0042\n",
      "Validation Loss: 0.0777\n",
      "Epoch [11/50], Class Loss: 0.0164, Discrepancy Loss: 0.0016\n",
      "Validation Loss: 0.0671\n",
      "Epoch [12/50], Class Loss: 0.0079, Discrepancy Loss: 0.0004\n",
      "Validation Loss: 0.0433\n",
      "Epoch [13/50], Class Loss: 0.0085, Discrepancy Loss: 0.0003\n",
      "Validation Loss: 0.0853\n",
      "Epoch [14/50], Class Loss: 0.0103, Discrepancy Loss: 0.0005\n",
      "Validation Loss: 0.0502\n",
      "Epoch [15/50], Class Loss: 0.0048, Discrepancy Loss: 0.0003\n",
      "Validation Loss: 0.0618\n",
      "Epoch [16/50], Class Loss: 0.0041, Discrepancy Loss: 0.0002\n",
      "Validation Loss: 0.0551\n",
      "Epoch [17/50], Class Loss: 0.0041, Discrepancy Loss: 0.0003\n",
      "Validation Loss: 0.0690\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.40%, Precision: 99.41%, Recall: 99.42%, F1 Score: 99.41%\n",
      "Target Domain Performance - Accuracy: 100.00%, Precision: 100.00%, Recall: 100.00%, F1 Score: 100.00%\n",
      "\n",
      "Run 4/5\n",
      "Epoch [1/50], Class Loss: 2.0146, Discrepancy Loss: 0.0793\n",
      "Validation Loss: 1.4839\n",
      "Epoch [2/50], Class Loss: 1.4981, Discrepancy Loss: 0.0569\n",
      "Validation Loss: 1.3447\n",
      "Epoch [3/50], Class Loss: 0.6371, Discrepancy Loss: 0.0313\n",
      "Validation Loss: 0.1396\n",
      "Epoch [4/50], Class Loss: 0.2120, Discrepancy Loss: 0.0090\n",
      "Validation Loss: 0.1443\n",
      "Epoch [5/50], Class Loss: 0.1522, Discrepancy Loss: 0.0056\n",
      "Validation Loss: 0.0616\n",
      "Epoch [6/50], Class Loss: 0.0655, Discrepancy Loss: 0.0037\n",
      "Validation Loss: 0.0647\n",
      "Epoch [7/50], Class Loss: 0.2144, Discrepancy Loss: 0.0066\n",
      "Validation Loss: 3.8193\n",
      "Epoch [8/50], Class Loss: 0.2183, Discrepancy Loss: 0.0069\n",
      "Validation Loss: 0.1931\n",
      "Epoch [9/50], Class Loss: 0.0846, Discrepancy Loss: 0.0056\n",
      "Validation Loss: 0.3349\n",
      "Epoch [10/50], Class Loss: 0.2882, Discrepancy Loss: 0.0067\n",
      "Validation Loss: 0.0826\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.10%, Precision: 99.13%, Recall: 99.11%, F1 Score: 99.12%\n",
      "Target Domain Performance - Accuracy: 99.46%, Precision: 99.45%, Recall: 99.45%, F1 Score: 99.45%\n",
      "\n",
      "Run 5/5\n",
      "Epoch [1/50], Class Loss: 2.0319, Discrepancy Loss: 0.0711\n",
      "Validation Loss: 1.7374\n",
      "Epoch [2/50], Class Loss: 1.5834, Discrepancy Loss: 0.0335\n",
      "Validation Loss: 1.5380\n",
      "Epoch [3/50], Class Loss: 0.9524, Discrepancy Loss: 0.0345\n",
      "Validation Loss: 0.2773\n",
      "Epoch [4/50], Class Loss: 0.7268, Discrepancy Loss: 0.0150\n",
      "Validation Loss: 0.2101\n",
      "Epoch [5/50], Class Loss: 0.1434, Discrepancy Loss: 0.0058\n",
      "Validation Loss: 0.1865\n",
      "Epoch [6/50], Class Loss: 0.1089, Discrepancy Loss: 0.0052\n",
      "Validation Loss: 0.1397\n",
      "Epoch [7/50], Class Loss: 0.2590, Discrepancy Loss: 0.0100\n",
      "Validation Loss: 0.1093\n",
      "Epoch [8/50], Class Loss: 0.1993, Discrepancy Loss: 0.0085\n",
      "Validation Loss: 0.1877\n",
      "Epoch [9/50], Class Loss: 0.1178, Discrepancy Loss: 0.0050\n",
      "Validation Loss: 0.3399\n",
      "Epoch [10/50], Class Loss: 0.1378, Discrepancy Loss: 0.0056\n",
      "Validation Loss: 0.3461\n",
      "Epoch [11/50], Class Loss: 0.0284, Discrepancy Loss: 0.0016\n",
      "Validation Loss: 0.0681\n",
      "Epoch [12/50], Class Loss: 0.0076, Discrepancy Loss: 0.0006\n",
      "Validation Loss: 0.0500\n",
      "Epoch [13/50], Class Loss: 0.0052, Discrepancy Loss: 0.0004\n",
      "Validation Loss: 0.0498\n",
      "Epoch [14/50], Class Loss: 0.0058, Discrepancy Loss: 0.0004\n",
      "Validation Loss: 0.0828\n",
      "Epoch [15/50], Class Loss: 0.0046, Discrepancy Loss: 0.0003\n",
      "Validation Loss: 0.0534\n",
      "Epoch [16/50], Class Loss: 0.0045, Discrepancy Loss: 0.0003\n",
      "Validation Loss: 0.0505\n",
      "Epoch [17/50], Class Loss: 0.0078, Discrepancy Loss: 0.0006\n",
      "Validation Loss: 0.0517\n",
      "Epoch [18/50], Class Loss: 0.0061, Discrepancy Loss: 0.0004\n",
      "Validation Loss: 0.0549\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 99.52%, Precision: 99.54%, Recall: 99.52%, F1 Score: 99.53%\n",
      "Target Domain Performance - Accuracy: 100.00%, Precision: 100.00%, Recall: 100.00%, F1 Score: 100.00%\n",
      "\n",
      "Source performance: 98.92% 98.95% 98.95% 98.94%\n",
      "Target performance: 99.45% 99.45% 99.43% 99.44%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 100.00%\n",
      "qpsk: 99.91%\n",
      "16qam: 98.32%\n",
      "8apsk: 99.48%\n"
     ]
    }
   ],
   "source": [
    "# Load testbed data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "file_path = \"/home/ash/ic3/testbed_da/data\"\n",
    "\n",
    "# Classes\n",
    "class_subset = [\"bpsk\", \"qpsk\", \"16qam\", \"8apsk\"]\n",
    "\n",
    "# Split source, target\n",
    "# try selecting some of the mods, not all\n",
    "X = np.load(file_path + \"/ota_X.npy\")\n",
    "Y = np.load(file_path + \"/ota_Y.npy\")\n",
    "\n",
    "sou_snr = 30\n",
    "tar_snr = 10\n",
    "\n",
    "t_base_acc = []\n",
    "t_dann_acc = []\n",
    "t_star_acc = []\n",
    "t_mcd_acc = []\n",
    "t_coral_acc = []\n",
    "t_jan_acc = []\n",
    "\n",
    "s_base_acc = []\n",
    "s_dann_acc = []\n",
    "s_star_acc = []\n",
    "s_mcd_acc = []\n",
    "s_coral_acc = []\n",
    "s_jan_acc = []\n",
    "\n",
    "n_runs = 5\n",
    "lr = 0.001\n",
    "\n",
    "for i in range(6):    \n",
    "    source_mask = (Y[:, 1] == sou_snr)\n",
    "    target_mask = (Y[:, 1] == tar_snr)\n",
    "    \n",
    "    X_s = X[source_mask]\n",
    "    Y_s = Y[source_mask]\n",
    "    Y_s = Y_s[:,0]\n",
    "    \n",
    "    X_t = X[target_mask]\n",
    "    Y_t = Y[target_mask]\n",
    "    Y_t = Y_t[:,0]\n",
    "\n",
    "    \n",
    "    # Dataloaders\n",
    "    S_train_loader, S_val_loader = funcs.create_loader(X_s, Y_s, permute=False)\n",
    "    T_train_loader, T_val_loader = funcs.create_loader(X_t, Y_t, permute=False)\n",
    "\n",
    "    s_base, t_base = base.Base(model_cls=CLDNN, device=device, S_train_loader=S_train_loader, \n",
    "                    S_val_loader=S_val_loader, T_val_loader=T_val_loader, class_subset=class_subset, \n",
    "                    n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_base_acc.append(s_base)\n",
    "    t_base_acc.append(t_base)\n",
    "    \n",
    "    s_dan, t_dan = dann.DAN(dann.DANN, FA=CLDNN_FA, LP=CLDNN_LP, DC=CLDNN_DC,\n",
    "                      device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,\n",
    "                      T_train_loader=T_train_loader, T_val_loader=T_val_loader,\n",
    "                      class_subset=class_subset, n_classes=len(class_subset), lr=lr,\n",
    "                      n_epochs=50, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_dann_acc.append(s_dan)\n",
    "    t_dann_acc.append(t_dan)\n",
    "    \n",
    "    s_star, t_star = star.Star(G=STAR_G, C=STAR_C, device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,  \n",
    "               T_train_loader=T_train_loader, T_val_loader=T_val_loader, class_subset=class_subset,\n",
    "               n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs, patience=5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_star_acc.append(s_star)\n",
    "    t_star_acc.append(t_star)\n",
    "    \n",
    "    s_mcd, t_mcd = mcd.Mcd(G=MCD_G, C=MCD_C, device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,  \n",
    "               T_train_loader=T_train_loader, T_val_loader=T_val_loader, class_subset=class_subset,\n",
    "               n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs, patience=5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_mcd_acc.append(s_mcd)\n",
    "    t_mcd_acc.append(t_mcd)\n",
    "\n",
    "    \"\"\"\n",
    "    s_coral, t_coral = coral.Coral(G=coral.CLDNN_G, C=coral.CLDNN_C, device=device, S_train_loader=S_train_loader,\n",
    "                           S_val_loader=S_val_loader, T_train_loader=T_train_loader, T_val_loader=T_val_loader,\n",
    "                           class_subset=class_subset, n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs,\n",
    "                           patience=5, lambda_coral=0.5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_coral_acc.append(s_coral)\n",
    "    t_coral_acc.append(t_coral)\n",
    "\n",
    "    s_jan, t_jan = jan.Jan(num_classes=len(class_subset), device=device, S_train_loader=S_train_loader,\n",
    "                     T_train_loader=T_train_loader, S_val_loader=S_val_loader, T_val_loader=T_val_loader,\n",
    "                     n_epochs=50, lr=lr, lambda_jmmd=0.1, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_jan_acc.append(s_jan)\n",
    "    t_jan_acc.append(t_jan)\n",
    "    \"\"\"\n",
    "    \n",
    "    tar_snr += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a75f4d8-b552-4e01-8024-24f80cc6eaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x = np.arange(1, 5)\n",
    "print(len(s_base_acc))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, s_base_acc, marker='o', linestyle='-', label='Base')\n",
    "plt.plot(x, s_dann_acc, marker='s', linestyle='--', label='Dann')\n",
    "plt.plot(x, s_star_acc, marker='^', linestyle='--', label='Star')\n",
    "plt.plot(x, s_mcd_acc, marker='D', linestyle='--', label='MCD')\n",
    "#plt.plot(x, s_coral_acc, marker='v', linestyle='--', label='CORAL')\n",
    "#plt.plot(x, s_jan_acc, marker='x', linestyle='--', label='JANN')\n",
    "\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Acc (%)')\n",
    "plt.title('Source performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "x = np.arange(1, 7)\n",
    "print(len(x))\n",
    "print(len(t_base_acc))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, t_base_acc, marker='o', linestyle='-', label='Base')\n",
    "plt.plot(x, t_dann_acc, marker='s', linestyle='--', label='Dann')\n",
    "plt.plot(x, t_star_acc, marker='^', linestyle='--', label='Star')\n",
    "plt.plot(x, t_mcd_acc, marker='D', linestyle='--', label='MCD')\n",
    "#plt.plot(x, t_coral_acc, marker='v', linestyle='--', label='CORAL')\n",
    "#plt.plot(x, t_jan_acc, marker='x', linestyle='--', label='JANN')\n",
    "\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Acc (%)')\n",
    "plt.title('Target performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624700c-1365-4593-810c-4abec1a6d6b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load testbed data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "file_path = \"/home/ash/ic3/testbed_da/data\"\n",
    "\n",
    "# Classes\n",
    "class_subset = [\"bpsk\", \"qpsk\", \"16qam\", \"8apsk\"]\n",
    "\n",
    "# Split source, target\n",
    "# try selecting some of the mods, not all\n",
    "X = np.load(file_path + \"/sim_X.npy\")\n",
    "Y = np.load(file_path + \"/sim_Y.npy\")\n",
    "\n",
    "sou_snr = 22\n",
    "tar_snr = 10\n",
    "\n",
    "t_base_acc = []\n",
    "t_dann_acc = []\n",
    "t_star_acc = []\n",
    "t_mcd_acc = []\n",
    "t_coral_acc = []\n",
    "t_jan_acc = []\n",
    "\n",
    "s_base_acc = []\n",
    "s_dann_acc = []\n",
    "s_star_acc = []\n",
    "s_mcd_acc = []\n",
    "s_coral_acc = []\n",
    "s_jan_acc = []\n",
    "\n",
    "n_runs = 10\n",
    "lr = 0.001\n",
    "n_snr = 4\n",
    "offset_snr = 4\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "for i in range(n_snr-1):    \n",
    "    source_mask = (Y[:, 1] == sou_snr)\n",
    "    target_mask = (Y[:, 1] == tar_snr)\n",
    "    \n",
    "    X_s = X[source_mask]\n",
    "    Y_s = Y[source_mask]\n",
    "    Y_s = Y_s[:,0]\n",
    "    \n",
    "    X_t = X[target_mask]\n",
    "    Y_t = Y[target_mask]\n",
    "    Y_t = Y_t[:,0]\n",
    "\n",
    "    \n",
    "    # Dataloaders\n",
    "    S_train_loader, S_val_loader = funcs.create_loader(X_s, Y_s, permute=False)\n",
    "    T_train_loader, T_val_loader = funcs.create_loader(X_t, Y_t, permute=False)\n",
    "\n",
    "    s_mcd, t_mcd = mcd.Mcd(G=MCD_G, C=MCD_C, device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,  \n",
    "               T_train_loader=T_train_loader, T_val_loader=T_val_loader, class_subset=class_subset,\n",
    "               n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs, patience=5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_mcd_acc.append(s_mcd)\n",
    "    t_mcd_acc.append(t_mcd)\n",
    "\n",
    "    s_base, t_base = base.Base(model_cls=CLDNN, device=device, S_train_loader=S_train_loader, \n",
    "                    S_val_loader=S_val_loader, T_val_loader=T_val_loader, class_subset=class_subset, \n",
    "                    n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_base_acc.append(s_base)\n",
    "    t_base_acc.append(t_base)\n",
    "    \n",
    "    s_dan, t_dan = dann.DAN(dann.DANN, FA=CLDNN_FA, LP=CLDNN_LP, DC=CLDNN_DC,\n",
    "                      device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,\n",
    "                      T_train_loader=T_train_loader, T_val_loader=T_val_loader,\n",
    "                      class_subset=class_subset, n_classes=len(class_subset), lr=lr,\n",
    "                      n_epochs=50, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_dann_acc.append(s_dan)\n",
    "    t_dann_acc.append(t_dan)\n",
    "    \n",
    "    s_star, t_star = star.Star(G=STAR_G, C=STAR_C, device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,  \n",
    "               T_train_loader=T_train_loader, T_val_loader=T_val_loader, class_subset=class_subset,\n",
    "               n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs, patience=5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_star_acc.append(s_star)\n",
    "    t_star_acc.append(t_star)\n",
    "\n",
    "    tar_snr += offset_snr\n",
    "\n",
    "x = np.arange(1, 5)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, s_base_acc, marker='o', linestyle='-', label='Base')\n",
    "plt.plot(x, s_dann_acc, marker='s', linestyle='--', label='Dann')\n",
    "plt.plot(x, s_star_acc, marker='^', linestyle='--', label='Star')\n",
    "plt.plot(x, s_mcd_acc, marker='D', linestyle='--', label='MCD')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Acc (%)')\n",
    "plt.title('Target performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "for i in range(n_snr):    \n",
    "    source_mask = (Y[:, 1] == sou_snr)\n",
    "    target_mask = (Y[:, 1] == tar_snr)\n",
    "    \n",
    "    X_s = X[source_mask]\n",
    "    Y_s = Y[source_mask]\n",
    "    Y_s = Y_s[:,0]\n",
    "    \n",
    "    X_t = X[target_mask]\n",
    "    Y_t = Y[target_mask]\n",
    "    Y_t = Y_t[:,0]\n",
    "\n",
    "    \n",
    "    # Dataloaders\n",
    "    S_train_loader, S_val_loader = funcs.create_loader(X_s, Y_s, permute=False)\n",
    "    T_train_loader, T_val_loader = funcs.create_loader(X_t, Y_t, permute=False)\n",
    "\n",
    "    s_base, t_base = base.Base(model_cls=CLDNN, device=device, S_train_loader=S_train_loader, \n",
    "                    S_val_loader=S_val_loader, T_val_loader=T_val_loader, class_subset=class_subset, \n",
    "                    n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_base_acc.append(s_base)\n",
    "    t_base_acc.append(t_base)\n",
    "    \n",
    "    s_dan, t_dan = dann.DAN(dann.DANN, FA=dann.CLDNN_FA, LP=dann.CLDNN_LP, DC=dann.CLDNN_DC,\n",
    "                      device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,\n",
    "                      T_train_loader=T_train_loader, T_val_loader=T_val_loader,\n",
    "                      class_subset=class_subset, n_classes=len(class_subset), lr=lr,\n",
    "                      n_epochs=25, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_dann_acc.append(s_dan)\n",
    "    t_dann_acc.append(t_dan)\n",
    "    \n",
    "    s_star, t_star = star.Star(G=star.CLDNN_G, C=star.CLDNN_C, device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,  \n",
    "               T_train_loader=T_train_loader, T_val_loader=T_val_loader, class_subset=class_subset,\n",
    "               n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs, patience=5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_star_acc.append(s_star)\n",
    "    t_star_acc.append(t_star)\n",
    "    \n",
    "    s_mcd, t_mcd = mcd.Mcd(G=mcd.CLDNN_G, C=mcd.CLDNN_C, device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,  \n",
    "               T_train_loader=T_train_loader, T_val_loader=T_val_loader, class_subset=class_subset,\n",
    "               n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs, patience=5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_mcd_acc.append(s_mcd)\n",
    "    t_mcd_acc.append(t_mcd)\n",
    "    \n",
    "    s_coral, t_coral = coral.Coral(G=coral.CLDNN_G, C=coral.CLDNN_C, device=device, S_train_loader=S_train_loader,\n",
    "                           S_val_loader=S_val_loader, T_train_loader=T_train_loader, T_val_loader=T_val_loader,\n",
    "                           class_subset=class_subset, n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs,\n",
    "                           patience=5, lambda_coral=0.5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_coral_acc.append(s_coral)\n",
    "    t_coral_acc.append(t_coral)\n",
    "\n",
    "    s_jan, t_jan = jan.Jan(num_classes=len(class_subset), device=device, S_train_loader=S_train_loader,\n",
    "                     T_train_loader=T_train_loader, S_val_loader=S_val_loader, T_val_loader=T_val_loader,\n",
    "                     n_epochs=50, lr=lr, lambda_jmmd=0.1, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_jan_acc.append(s_jan)\n",
    "    t_jan_acc.append(t_jan)\n",
    "    \n",
    "    tar_snr += offset_snr\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352549d-28ec-4140-aa35-78f2bcffed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 4)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, t_base_acc, marker='o', linestyle='-', label='Base')\n",
    "plt.plot(x, t_dann_acc, marker='s', linestyle='--', label='Dann')\n",
    "plt.plot(x, t_star_acc, marker='^', linestyle='--', label='Star')\n",
    "plt.plot(x, t_mcd_acc, marker='D', linestyle='--', label='MCD')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Acc (%)')\n",
    "plt.title('Target performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04e643-cec3-48d4-bd5c-88fb4a4069ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 8)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, s_base_acc, marker='o', linestyle='-', label='Base')\n",
    "plt.plot(x, s_dann_acc, marker='s', linestyle='--', label='Dann')\n",
    "plt.plot(x, s_star_acc, marker='^', linestyle='--', label='Star')\n",
    "plt.plot(x, s_mcd_acc, marker='D', linestyle='--', label='MCD')\n",
    "plt.plot(x, s_coral_acc, marker='v', linestyle='--', label='CORAL')\n",
    "plt.plot(x, s_jan_acc, marker='x', linestyle='--', label='JANN')\n",
    "\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Acc (%)')\n",
    "plt.title('Source performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "x = np.arange(1, 8)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, t_base_acc, marker='o', linestyle='-', label='Base')\n",
    "plt.plot(x, t_dann_acc, marker='s', linestyle='--', label='Dann')\n",
    "plt.plot(x, t_star_acc, marker='^', linestyle='--', label='Star')\n",
    "plt.plot(x, t_mcd_acc, marker='D', linestyle='--', label='MCD')\n",
    "plt.plot(x, t_coral_acc, marker='v', linestyle='--', label='CORAL')\n",
    "plt.plot(x, t_jan_acc, marker='x', linestyle='--', label='JANN')\n",
    "\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Acc (%)')\n",
    "plt.title('Target performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
