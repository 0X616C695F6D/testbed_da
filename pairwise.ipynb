{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ecf190-98b8-4c74-ba16-c3047eb29e38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pairwise evaluation. Simulated vs. OTA datasets.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import funcs\n",
    "import jan\n",
    "import coral\n",
    "import star\n",
    "import mcd\n",
    "import dann\n",
    "import base\n",
    "import plots\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# Base\n",
    "class CLDNN(nn.Module):\n",
    "    def __init__(self, output_dim=4):\n",
    "        super(CLDNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=8, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # After conv1 and pooling: input length 4096 becomes 4089 then 2044 after pooling.\n",
    "        # So the flattened output from the LSTM will be 2044 * 64.\n",
    "        self.fc1 = nn.Linear(2044 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x has shape: (batch, 2, 4096)\n",
    "        x = self.conv1(x)      # -> (batch, 64, 4089)\n",
    "        x = self.pool(x)       # -> (batch, 64, 2044)\n",
    "        \n",
    "        # Permute to have sequence first: (batch, 2044, 64)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x, _ = self.lstm1(x)   # -> (batch, 2044, 64)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)   # -> (batch, 2044, 64)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Flatten: (batch, 2044*64)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "#%% DANN\n",
    "from torch.autograd import Function\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "def grad_reverse(x, alpha=1.0):\n",
    "    return ReverseLayerF.apply(x, alpha)\n",
    "class CLDNN_FA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLDNN_FA, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=8, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        return x\n",
    "\n",
    "class CLDNN_LP(nn.Module):\n",
    "    def __init__(self, output_dim=7):\n",
    "        super(CLDNN_LP, self).__init__()\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(2044 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CLDNN_DC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLDNN_DC, self).__init__()\n",
    "        self.fc1 = nn.Linear(2044 * 64, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        x = ReverseLayerF.apply(x, alpha)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# star\n",
    "class STAR_G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAR_G, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=8, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class STAR_C(nn.Module):\n",
    "    def __init__(self, output_dim, num_classifiers_train=2, num_classifiers_test=20, init='kaiming_u', use_init=False):\n",
    "        super(STAR_C, self).__init__()\n",
    "        self.num_classifiers_train = num_classifiers_train\n",
    "        self.num_classifiers_test = num_classifiers_test\n",
    "        self.init = init\n",
    "\n",
    "        function_init = {\n",
    "            'kaiming_u': nn.init.kaiming_uniform_,\n",
    "            'kaiming_n': nn.init.kaiming_normal_,\n",
    "            'xavier': nn.init.xavier_normal_\n",
    "        }\n",
    "\n",
    "        self.fc1 = nn.Linear(2044 * 64, 128)\n",
    "        self.bn1_fc = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.mu2 = nn.Parameter(torch.randn(output_dim, 128))\n",
    "        self.sigma2 = nn.Parameter(torch.zeros(output_dim, 128))\n",
    "\n",
    "        if use_init:\n",
    "            all_parameters = [self.mu2, self.sigma2]\n",
    "            for item in all_parameters:\n",
    "                function_init[self.init](item)\n",
    "\n",
    "        self.b2 = nn.Parameter(torch.zeros(output_dim))\n",
    "\n",
    "    def forward(self, x, only_mu=True):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn1_fc(x))\n",
    "\n",
    "        sigma2_pos = torch.sigmoid(self.sigma2)\n",
    "        fc2_distribution = torch.distributions.Normal(self.mu2, sigma2_pos)\n",
    "\n",
    "        if self.training:\n",
    "            classifiers = []\n",
    "            for _ in range(self.num_classifiers_train):\n",
    "                fc2_w = fc2_distribution.rsample()\n",
    "                classifiers.append([fc2_w, self.b2])\n",
    "\n",
    "            outputs = []\n",
    "            for classifier in classifiers:\n",
    "                out = F.linear(x, classifier[0], classifier[1])\n",
    "                outputs.append(out)\n",
    "\n",
    "            return outputs\n",
    "        else:\n",
    "            if only_mu:\n",
    "                out = F.linear(x, self.mu2, self.b2)\n",
    "                return [out]\n",
    "            else:\n",
    "                classifiers = []\n",
    "                for _ in range(self.num_classifiers_test):\n",
    "                    fc2_w = fc2_distribution.rsample()\n",
    "                    classifiers.append([fc2_w, self.b2])\n",
    "\n",
    "                outputs = []\n",
    "                for classifier in classifiers:\n",
    "                    out = F.linear(x, classifier[0], classifier[1])\n",
    "                    outputs.append(out)\n",
    "                return outputs\n",
    "\n",
    "\n",
    "#%% mcd\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.view_as(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.lambda_, None\n",
    "\n",
    "def grad_reverse(x, lambda_=1.0):\n",
    "    return GradReverse.apply(x, lambda_)\n",
    "\n",
    "class MCD_G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MCD_G, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=8, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "class MCD_C(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(MCD_C, self).__init__()\n",
    "        self.fc1 = nn.Linear(2044 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "    \n",
    "    def forward(self, x, reverse=False, lambda_=1.0):\n",
    "        if reverse:\n",
    "            x = grad_reverse(x, lambda_)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# coral\n",
    "class CORAL_G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CORAL_G, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=2, out_channels=64,\n",
    "            kernel_size=8, stride=1, padding=0\n",
    "        )\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=64, hidden_size=64,\n",
    "            num_layers=1, batch_first=True\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=64, hidden_size=64,\n",
    "            num_layers=1, batch_first=True\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc_bottleneck = nn.Linear(2044 * 64, 512)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  \n",
    "        x = self.pool(x)   \n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x, _ = self.lstm1(x)   \n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)    \n",
    "        x = self.dropout2(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        x = self.fc_bottleneck(x)\n",
    "        return x  \n",
    "\n",
    "\n",
    "class CORAL_C(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(CORAL_C, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23a9e67-c724-4289-b356-94ed978f9d95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR level: 10\n",
      "SNR level: 10\n",
      "CORAL\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 1.2543, CORAL Loss: 0.0271\n",
      "Validation Loss: 0.7354\n",
      "Epoch [2/50], Class Loss: 0.6462, CORAL Loss: 0.0426\n",
      "Validation Loss: 0.7043\n",
      "Epoch [3/50], Class Loss: 0.6354, CORAL Loss: 0.0241\n",
      "Validation Loss: 0.6332\n",
      "Epoch [4/50], Class Loss: 0.5769, CORAL Loss: 0.0215\n",
      "Validation Loss: 0.5677\n",
      "Epoch [5/50], Class Loss: 0.5058, CORAL Loss: 0.0301\n",
      "Validation Loss: 0.4383\n",
      "Epoch [6/50], Class Loss: 0.3462, CORAL Loss: 0.0398\n",
      "Validation Loss: 0.2598\n",
      "Epoch [7/50], Class Loss: 0.2346, CORAL Loss: 0.0477\n",
      "Validation Loss: 0.2197\n",
      "Epoch [8/50], Class Loss: 0.1805, CORAL Loss: 0.0386\n",
      "Validation Loss: 0.2829\n",
      "Epoch [9/50], Class Loss: 0.2282, CORAL Loss: 0.0332\n",
      "Validation Loss: 0.2566\n",
      "Epoch [10/50], Class Loss: 0.1480, CORAL Loss: 0.0373\n",
      "Validation Loss: 0.1338\n",
      "Epoch [11/50], Class Loss: 0.0768, CORAL Loss: 0.0337\n",
      "Validation Loss: 0.1148\n",
      "Epoch [12/50], Class Loss: 0.0676, CORAL Loss: 0.0310\n",
      "Validation Loss: 0.1141\n",
      "Epoch [13/50], Class Loss: 0.0677, CORAL Loss: 0.0305\n",
      "Validation Loss: 0.1174\n",
      "Epoch [14/50], Class Loss: 0.0586, CORAL Loss: 0.0294\n",
      "Validation Loss: 0.1044\n",
      "Epoch [15/50], Class Loss: 0.0553, CORAL Loss: 0.0291\n",
      "Validation Loss: 0.1057\n",
      "Epoch [16/50], Class Loss: 0.0556, CORAL Loss: 0.0282\n",
      "Validation Loss: 0.1153\n",
      "Epoch [17/50], Class Loss: 0.0537, CORAL Loss: 0.0260\n",
      "Validation Loss: 0.1132\n",
      "Epoch [18/50], Class Loss: 0.0469, CORAL Loss: 0.0237\n",
      "Validation Loss: 0.1033\n",
      "Epoch [19/50], Class Loss: 0.0434, CORAL Loss: 0.0254\n",
      "Validation Loss: 0.0975\n",
      "Epoch [20/50], Class Loss: 0.0452, CORAL Loss: 0.0255\n",
      "Validation Loss: 0.0950\n",
      "Epoch [21/50], Class Loss: 0.0426, CORAL Loss: 0.0230\n",
      "Validation Loss: 0.0972\n",
      "Epoch [22/50], Class Loss: 0.0386, CORAL Loss: 0.0216\n",
      "Validation Loss: 0.1046\n",
      "Epoch [23/50], Class Loss: 0.0369, CORAL Loss: 0.0240\n",
      "Validation Loss: 0.0987\n",
      "Epoch [24/50], Class Loss: 0.0368, CORAL Loss: 0.0221\n",
      "Validation Loss: 0.0991\n",
      "Epoch [25/50], Class Loss: 0.0394, CORAL Loss: 0.0227\n",
      "Validation Loss: 0.1042\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.52%, Precision: 96.71%, Recall: 96.42%, F1 Score: 96.51%\n",
      "Target Domain Performance - Accuracy: 53.24%, Precision: 39.01%, Recall: 51.09%, F1 Score: 43.07%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 1.2700, CORAL Loss: 0.0321\n",
      "Validation Loss: 0.9641\n",
      "Epoch [2/50], Class Loss: 0.6865, CORAL Loss: 0.0328\n",
      "Validation Loss: 0.6425\n",
      "Epoch [3/50], Class Loss: 0.6305, CORAL Loss: 0.0226\n",
      "Validation Loss: 0.9524\n",
      "Epoch [4/50], Class Loss: 0.5923, CORAL Loss: 0.0236\n",
      "Validation Loss: 0.5754\n",
      "Epoch [5/50], Class Loss: 0.5630, CORAL Loss: 0.0236\n",
      "Validation Loss: 0.6186\n",
      "Epoch [6/50], Class Loss: 0.5294, CORAL Loss: 0.0249\n",
      "Validation Loss: 0.5766\n",
      "Epoch [7/50], Class Loss: 0.4730, CORAL Loss: 0.0274\n",
      "Validation Loss: 0.4358\n",
      "Epoch [8/50], Class Loss: 0.3181, CORAL Loss: 0.0379\n",
      "Validation Loss: 0.2666\n",
      "Epoch [9/50], Class Loss: 0.2036, CORAL Loss: 0.0350\n",
      "Validation Loss: 0.4324\n",
      "Epoch [10/50], Class Loss: 0.1628, CORAL Loss: 0.0397\n",
      "Validation Loss: 0.1348\n",
      "Epoch [11/50], Class Loss: 0.0770, CORAL Loss: 0.0295\n",
      "Validation Loss: 0.1181\n",
      "Epoch [12/50], Class Loss: 0.0685, CORAL Loss: 0.0301\n",
      "Validation Loss: 0.1125\n",
      "Epoch [13/50], Class Loss: 0.0665, CORAL Loss: 0.0309\n",
      "Validation Loss: 0.1345\n",
      "Epoch [14/50], Class Loss: 0.0598, CORAL Loss: 0.0297\n",
      "Validation Loss: 0.1083\n",
      "Epoch [15/50], Class Loss: 0.0608, CORAL Loss: 0.0301\n",
      "Validation Loss: 0.1059\n",
      "Epoch [16/50], Class Loss: 0.0614, CORAL Loss: 0.0264\n",
      "Validation Loss: 0.1000\n",
      "Epoch [17/50], Class Loss: 0.0539, CORAL Loss: 0.0251\n",
      "Validation Loss: 0.1019\n",
      "Epoch [18/50], Class Loss: 0.0496, CORAL Loss: 0.0270\n",
      "Validation Loss: 0.0977\n",
      "Epoch [19/50], Class Loss: 0.0478, CORAL Loss: 0.0287\n",
      "Validation Loss: 0.1113\n",
      "Epoch [20/50], Class Loss: 0.0452, CORAL Loss: 0.0263\n",
      "Validation Loss: 0.1081\n",
      "Epoch [21/50], Class Loss: 0.0394, CORAL Loss: 0.0245\n",
      "Validation Loss: 0.0975\n",
      "Epoch [22/50], Class Loss: 0.0362, CORAL Loss: 0.0247\n",
      "Validation Loss: 0.0982\n",
      "Epoch [23/50], Class Loss: 0.0375, CORAL Loss: 0.0210\n",
      "Validation Loss: 0.0961\n",
      "Epoch [24/50], Class Loss: 0.0368, CORAL Loss: 0.0257\n",
      "Validation Loss: 0.0974\n",
      "Epoch [25/50], Class Loss: 0.0360, CORAL Loss: 0.0292\n",
      "Validation Loss: 0.1006\n",
      "Epoch [26/50], Class Loss: 0.0368, CORAL Loss: 0.0247\n",
      "Validation Loss: 0.0958\n",
      "Epoch [27/50], Class Loss: 0.0365, CORAL Loss: 0.0225\n",
      "Validation Loss: 0.0943\n",
      "Epoch [28/50], Class Loss: 0.0363, CORAL Loss: 0.0246\n",
      "Validation Loss: 0.1027\n",
      "Epoch [29/50], Class Loss: 0.0354, CORAL Loss: 0.0226\n",
      "Validation Loss: 0.0965\n",
      "Epoch [30/50], Class Loss: 0.0358, CORAL Loss: 0.0215\n",
      "Validation Loss: 0.0991\n",
      "Epoch [31/50], Class Loss: 0.0348, CORAL Loss: 0.0280\n",
      "Validation Loss: 0.0973\n",
      "Epoch [32/50], Class Loss: 0.0338, CORAL Loss: 0.0221\n",
      "Validation Loss: 0.0965\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.28%, Precision: 96.41%, Recall: 96.20%, F1 Score: 96.27%\n",
      "Target Domain Performance - Accuracy: 53.30%, Precision: 39.33%, Recall: 51.16%, F1 Score: 43.38%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 1.1436, CORAL Loss: 0.0239\n",
      "Validation Loss: 0.7938\n",
      "Epoch [2/50], Class Loss: 0.6460, CORAL Loss: 0.0215\n",
      "Validation Loss: 0.7264\n",
      "Epoch [3/50], Class Loss: 0.6001, CORAL Loss: 0.0189\n",
      "Validation Loss: 0.7406\n",
      "Epoch [4/50], Class Loss: 0.6107, CORAL Loss: 0.0183\n",
      "Validation Loss: 0.5586\n",
      "Epoch [5/50], Class Loss: 0.5045, CORAL Loss: 0.0186\n",
      "Validation Loss: 0.5966\n",
      "Epoch [6/50], Class Loss: 0.4923, CORAL Loss: 0.0346\n",
      "Validation Loss: 0.5594\n",
      "Epoch [7/50], Class Loss: 0.2967, CORAL Loss: 0.0376\n",
      "Validation Loss: 0.2655\n",
      "Epoch [8/50], Class Loss: 0.2190, CORAL Loss: 0.0393\n",
      "Validation Loss: 0.1974\n",
      "Epoch [9/50], Class Loss: 0.1667, CORAL Loss: 0.0372\n",
      "Validation Loss: 0.1384\n",
      "Epoch [10/50], Class Loss: 0.1433, CORAL Loss: 0.0352\n",
      "Validation Loss: 0.1640\n",
      "Epoch [11/50], Class Loss: 0.0696, CORAL Loss: 0.0266\n",
      "Validation Loss: 0.1138\n",
      "Epoch [12/50], Class Loss: 0.0621, CORAL Loss: 0.0293\n",
      "Validation Loss: 0.1085\n",
      "Epoch [13/50], Class Loss: 0.0535, CORAL Loss: 0.0288\n",
      "Validation Loss: 0.1095\n",
      "Epoch [14/50], Class Loss: 0.0550, CORAL Loss: 0.0266\n",
      "Validation Loss: 0.1272\n",
      "Epoch [15/50], Class Loss: 0.0470, CORAL Loss: 0.0259\n",
      "Validation Loss: 0.0968\n",
      "Epoch [16/50], Class Loss: 0.0450, CORAL Loss: 0.0271\n",
      "Validation Loss: 0.0962\n",
      "Epoch [17/50], Class Loss: 0.0432, CORAL Loss: 0.0244\n",
      "Validation Loss: 0.1265\n",
      "Epoch [18/50], Class Loss: 0.0405, CORAL Loss: 0.0264\n",
      "Validation Loss: 0.1101\n",
      "Epoch [19/50], Class Loss: 0.0421, CORAL Loss: 0.0229\n",
      "Validation Loss: 0.0971\n",
      "Epoch [20/50], Class Loss: 0.0383, CORAL Loss: 0.0218\n",
      "Validation Loss: 0.0962\n",
      "Epoch [21/50], Class Loss: 0.0325, CORAL Loss: 0.0200\n",
      "Validation Loss: 0.0938\n",
      "Epoch [22/50], Class Loss: 0.0309, CORAL Loss: 0.0215\n",
      "Validation Loss: 0.0948\n",
      "Epoch [23/50], Class Loss: 0.0313, CORAL Loss: 0.0206\n",
      "Validation Loss: 0.0955\n",
      "Epoch [24/50], Class Loss: 0.0289, CORAL Loss: 0.0214\n",
      "Validation Loss: 0.0967\n",
      "Epoch [25/50], Class Loss: 0.0308, CORAL Loss: 0.0202\n",
      "Validation Loss: 0.0996\n",
      "Epoch [26/50], Class Loss: 0.0295, CORAL Loss: 0.0212\n",
      "Validation Loss: 0.0939\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.16%, Precision: 96.21%, Recall: 96.12%, F1 Score: 96.16%\n",
      "Target Domain Performance - Accuracy: 53.84%, Precision: 48.52%, Recall: 51.74%, F1 Score: 44.34%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 1.1806, CORAL Loss: 0.0266\n",
      "Validation Loss: 0.8062\n",
      "Epoch [2/50], Class Loss: 0.6632, CORAL Loss: 0.0421\n",
      "Validation Loss: 0.7598\n",
      "Epoch [3/50], Class Loss: 0.6433, CORAL Loss: 0.0271\n",
      "Validation Loss: 0.6508\n",
      "Epoch [4/50], Class Loss: 0.5580, CORAL Loss: 0.0233\n",
      "Validation Loss: 0.8572\n",
      "Epoch [5/50], Class Loss: 0.5163, CORAL Loss: 0.0254\n",
      "Validation Loss: 0.6551\n",
      "Epoch [6/50], Class Loss: 0.4460, CORAL Loss: 0.0289\n",
      "Validation Loss: 0.4123\n",
      "Epoch [7/50], Class Loss: 0.2939, CORAL Loss: 0.0545\n",
      "Validation Loss: 0.2038\n",
      "Epoch [8/50], Class Loss: 0.2162, CORAL Loss: 0.0407\n",
      "Validation Loss: 0.1871\n",
      "Epoch [9/50], Class Loss: 0.1165, CORAL Loss: 0.0388\n",
      "Validation Loss: 0.0992\n",
      "Epoch [10/50], Class Loss: 0.1383, CORAL Loss: 0.0348\n",
      "Validation Loss: 0.2193\n",
      "Epoch [11/50], Class Loss: 0.0793, CORAL Loss: 0.0250\n",
      "Validation Loss: 0.1069\n",
      "Epoch [12/50], Class Loss: 0.0526, CORAL Loss: 0.0261\n",
      "Validation Loss: 0.0983\n",
      "Epoch [13/50], Class Loss: 0.0446, CORAL Loss: 0.0339\n",
      "Validation Loss: 0.0888\n",
      "Epoch [14/50], Class Loss: 0.0407, CORAL Loss: 0.0273\n",
      "Validation Loss: 0.0944\n",
      "Epoch [15/50], Class Loss: 0.0415, CORAL Loss: 0.0259\n",
      "Validation Loss: 0.0827\n",
      "Epoch [16/50], Class Loss: 0.0350, CORAL Loss: 0.0306\n",
      "Validation Loss: 0.0848\n",
      "Epoch [17/50], Class Loss: 0.0355, CORAL Loss: 0.0239\n",
      "Validation Loss: 0.0864\n",
      "Epoch [18/50], Class Loss: 0.0333, CORAL Loss: 0.0300\n",
      "Validation Loss: 0.0809\n",
      "Epoch [19/50], Class Loss: 0.0299, CORAL Loss: 0.0318\n",
      "Validation Loss: 0.0838\n",
      "Epoch [20/50], Class Loss: 0.0303, CORAL Loss: 0.0170\n",
      "Validation Loss: 0.0828\n",
      "Epoch [21/50], Class Loss: 0.0266, CORAL Loss: 0.0229\n",
      "Validation Loss: 0.0765\n",
      "Epoch [22/50], Class Loss: 0.0255, CORAL Loss: 0.0211\n",
      "Validation Loss: 0.0761\n",
      "Epoch [23/50], Class Loss: 0.0257, CORAL Loss: 0.0222\n",
      "Validation Loss: 0.0762\n",
      "Epoch [24/50], Class Loss: 0.0253, CORAL Loss: 0.0242\n",
      "Validation Loss: 0.0771\n",
      "Epoch [25/50], Class Loss: 0.0238, CORAL Loss: 0.0209\n",
      "Validation Loss: 0.0764\n",
      "Epoch [26/50], Class Loss: 0.0241, CORAL Loss: 0.0185\n",
      "Validation Loss: 0.0774\n",
      "Epoch [27/50], Class Loss: 0.0253, CORAL Loss: 0.0223\n",
      "Validation Loss: 0.0771\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.06%, Precision: 97.08%, Recall: 97.05%, F1 Score: 97.06%\n",
      "Target Domain Performance - Accuracy: 54.62%, Precision: 60.97%, Recall: 52.56%, F1 Score: 45.50%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 1.3949, CORAL Loss: 0.0212\n",
      "Validation Loss: 0.7172\n",
      "Epoch [2/50], Class Loss: 0.6517, CORAL Loss: 0.0408\n",
      "Validation Loss: 0.6409\n",
      "Epoch [3/50], Class Loss: 0.5785, CORAL Loss: 0.0245\n",
      "Validation Loss: 0.6040\n",
      "Epoch [4/50], Class Loss: 0.5408, CORAL Loss: 0.0264\n",
      "Validation Loss: 0.8753\n",
      "Epoch [5/50], Class Loss: 0.5144, CORAL Loss: 0.0322\n",
      "Validation Loss: 0.5046\n",
      "Epoch [6/50], Class Loss: 0.3346, CORAL Loss: 0.0430\n",
      "Validation Loss: 0.5343\n",
      "Epoch [7/50], Class Loss: 0.2239, CORAL Loss: 0.0383\n",
      "Validation Loss: 0.2988\n",
      "Epoch [8/50], Class Loss: 0.1972, CORAL Loss: 0.0479\n",
      "Validation Loss: 0.1656\n",
      "Epoch [9/50], Class Loss: 0.1841, CORAL Loss: 0.0304\n",
      "Validation Loss: 0.1791\n",
      "Epoch [10/50], Class Loss: 0.1348, CORAL Loss: 0.0308\n",
      "Validation Loss: 0.1666\n",
      "Epoch [11/50], Class Loss: 0.0781, CORAL Loss: 0.0238\n",
      "Validation Loss: 0.1126\n",
      "Epoch [12/50], Class Loss: 0.0657, CORAL Loss: 0.0226\n",
      "Validation Loss: 0.1098\n",
      "Epoch [13/50], Class Loss: 0.0622, CORAL Loss: 0.0300\n",
      "Validation Loss: 0.1445\n",
      "Epoch [14/50], Class Loss: 0.0577, CORAL Loss: 0.0260\n",
      "Validation Loss: 0.1054\n",
      "Epoch [15/50], Class Loss: 0.0541, CORAL Loss: 0.0259\n",
      "Validation Loss: 0.1341\n",
      "Epoch [16/50], Class Loss: 0.0533, CORAL Loss: 0.0262\n",
      "Validation Loss: 0.1048\n",
      "Epoch [17/50], Class Loss: 0.0549, CORAL Loss: 0.0220\n",
      "Validation Loss: 0.1383\n",
      "Epoch [18/50], Class Loss: 0.0613, CORAL Loss: 0.0247\n",
      "Validation Loss: 0.1112\n",
      "Epoch [19/50], Class Loss: 0.0514, CORAL Loss: 0.0256\n",
      "Validation Loss: 0.1010\n",
      "Epoch [20/50], Class Loss: 0.0464, CORAL Loss: 0.0276\n",
      "Validation Loss: 0.1007\n",
      "Epoch [21/50], Class Loss: 0.0371, CORAL Loss: 0.0228\n",
      "Validation Loss: 0.1082\n",
      "Epoch [22/50], Class Loss: 0.0410, CORAL Loss: 0.0208\n",
      "Validation Loss: 0.1089\n",
      "Epoch [23/50], Class Loss: 0.0394, CORAL Loss: 0.0223\n",
      "Validation Loss: 0.1154\n",
      "Epoch [24/50], Class Loss: 0.0393, CORAL Loss: 0.0236\n",
      "Validation Loss: 0.1076\n",
      "Epoch [25/50], Class Loss: 0.0379, CORAL Loss: 0.0218\n",
      "Validation Loss: 0.1027\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.34%, Precision: 96.46%, Recall: 96.26%, F1 Score: 96.33%\n",
      "Target Domain Performance - Accuracy: 53.18%, Precision: 39.35%, Recall: 51.03%, F1 Score: 43.39%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 1.3430, CORAL Loss: 0.0225\n",
      "Validation Loss: 0.8048\n",
      "Epoch [2/50], Class Loss: 0.7424, CORAL Loss: 0.0441\n",
      "Validation Loss: 0.6160\n",
      "Epoch [3/50], Class Loss: 0.5992, CORAL Loss: 0.0253\n",
      "Validation Loss: 0.7735\n",
      "Epoch [4/50], Class Loss: 0.5903, CORAL Loss: 0.0201\n",
      "Validation Loss: 0.6022\n",
      "Epoch [5/50], Class Loss: 0.5446, CORAL Loss: 0.0227\n",
      "Validation Loss: 0.7216\n",
      "Epoch [6/50], Class Loss: 0.5269, CORAL Loss: 0.0219\n",
      "Validation Loss: 0.8092\n",
      "Epoch [7/50], Class Loss: 0.4504, CORAL Loss: 0.0289\n",
      "Validation Loss: 0.3970\n",
      "Epoch [8/50], Class Loss: 0.3622, CORAL Loss: 0.0484\n",
      "Validation Loss: 0.2834\n",
      "Epoch [9/50], Class Loss: 0.2216, CORAL Loss: 0.0403\n",
      "Validation Loss: 0.1970\n",
      "Epoch [10/50], Class Loss: 0.2046, CORAL Loss: 0.0424\n",
      "Validation Loss: 0.2279\n",
      "Epoch [11/50], Class Loss: 0.1266, CORAL Loss: 0.0285\n",
      "Validation Loss: 0.1588\n",
      "Epoch [12/50], Class Loss: 0.0932, CORAL Loss: 0.0336\n",
      "Validation Loss: 0.1437\n",
      "Epoch [13/50], Class Loss: 0.0805, CORAL Loss: 0.0344\n",
      "Validation Loss: 0.1477\n",
      "Epoch [14/50], Class Loss: 0.0772, CORAL Loss: 0.0396\n",
      "Validation Loss: 0.1310\n",
      "Epoch [15/50], Class Loss: 0.0724, CORAL Loss: 0.0351\n",
      "Validation Loss: 0.1302\n",
      "Epoch [16/50], Class Loss: 0.0700, CORAL Loss: 0.0316\n",
      "Validation Loss: 0.1511\n",
      "Epoch [17/50], Class Loss: 0.0629, CORAL Loss: 0.0287\n",
      "Validation Loss: 0.1270\n",
      "Epoch [18/50], Class Loss: 0.0607, CORAL Loss: 0.0291\n",
      "Validation Loss: 0.1270\n",
      "Epoch [19/50], Class Loss: 0.0567, CORAL Loss: 0.0320\n",
      "Validation Loss: 0.1598\n",
      "Epoch [20/50], Class Loss: 0.0553, CORAL Loss: 0.0291\n",
      "Validation Loss: 0.1210\n",
      "Epoch [21/50], Class Loss: 0.0493, CORAL Loss: 0.0271\n",
      "Validation Loss: 0.1173\n",
      "Epoch [22/50], Class Loss: 0.0446, CORAL Loss: 0.0304\n",
      "Validation Loss: 0.1207\n",
      "Epoch [23/50], Class Loss: 0.0442, CORAL Loss: 0.0246\n",
      "Validation Loss: 0.1176\n",
      "Epoch [24/50], Class Loss: 0.0448, CORAL Loss: 0.0263\n",
      "Validation Loss: 0.1166\n",
      "Epoch [25/50], Class Loss: 0.0444, CORAL Loss: 0.0266\n",
      "Validation Loss: 0.1259\n",
      "Epoch [26/50], Class Loss: 0.0431, CORAL Loss: 0.0262\n",
      "Validation Loss: 0.1185\n",
      "Epoch [27/50], Class Loss: 0.0441, CORAL Loss: 0.0321\n",
      "Validation Loss: 0.1168\n",
      "Epoch [28/50], Class Loss: 0.0432, CORAL Loss: 0.0272\n",
      "Validation Loss: 0.1175\n",
      "Epoch [29/50], Class Loss: 0.0438, CORAL Loss: 0.0238\n",
      "Validation Loss: 0.1181\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 95.62%, Precision: 95.73%, Recall: 95.55%, F1 Score: 95.61%\n",
      "Target Domain Performance - Accuracy: 53.12%, Precision: 39.24%, Recall: 50.99%, F1 Score: 43.27%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 1.2816, CORAL Loss: 0.0301\n",
      "Validation Loss: 1.1632\n",
      "Epoch [2/50], Class Loss: 0.6761, CORAL Loss: 0.0389\n",
      "Validation Loss: 0.6419\n",
      "Epoch [3/50], Class Loss: 0.6067, CORAL Loss: 0.0238\n",
      "Validation Loss: 0.5936\n",
      "Epoch [4/50], Class Loss: 0.5514, CORAL Loss: 0.0241\n",
      "Validation Loss: 0.5865\n",
      "Epoch [5/50], Class Loss: 0.5025, CORAL Loss: 0.0206\n",
      "Validation Loss: 0.7125\n",
      "Epoch [6/50], Class Loss: 0.4885, CORAL Loss: 0.0312\n",
      "Validation Loss: 0.6899\n",
      "Epoch [7/50], Class Loss: 0.4128, CORAL Loss: 0.0387\n",
      "Validation Loss: 0.5254\n",
      "Epoch [8/50], Class Loss: 0.2343, CORAL Loss: 0.0378\n",
      "Validation Loss: 0.2638\n",
      "Epoch [9/50], Class Loss: 0.1682, CORAL Loss: 0.0387\n",
      "Validation Loss: 0.2459\n",
      "Epoch [10/50], Class Loss: 0.1214, CORAL Loss: 0.0444\n",
      "Validation Loss: 0.1346\n",
      "Epoch [11/50], Class Loss: 0.0760, CORAL Loss: 0.0274\n",
      "Validation Loss: 0.1235\n",
      "Epoch [12/50], Class Loss: 0.0695, CORAL Loss: 0.0313\n",
      "Validation Loss: 0.1212\n",
      "Epoch [13/50], Class Loss: 0.0603, CORAL Loss: 0.0274\n",
      "Validation Loss: 0.1139\n",
      "Epoch [14/50], Class Loss: 0.0544, CORAL Loss: 0.0357\n",
      "Validation Loss: 0.1197\n",
      "Epoch [15/50], Class Loss: 0.0517, CORAL Loss: 0.0284\n",
      "Validation Loss: 0.1145\n",
      "Epoch [16/50], Class Loss: 0.0474, CORAL Loss: 0.0274\n",
      "Validation Loss: 0.1389\n",
      "Epoch [17/50], Class Loss: 0.0479, CORAL Loss: 0.0269\n",
      "Validation Loss: 0.1182\n",
      "Epoch [18/50], Class Loss: 0.0443, CORAL Loss: 0.0286\n",
      "Validation Loss: 0.1217\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 95.50%, Precision: 95.77%, Recall: 95.37%, F1 Score: 95.47%\n",
      "Target Domain Performance - Accuracy: 53.24%, Precision: 39.10%, Recall: 51.11%, F1 Score: 43.16%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 1.4709, CORAL Loss: 0.0130\n",
      "Validation Loss: 0.9887\n",
      "Epoch [2/50], Class Loss: 0.7077, CORAL Loss: 0.0500\n",
      "Validation Loss: 0.7739\n",
      "Epoch [3/50], Class Loss: 0.5789, CORAL Loss: 0.0308\n",
      "Validation Loss: 0.5579\n",
      "Epoch [4/50], Class Loss: 0.5775, CORAL Loss: 0.0275\n",
      "Validation Loss: 0.6213\n",
      "Epoch [5/50], Class Loss: 0.5141, CORAL Loss: 0.0273\n",
      "Validation Loss: 0.8852\n",
      "Epoch [6/50], Class Loss: 0.4838, CORAL Loss: 0.0272\n",
      "Validation Loss: 0.6180\n",
      "Epoch [7/50], Class Loss: 0.4118, CORAL Loss: 0.0302\n",
      "Validation Loss: 0.3352\n",
      "Epoch [8/50], Class Loss: 0.2420, CORAL Loss: 0.0374\n",
      "Validation Loss: 0.3031\n",
      "Epoch [9/50], Class Loss: 0.2180, CORAL Loss: 0.0419\n",
      "Validation Loss: 0.1774\n",
      "Epoch [10/50], Class Loss: 0.1531, CORAL Loss: 0.0425\n",
      "Validation Loss: 0.1411\n",
      "Epoch [11/50], Class Loss: 0.0742, CORAL Loss: 0.0390\n",
      "Validation Loss: 0.1166\n",
      "Epoch [12/50], Class Loss: 0.0684, CORAL Loss: 0.0357\n",
      "Validation Loss: 0.1174\n",
      "Epoch [13/50], Class Loss: 0.0646, CORAL Loss: 0.0385\n",
      "Validation Loss: 0.1133\n",
      "Epoch [14/50], Class Loss: 0.0558, CORAL Loss: 0.0441\n",
      "Validation Loss: 0.1090\n",
      "Epoch [15/50], Class Loss: 0.0523, CORAL Loss: 0.0251\n",
      "Validation Loss: 0.1112\n",
      "Epoch [16/50], Class Loss: 0.0475, CORAL Loss: 0.0290\n",
      "Validation Loss: 0.1030\n",
      "Epoch [17/50], Class Loss: 0.0447, CORAL Loss: 0.0281\n",
      "Validation Loss: 0.1068\n",
      "Epoch [18/50], Class Loss: 0.0462, CORAL Loss: 0.0339\n",
      "Validation Loss: 0.1408\n",
      "Epoch [19/50], Class Loss: 0.0431, CORAL Loss: 0.0339\n",
      "Validation Loss: 0.1055\n",
      "Epoch [20/50], Class Loss: 0.0412, CORAL Loss: 0.0290\n",
      "Validation Loss: 0.1036\n",
      "Epoch [21/50], Class Loss: 0.0342, CORAL Loss: 0.0283\n",
      "Validation Loss: 0.1034\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.46%, Precision: 96.57%, Recall: 96.39%, F1 Score: 96.45%\n",
      "Target Domain Performance - Accuracy: 54.26%, Precision: 53.15%, Recall: 52.18%, F1 Score: 44.83%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.3493, CORAL Loss: 0.0268\n",
      "Validation Loss: 0.8850\n",
      "Epoch [2/50], Class Loss: 0.6747, CORAL Loss: 0.0327\n",
      "Validation Loss: 0.6146\n",
      "Epoch [3/50], Class Loss: 0.6259, CORAL Loss: 0.0251\n",
      "Validation Loss: 0.6248\n",
      "Epoch [4/50], Class Loss: 0.5451, CORAL Loss: 0.0220\n",
      "Validation Loss: 0.6246\n",
      "Epoch [5/50], Class Loss: 0.5376, CORAL Loss: 0.0227\n",
      "Validation Loss: 1.0385\n",
      "Epoch [6/50], Class Loss: 0.5153, CORAL Loss: 0.0370\n",
      "Validation Loss: 0.4646\n",
      "Epoch [7/50], Class Loss: 0.2729, CORAL Loss: 0.0393\n",
      "Validation Loss: 0.2638\n",
      "Epoch [8/50], Class Loss: 0.2063, CORAL Loss: 0.0365\n",
      "Validation Loss: 0.1863\n",
      "Epoch [9/50], Class Loss: 0.1491, CORAL Loss: 0.0420\n",
      "Validation Loss: 0.5724\n",
      "Epoch [10/50], Class Loss: 0.1394, CORAL Loss: 0.0318\n",
      "Validation Loss: 0.3625\n",
      "Epoch [11/50], Class Loss: 0.0779, CORAL Loss: 0.0294\n",
      "Validation Loss: 0.0991\n",
      "Epoch [12/50], Class Loss: 0.0566, CORAL Loss: 0.0334\n",
      "Validation Loss: 0.1133\n",
      "Epoch [13/50], Class Loss: 0.0531, CORAL Loss: 0.0293\n",
      "Validation Loss: 0.1535\n",
      "Epoch [14/50], Class Loss: 0.0520, CORAL Loss: 0.0304\n",
      "Validation Loss: 0.1077\n",
      "Epoch [15/50], Class Loss: 0.0503, CORAL Loss: 0.0292\n",
      "Validation Loss: 0.1491\n",
      "Epoch [16/50], Class Loss: 0.0451, CORAL Loss: 0.0301\n",
      "Validation Loss: 0.1161\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.46%, Precision: 96.84%, Recall: 96.31%, F1 Score: 96.43%\n",
      "Target Domain Performance - Accuracy: 53.30%, Precision: 39.38%, Recall: 51.16%, F1 Score: 43.43%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 1.3624, CORAL Loss: 0.0213\n",
      "Validation Loss: 0.7212\n",
      "Epoch [2/50], Class Loss: 0.6517, CORAL Loss: 0.0350\n",
      "Validation Loss: 0.6375\n",
      "Epoch [3/50], Class Loss: 0.5955, CORAL Loss: 0.0222\n",
      "Validation Loss: 0.6228\n",
      "Epoch [4/50], Class Loss: 0.5356, CORAL Loss: 0.0227\n",
      "Validation Loss: 0.5917\n",
      "Epoch [5/50], Class Loss: 0.5161, CORAL Loss: 0.0258\n",
      "Validation Loss: 0.5259\n",
      "Epoch [6/50], Class Loss: 0.4409, CORAL Loss: 0.0251\n",
      "Validation Loss: 0.3625\n",
      "Epoch [7/50], Class Loss: 0.2740, CORAL Loss: 0.0365\n",
      "Validation Loss: 0.8244\n",
      "Epoch [8/50], Class Loss: 0.2092, CORAL Loss: 0.0464\n",
      "Validation Loss: 0.2682\n",
      "Epoch [9/50], Class Loss: 0.1453, CORAL Loss: 0.0423\n",
      "Validation Loss: 0.3516\n",
      "Epoch [10/50], Class Loss: 0.1144, CORAL Loss: 0.0349\n",
      "Validation Loss: 0.0853\n",
      "Epoch [11/50], Class Loss: 0.0456, CORAL Loss: 0.0255\n",
      "Validation Loss: 0.0794\n",
      "Epoch [12/50], Class Loss: 0.0409, CORAL Loss: 0.0291\n",
      "Validation Loss: 0.0832\n",
      "Epoch [13/50], Class Loss: 0.0439, CORAL Loss: 0.0305\n",
      "Validation Loss: 0.0812\n",
      "Epoch [14/50], Class Loss: 0.0431, CORAL Loss: 0.0263\n",
      "Validation Loss: 0.0910\n",
      "Epoch [15/50], Class Loss: 0.0384, CORAL Loss: 0.0254\n",
      "Validation Loss: 0.0947\n",
      "Epoch [16/50], Class Loss: 0.0342, CORAL Loss: 0.0240\n",
      "Validation Loss: 0.0822\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.70%, Precision: 96.85%, Recall: 96.61%, F1 Score: 96.69%\n",
      "Target Domain Performance - Accuracy: 54.32%, Precision: 57.60%, Recall: 52.25%, F1 Score: 45.21%\n",
      "\n",
      "Source performance: 96.31% 96.46% 96.23% 96.30%\n",
      "Target performance: 53.64% 45.57% 51.53% 43.96%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.76%\n",
      "qpsk: 0.20%\n",
      "16qam: 6.31%\n",
      "16apsk: 99.85%\n",
      "SNR level: 10\n",
      "JAN\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 1.3115, JMMD Loss: 0.1998\n",
      "Validation Loss: 0.8368\n",
      "Epoch [2/50], Class Loss: 0.6507, JMMD Loss: 0.2479\n",
      "Validation Loss: 0.5869\n",
      "Epoch [3/50], Class Loss: 0.5424, JMMD Loss: 0.2577\n",
      "Validation Loss: 0.6622\n",
      "Epoch [4/50], Class Loss: 0.5205, JMMD Loss: 0.2284\n",
      "Validation Loss: 0.7635\n",
      "Epoch [5/50], Class Loss: 0.4465, JMMD Loss: 0.2433\n",
      "Validation Loss: 0.3862\n",
      "Epoch [6/50], Class Loss: 0.3091, JMMD Loss: 0.3425\n",
      "Validation Loss: 0.2425\n",
      "Epoch [7/50], Class Loss: 0.2138, JMMD Loss: 0.3573\n",
      "Validation Loss: 0.2535\n",
      "Epoch [8/50], Class Loss: 0.1528, JMMD Loss: 0.3543\n",
      "Validation Loss: 0.1348\n",
      "Epoch [9/50], Class Loss: 0.1033, JMMD Loss: 0.3474\n",
      "Validation Loss: 0.1812\n",
      "Epoch [10/50], Class Loss: 0.0956, JMMD Loss: 0.3434\n",
      "Validation Loss: 0.1044\n",
      "Epoch [11/50], Class Loss: 0.0268, JMMD Loss: 0.3334\n",
      "Validation Loss: 0.1024\n",
      "Epoch [12/50], Class Loss: 0.0223, JMMD Loss: 0.3245\n",
      "Validation Loss: 0.1009\n",
      "Epoch [13/50], Class Loss: 0.0217, JMMD Loss: 0.3158\n",
      "Validation Loss: 0.1039\n",
      "Epoch [14/50], Class Loss: 0.0194, JMMD Loss: 0.3102\n",
      "Validation Loss: 0.1016\n",
      "Epoch [15/50], Class Loss: 0.0164, JMMD Loss: 0.3076\n",
      "Validation Loss: 0.1008\n",
      "Epoch [16/50], Class Loss: 0.0177, JMMD Loss: 0.2873\n",
      "Validation Loss: 0.1006\n",
      "Epoch [17/50], Class Loss: 0.0176, JMMD Loss: 0.2864\n",
      "Validation Loss: 0.0997\n",
      "Epoch [18/50], Class Loss: 0.0146, JMMD Loss: 0.2934\n",
      "Validation Loss: 0.0983\n",
      "Epoch [19/50], Class Loss: 0.0140, JMMD Loss: 0.2848\n",
      "Validation Loss: 0.0974\n",
      "Epoch [20/50], Class Loss: 0.0121, JMMD Loss: 0.2797\n",
      "Validation Loss: 0.1075\n",
      "Epoch [21/50], Class Loss: 0.0117, JMMD Loss: 0.2841\n",
      "Validation Loss: 0.1005\n",
      "Epoch [22/50], Class Loss: 0.0106, JMMD Loss: 0.2851\n",
      "Validation Loss: 0.0989\n",
      "Epoch [23/50], Class Loss: 0.0095, JMMD Loss: 0.2818\n",
      "Validation Loss: 0.0983\n",
      "Epoch [24/50], Class Loss: 0.0099, JMMD Loss: 0.2748\n",
      "Validation Loss: 0.0985\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.16%, Precision: 96.17%, Recall: 96.17%, F1 Score: 96.16%\n",
      "Target Domain Performance - Accuracy: 55.88%, Precision: 67.41%, Recall: 53.91%, F1 Score: 46.91%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 1.3407, JMMD Loss: 0.2077\n",
      "Validation Loss: 0.6914\n",
      "Epoch [2/50], Class Loss: 0.6448, JMMD Loss: 0.2716\n",
      "Validation Loss: 0.7126\n",
      "Epoch [3/50], Class Loss: 0.5779, JMMD Loss: 0.2701\n",
      "Validation Loss: 0.5615\n",
      "Epoch [4/50], Class Loss: 0.5694, JMMD Loss: 0.2650\n",
      "Validation Loss: 0.5985\n",
      "Epoch [5/50], Class Loss: 0.4269, JMMD Loss: 0.3051\n",
      "Validation Loss: 0.4666\n",
      "Epoch [6/50], Class Loss: 0.2469, JMMD Loss: 0.3952\n",
      "Validation Loss: 0.3447\n",
      "Epoch [7/50], Class Loss: 0.1992, JMMD Loss: 0.3786\n",
      "Validation Loss: 0.3692\n",
      "Epoch [8/50], Class Loss: 0.1566, JMMD Loss: 0.3796\n",
      "Validation Loss: 0.1477\n",
      "Epoch [9/50], Class Loss: 0.1547, JMMD Loss: 0.3591\n",
      "Validation Loss: 0.1484\n",
      "Epoch [10/50], Class Loss: 0.1210, JMMD Loss: 0.3393\n",
      "Validation Loss: 0.1465\n",
      "Epoch [11/50], Class Loss: 0.0694, JMMD Loss: 0.3144\n",
      "Validation Loss: 0.1217\n",
      "Epoch [12/50], Class Loss: 0.0493, JMMD Loss: 0.3332\n",
      "Validation Loss: 0.1119\n",
      "Epoch [13/50], Class Loss: 0.0399, JMMD Loss: 0.3162\n",
      "Validation Loss: 0.1168\n",
      "Epoch [14/50], Class Loss: 0.0360, JMMD Loss: 0.3102\n",
      "Validation Loss: 0.1104\n",
      "Epoch [15/50], Class Loss: 0.0328, JMMD Loss: 0.3114\n",
      "Validation Loss: 0.1247\n",
      "Epoch [16/50], Class Loss: 0.0324, JMMD Loss: 0.3010\n",
      "Validation Loss: 0.1048\n",
      "Epoch [17/50], Class Loss: 0.0297, JMMD Loss: 0.2990\n",
      "Validation Loss: 0.1053\n",
      "Epoch [18/50], Class Loss: 0.0258, JMMD Loss: 0.3055\n",
      "Validation Loss: 0.1112\n",
      "Epoch [19/50], Class Loss: 0.0255, JMMD Loss: 0.3049\n",
      "Validation Loss: 0.1061\n",
      "Epoch [20/50], Class Loss: 0.0217, JMMD Loss: 0.3008\n",
      "Validation Loss: 0.1149\n",
      "Epoch [21/50], Class Loss: 0.0179, JMMD Loss: 0.2843\n",
      "Validation Loss: 0.1091\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 95.86%, Precision: 95.92%, Recall: 95.81%, F1 Score: 95.85%\n",
      "Target Domain Performance - Accuracy: 55.46%, Precision: 67.10%, Recall: 53.47%, F1 Score: 46.46%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 1.2225, JMMD Loss: 0.1989\n",
      "Validation Loss: 0.6234\n",
      "Epoch [2/50], Class Loss: 0.6454, JMMD Loss: 0.2587\n",
      "Validation Loss: 0.6750\n",
      "Epoch [3/50], Class Loss: 0.5671, JMMD Loss: 0.2646\n",
      "Validation Loss: 0.8031\n",
      "Epoch [4/50], Class Loss: 0.5475, JMMD Loss: 0.2556\n",
      "Validation Loss: 0.5430\n",
      "Epoch [5/50], Class Loss: 0.4781, JMMD Loss: 0.1963\n",
      "Validation Loss: 0.4731\n",
      "Epoch [6/50], Class Loss: 0.3694, JMMD Loss: 0.2495\n",
      "Validation Loss: 0.3348\n",
      "Epoch [7/50], Class Loss: 0.2215, JMMD Loss: 0.2721\n",
      "Validation Loss: 0.6057\n",
      "Epoch [8/50], Class Loss: 0.2029, JMMD Loss: 0.3148\n",
      "Validation Loss: 0.3090\n",
      "Epoch [9/50], Class Loss: 0.0931, JMMD Loss: 0.2894\n",
      "Validation Loss: 0.1228\n",
      "Epoch [10/50], Class Loss: 0.0983, JMMD Loss: 0.3087\n",
      "Validation Loss: 0.1665\n",
      "Epoch [11/50], Class Loss: 0.0472, JMMD Loss: 0.2778\n",
      "Validation Loss: 0.1062\n",
      "Epoch [12/50], Class Loss: 0.0335, JMMD Loss: 0.2768\n",
      "Validation Loss: 0.0979\n",
      "Epoch [13/50], Class Loss: 0.0289, JMMD Loss: 0.2708\n",
      "Validation Loss: 0.0970\n",
      "Epoch [14/50], Class Loss: 0.0263, JMMD Loss: 0.2588\n",
      "Validation Loss: 0.0950\n",
      "Epoch [15/50], Class Loss: 0.0253, JMMD Loss: 0.2528\n",
      "Validation Loss: 0.0948\n",
      "Epoch [16/50], Class Loss: 0.0219, JMMD Loss: 0.2472\n",
      "Validation Loss: 0.0947\n",
      "Epoch [17/50], Class Loss: 0.0179, JMMD Loss: 0.2478\n",
      "Validation Loss: 0.0940\n",
      "Epoch [18/50], Class Loss: 0.0202, JMMD Loss: 0.2472\n",
      "Validation Loss: 0.0906\n",
      "Epoch [19/50], Class Loss: 0.0187, JMMD Loss: 0.2488\n",
      "Validation Loss: 0.0889\n",
      "Epoch [20/50], Class Loss: 0.0155, JMMD Loss: 0.2313\n",
      "Validation Loss: 0.0898\n",
      "Epoch [21/50], Class Loss: 0.0140, JMMD Loss: 0.2335\n",
      "Validation Loss: 0.0887\n",
      "Epoch [22/50], Class Loss: 0.0132, JMMD Loss: 0.2240\n",
      "Validation Loss: 0.0892\n",
      "Epoch [23/50], Class Loss: 0.0128, JMMD Loss: 0.2301\n",
      "Validation Loss: 0.0899\n",
      "Epoch [24/50], Class Loss: 0.0127, JMMD Loss: 0.2320\n",
      "Validation Loss: 0.0897\n",
      "Epoch [25/50], Class Loss: 0.0134, JMMD Loss: 0.2291\n",
      "Validation Loss: 0.0904\n",
      "Epoch [26/50], Class Loss: 0.0133, JMMD Loss: 0.2279\n",
      "Validation Loss: 0.0911\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.70%, Precision: 96.71%, Recall: 96.68%, F1 Score: 96.69%\n",
      "Target Domain Performance - Accuracy: 58.51%, Precision: 67.67%, Recall: 56.71%, F1 Score: 50.39%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 1.2434, JMMD Loss: 0.2130\n",
      "Validation Loss: 0.6879\n",
      "Epoch [2/50], Class Loss: 0.6112, JMMD Loss: 0.2675\n",
      "Validation Loss: 0.7139\n",
      "Epoch [3/50], Class Loss: 0.5722, JMMD Loss: 0.2629\n",
      "Validation Loss: 0.9763\n",
      "Epoch [4/50], Class Loss: 0.5662, JMMD Loss: 0.2387\n",
      "Validation Loss: 0.7619\n",
      "Epoch [5/50], Class Loss: 0.5311, JMMD Loss: 0.2188\n",
      "Validation Loss: 0.6162\n",
      "Epoch [6/50], Class Loss: 0.4543, JMMD Loss: 0.2401\n",
      "Validation Loss: 0.5405\n",
      "Epoch [7/50], Class Loss: 0.3145, JMMD Loss: 0.2987\n",
      "Validation Loss: 0.2207\n",
      "Epoch [8/50], Class Loss: 0.2966, JMMD Loss: 0.3172\n",
      "Validation Loss: 0.5852\n",
      "Epoch [9/50], Class Loss: 0.1448, JMMD Loss: 0.3139\n",
      "Validation Loss: 0.2103\n",
      "Epoch [10/50], Class Loss: 0.0839, JMMD Loss: 0.3158\n",
      "Validation Loss: 0.1264\n",
      "Epoch [11/50], Class Loss: 0.0392, JMMD Loss: 0.3089\n",
      "Validation Loss: 0.1004\n",
      "Epoch [12/50], Class Loss: 0.0341, JMMD Loss: 0.2997\n",
      "Validation Loss: 0.0967\n",
      "Epoch [13/50], Class Loss: 0.0295, JMMD Loss: 0.3061\n",
      "Validation Loss: 0.0952\n",
      "Epoch [14/50], Class Loss: 0.0266, JMMD Loss: 0.3135\n",
      "Validation Loss: 0.0951\n",
      "Epoch [15/50], Class Loss: 0.0262, JMMD Loss: 0.2981\n",
      "Validation Loss: 0.0963\n",
      "Epoch [16/50], Class Loss: 0.0247, JMMD Loss: 0.3043\n",
      "Validation Loss: 0.0945\n",
      "Epoch [17/50], Class Loss: 0.0228, JMMD Loss: 0.2860\n",
      "Validation Loss: 0.0926\n",
      "Epoch [18/50], Class Loss: 0.0190, JMMD Loss: 0.2847\n",
      "Validation Loss: 0.0960\n",
      "Epoch [19/50], Class Loss: 0.0192, JMMD Loss: 0.2787\n",
      "Validation Loss: 0.0912\n",
      "Epoch [20/50], Class Loss: 0.0190, JMMD Loss: 0.2783\n",
      "Validation Loss: 0.0916\n",
      "Epoch [21/50], Class Loss: 0.0154, JMMD Loss: 0.2704\n",
      "Validation Loss: 0.0921\n",
      "Epoch [22/50], Class Loss: 0.0148, JMMD Loss: 0.2807\n",
      "Validation Loss: 0.0912\n",
      "Epoch [23/50], Class Loss: 0.0156, JMMD Loss: 0.2829\n",
      "Validation Loss: 0.0905\n",
      "Epoch [24/50], Class Loss: 0.0136, JMMD Loss: 0.2840\n",
      "Validation Loss: 0.0917\n",
      "Epoch [25/50], Class Loss: 0.0148, JMMD Loss: 0.2825\n",
      "Validation Loss: 0.0927\n",
      "Epoch [26/50], Class Loss: 0.0143, JMMD Loss: 0.2767\n",
      "Validation Loss: 0.0916\n",
      "Epoch [27/50], Class Loss: 0.0135, JMMD Loss: 0.2782\n",
      "Validation Loss: 0.0920\n",
      "Epoch [28/50], Class Loss: 0.0136, JMMD Loss: 0.2774\n",
      "Validation Loss: 0.0907\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.34%, Precision: 96.38%, Recall: 96.30%, F1 Score: 96.34%\n",
      "Target Domain Performance - Accuracy: 56.53%, Precision: 68.21%, Recall: 54.62%, F1 Score: 47.75%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 1.2476, JMMD Loss: 0.2060\n",
      "Validation Loss: 0.6531\n",
      "Epoch [2/50], Class Loss: 0.6387, JMMD Loss: 0.2580\n",
      "Validation Loss: 1.4552\n",
      "Epoch [3/50], Class Loss: 0.5999, JMMD Loss: 0.2483\n",
      "Validation Loss: 0.5759\n",
      "Epoch [4/50], Class Loss: 0.5320, JMMD Loss: 0.2401\n",
      "Validation Loss: 0.5725\n",
      "Epoch [5/50], Class Loss: 0.5186, JMMD Loss: 0.2204\n",
      "Validation Loss: 0.5615\n",
      "Epoch [6/50], Class Loss: 0.4703, JMMD Loss: 0.2239\n",
      "Validation Loss: 0.4532\n",
      "Epoch [7/50], Class Loss: 0.3141, JMMD Loss: 0.2605\n",
      "Validation Loss: 0.2703\n",
      "Epoch [8/50], Class Loss: 0.1975, JMMD Loss: 0.2701\n",
      "Validation Loss: 0.1607\n",
      "Epoch [9/50], Class Loss: 0.1302, JMMD Loss: 0.2957\n",
      "Validation Loss: 0.2557\n",
      "Epoch [10/50], Class Loss: 0.1220, JMMD Loss: 0.3145\n",
      "Validation Loss: 0.1124\n",
      "Epoch [11/50], Class Loss: 0.0338, JMMD Loss: 0.3044\n",
      "Validation Loss: 0.1062\n",
      "Epoch [12/50], Class Loss: 0.0339, JMMD Loss: 0.2988\n",
      "Validation Loss: 0.1100\n",
      "Epoch [13/50], Class Loss: 0.0319, JMMD Loss: 0.3037\n",
      "Validation Loss: 0.1066\n",
      "Epoch [14/50], Class Loss: 0.0253, JMMD Loss: 0.2920\n",
      "Validation Loss: 0.1029\n",
      "Epoch [15/50], Class Loss: 0.0237, JMMD Loss: 0.2818\n",
      "Validation Loss: 0.0996\n",
      "Epoch [16/50], Class Loss: 0.0228, JMMD Loss: 0.2749\n",
      "Validation Loss: 0.1010\n",
      "Epoch [17/50], Class Loss: 0.0216, JMMD Loss: 0.2728\n",
      "Validation Loss: 0.0993\n",
      "Epoch [18/50], Class Loss: 0.0179, JMMD Loss: 0.2679\n",
      "Validation Loss: 0.1048\n",
      "Epoch [19/50], Class Loss: 0.0198, JMMD Loss: 0.2647\n",
      "Validation Loss: 0.0995\n",
      "Epoch [20/50], Class Loss: 0.0185, JMMD Loss: 0.2676\n",
      "Validation Loss: 0.1004\n",
      "Epoch [21/50], Class Loss: 0.0154, JMMD Loss: 0.2621\n",
      "Validation Loss: 0.0994\n",
      "Epoch [22/50], Class Loss: 0.0141, JMMD Loss: 0.2818\n",
      "Validation Loss: 0.0987\n",
      "Epoch [23/50], Class Loss: 0.0141, JMMD Loss: 0.2677\n",
      "Validation Loss: 0.0985\n",
      "Epoch [24/50], Class Loss: 0.0141, JMMD Loss: 0.2611\n",
      "Validation Loss: 0.0989\n",
      "Epoch [25/50], Class Loss: 0.0141, JMMD Loss: 0.2667\n",
      "Validation Loss: 0.0990\n",
      "Epoch [26/50], Class Loss: 0.0144, JMMD Loss: 0.2814\n",
      "Validation Loss: 0.0991\n",
      "Epoch [27/50], Class Loss: 0.0132, JMMD Loss: 0.2741\n",
      "Validation Loss: 0.0985\n",
      "Epoch [28/50], Class Loss: 0.0145, JMMD Loss: 0.2735\n",
      "Validation Loss: 0.0993\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.22%, Precision: 96.24%, Recall: 96.20%, F1 Score: 96.22%\n",
      "Target Domain Performance - Accuracy: 57.07%, Precision: 68.84%, Recall: 55.20%, F1 Score: 48.30%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 1.2355, JMMD Loss: 0.2105\n",
      "Validation Loss: 0.7441\n",
      "Epoch [2/50], Class Loss: 0.6538, JMMD Loss: 0.2740\n",
      "Validation Loss: 0.6114\n",
      "Epoch [3/50], Class Loss: 0.5874, JMMD Loss: 0.2735\n",
      "Validation Loss: 0.5640\n",
      "Epoch [4/50], Class Loss: 0.5444, JMMD Loss: 0.2458\n",
      "Validation Loss: 0.5628\n",
      "Epoch [5/50], Class Loss: 0.5155, JMMD Loss: 0.2260\n",
      "Validation Loss: 0.5208\n",
      "Epoch [6/50], Class Loss: 0.5406, JMMD Loss: 0.2058\n",
      "Validation Loss: 0.4859\n",
      "Epoch [7/50], Class Loss: 0.4267, JMMD Loss: 0.2308\n",
      "Validation Loss: 0.3458\n",
      "Epoch [8/50], Class Loss: 0.2159, JMMD Loss: 0.2812\n",
      "Validation Loss: 0.1791\n",
      "Epoch [9/50], Class Loss: 0.2135, JMMD Loss: 0.2907\n",
      "Validation Loss: 0.3308\n",
      "Epoch [10/50], Class Loss: 0.1187, JMMD Loss: 0.2874\n",
      "Validation Loss: 0.1738\n",
      "Epoch [11/50], Class Loss: 0.0540, JMMD Loss: 0.2734\n",
      "Validation Loss: 0.1023\n",
      "Epoch [12/50], Class Loss: 0.0436, JMMD Loss: 0.2611\n",
      "Validation Loss: 0.0978\n",
      "Epoch [13/50], Class Loss: 0.0432, JMMD Loss: 0.2780\n",
      "Validation Loss: 0.0968\n",
      "Epoch [14/50], Class Loss: 0.0386, JMMD Loss: 0.2781\n",
      "Validation Loss: 0.0950\n",
      "Epoch [15/50], Class Loss: 0.0373, JMMD Loss: 0.2805\n",
      "Validation Loss: 0.0929\n",
      "Epoch [16/50], Class Loss: 0.0316, JMMD Loss: 0.2661\n",
      "Validation Loss: 0.0913\n",
      "Epoch [17/50], Class Loss: 0.0298, JMMD Loss: 0.2698\n",
      "Validation Loss: 0.1006\n",
      "Epoch [18/50], Class Loss: 0.0292, JMMD Loss: 0.2683\n",
      "Validation Loss: 0.0890\n",
      "Epoch [19/50], Class Loss: 0.0262, JMMD Loss: 0.2741\n",
      "Validation Loss: 0.0947\n",
      "Epoch [20/50], Class Loss: 0.0268, JMMD Loss: 0.2702\n",
      "Validation Loss: 0.0879\n",
      "Epoch [21/50], Class Loss: 0.0211, JMMD Loss: 0.2589\n",
      "Validation Loss: 0.0862\n",
      "Epoch [22/50], Class Loss: 0.0189, JMMD Loss: 0.2722\n",
      "Validation Loss: 0.0865\n",
      "Epoch [23/50], Class Loss: 0.0197, JMMD Loss: 0.2704\n",
      "Validation Loss: 0.0863\n",
      "Epoch [24/50], Class Loss: 0.0210, JMMD Loss: 0.2681\n",
      "Validation Loss: 0.0861\n",
      "Epoch [25/50], Class Loss: 0.0210, JMMD Loss: 0.2631\n",
      "Validation Loss: 0.0859\n",
      "Epoch [26/50], Class Loss: 0.0199, JMMD Loss: 0.2639\n",
      "Validation Loss: 0.0870\n",
      "Epoch [27/50], Class Loss: 0.0207, JMMD Loss: 0.2611\n",
      "Validation Loss: 0.0856\n",
      "Epoch [28/50], Class Loss: 0.0198, JMMD Loss: 0.2684\n",
      "Validation Loss: 0.0873\n",
      "Epoch [29/50], Class Loss: 0.0206, JMMD Loss: 0.2593\n",
      "Validation Loss: 0.0855\n",
      "Epoch [30/50], Class Loss: 0.0192, JMMD Loss: 0.2624\n",
      "Validation Loss: 0.0850\n",
      "Epoch [31/50], Class Loss: 0.0195, JMMD Loss: 0.2617\n",
      "Validation Loss: 0.0850\n",
      "Epoch [32/50], Class Loss: 0.0189, JMMD Loss: 0.2643\n",
      "Validation Loss: 0.0848\n",
      "Epoch [33/50], Class Loss: 0.0187, JMMD Loss: 0.2711\n",
      "Validation Loss: 0.0848\n",
      "Epoch [34/50], Class Loss: 0.0178, JMMD Loss: 0.2663\n",
      "Validation Loss: 0.0848\n",
      "Epoch [35/50], Class Loss: 0.0187, JMMD Loss: 0.2760\n",
      "Validation Loss: 0.0850\n",
      "Epoch [36/50], Class Loss: 0.0183, JMMD Loss: 0.2644\n",
      "Validation Loss: 0.0848\n",
      "Epoch [37/50], Class Loss: 0.0188, JMMD Loss: 0.2629\n",
      "Validation Loss: 0.0847\n",
      "Epoch [38/50], Class Loss: 0.0193, JMMD Loss: 0.2705\n",
      "Validation Loss: 0.0847\n",
      "Epoch [39/50], Class Loss: 0.0186, JMMD Loss: 0.2559\n",
      "Validation Loss: 0.0846\n",
      "Epoch [40/50], Class Loss: 0.0198, JMMD Loss: 0.2705\n",
      "Validation Loss: 0.0847\n",
      "Epoch [41/50], Class Loss: 0.0191, JMMD Loss: 0.2593\n",
      "Validation Loss: 0.0847\n",
      "Epoch [42/50], Class Loss: 0.0180, JMMD Loss: 0.2584\n",
      "Validation Loss: 0.0847\n",
      "Epoch [43/50], Class Loss: 0.0197, JMMD Loss: 0.2689\n",
      "Validation Loss: 0.0847\n",
      "Epoch [44/50], Class Loss: 0.0189, JMMD Loss: 0.2601\n",
      "Validation Loss: 0.0847\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.40%, Precision: 96.41%, Recall: 96.39%, F1 Score: 96.40%\n",
      "Target Domain Performance - Accuracy: 56.35%, Precision: 68.11%, Recall: 54.43%, F1 Score: 47.41%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 1.2246, JMMD Loss: 0.2294\n",
      "Validation Loss: 0.9896\n",
      "Epoch [2/50], Class Loss: 0.6522, JMMD Loss: 0.2557\n",
      "Validation Loss: 0.6738\n",
      "Epoch [3/50], Class Loss: 0.6226, JMMD Loss: 0.2459\n",
      "Validation Loss: 0.6001\n",
      "Epoch [4/50], Class Loss: 0.5802, JMMD Loss: 0.2730\n",
      "Validation Loss: 0.6811\n",
      "Epoch [5/50], Class Loss: 0.5766, JMMD Loss: 0.2555\n",
      "Validation Loss: 0.9583\n",
      "Epoch [6/50], Class Loss: 0.5481, JMMD Loss: 0.2482\n",
      "Validation Loss: 0.4608\n",
      "Epoch [7/50], Class Loss: 0.3723, JMMD Loss: 0.2614\n",
      "Validation Loss: 0.3661\n",
      "Epoch [8/50], Class Loss: 0.2448, JMMD Loss: 0.3232\n",
      "Validation Loss: 0.2186\n",
      "Epoch [9/50], Class Loss: 0.1513, JMMD Loss: 0.3228\n",
      "Validation Loss: 0.1492\n",
      "Epoch [10/50], Class Loss: 0.2395, JMMD Loss: 0.3009\n",
      "Validation Loss: 0.2705\n",
      "Epoch [11/50], Class Loss: 0.1307, JMMD Loss: 0.3178\n",
      "Validation Loss: 0.1616\n",
      "Epoch [12/50], Class Loss: 0.0938, JMMD Loss: 0.3255\n",
      "Validation Loss: 0.1473\n",
      "Epoch [13/50], Class Loss: 0.0831, JMMD Loss: 0.3305\n",
      "Validation Loss: 0.1417\n",
      "Epoch [14/50], Class Loss: 0.0719, JMMD Loss: 0.3292\n",
      "Validation Loss: 0.1304\n",
      "Epoch [15/50], Class Loss: 0.0622, JMMD Loss: 0.3209\n",
      "Validation Loss: 0.1238\n",
      "Epoch [16/50], Class Loss: 0.0550, JMMD Loss: 0.3155\n",
      "Validation Loss: 0.1221\n",
      "Epoch [17/50], Class Loss: 0.0479, JMMD Loss: 0.3210\n",
      "Validation Loss: 0.1154\n",
      "Epoch [18/50], Class Loss: 0.0444, JMMD Loss: 0.3036\n",
      "Validation Loss: 0.1145\n",
      "Epoch [19/50], Class Loss: 0.0416, JMMD Loss: 0.3034\n",
      "Validation Loss: 0.1225\n",
      "Epoch [20/50], Class Loss: 0.0348, JMMD Loss: 0.3043\n",
      "Validation Loss: 0.1144\n",
      "Epoch [21/50], Class Loss: 0.0308, JMMD Loss: 0.3038\n",
      "Validation Loss: 0.1172\n",
      "Epoch [22/50], Class Loss: 0.0302, JMMD Loss: 0.3140\n",
      "Validation Loss: 0.1136\n",
      "Epoch [23/50], Class Loss: 0.0303, JMMD Loss: 0.3056\n",
      "Validation Loss: 0.1170\n",
      "Epoch [24/50], Class Loss: 0.0299, JMMD Loss: 0.3094\n",
      "Validation Loss: 0.1124\n",
      "Epoch [25/50], Class Loss: 0.0301, JMMD Loss: 0.3002\n",
      "Validation Loss: 0.1131\n",
      "Epoch [26/50], Class Loss: 0.0293, JMMD Loss: 0.3008\n",
      "Validation Loss: 0.1130\n",
      "Epoch [27/50], Class Loss: 0.0306, JMMD Loss: 0.3126\n",
      "Validation Loss: 0.1156\n",
      "Epoch [28/50], Class Loss: 0.0283, JMMD Loss: 0.3045\n",
      "Validation Loss: 0.1127\n",
      "Epoch [29/50], Class Loss: 0.0273, JMMD Loss: 0.2989\n",
      "Validation Loss: 0.1137\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 95.26%, Precision: 95.32%, Recall: 95.20%, F1 Score: 95.25%\n",
      "Target Domain Performance - Accuracy: 54.92%, Precision: 41.41%, Recall: 52.89%, F1 Score: 45.50%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 1.3160, JMMD Loss: 0.1885\n",
      "Validation Loss: 0.7772\n",
      "Epoch [2/50], Class Loss: 0.6589, JMMD Loss: 0.2596\n",
      "Validation Loss: 1.3058\n",
      "Epoch [3/50], Class Loss: 0.6326, JMMD Loss: 0.2707\n",
      "Validation Loss: 0.6566\n",
      "Epoch [4/50], Class Loss: 0.5774, JMMD Loss: 0.2594\n",
      "Validation Loss: 0.6388\n",
      "Epoch [5/50], Class Loss: 0.5118, JMMD Loss: 0.2388\n",
      "Validation Loss: 0.5326\n",
      "Epoch [6/50], Class Loss: 0.4343, JMMD Loss: 0.2237\n",
      "Validation Loss: 0.3690\n",
      "Epoch [7/50], Class Loss: 0.4303, JMMD Loss: 0.2939\n",
      "Validation Loss: 0.2569\n",
      "Epoch [8/50], Class Loss: 0.2340, JMMD Loss: 0.3474\n",
      "Validation Loss: 0.2618\n",
      "Epoch [9/50], Class Loss: 0.1848, JMMD Loss: 0.3047\n",
      "Validation Loss: 0.2403\n",
      "Epoch [10/50], Class Loss: 0.1240, JMMD Loss: 0.3014\n",
      "Validation Loss: 0.1338\n",
      "Epoch [11/50], Class Loss: 0.0503, JMMD Loss: 0.2829\n",
      "Validation Loss: 0.1069\n",
      "Epoch [12/50], Class Loss: 0.0466, JMMD Loss: 0.2938\n",
      "Validation Loss: 0.1085\n",
      "Epoch [13/50], Class Loss: 0.0409, JMMD Loss: 0.2866\n",
      "Validation Loss: 0.1019\n",
      "Epoch [14/50], Class Loss: 0.0421, JMMD Loss: 0.2807\n",
      "Validation Loss: 0.1056\n",
      "Epoch [15/50], Class Loss: 0.0359, JMMD Loss: 0.2784\n",
      "Validation Loss: 0.1107\n",
      "Epoch [16/50], Class Loss: 0.0340, JMMD Loss: 0.2804\n",
      "Validation Loss: 0.1152\n",
      "Epoch [17/50], Class Loss: 0.0338, JMMD Loss: 0.2778\n",
      "Validation Loss: 0.1063\n",
      "Epoch [18/50], Class Loss: 0.0294, JMMD Loss: 0.2650\n",
      "Validation Loss: 0.1176\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 95.50%, Precision: 95.86%, Recall: 95.35%, F1 Score: 95.46%\n",
      "Target Domain Performance - Accuracy: 54.38%, Precision: 65.82%, Recall: 52.31%, F1 Score: 45.02%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.3025, JMMD Loss: 0.1883\n",
      "Validation Loss: 0.7428\n",
      "Epoch [2/50], Class Loss: 0.6266, JMMD Loss: 0.2650\n",
      "Validation Loss: 0.6555\n",
      "Epoch [3/50], Class Loss: 0.5824, JMMD Loss: 0.2741\n",
      "Validation Loss: 0.5731\n",
      "Epoch [4/50], Class Loss: 0.5617, JMMD Loss: 0.2502\n",
      "Validation Loss: 0.6638\n",
      "Epoch [5/50], Class Loss: 0.5079, JMMD Loss: 0.2173\n",
      "Validation Loss: 0.5960\n",
      "Epoch [6/50], Class Loss: 0.4170, JMMD Loss: 0.2369\n",
      "Validation Loss: 1.4592\n",
      "Epoch [7/50], Class Loss: 0.2791, JMMD Loss: 0.3322\n",
      "Validation Loss: 0.1732\n",
      "Epoch [8/50], Class Loss: 0.2039, JMMD Loss: 0.3298\n",
      "Validation Loss: 0.1931\n",
      "Epoch [9/50], Class Loss: 0.1394, JMMD Loss: 0.3670\n",
      "Validation Loss: 0.2226\n",
      "Epoch [10/50], Class Loss: 0.0858, JMMD Loss: 0.3415\n",
      "Validation Loss: 0.7297\n",
      "Epoch [11/50], Class Loss: 0.0556, JMMD Loss: 0.3334\n",
      "Validation Loss: 0.0890\n",
      "Epoch [12/50], Class Loss: 0.0342, JMMD Loss: 0.3357\n",
      "Validation Loss: 0.0870\n",
      "Epoch [13/50], Class Loss: 0.0324, JMMD Loss: 0.3223\n",
      "Validation Loss: 0.0880\n",
      "Epoch [14/50], Class Loss: 0.0341, JMMD Loss: 0.3192\n",
      "Validation Loss: 0.0880\n",
      "Epoch [15/50], Class Loss: 0.0267, JMMD Loss: 0.3156\n",
      "Validation Loss: 0.0904\n",
      "Epoch [16/50], Class Loss: 0.0276, JMMD Loss: 0.3098\n",
      "Validation Loss: 0.0902\n",
      "Epoch [17/50], Class Loss: 0.0257, JMMD Loss: 0.3008\n",
      "Validation Loss: 0.0908\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.16%, Precision: 96.14%, Recall: 96.18%, F1 Score: 96.16%\n",
      "Target Domain Performance - Accuracy: 55.34%, Precision: 66.86%, Recall: 53.34%, F1 Score: 46.21%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 1.3628, JMMD Loss: 0.1981\n",
      "Validation Loss: 1.0739\n",
      "Epoch [2/50], Class Loss: 0.6718, JMMD Loss: 0.2522\n",
      "Validation Loss: 0.6418\n",
      "Epoch [3/50], Class Loss: 0.6068, JMMD Loss: 0.2534\n",
      "Validation Loss: 0.6067\n",
      "Epoch [4/50], Class Loss: 0.5793, JMMD Loss: 0.2527\n",
      "Validation Loss: 0.7045\n",
      "Epoch [5/50], Class Loss: 0.5293, JMMD Loss: 0.2473\n",
      "Validation Loss: 0.5526\n",
      "Epoch [6/50], Class Loss: 0.4849, JMMD Loss: 0.2221\n",
      "Validation Loss: 0.7195\n",
      "Epoch [7/50], Class Loss: 0.3727, JMMD Loss: 0.2500\n",
      "Validation Loss: 0.3612\n",
      "Epoch [8/50], Class Loss: 0.3344, JMMD Loss: 0.2994\n",
      "Validation Loss: 0.3776\n",
      "Epoch [9/50], Class Loss: 0.1542, JMMD Loss: 0.3039\n",
      "Validation Loss: 0.1675\n",
      "Epoch [10/50], Class Loss: 0.3149, JMMD Loss: 0.3011\n",
      "Validation Loss: 0.2142\n",
      "Epoch [11/50], Class Loss: 0.1142, JMMD Loss: 0.3060\n",
      "Validation Loss: 0.1665\n",
      "Epoch [12/50], Class Loss: 0.0891, JMMD Loss: 0.2990\n",
      "Validation Loss: 0.1479\n",
      "Epoch [13/50], Class Loss: 0.0754, JMMD Loss: 0.2995\n",
      "Validation Loss: 0.1418\n",
      "Epoch [14/50], Class Loss: 0.0637, JMMD Loss: 0.3076\n",
      "Validation Loss: 0.1310\n",
      "Epoch [15/50], Class Loss: 0.0561, JMMD Loss: 0.2924\n",
      "Validation Loss: 0.1278\n",
      "Epoch [16/50], Class Loss: 0.0478, JMMD Loss: 0.2906\n",
      "Validation Loss: 0.1211\n",
      "Epoch [17/50], Class Loss: 0.0476, JMMD Loss: 0.2950\n",
      "Validation Loss: 0.1359\n",
      "Epoch [18/50], Class Loss: 0.0374, JMMD Loss: 0.2923\n",
      "Validation Loss: 0.1306\n",
      "Epoch [19/50], Class Loss: 0.0394, JMMD Loss: 0.2818\n",
      "Validation Loss: 0.1143\n",
      "Epoch [20/50], Class Loss: 0.0338, JMMD Loss: 0.2823\n",
      "Validation Loss: 0.1196\n",
      "Epoch [21/50], Class Loss: 0.0283, JMMD Loss: 0.2789\n",
      "Validation Loss: 0.1132\n",
      "Epoch [22/50], Class Loss: 0.0276, JMMD Loss: 0.2716\n",
      "Validation Loss: 0.1132\n",
      "Epoch [23/50], Class Loss: 0.0289, JMMD Loss: 0.2743\n",
      "Validation Loss: 0.1131\n",
      "Epoch [24/50], Class Loss: 0.0270, JMMD Loss: 0.2708\n",
      "Validation Loss: 0.1163\n",
      "Epoch [25/50], Class Loss: 0.0270, JMMD Loss: 0.2793\n",
      "Validation Loss: 0.1152\n",
      "Epoch [26/50], Class Loss: 0.0273, JMMD Loss: 0.2803\n",
      "Validation Loss: 0.1148\n",
      "Epoch [27/50], Class Loss: 0.0260, JMMD Loss: 0.2737\n",
      "Validation Loss: 0.1155\n",
      "Epoch [28/50], Class Loss: 0.0268, JMMD Loss: 0.2738\n",
      "Validation Loss: 0.1127\n",
      "Epoch [29/50], Class Loss: 0.0265, JMMD Loss: 0.2746\n",
      "Validation Loss: 0.1138\n",
      "Epoch [30/50], Class Loss: 0.0271, JMMD Loss: 0.2715\n",
      "Validation Loss: 0.1132\n",
      "Epoch [31/50], Class Loss: 0.0260, JMMD Loss: 0.2775\n",
      "Validation Loss: 0.1136\n",
      "Epoch [32/50], Class Loss: 0.0255, JMMD Loss: 0.2762\n",
      "Validation Loss: 0.1139\n",
      "Epoch [33/50], Class Loss: 0.0252, JMMD Loss: 0.2737\n",
      "Validation Loss: 0.1132\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 95.56%, Precision: 95.62%, Recall: 95.51%, F1 Score: 95.55%\n",
      "Target Domain Performance - Accuracy: 55.58%, Precision: 54.64%, Recall: 53.60%, F1 Score: 46.38%\n",
      "\n",
      "Source performance: 96.02% 96.08% 95.98% 96.01%\n",
      "Target performance: 56.00% 63.61% 54.05% 47.03%\n",
      "\n",
      "Per-Class Accuracy on Target Domain (Mean over runs):\n",
      "  Class 0: 99.98%\n",
      "  Class 1: 0.61%\n",
      "  Class 2: 15.79%\n",
      "  Class 3: 99.80%\n",
      "SNR level: 10\n",
      "BASE\n",
      "\n",
      "Run 1/10\n",
      "Epoch 1/50, Train Loss: 0.9918, Train Acc: 0.5592, Val Loss: 0.7452, Val Acc: 0.6487\n",
      "Epoch 2/50, Train Loss: 0.6423, Train Acc: 0.7017, Val Loss: 0.8667, Val Acc: 0.6097\n",
      "Epoch 3/50, Train Loss: 0.6117, Train Acc: 0.7292, Val Loss: 0.5860, Val Acc: 0.7188\n",
      "Epoch 4/50, Train Loss: 0.6308, Train Acc: 0.7385, Val Loss: 0.6778, Val Acc: 0.6625\n",
      "Epoch 5/50, Train Loss: 0.4548, Train Acc: 0.8049, Val Loss: 0.6124, Val Acc: 0.7332\n",
      "Epoch 6/50, Train Loss: 0.4181, Train Acc: 0.8485, Val Loss: 0.1617, Val Acc: 0.9353\n",
      "Epoch 7/50, Train Loss: 0.2263, Train Acc: 0.9124, Val Loss: 0.1484, Val Acc: 0.9382\n",
      "Epoch 8/50, Train Loss: 0.2134, Train Acc: 0.9229, Val Loss: 0.7959, Val Acc: 0.7776\n",
      "Epoch 9/50, Train Loss: 0.1996, Train Acc: 0.9262, Val Loss: 0.2132, Val Acc: 0.9269\n",
      "Epoch 10/50, Train Loss: 0.2886, Train Acc: 0.9030, Val Loss: 1.1781, Val Acc: 0.7314\n",
      "Epoch 11/50, Train Loss: 0.1229, Train Acc: 0.9600, Val Loss: 0.0790, Val Acc: 0.9676\n",
      "Epoch 12/50, Train Loss: 0.0344, Train Acc: 0.9870, Val Loss: 0.0863, Val Acc: 0.9700\n",
      "Epoch 13/50, Train Loss: 0.0327, Train Acc: 0.9877, Val Loss: 0.0787, Val Acc: 0.9736\n",
      "Epoch 14/50, Train Loss: 0.0291, Train Acc: 0.9903, Val Loss: 0.0965, Val Acc: 0.9676\n",
      "Epoch 15/50, Train Loss: 0.0303, Train Acc: 0.9897, Val Loss: 0.0724, Val Acc: 0.9718\n",
      "Epoch 16/50, Train Loss: 0.0251, Train Acc: 0.9907, Val Loss: 0.0777, Val Acc: 0.9724\n",
      "Epoch 17/50, Train Loss: 0.0264, Train Acc: 0.9898, Val Loss: 0.0923, Val Acc: 0.9706\n",
      "Epoch 18/50, Train Loss: 0.0210, Train Acc: 0.9928, Val Loss: 0.0850, Val Acc: 0.9718\n",
      "Epoch 19/50, Train Loss: 0.0152, Train Acc: 0.9940, Val Loss: 0.1073, Val Acc: 0.9712\n",
      "Epoch 20/50, Train Loss: 0.0158, Train Acc: 0.9942, Val Loss: 0.0869, Val Acc: 0.9730\n",
      "Early stopping!\n",
      "\n",
      "Run 2/10\n",
      "Epoch 1/50, Train Loss: 1.2803, Train Acc: 0.4874, Val Loss: 0.9163, Val Acc: 0.6289\n",
      "Epoch 2/50, Train Loss: 0.6565, Train Acc: 0.6938, Val Loss: 0.6078, Val Acc: 0.7398\n",
      "Epoch 3/50, Train Loss: 0.6771, Train Acc: 0.7004, Val Loss: 0.6031, Val Acc: 0.7002\n",
      "Epoch 4/50, Train Loss: 0.5372, Train Acc: 0.7463, Val Loss: 0.4293, Val Acc: 0.8070\n",
      "Epoch 5/50, Train Loss: 0.5294, Train Acc: 0.8407, Val Loss: 0.6786, Val Acc: 0.7326\n",
      "Epoch 6/50, Train Loss: 0.3297, Train Acc: 0.8791, Val Loss: 0.2691, Val Acc: 0.8909\n",
      "Epoch 7/50, Train Loss: 0.3403, Train Acc: 0.8598, Val Loss: 0.2652, Val Acc: 0.8771\n",
      "Epoch 8/50, Train Loss: 0.2376, Train Acc: 0.8976, Val Loss: 0.3961, Val Acc: 0.8477\n",
      "Epoch 9/50, Train Loss: 0.2540, Train Acc: 0.9067, Val Loss: 0.1699, Val Acc: 0.9430\n",
      "Epoch 10/50, Train Loss: 0.1875, Train Acc: 0.9435, Val Loss: 0.2199, Val Acc: 0.9305\n",
      "Epoch 11/50, Train Loss: 0.0511, Train Acc: 0.9814, Val Loss: 0.0904, Val Acc: 0.9682\n",
      "Epoch 12/50, Train Loss: 0.0392, Train Acc: 0.9850, Val Loss: 0.0773, Val Acc: 0.9748\n",
      "Epoch 13/50, Train Loss: 0.0385, Train Acc: 0.9859, Val Loss: 0.0774, Val Acc: 0.9748\n",
      "Epoch 14/50, Train Loss: 0.0356, Train Acc: 0.9861, Val Loss: 0.0801, Val Acc: 0.9712\n",
      "Epoch 15/50, Train Loss: 0.0314, Train Acc: 0.9882, Val Loss: 0.1092, Val Acc: 0.9640\n",
      "Epoch 16/50, Train Loss: 0.0300, Train Acc: 0.9886, Val Loss: 0.0767, Val Acc: 0.9760\n",
      "Epoch 17/50, Train Loss: 0.0240, Train Acc: 0.9907, Val Loss: 0.0819, Val Acc: 0.9748\n",
      "Epoch 18/50, Train Loss: 0.0292, Train Acc: 0.9897, Val Loss: 0.0782, Val Acc: 0.9754\n",
      "Epoch 19/50, Train Loss: 0.0225, Train Acc: 0.9918, Val Loss: 0.0896, Val Acc: 0.9724\n",
      "Epoch 20/50, Train Loss: 0.0229, Train Acc: 0.9925, Val Loss: 0.0886, Val Acc: 0.9712\n",
      "Epoch 21/50, Train Loss: 0.0148, Train Acc: 0.9949, Val Loss: 0.0794, Val Acc: 0.9742\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 3/10\n",
      "Epoch 1/50, Train Loss: 1.0049, Train Acc: 0.5447, Val Loss: 0.7553, Val Acc: 0.6829\n",
      "Epoch 2/50, Train Loss: 0.6822, Train Acc: 0.6890, Val Loss: 1.8697, Val Acc: 0.3801\n",
      "Epoch 3/50, Train Loss: 0.6283, Train Acc: 0.7224, Val Loss: 2.7107, Val Acc: 0.7074\n",
      "Epoch 4/50, Train Loss: 0.6494, Train Acc: 0.7398, Val Loss: 0.5350, Val Acc: 0.7536\n",
      "Epoch 5/50, Train Loss: 0.4212, Train Acc: 0.8179, Val Loss: 0.5094, Val Acc: 0.7986\n",
      "Epoch 6/50, Train Loss: 0.3390, Train Acc: 0.8620, Val Loss: 0.3087, Val Acc: 0.8657\n",
      "Epoch 7/50, Train Loss: 0.3562, Train Acc: 0.8583, Val Loss: 0.3833, Val Acc: 0.8315\n",
      "Epoch 8/50, Train Loss: 0.3237, Train Acc: 0.8730, Val Loss: 0.3407, Val Acc: 0.8807\n",
      "Epoch 9/50, Train Loss: 0.2113, Train Acc: 0.9207, Val Loss: 0.1165, Val Acc: 0.9616\n",
      "Epoch 10/50, Train Loss: 0.1728, Train Acc: 0.9435, Val Loss: 0.1205, Val Acc: 0.9580\n",
      "Epoch 11/50, Train Loss: 0.0480, Train Acc: 0.9832, Val Loss: 0.0901, Val Acc: 0.9676\n",
      "Epoch 12/50, Train Loss: 0.0427, Train Acc: 0.9847, Val Loss: 0.0716, Val Acc: 0.9700\n",
      "Epoch 13/50, Train Loss: 0.0344, Train Acc: 0.9870, Val Loss: 0.0676, Val Acc: 0.9754\n",
      "Epoch 14/50, Train Loss: 0.0324, Train Acc: 0.9891, Val Loss: 0.1330, Val Acc: 0.9556\n",
      "Epoch 15/50, Train Loss: 0.0287, Train Acc: 0.9895, Val Loss: 0.1077, Val Acc: 0.9676\n",
      "Epoch 16/50, Train Loss: 0.0252, Train Acc: 0.9910, Val Loss: 0.0683, Val Acc: 0.9784\n",
      "Epoch 17/50, Train Loss: 0.0230, Train Acc: 0.9924, Val Loss: 0.0901, Val Acc: 0.9676\n",
      "Epoch 18/50, Train Loss: 0.0287, Train Acc: 0.9889, Val Loss: 0.0743, Val Acc: 0.9772\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 4/10\n",
      "Epoch 1/50, Train Loss: 1.2588, Train Acc: 0.4913, Val Loss: 0.9471, Val Acc: 0.5803\n",
      "Epoch 2/50, Train Loss: 0.6485, Train Acc: 0.6926, Val Loss: 0.5739, Val Acc: 0.7272\n",
      "Epoch 3/50, Train Loss: 0.5691, Train Acc: 0.7389, Val Loss: 0.5899, Val Acc: 0.7362\n",
      "Epoch 4/50, Train Loss: 0.5239, Train Acc: 0.7612, Val Loss: 0.6516, Val Acc: 0.7140\n",
      "Epoch 5/50, Train Loss: 0.4953, Train Acc: 0.8125, Val Loss: 0.1727, Val Acc: 0.9371\n",
      "Epoch 6/50, Train Loss: 0.4691, Train Acc: 0.8326, Val Loss: 0.4046, Val Acc: 0.8417\n",
      "Epoch 7/50, Train Loss: 0.3794, Train Acc: 0.8716, Val Loss: 0.3158, Val Acc: 0.8741\n",
      "Epoch 8/50, Train Loss: 0.3188, Train Acc: 0.8926, Val Loss: 0.1397, Val Acc: 0.9574\n",
      "Epoch 9/50, Train Loss: 0.1918, Train Acc: 0.9328, Val Loss: 0.2367, Val Acc: 0.9173\n",
      "Epoch 10/50, Train Loss: 0.2254, Train Acc: 0.9277, Val Loss: 0.1220, Val Acc: 0.9526\n",
      "Epoch 11/50, Train Loss: 0.0305, Train Acc: 0.9888, Val Loss: 0.1045, Val Acc: 0.9622\n",
      "Epoch 12/50, Train Loss: 0.0291, Train Acc: 0.9913, Val Loss: 0.0754, Val Acc: 0.9730\n",
      "Epoch 13/50, Train Loss: 0.0265, Train Acc: 0.9931, Val Loss: 0.1054, Val Acc: 0.9682\n",
      "Epoch 14/50, Train Loss: 0.0269, Train Acc: 0.9916, Val Loss: 0.0753, Val Acc: 0.9730\n",
      "Epoch 15/50, Train Loss: 0.0195, Train Acc: 0.9942, Val Loss: 0.1301, Val Acc: 0.9634\n",
      "Epoch 16/50, Train Loss: 0.0192, Train Acc: 0.9936, Val Loss: 0.0745, Val Acc: 0.9748\n",
      "Epoch 17/50, Train Loss: 0.0168, Train Acc: 0.9943, Val Loss: 0.1176, Val Acc: 0.9712\n",
      "Epoch 18/50, Train Loss: 0.0169, Train Acc: 0.9952, Val Loss: 0.0892, Val Acc: 0.9718\n",
      "Epoch 19/50, Train Loss: 0.0148, Train Acc: 0.9958, Val Loss: 0.0890, Val Acc: 0.9754\n",
      "Epoch 20/50, Train Loss: 0.0136, Train Acc: 0.9960, Val Loss: 0.0951, Val Acc: 0.9754\n",
      "Epoch 21/50, Train Loss: 0.0090, Train Acc: 0.9978, Val Loss: 0.0776, Val Acc: 0.9760\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 5/10\n",
      "Epoch 1/50, Train Loss: 1.0371, Train Acc: 0.5256, Val Loss: 0.7251, Val Acc: 0.6595\n",
      "Epoch 2/50, Train Loss: 0.6852, Train Acc: 0.6849, Val Loss: 0.6501, Val Acc: 0.6793\n",
      "Epoch 3/50, Train Loss: 0.7128, Train Acc: 0.7065, Val Loss: 0.5744, Val Acc: 0.7332\n",
      "Epoch 4/50, Train Loss: 0.6838, Train Acc: 0.7308, Val Loss: 0.5389, Val Acc: 0.7530\n",
      "Epoch 5/50, Train Loss: 0.4754, Train Acc: 0.7947, Val Loss: 0.2935, Val Acc: 0.8789\n",
      "Epoch 6/50, Train Loss: 0.4671, Train Acc: 0.8305, Val Loss: 0.2332, Val Acc: 0.9047\n",
      "Epoch 7/50, Train Loss: 0.2300, Train Acc: 0.9027, Val Loss: 0.1609, Val Acc: 0.9406\n",
      "Epoch 8/50, Train Loss: 0.4080, Train Acc: 0.8530, Val Loss: 1.2138, Val Acc: 0.6499\n",
      "Epoch 9/50, Train Loss: 0.3833, Train Acc: 0.8628, Val Loss: 0.3408, Val Acc: 0.8765\n",
      "Epoch 10/50, Train Loss: 0.2335, Train Acc: 0.9202, Val Loss: 0.1345, Val Acc: 0.9484\n",
      "Epoch 11/50, Train Loss: 0.0529, Train Acc: 0.9801, Val Loss: 0.0867, Val Acc: 0.9676\n",
      "Epoch 12/50, Train Loss: 0.0433, Train Acc: 0.9835, Val Loss: 0.0902, Val Acc: 0.9670\n",
      "Epoch 13/50, Train Loss: 0.0435, Train Acc: 0.9844, Val Loss: 0.1918, Val Acc: 0.9442\n",
      "Epoch 14/50, Train Loss: 0.0406, Train Acc: 0.9861, Val Loss: 0.1301, Val Acc: 0.9616\n",
      "Epoch 15/50, Train Loss: 0.0306, Train Acc: 0.9886, Val Loss: 0.1560, Val Acc: 0.9526\n",
      "Epoch 16/50, Train Loss: 0.0351, Train Acc: 0.9859, Val Loss: 0.0770, Val Acc: 0.9724\n",
      "Epoch 17/50, Train Loss: 0.0293, Train Acc: 0.9901, Val Loss: 0.0800, Val Acc: 0.9730\n",
      "Epoch 18/50, Train Loss: 0.0286, Train Acc: 0.9912, Val Loss: 0.0861, Val Acc: 0.9718\n",
      "Epoch 19/50, Train Loss: 0.0238, Train Acc: 0.9912, Val Loss: 0.0890, Val Acc: 0.9712\n",
      "Epoch 20/50, Train Loss: 0.0270, Train Acc: 0.9904, Val Loss: 0.1381, Val Acc: 0.9622\n",
      "Epoch 21/50, Train Loss: 0.0159, Train Acc: 0.9940, Val Loss: 0.0820, Val Acc: 0.9724\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 6/10\n",
      "Epoch 1/50, Train Loss: 1.0819, Train Acc: 0.4991, Val Loss: 0.6300, Val Acc: 0.7026\n",
      "Epoch 2/50, Train Loss: 0.6645, Train Acc: 0.6926, Val Loss: 0.5783, Val Acc: 0.7452\n",
      "Epoch 3/50, Train Loss: 0.5917, Train Acc: 0.7473, Val Loss: 0.6794, Val Acc: 0.7080\n",
      "Epoch 4/50, Train Loss: 0.6119, Train Acc: 0.7332, Val Loss: 0.5421, Val Acc: 0.7266\n",
      "Epoch 5/50, Train Loss: 0.4674, Train Acc: 0.7951, Val Loss: 0.3828, Val Acc: 0.8351\n",
      "Epoch 6/50, Train Loss: 0.4001, Train Acc: 0.8311, Val Loss: 0.5888, Val Acc: 0.7332\n",
      "Epoch 7/50, Train Loss: 0.3255, Train Acc: 0.8728, Val Loss: 0.2258, Val Acc: 0.9011\n",
      "Epoch 8/50, Train Loss: 0.2237, Train Acc: 0.9213, Val Loss: 0.2437, Val Acc: 0.9197\n",
      "Epoch 9/50, Train Loss: 0.2361, Train Acc: 0.9150, Val Loss: 0.5017, Val Acc: 0.8495\n",
      "Epoch 10/50, Train Loss: 0.1864, Train Acc: 0.9349, Val Loss: 0.5189, Val Acc: 0.8489\n",
      "Epoch 11/50, Train Loss: 0.0742, Train Acc: 0.9745, Val Loss: 0.0850, Val Acc: 0.9676\n",
      "Epoch 12/50, Train Loss: 0.0322, Train Acc: 0.9891, Val Loss: 0.0821, Val Acc: 0.9682\n",
      "Epoch 13/50, Train Loss: 0.0359, Train Acc: 0.9870, Val Loss: 0.0765, Val Acc: 0.9718\n",
      "Epoch 14/50, Train Loss: 0.0317, Train Acc: 0.9891, Val Loss: 0.0796, Val Acc: 0.9754\n",
      "Epoch 15/50, Train Loss: 0.0267, Train Acc: 0.9904, Val Loss: 0.0872, Val Acc: 0.9724\n",
      "Epoch 16/50, Train Loss: 0.0222, Train Acc: 0.9931, Val Loss: 0.0780, Val Acc: 0.9748\n",
      "Epoch 17/50, Train Loss: 0.0195, Train Acc: 0.9934, Val Loss: 0.0760, Val Acc: 0.9784\n",
      "Epoch 18/50, Train Loss: 0.0177, Train Acc: 0.9943, Val Loss: 0.1108, Val Acc: 0.9664\n",
      "Epoch 19/50, Train Loss: 0.0158, Train Acc: 0.9949, Val Loss: 0.0790, Val Acc: 0.9736\n",
      "Epoch 20/50, Train Loss: 0.0152, Train Acc: 0.9939, Val Loss: 0.0723, Val Acc: 0.9760\n",
      "Epoch 21/50, Train Loss: 0.0089, Train Acc: 0.9969, Val Loss: 0.0720, Val Acc: 0.9766\n",
      "Epoch 22/50, Train Loss: 0.0092, Train Acc: 0.9967, Val Loss: 0.0720, Val Acc: 0.9748\n",
      "Epoch 23/50, Train Loss: 0.0099, Train Acc: 0.9963, Val Loss: 0.0780, Val Acc: 0.9754\n",
      "Epoch 24/50, Train Loss: 0.0079, Train Acc: 0.9973, Val Loss: 0.0737, Val Acc: 0.9766\n",
      "Epoch 25/50, Train Loss: 0.0091, Train Acc: 0.9970, Val Loss: 0.0729, Val Acc: 0.9766\n",
      "Epoch 26/50, Train Loss: 0.0077, Train Acc: 0.9969, Val Loss: 0.0718, Val Acc: 0.9754\n",
      "Epoch 27/50, Train Loss: 0.0075, Train Acc: 0.9975, Val Loss: 0.0741, Val Acc: 0.9772\n",
      "Epoch 28/50, Train Loss: 0.0088, Train Acc: 0.9972, Val Loss: 0.0723, Val Acc: 0.9790\n",
      "Epoch 29/50, Train Loss: 0.0095, Train Acc: 0.9969, Val Loss: 0.0723, Val Acc: 0.9766\n",
      "Epoch 30/50, Train Loss: 0.0072, Train Acc: 0.9978, Val Loss: 0.0725, Val Acc: 0.9760\n",
      "Epoch 31/50, Train Loss: 0.0058, Train Acc: 0.9982, Val Loss: 0.0727, Val Acc: 0.9760\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 7/10\n",
      "Epoch 1/50, Train Loss: 1.3475, Train Acc: 0.4894, Val Loss: 0.7871, Val Acc: 0.6631\n",
      "Epoch 2/50, Train Loss: 0.7572, Train Acc: 0.6639, Val Loss: 0.7051, Val Acc: 0.6894\n",
      "Epoch 3/50, Train Loss: 0.6441, Train Acc: 0.7094, Val Loss: 0.8570, Val Acc: 0.6037\n",
      "Epoch 4/50, Train Loss: 0.5937, Train Acc: 0.7322, Val Loss: 0.5882, Val Acc: 0.7440\n",
      "Epoch 5/50, Train Loss: 0.5549, Train Acc: 0.7599, Val Loss: 0.4592, Val Acc: 0.8046\n",
      "Epoch 6/50, Train Loss: 0.4278, Train Acc: 0.8484, Val Loss: 0.5137, Val Acc: 0.8082\n",
      "Epoch 7/50, Train Loss: 0.4768, Train Acc: 0.8421, Val Loss: 0.7315, Val Acc: 0.7518\n",
      "Epoch 8/50, Train Loss: 0.2981, Train Acc: 0.8877, Val Loss: 0.3251, Val Acc: 0.8741\n",
      "Epoch 9/50, Train Loss: 0.2528, Train Acc: 0.9202, Val Loss: 0.1588, Val Acc: 0.9353\n",
      "Epoch 10/50, Train Loss: 0.2145, Train Acc: 0.9210, Val Loss: 0.1049, Val Acc: 0.9598\n",
      "Epoch 11/50, Train Loss: 0.0509, Train Acc: 0.9811, Val Loss: 0.0833, Val Acc: 0.9694\n",
      "Epoch 12/50, Train Loss: 0.0418, Train Acc: 0.9855, Val Loss: 0.1282, Val Acc: 0.9580\n",
      "Epoch 13/50, Train Loss: 0.0362, Train Acc: 0.9871, Val Loss: 0.0829, Val Acc: 0.9718\n",
      "Epoch 14/50, Train Loss: 0.0342, Train Acc: 0.9886, Val Loss: 0.0933, Val Acc: 0.9706\n",
      "Epoch 15/50, Train Loss: 0.0264, Train Acc: 0.9913, Val Loss: 0.1159, Val Acc: 0.9634\n",
      "Epoch 16/50, Train Loss: 0.0264, Train Acc: 0.9918, Val Loss: 0.1083, Val Acc: 0.9670\n",
      "Epoch 17/50, Train Loss: 0.0232, Train Acc: 0.9934, Val Loss: 0.1147, Val Acc: 0.9646\n",
      "Epoch 18/50, Train Loss: 0.0210, Train Acc: 0.9930, Val Loss: 0.0812, Val Acc: 0.9730\n",
      "Epoch 19/50, Train Loss: 0.0201, Train Acc: 0.9946, Val Loss: 0.0832, Val Acc: 0.9754\n",
      "Epoch 20/50, Train Loss: 0.0199, Train Acc: 0.9945, Val Loss: 0.0859, Val Acc: 0.9736\n",
      "Epoch 21/50, Train Loss: 0.0110, Train Acc: 0.9967, Val Loss: 0.0828, Val Acc: 0.9742\n",
      "Epoch 22/50, Train Loss: 0.0102, Train Acc: 0.9973, Val Loss: 0.0822, Val Acc: 0.9766\n",
      "Epoch 23/50, Train Loss: 0.0097, Train Acc: 0.9969, Val Loss: 0.0823, Val Acc: 0.9772\n",
      "Early stopping!\n",
      "\n",
      "Run 8/10\n",
      "Epoch 1/50, Train Loss: 1.1875, Train Acc: 0.5001, Val Loss: 1.0001, Val Acc: 0.5102\n",
      "Epoch 2/50, Train Loss: 0.6624, Train Acc: 0.6956, Val Loss: 0.6739, Val Acc: 0.6541\n",
      "Epoch 3/50, Train Loss: 0.5923, Train Acc: 0.7328, Val Loss: 1.1525, Val Acc: 0.4988\n",
      "Epoch 4/50, Train Loss: 0.5861, Train Acc: 0.7443, Val Loss: 0.5567, Val Acc: 0.7272\n",
      "Epoch 5/50, Train Loss: 0.5781, Train Acc: 0.7618, Val Loss: 0.3746, Val Acc: 0.8231\n",
      "Epoch 6/50, Train Loss: 0.4945, Train Acc: 0.7918, Val Loss: 0.5664, Val Acc: 0.7404\n",
      "Epoch 7/50, Train Loss: 0.3525, Train Acc: 0.8466, Val Loss: 0.2054, Val Acc: 0.9167\n",
      "Epoch 8/50, Train Loss: 0.2238, Train Acc: 0.9127, Val Loss: 0.1781, Val Acc: 0.9323\n",
      "Epoch 9/50, Train Loss: 0.1933, Train Acc: 0.9300, Val Loss: 0.1040, Val Acc: 0.9562\n",
      "Epoch 10/50, Train Loss: 0.2950, Train Acc: 0.9066, Val Loss: 0.1450, Val Acc: 0.9514\n",
      "Epoch 11/50, Train Loss: 0.0413, Train Acc: 0.9847, Val Loss: 0.1056, Val Acc: 0.9616\n",
      "Epoch 12/50, Train Loss: 0.0409, Train Acc: 0.9858, Val Loss: 0.0917, Val Acc: 0.9694\n",
      "Epoch 13/50, Train Loss: 0.0351, Train Acc: 0.9877, Val Loss: 0.1424, Val Acc: 0.9562\n",
      "Epoch 14/50, Train Loss: 0.0310, Train Acc: 0.9889, Val Loss: 0.0849, Val Acc: 0.9718\n",
      "Epoch 15/50, Train Loss: 0.0249, Train Acc: 0.9922, Val Loss: 0.0816, Val Acc: 0.9730\n",
      "Epoch 16/50, Train Loss: 0.0245, Train Acc: 0.9927, Val Loss: 0.0799, Val Acc: 0.9742\n",
      "Epoch 17/50, Train Loss: 0.0272, Train Acc: 0.9913, Val Loss: 0.0873, Val Acc: 0.9748\n",
      "Epoch 18/50, Train Loss: 0.0202, Train Acc: 0.9930, Val Loss: 0.1038, Val Acc: 0.9682\n",
      "Epoch 19/50, Train Loss: 0.0187, Train Acc: 0.9939, Val Loss: 0.0883, Val Acc: 0.9760\n",
      "Epoch 20/50, Train Loss: 0.0168, Train Acc: 0.9948, Val Loss: 0.0917, Val Acc: 0.9748\n",
      "Epoch 21/50, Train Loss: 0.0105, Train Acc: 0.9967, Val Loss: 0.0879, Val Acc: 0.9754\n",
      "Early stopping!\n",
      "\n",
      "Run 9/10\n",
      "Epoch 1/50, Train Loss: 0.9946, Train Acc: 0.5678, Val Loss: 1.0210, Val Acc: 0.5048\n",
      "Epoch 2/50, Train Loss: 0.7558, Train Acc: 0.6524, Val Loss: 0.6720, Val Acc: 0.6691\n",
      "Epoch 3/50, Train Loss: 0.6345, Train Acc: 0.7137, Val Loss: 0.6236, Val Acc: 0.6984\n",
      "Epoch 4/50, Train Loss: 0.5530, Train Acc: 0.7630, Val Loss: 0.3674, Val Acc: 0.8279\n",
      "Epoch 5/50, Train Loss: 0.4306, Train Acc: 0.8301, Val Loss: 0.2464, Val Acc: 0.8981\n",
      "Epoch 6/50, Train Loss: 0.4818, Train Acc: 0.8005, Val Loss: 0.3277, Val Acc: 0.8627\n",
      "Epoch 7/50, Train Loss: 0.4929, Train Acc: 0.8311, Val Loss: 0.1919, Val Acc: 0.9329\n",
      "Epoch 8/50, Train Loss: 0.3277, Train Acc: 0.8805, Val Loss: 0.2693, Val Acc: 0.9053\n",
      "Epoch 9/50, Train Loss: 0.2996, Train Acc: 0.8941, Val Loss: 0.3232, Val Acc: 0.8927\n",
      "Epoch 10/50, Train Loss: 0.2709, Train Acc: 0.9099, Val Loss: 0.1703, Val Acc: 0.9341\n",
      "Epoch 11/50, Train Loss: 0.0534, Train Acc: 0.9801, Val Loss: 0.0814, Val Acc: 0.9724\n",
      "Epoch 12/50, Train Loss: 0.0406, Train Acc: 0.9850, Val Loss: 0.0962, Val Acc: 0.9658\n",
      "Epoch 13/50, Train Loss: 0.0344, Train Acc: 0.9885, Val Loss: 0.0779, Val Acc: 0.9736\n",
      "Epoch 14/50, Train Loss: 0.0272, Train Acc: 0.9903, Val Loss: 0.1176, Val Acc: 0.9598\n",
      "Epoch 15/50, Train Loss: 0.0243, Train Acc: 0.9906, Val Loss: 0.0695, Val Acc: 0.9748\n",
      "Epoch 16/50, Train Loss: 0.0225, Train Acc: 0.9922, Val Loss: 0.0835, Val Acc: 0.9730\n",
      "Epoch 17/50, Train Loss: 0.0222, Train Acc: 0.9918, Val Loss: 0.0697, Val Acc: 0.9748\n",
      "Epoch 18/50, Train Loss: 0.0174, Train Acc: 0.9946, Val Loss: 0.0704, Val Acc: 0.9748\n",
      "Epoch 19/50, Train Loss: 0.0155, Train Acc: 0.9948, Val Loss: 0.0824, Val Acc: 0.9742\n",
      "Epoch 20/50, Train Loss: 0.0169, Train Acc: 0.9943, Val Loss: 0.0714, Val Acc: 0.9754\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 10/10\n",
      "Epoch 1/50, Train Loss: 1.0405, Train Acc: 0.5541, Val Loss: 0.8118, Val Acc: 0.6037\n",
      "Epoch 2/50, Train Loss: 0.7676, Train Acc: 0.6531, Val Loss: 0.8347, Val Acc: 0.6409\n",
      "Epoch 3/50, Train Loss: 0.7070, Train Acc: 0.6800, Val Loss: 0.6836, Val Acc: 0.6906\n",
      "Epoch 4/50, Train Loss: 0.6404, Train Acc: 0.7073, Val Loss: 0.5757, Val Acc: 0.7398\n",
      "Epoch 5/50, Train Loss: 0.6309, Train Acc: 0.7320, Val Loss: 1.5125, Val Acc: 0.6709\n",
      "Epoch 6/50, Train Loss: 0.5385, Train Acc: 0.7606, Val Loss: 0.5177, Val Acc: 0.7770\n",
      "Epoch 7/50, Train Loss: 0.4837, Train Acc: 0.8143, Val Loss: 0.2269, Val Acc: 0.9035\n",
      "Epoch 8/50, Train Loss: 0.4449, Train Acc: 0.8238, Val Loss: 0.1882, Val Acc: 0.9191\n",
      "Epoch 9/50, Train Loss: 0.4990, Train Acc: 0.8266, Val Loss: 0.3138, Val Acc: 0.8663\n",
      "Epoch 10/50, Train Loss: 0.2514, Train Acc: 0.9048, Val Loss: 0.1351, Val Acc: 0.9460\n",
      "Epoch 11/50, Train Loss: 0.0690, Train Acc: 0.9729, Val Loss: 0.1003, Val Acc: 0.9586\n",
      "Epoch 12/50, Train Loss: 0.0541, Train Acc: 0.9802, Val Loss: 0.1212, Val Acc: 0.9556\n",
      "Epoch 13/50, Train Loss: 0.0541, Train Acc: 0.9795, Val Loss: 0.0904, Val Acc: 0.9634\n",
      "Epoch 14/50, Train Loss: 0.0511, Train Acc: 0.9807, Val Loss: 0.0879, Val Acc: 0.9652\n",
      "Epoch 15/50, Train Loss: 0.0422, Train Acc: 0.9864, Val Loss: 0.1024, Val Acc: 0.9610\n",
      "Epoch 16/50, Train Loss: 0.0379, Train Acc: 0.9858, Val Loss: 0.1075, Val Acc: 0.9664\n",
      "Epoch 17/50, Train Loss: 0.0332, Train Acc: 0.9880, Val Loss: 0.1115, Val Acc: 0.9598\n",
      "Epoch 18/50, Train Loss: 0.0265, Train Acc: 0.9909, Val Loss: 0.0964, Val Acc: 0.9700\n",
      "Epoch 19/50, Train Loss: 0.0328, Train Acc: 0.9897, Val Loss: 0.1527, Val Acc: 0.9556\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source performance: 97.33 97.39 97.29 97.32\n",
      "Target performance: 53.78 45.21 51.67 44.30\n",
      "\n",
      "bpsk: 100.00\n",
      "qpsk: 0.05\n",
      "16qam: 6.62\n",
      "16apsk: 100.00\n",
      "SNR level: 10\n",
      "DANN\n",
      "Epoch 1/50, Loss: 3.7504, Domain Loss: 1.6503, Class Loss: 2.1000\n",
      "Epoch 2/50, Loss: 2.6563, Domain Loss: 1.3751, Class Loss: 1.2812\n",
      "Epoch 3/50, Loss: 2.2237, Domain Loss: 1.4080, Class Loss: 0.8158\n",
      "Epoch 4/50, Loss: 2.0220, Domain Loss: 1.3678, Class Loss: 0.6542\n",
      "Epoch 5/50, Loss: 1.9369, Domain Loss: 1.3603, Class Loss: 0.5766\n",
      "Epoch 6/50, Loss: 1.9964, Domain Loss: 1.3503, Class Loss: 0.6461\n",
      "Epoch 7/50, Loss: 1.9709, Domain Loss: 1.3489, Class Loss: 0.6220\n",
      "Epoch 8/50, Loss: 1.9281, Domain Loss: 1.3387, Class Loss: 0.5894\n",
      "Epoch 9/50, Loss: 1.8879, Domain Loss: 1.3368, Class Loss: 0.5511\n",
      "Epoch 10/50, Loss: 1.8610, Domain Loss: 1.3395, Class Loss: 0.5215\n",
      "Epoch 11/50, Loss: 1.9192, Domain Loss: 1.3391, Class Loss: 0.5800\n",
      "Epoch 12/50, Loss: 1.8738, Domain Loss: 1.3293, Class Loss: 0.5445\n",
      "Epoch 13/50, Loss: 1.8624, Domain Loss: 1.2974, Class Loss: 0.5649\n",
      "Epoch 14/50, Loss: 1.8198, Domain Loss: 1.2695, Class Loss: 0.5503\n",
      "Epoch 15/50, Loss: 1.8183, Domain Loss: 1.2553, Class Loss: 0.5630\n",
      "Epoch 16/50, Loss: 1.7735, Domain Loss: 1.2641, Class Loss: 0.5094\n",
      "Epoch 17/50, Loss: 1.7636, Domain Loss: 1.2396, Class Loss: 0.5240\n",
      "Epoch 18/50, Loss: 1.7134, Domain Loss: 1.2311, Class Loss: 0.4823\n",
      "Epoch 19/50, Loss: 1.7636, Domain Loss: 1.2390, Class Loss: 0.5247\n",
      "Epoch 20/50, Loss: 1.8162, Domain Loss: 1.2532, Class Loss: 0.5630\n",
      "Epoch 21/50, Loss: 1.7746, Domain Loss: 1.2219, Class Loss: 0.5528\n",
      "Epoch 22/50, Loss: 1.7158, Domain Loss: 1.2405, Class Loss: 0.4753\n",
      "Epoch 23/50, Loss: 2.1862, Domain Loss: 1.5567, Class Loss: 0.6295\n",
      "Epoch 24/50, Loss: 14.4486, Domain Loss: 8.9807, Class Loss: 5.4679\n",
      "Epoch 25/50, Loss: 14.9012, Domain Loss: 13.0902, Class Loss: 1.8110\n",
      "Epoch 26/50, Loss: 10.7506, Domain Loss: 9.3823, Class Loss: 1.3683\n",
      "Epoch 27/50, Loss: 7.7476, Domain Loss: 6.4186, Class Loss: 1.3290\n",
      "Epoch 28/50, Loss: 6.1678, Domain Loss: 4.8594, Class Loss: 1.3084\n",
      "Epoch 29/50, Loss: 5.1168, Domain Loss: 4.0511, Class Loss: 1.0656\n",
      "Epoch 30/50, Loss: 3.8474, Domain Loss: 2.9304, Class Loss: 0.9170\n",
      "Epoch 31/50, Loss: 6.1451, Domain Loss: 5.3957, Class Loss: 0.7494\n",
      "Epoch 32/50, Loss: 8.0801, Domain Loss: 7.0657, Class Loss: 1.0144\n",
      "Epoch 33/50, Loss: 5.4245, Domain Loss: 4.6107, Class Loss: 0.8138\n",
      "Epoch 34/50, Loss: 3.3584, Domain Loss: 2.6979, Class Loss: 0.6605\n",
      "Epoch 35/50, Loss: 4.9832, Domain Loss: 4.3785, Class Loss: 0.6048\n",
      "Epoch 36/50, Loss: 6.6350, Domain Loss: 5.9914, Class Loss: 0.6437\n",
      "Epoch 37/50, Loss: 5.7566, Domain Loss: 5.1849, Class Loss: 0.5717\n",
      "Epoch 38/50, Loss: 4.3084, Domain Loss: 3.7434, Class Loss: 0.5650\n",
      "Epoch 39/50, Loss: 2.9286, Domain Loss: 2.3465, Class Loss: 0.5821\n",
      "Epoch 40/50, Loss: 3.1101, Domain Loss: 2.5012, Class Loss: 0.6089\n",
      "Epoch 41/50, Loss: 2.8115, Domain Loss: 2.2649, Class Loss: 0.5465\n",
      "Epoch 42/50, Loss: 2.9506, Domain Loss: 2.3318, Class Loss: 0.6188\n",
      "Epoch 43/50, Loss: 2.6901, Domain Loss: 2.1207, Class Loss: 0.5694\n",
      "Epoch 44/50, Loss: 3.0953, Domain Loss: 2.5138, Class Loss: 0.5814\n",
      "Epoch 45/50, Loss: 2.6612, Domain Loss: 2.0830, Class Loss: 0.5782\n",
      "Epoch 46/50, Loss: 2.7699, Domain Loss: 2.2184, Class Loss: 0.5515\n",
      "Epoch 47/50, Loss: 2.8011, Domain Loss: 2.2163, Class Loss: 0.5849\n",
      "Epoch 48/50, Loss: 2.4915, Domain Loss: 1.9415, Class Loss: 0.5500\n",
      "Epoch 49/50, Loss: 2.7245, Domain Loss: 2.1447, Class Loss: 0.5798\n",
      "Epoch 50/50, Loss: 2.7033, Domain Loss: 2.1405, Class Loss: 0.5628\n",
      "59.17\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.0810, Domain Loss: 1.9588, Class Loss: 2.1222\n",
      "Epoch 2/50, Loss: 2.7507, Domain Loss: 1.3737, Class Loss: 1.3770\n",
      "Epoch 3/50, Loss: 2.6817, Domain Loss: 1.3669, Class Loss: 1.3147\n",
      "Epoch 4/50, Loss: 2.4014, Domain Loss: 1.3872, Class Loss: 1.0142\n",
      "Epoch 5/50, Loss: 2.0731, Domain Loss: 1.3669, Class Loss: 0.7062\n",
      "Epoch 6/50, Loss: 1.9792, Domain Loss: 1.3492, Class Loss: 0.6299\n",
      "Epoch 7/50, Loss: 1.9311, Domain Loss: 1.3203, Class Loss: 0.6109\n",
      "Epoch 8/50, Loss: 1.9281, Domain Loss: 1.3043, Class Loss: 0.6238\n",
      "Epoch 9/50, Loss: 1.9922, Domain Loss: 1.3452, Class Loss: 0.6470\n",
      "Epoch 10/50, Loss: 1.8755, Domain Loss: 1.2778, Class Loss: 0.5977\n",
      "Epoch 11/50, Loss: 1.8420, Domain Loss: 1.2697, Class Loss: 0.5724\n",
      "Epoch 12/50, Loss: 1.8196, Domain Loss: 1.2642, Class Loss: 0.5555\n",
      "Epoch 13/50, Loss: 21.6029, Domain Loss: 19.1850, Class Loss: 2.4180\n",
      "Epoch 14/50, Loss: 112.8657, Domain Loss: 111.3471, Class Loss: 1.5186\n",
      "Epoch 15/50, Loss: 56.5452, Domain Loss: 55.1317, Class Loss: 1.4135\n",
      "Epoch 16/50, Loss: 11.7068, Domain Loss: 10.2972, Class Loss: 1.4096\n",
      "Epoch 17/50, Loss: 6.1594, Domain Loss: 4.7679, Class Loss: 1.3915\n",
      "Epoch 18/50, Loss: 5.3507, Domain Loss: 3.9618, Class Loss: 1.3888\n",
      "Epoch 19/50, Loss: 4.4877, Domain Loss: 3.0981, Class Loss: 1.3896\n",
      "Epoch 20/50, Loss: 4.6800, Domain Loss: 3.2940, Class Loss: 1.3860\n",
      "Epoch 21/50, Loss: 5.0973, Domain Loss: 3.7126, Class Loss: 1.3847\n",
      "Epoch 22/50, Loss: 5.8668, Domain Loss: 4.4612, Class Loss: 1.4057\n",
      "Epoch 23/50, Loss: 5.8325, Domain Loss: 4.4492, Class Loss: 1.3833\n",
      "Epoch 24/50, Loss: 4.6828, Domain Loss: 3.3192, Class Loss: 1.3636\n",
      "Epoch 25/50, Loss: 3.0608, Domain Loss: 1.7874, Class Loss: 1.2735\n",
      "Epoch 26/50, Loss: 2.8834, Domain Loss: 1.4664, Class Loss: 1.4170\n",
      "Epoch 27/50, Loss: 2.5480, Domain Loss: 1.4619, Class Loss: 1.0861\n",
      "Epoch 28/50, Loss: 2.5412, Domain Loss: 1.5762, Class Loss: 0.9650\n",
      "Epoch 29/50, Loss: 2.3413, Domain Loss: 1.4715, Class Loss: 0.8698\n",
      "Epoch 30/50, Loss: 2.2586, Domain Loss: 1.4821, Class Loss: 0.7765\n",
      "Epoch 31/50, Loss: 2.1895, Domain Loss: 1.4317, Class Loss: 0.7578\n",
      "Epoch 32/50, Loss: 2.0411, Domain Loss: 1.3587, Class Loss: 0.6823\n",
      "Epoch 33/50, Loss: 2.1668, Domain Loss: 1.4757, Class Loss: 0.6911\n",
      "Epoch 34/50, Loss: 2.2333, Domain Loss: 1.6027, Class Loss: 0.6306\n",
      "Epoch 35/50, Loss: 2.1188, Domain Loss: 1.4304, Class Loss: 0.6883\n",
      "Epoch 36/50, Loss: 1.9675, Domain Loss: 1.3694, Class Loss: 0.5982\n",
      "Epoch 37/50, Loss: 2.1092, Domain Loss: 1.3819, Class Loss: 0.7273\n",
      "Epoch 38/50, Loss: 2.0074, Domain Loss: 1.3865, Class Loss: 0.6208\n",
      "Epoch 39/50, Loss: 2.0200, Domain Loss: 1.4249, Class Loss: 0.5951\n",
      "Epoch 40/50, Loss: 2.2307, Domain Loss: 1.5462, Class Loss: 0.6845\n",
      "Epoch 41/50, Loss: 2.0717, Domain Loss: 1.4412, Class Loss: 0.6304\n",
      "Epoch 42/50, Loss: 2.0300, Domain Loss: 1.4132, Class Loss: 0.6168\n",
      "Epoch 43/50, Loss: 1.9174, Domain Loss: 1.3253, Class Loss: 0.5921\n",
      "Epoch 44/50, Loss: 1.9222, Domain Loss: 1.3343, Class Loss: 0.5879\n",
      "Epoch 45/50, Loss: 1.9189, Domain Loss: 1.3606, Class Loss: 0.5582\n",
      "Epoch 46/50, Loss: 2.0290, Domain Loss: 1.4263, Class Loss: 0.6027\n",
      "Epoch 47/50, Loss: 2.0287, Domain Loss: 1.4168, Class Loss: 0.6119\n",
      "Epoch 48/50, Loss: 2.1006, Domain Loss: 1.4954, Class Loss: 0.6052\n",
      "Epoch 49/50, Loss: 2.2405, Domain Loss: 1.6066, Class Loss: 0.6339\n",
      "Epoch 50/50, Loss: 1.9454, Domain Loss: 1.3666, Class Loss: 0.5789\n",
      "62.47\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.9254, Domain Loss: 2.0164, Class Loss: 1.9089\n",
      "Epoch 2/50, Loss: 2.6736, Domain Loss: 1.3826, Class Loss: 1.2910\n",
      "Epoch 3/50, Loss: 2.2274, Domain Loss: 1.3906, Class Loss: 0.8368\n",
      "Epoch 4/50, Loss: 1.9668, Domain Loss: 1.3591, Class Loss: 0.6076\n",
      "Epoch 5/50, Loss: 2.0954, Domain Loss: 1.3444, Class Loss: 0.7510\n",
      "Epoch 6/50, Loss: 1.8948, Domain Loss: 1.3195, Class Loss: 0.5753\n",
      "Epoch 7/50, Loss: 1.8881, Domain Loss: 1.3107, Class Loss: 0.5773\n",
      "Epoch 8/50, Loss: 1.8247, Domain Loss: 1.2945, Class Loss: 0.5302\n",
      "Epoch 9/50, Loss: 1.8353, Domain Loss: 1.2771, Class Loss: 0.5582\n",
      "Epoch 10/50, Loss: 1.8154, Domain Loss: 1.2846, Class Loss: 0.5308\n",
      "Epoch 11/50, Loss: 1.9200, Domain Loss: 1.3015, Class Loss: 0.6185\n",
      "Epoch 12/50, Loss: 1.8559, Domain Loss: 1.2792, Class Loss: 0.5767\n",
      "Epoch 13/50, Loss: 1.8064, Domain Loss: 1.2787, Class Loss: 0.5277\n",
      "Epoch 14/50, Loss: 1.7554, Domain Loss: 1.2444, Class Loss: 0.5110\n",
      "Epoch 15/50, Loss: 1.7619, Domain Loss: 1.2480, Class Loss: 0.5139\n",
      "Epoch 16/50, Loss: 1.8521, Domain Loss: 1.2636, Class Loss: 0.5885\n",
      "Epoch 17/50, Loss: 1.7604, Domain Loss: 1.2304, Class Loss: 0.5300\n",
      "Epoch 18/50, Loss: 1.7044, Domain Loss: 1.2327, Class Loss: 0.4717\n",
      "Epoch 19/50, Loss: 1.6417, Domain Loss: 1.2041, Class Loss: 0.4376\n",
      "Epoch 20/50, Loss: 1.6401, Domain Loss: 1.1983, Class Loss: 0.4419\n",
      "Epoch 21/50, Loss: 1.6690, Domain Loss: 1.2435, Class Loss: 0.4255\n",
      "Epoch 22/50, Loss: 1.7577, Domain Loss: 1.2924, Class Loss: 0.4654\n",
      "Epoch 23/50, Loss: 1.6535, Domain Loss: 1.2433, Class Loss: 0.4101\n",
      "Epoch 24/50, Loss: 1.6055, Domain Loss: 1.2290, Class Loss: 0.3765\n",
      "Epoch 25/50, Loss: 1.5512, Domain Loss: 1.2549, Class Loss: 0.2963\n",
      "Epoch 26/50, Loss: 1.5778, Domain Loss: 1.2994, Class Loss: 0.2784\n",
      "Epoch 27/50, Loss: 2.9600, Domain Loss: 2.0061, Class Loss: 0.9538\n",
      "Epoch 28/50, Loss: 62.5076, Domain Loss: 55.9382, Class Loss: 6.5694\n",
      "Epoch 29/50, Loss: 13.4800, Domain Loss: 11.9309, Class Loss: 1.5491\n",
      "Epoch 30/50, Loss: 2.7948, Domain Loss: 1.3969, Class Loss: 1.3978\n",
      "Epoch 31/50, Loss: 2.7817, Domain Loss: 1.3905, Class Loss: 1.3913\n",
      "Epoch 32/50, Loss: 2.7801, Domain Loss: 1.3897, Class Loss: 1.3904\n",
      "Epoch 33/50, Loss: 2.7773, Domain Loss: 1.3891, Class Loss: 1.3882\n",
      "Epoch 34/50, Loss: 2.7786, Domain Loss: 1.3886, Class Loss: 1.3900\n",
      "Epoch 35/50, Loss: 2.7776, Domain Loss: 1.3882, Class Loss: 1.3894\n",
      "Epoch 36/50, Loss: 2.7772, Domain Loss: 1.3878, Class Loss: 1.3893\n",
      "Epoch 37/50, Loss: 2.7783, Domain Loss: 1.3875, Class Loss: 1.3908\n",
      "Epoch 38/50, Loss: 2.7770, Domain Loss: 1.3873, Class Loss: 1.3897\n",
      "Epoch 39/50, Loss: 2.7765, Domain Loss: 1.3871, Class Loss: 1.3894\n",
      "Epoch 40/50, Loss: 2.7752, Domain Loss: 1.3869, Class Loss: 1.3882\n",
      "Epoch 41/50, Loss: 2.7752, Domain Loss: 1.3868, Class Loss: 1.3884\n",
      "Epoch 42/50, Loss: 2.7749, Domain Loss: 1.3867, Class Loss: 1.3882\n",
      "Epoch 43/50, Loss: 2.7757, Domain Loss: 1.3866, Class Loss: 1.3891\n",
      "Epoch 44/50, Loss: 2.7742, Domain Loss: 1.3865, Class Loss: 1.3876\n",
      "Epoch 45/50, Loss: 2.7752, Domain Loss: 1.3865, Class Loss: 1.3887\n",
      "Epoch 46/50, Loss: 2.7770, Domain Loss: 1.3864, Class Loss: 1.3905\n",
      "Epoch 47/50, Loss: 2.7742, Domain Loss: 1.3864, Class Loss: 1.3878\n",
      "Epoch 48/50, Loss: 2.7745, Domain Loss: 1.3864, Class Loss: 1.3881\n",
      "Epoch 49/50, Loss: 2.7742, Domain Loss: 1.3864, Class Loss: 1.3878\n",
      "Epoch 50/50, Loss: 2.7733, Domain Loss: 1.3863, Class Loss: 1.3870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.40\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.3807, Domain Loss: 2.0933, Class Loss: 2.2874\n",
      "Epoch 2/50, Loss: 2.7674, Domain Loss: 1.3778, Class Loss: 1.3896\n",
      "Epoch 3/50, Loss: 2.5549, Domain Loss: 1.4387, Class Loss: 1.1162\n",
      "Epoch 4/50, Loss: 2.2072, Domain Loss: 1.4407, Class Loss: 0.7665\n",
      "Epoch 5/50, Loss: 2.0972, Domain Loss: 1.3759, Class Loss: 0.7213\n",
      "Epoch 6/50, Loss: 2.0397, Domain Loss: 1.3501, Class Loss: 0.6896\n",
      "Epoch 7/50, Loss: 1.9771, Domain Loss: 1.3523, Class Loss: 0.6247\n",
      "Epoch 8/50, Loss: 1.9762, Domain Loss: 1.3866, Class Loss: 0.5896\n",
      "Epoch 9/50, Loss: 1.9038, Domain Loss: 1.3362, Class Loss: 0.5676\n",
      "Epoch 10/50, Loss: 1.8869, Domain Loss: 1.3174, Class Loss: 0.5694\n",
      "Epoch 11/50, Loss: 1.9323, Domain Loss: 1.2986, Class Loss: 0.6337\n",
      "Epoch 12/50, Loss: 1.9234, Domain Loss: 1.3908, Class Loss: 0.5326\n",
      "Epoch 13/50, Loss: 1.9370, Domain Loss: 1.3088, Class Loss: 0.6281\n",
      "Epoch 14/50, Loss: 1.9090, Domain Loss: 1.3164, Class Loss: 0.5926\n",
      "Epoch 15/50, Loss: 1.8230, Domain Loss: 1.3086, Class Loss: 0.5144\n",
      "Epoch 16/50, Loss: 1.7646, Domain Loss: 1.2665, Class Loss: 0.4980\n",
      "Epoch 17/50, Loss: 1.8053, Domain Loss: 1.2748, Class Loss: 0.5305\n",
      "Epoch 18/50, Loss: 1.7882, Domain Loss: 1.2519, Class Loss: 0.5364\n",
      "Epoch 19/50, Loss: 1.7813, Domain Loss: 1.2782, Class Loss: 0.5031\n",
      "Epoch 20/50, Loss: 1.7299, Domain Loss: 1.2358, Class Loss: 0.4941\n",
      "Epoch 21/50, Loss: 1.6998, Domain Loss: 1.2404, Class Loss: 0.4595\n",
      "Epoch 22/50, Loss: 1.6867, Domain Loss: 1.2340, Class Loss: 0.4527\n",
      "Epoch 23/50, Loss: 1.7587, Domain Loss: 1.2498, Class Loss: 0.5089\n",
      "Epoch 24/50, Loss: 1.6797, Domain Loss: 1.2193, Class Loss: 0.4603\n",
      "Epoch 25/50, Loss: 1.7294, Domain Loss: 1.2489, Class Loss: 0.4805\n",
      "Epoch 26/50, Loss: 1.7420, Domain Loss: 1.1995, Class Loss: 0.5426\n",
      "Epoch 27/50, Loss: 1.6344, Domain Loss: 1.2241, Class Loss: 0.4104\n",
      "Epoch 28/50, Loss: 1.7368, Domain Loss: 1.2735, Class Loss: 0.4633\n",
      "Epoch 29/50, Loss: 1.6826, Domain Loss: 1.3136, Class Loss: 0.3690\n",
      "Epoch 30/50, Loss: 1.8999, Domain Loss: 1.3135, Class Loss: 0.5864\n",
      "Epoch 31/50, Loss: 1.9135, Domain Loss: 1.2339, Class Loss: 0.6796\n",
      "Epoch 32/50, Loss: 1.6327, Domain Loss: 1.2139, Class Loss: 0.4188\n",
      "Epoch 33/50, Loss: 1.6218, Domain Loss: 1.2095, Class Loss: 0.4124\n",
      "Epoch 34/50, Loss: 1.5677, Domain Loss: 1.2173, Class Loss: 0.3504\n",
      "Epoch 35/50, Loss: 1.6999, Domain Loss: 1.3400, Class Loss: 0.3598\n",
      "Epoch 36/50, Loss: 2.4755, Domain Loss: 1.6459, Class Loss: 0.8296\n",
      "Epoch 37/50, Loss: 5.9515, Domain Loss: 4.7018, Class Loss: 1.2497\n",
      "Epoch 38/50, Loss: 3.5253, Domain Loss: 2.3140, Class Loss: 1.2113\n",
      "Epoch 39/50, Loss: 2.0026, Domain Loss: 1.3869, Class Loss: 0.6157\n",
      "Epoch 40/50, Loss: 1.9000, Domain Loss: 1.3678, Class Loss: 0.5322\n",
      "Epoch 41/50, Loss: 1.8680, Domain Loss: 1.3691, Class Loss: 0.4989\n",
      "Epoch 42/50, Loss: 1.8876, Domain Loss: 1.3692, Class Loss: 0.5184\n",
      "Epoch 43/50, Loss: 1.7705, Domain Loss: 1.3619, Class Loss: 0.4085\n",
      "Epoch 44/50, Loss: 1.7710, Domain Loss: 1.3608, Class Loss: 0.4102\n",
      "Epoch 45/50, Loss: 1.7571, Domain Loss: 1.3572, Class Loss: 0.3999\n",
      "Epoch 46/50, Loss: 1.6587, Domain Loss: 1.3470, Class Loss: 0.3117\n",
      "Epoch 47/50, Loss: 1.6212, Domain Loss: 1.3406, Class Loss: 0.2807\n",
      "Epoch 48/50, Loss: 1.7723, Domain Loss: 1.3306, Class Loss: 0.4417\n",
      "Epoch 49/50, Loss: 1.6589, Domain Loss: 1.3209, Class Loss: 0.3380\n",
      "Epoch 50/50, Loss: 1.5464, Domain Loss: 1.3084, Class Loss: 0.2379\n",
      "70.08\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.9919, Domain Loss: 1.8149, Class Loss: 2.1770\n",
      "Epoch 2/50, Loss: 2.5402, Domain Loss: 1.3754, Class Loss: 1.1648\n",
      "Epoch 3/50, Loss: 2.1896, Domain Loss: 1.4166, Class Loss: 0.7730\n",
      "Epoch 4/50, Loss: 2.0390, Domain Loss: 1.3834, Class Loss: 0.6557\n",
      "Epoch 5/50, Loss: 1.9648, Domain Loss: 1.3587, Class Loss: 0.6061\n",
      "Epoch 6/50, Loss: 1.9987, Domain Loss: 1.3546, Class Loss: 0.6442\n",
      "Epoch 7/50, Loss: 1.9377, Domain Loss: 1.3387, Class Loss: 0.5990\n",
      "Epoch 8/50, Loss: 1.9059, Domain Loss: 1.3435, Class Loss: 0.5624\n",
      "Epoch 9/50, Loss: 1.9015, Domain Loss: 1.3362, Class Loss: 0.5653\n",
      "Epoch 10/50, Loss: 1.9029, Domain Loss: 1.3386, Class Loss: 0.5643\n",
      "Epoch 11/50, Loss: 1.8924, Domain Loss: 1.3237, Class Loss: 0.5687\n",
      "Epoch 12/50, Loss: 1.8920, Domain Loss: 1.3247, Class Loss: 0.5674\n",
      "Epoch 13/50, Loss: 1.8945, Domain Loss: 1.3386, Class Loss: 0.5558\n",
      "Epoch 14/50, Loss: 1.9252, Domain Loss: 1.3349, Class Loss: 0.5903\n",
      "Epoch 15/50, Loss: 1.8193, Domain Loss: 1.3330, Class Loss: 0.4863\n",
      "Epoch 16/50, Loss: 1.8987, Domain Loss: 1.3739, Class Loss: 0.5248\n",
      "Epoch 17/50, Loss: 41.8618, Domain Loss: 30.0638, Class Loss: 11.7980\n",
      "Epoch 18/50, Loss: 9.2970, Domain Loss: 6.9861, Class Loss: 2.3108\n",
      "Epoch 19/50, Loss: 2.9931, Domain Loss: 1.5327, Class Loss: 1.4604\n",
      "Epoch 20/50, Loss: 2.8511, Domain Loss: 1.3902, Class Loss: 1.4609\n",
      "Epoch 21/50, Loss: 2.7820, Domain Loss: 1.3838, Class Loss: 1.3982\n",
      "Epoch 22/50, Loss: 2.7627, Domain Loss: 1.3840, Class Loss: 1.3787\n",
      "Epoch 23/50, Loss: 2.7752, Domain Loss: 1.3847, Class Loss: 1.3905\n",
      "Epoch 24/50, Loss: 2.7938, Domain Loss: 1.3856, Class Loss: 1.4082\n",
      "Epoch 25/50, Loss: 2.7702, Domain Loss: 1.3869, Class Loss: 1.3833\n",
      "Epoch 26/50, Loss: 2.7696, Domain Loss: 1.3877, Class Loss: 1.3819\n",
      "Epoch 27/50, Loss: 2.7715, Domain Loss: 1.3894, Class Loss: 1.3821\n",
      "Epoch 28/50, Loss: 2.7706, Domain Loss: 1.3914, Class Loss: 1.3793\n",
      "Epoch 29/50, Loss: 2.8311, Domain Loss: 1.3933, Class Loss: 1.4377\n",
      "Epoch 30/50, Loss: 2.7661, Domain Loss: 1.3960, Class Loss: 1.3701\n",
      "Epoch 31/50, Loss: 2.7578, Domain Loss: 1.3974, Class Loss: 1.3603\n",
      "Epoch 32/50, Loss: 2.7830, Domain Loss: 1.4031, Class Loss: 1.3800\n",
      "Epoch 33/50, Loss: 2.6969, Domain Loss: 1.4066, Class Loss: 1.2903\n",
      "Epoch 34/50, Loss: 2.6217, Domain Loss: 1.4046, Class Loss: 1.2171\n",
      "Epoch 35/50, Loss: 2.3209, Domain Loss: 1.3784, Class Loss: 0.9425\n",
      "Epoch 36/50, Loss: 2.2376, Domain Loss: 1.3771, Class Loss: 0.8605\n",
      "Epoch 37/50, Loss: 2.0427, Domain Loss: 1.3727, Class Loss: 0.6699\n",
      "Epoch 38/50, Loss: 2.0088, Domain Loss: 1.3758, Class Loss: 0.6329\n",
      "Epoch 39/50, Loss: 1.9863, Domain Loss: 1.3693, Class Loss: 0.6170\n",
      "Epoch 40/50, Loss: 2.0199, Domain Loss: 1.3705, Class Loss: 0.6495\n",
      "Epoch 41/50, Loss: 1.9450, Domain Loss: 1.3617, Class Loss: 0.5833\n",
      "Epoch 42/50, Loss: 1.9543, Domain Loss: 1.3616, Class Loss: 0.5928\n",
      "Epoch 43/50, Loss: 1.8429, Domain Loss: 1.3504, Class Loss: 0.4924\n",
      "Epoch 44/50, Loss: 1.8974, Domain Loss: 1.3510, Class Loss: 0.5464\n",
      "Epoch 45/50, Loss: 1.8533, Domain Loss: 1.3383, Class Loss: 0.5151\n",
      "Epoch 46/50, Loss: 1.8469, Domain Loss: 1.3379, Class Loss: 0.5090\n",
      "Epoch 47/50, Loss: 1.8253, Domain Loss: 1.3360, Class Loss: 0.4893\n",
      "Epoch 48/50, Loss: 1.8698, Domain Loss: 1.3269, Class Loss: 0.5429\n",
      "Epoch 49/50, Loss: 1.8548, Domain Loss: 1.3348, Class Loss: 0.5201\n",
      "Epoch 50/50, Loss: 1.8425, Domain Loss: 1.3377, Class Loss: 0.5047\n",
      "52.82\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.1588, Domain Loss: 2.1119, Class Loss: 2.0469\n",
      "Epoch 2/50, Loss: 2.7342, Domain Loss: 1.3784, Class Loss: 1.3558\n",
      "Epoch 3/50, Loss: 2.5206, Domain Loss: 1.4103, Class Loss: 1.1103\n",
      "Epoch 4/50, Loss: 2.1161, Domain Loss: 1.3841, Class Loss: 0.7319\n",
      "Epoch 5/50, Loss: 2.0969, Domain Loss: 1.3696, Class Loss: 0.7273\n",
      "Epoch 6/50, Loss: 2.0121, Domain Loss: 1.3301, Class Loss: 0.6820\n",
      "Epoch 7/50, Loss: 1.9338, Domain Loss: 1.3362, Class Loss: 0.5976\n",
      "Epoch 8/50, Loss: 1.9015, Domain Loss: 1.2917, Class Loss: 0.6098\n",
      "Epoch 9/50, Loss: 1.9014, Domain Loss: 1.2931, Class Loss: 0.6082\n",
      "Epoch 10/50, Loss: 1.8678, Domain Loss: 1.2818, Class Loss: 0.5859\n",
      "Epoch 11/50, Loss: 1.8550, Domain Loss: 1.2936, Class Loss: 0.5614\n",
      "Epoch 12/50, Loss: 1.9076, Domain Loss: 1.2982, Class Loss: 0.6094\n",
      "Epoch 13/50, Loss: 1.8218, Domain Loss: 1.2777, Class Loss: 0.5440\n",
      "Epoch 14/50, Loss: 6.2901, Domain Loss: 2.5347, Class Loss: 3.7554\n",
      "Epoch 15/50, Loss: 8.1454, Domain Loss: 5.7236, Class Loss: 2.4219\n",
      "Epoch 16/50, Loss: 18.6544, Domain Loss: 17.1553, Class Loss: 1.4991\n",
      "Epoch 17/50, Loss: 11.1708, Domain Loss: 9.7874, Class Loss: 1.3833\n",
      "Epoch 18/50, Loss: 2.9843, Domain Loss: 1.6134, Class Loss: 1.3709\n",
      "Epoch 19/50, Loss: 2.7464, Domain Loss: 1.4166, Class Loss: 1.3298\n",
      "Epoch 20/50, Loss: 3.8347, Domain Loss: 2.5931, Class Loss: 1.2416\n",
      "Epoch 21/50, Loss: 74.4485, Domain Loss: 70.3364, Class Loss: 4.1121\n",
      "Epoch 22/50, Loss: 61.4459, Domain Loss: 60.0451, Class Loss: 1.4007\n",
      "Epoch 23/50, Loss: 13.4303, Domain Loss: 12.0433, Class Loss: 1.3870\n",
      "Epoch 24/50, Loss: 14.9254, Domain Loss: 13.5360, Class Loss: 1.3894\n",
      "Epoch 25/50, Loss: 18.9517, Domain Loss: 17.5616, Class Loss: 1.3901\n",
      "Epoch 26/50, Loss: 41.0193, Domain Loss: 39.6298, Class Loss: 1.3894\n",
      "Epoch 27/50, Loss: 21.0772, Domain Loss: 19.6863, Class Loss: 1.3909\n",
      "Epoch 28/50, Loss: 36.7321, Domain Loss: 35.3419, Class Loss: 1.3902\n",
      "Epoch 29/50, Loss: 34.0485, Domain Loss: 32.6590, Class Loss: 1.3895\n",
      "Epoch 30/50, Loss: 31.1474, Domain Loss: 29.7556, Class Loss: 1.3918\n",
      "Epoch 31/50, Loss: 28.4537, Domain Loss: 27.0679, Class Loss: 1.3858\n",
      "Epoch 32/50, Loss: 25.3464, Domain Loss: 23.9599, Class Loss: 1.3865\n",
      "Epoch 33/50, Loss: 22.8068, Domain Loss: 21.4090, Class Loss: 1.3978\n",
      "Epoch 34/50, Loss: 21.1476, Domain Loss: 19.7620, Class Loss: 1.3857\n",
      "Epoch 35/50, Loss: 19.2934, Domain Loss: 17.8347, Class Loss: 1.4587\n",
      "Epoch 36/50, Loss: 17.0282, Domain Loss: 15.6039, Class Loss: 1.4244\n",
      "Epoch 37/50, Loss: 9.1033, Domain Loss: 7.7126, Class Loss: 1.3908\n",
      "Epoch 38/50, Loss: 8.4411, Domain Loss: 7.0561, Class Loss: 1.3851\n",
      "Epoch 39/50, Loss: 7.0381, Domain Loss: 5.6554, Class Loss: 1.3827\n",
      "Epoch 40/50, Loss: 6.5083, Domain Loss: 5.1308, Class Loss: 1.3775\n",
      "Epoch 41/50, Loss: 5.8072, Domain Loss: 4.4358, Class Loss: 1.3715\n",
      "Epoch 42/50, Loss: 5.4369, Domain Loss: 4.0503, Class Loss: 1.3866\n",
      "Epoch 43/50, Loss: 5.1673, Domain Loss: 3.8194, Class Loss: 1.3479\n",
      "Epoch 44/50, Loss: 4.9383, Domain Loss: 3.6213, Class Loss: 1.3170\n",
      "Epoch 45/50, Loss: 4.7664, Domain Loss: 3.4629, Class Loss: 1.3035\n",
      "Epoch 46/50, Loss: 4.6336, Domain Loss: 3.4184, Class Loss: 1.2152\n",
      "Epoch 47/50, Loss: 4.4259, Domain Loss: 3.2302, Class Loss: 1.1957\n",
      "Epoch 48/50, Loss: 4.3382, Domain Loss: 3.1450, Class Loss: 1.1932\n",
      "Epoch 49/50, Loss: 4.3229, Domain Loss: 3.1422, Class Loss: 1.1807\n",
      "Epoch 50/50, Loss: 4.1130, Domain Loss: 2.9592, Class Loss: 1.1538\n",
      "59.83\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.4364, Domain Loss: 1.4862, Class Loss: 1.9502\n",
      "Epoch 2/50, Loss: 2.7040, Domain Loss: 1.3764, Class Loss: 1.3276\n",
      "Epoch 3/50, Loss: 2.4446, Domain Loss: 1.5014, Class Loss: 0.9432\n",
      "Epoch 4/50, Loss: 2.1893, Domain Loss: 1.4292, Class Loss: 0.7601\n",
      "Epoch 5/50, Loss: 2.0066, Domain Loss: 1.4105, Class Loss: 0.5961\n",
      "Epoch 6/50, Loss: 2.1107, Domain Loss: 1.3956, Class Loss: 0.7151\n",
      "Epoch 7/50, Loss: 2.0240, Domain Loss: 1.3866, Class Loss: 0.6374\n",
      "Epoch 8/50, Loss: 1.9631, Domain Loss: 1.3793, Class Loss: 0.5838\n",
      "Epoch 9/50, Loss: 1.9180, Domain Loss: 1.3502, Class Loss: 0.5678\n",
      "Epoch 10/50, Loss: 1.8573, Domain Loss: 1.3050, Class Loss: 0.5524\n",
      "Epoch 11/50, Loss: 1.8830, Domain Loss: 1.2988, Class Loss: 0.5842\n",
      "Epoch 12/50, Loss: 1.8428, Domain Loss: 1.2753, Class Loss: 0.5675\n",
      "Epoch 13/50, Loss: 1.8044, Domain Loss: 1.2700, Class Loss: 0.5344\n",
      "Epoch 14/50, Loss: 1.7772, Domain Loss: 1.2663, Class Loss: 0.5109\n",
      "Epoch 15/50, Loss: 1.7820, Domain Loss: 1.2558, Class Loss: 0.5261\n",
      "Epoch 16/50, Loss: 1.8649, Domain Loss: 1.2868, Class Loss: 0.5782\n",
      "Epoch 17/50, Loss: 1.9396, Domain Loss: 1.2933, Class Loss: 0.6463\n",
      "Epoch 18/50, Loss: 1.8916, Domain Loss: 1.3085, Class Loss: 0.5832\n",
      "Epoch 19/50, Loss: 1.7771, Domain Loss: 1.2716, Class Loss: 0.5055\n",
      "Epoch 20/50, Loss: 3.1540, Domain Loss: 1.5438, Class Loss: 1.6102\n",
      "Epoch 21/50, Loss: 2.2471, Domain Loss: 1.3486, Class Loss: 0.8985\n",
      "Epoch 22/50, Loss: 1.9548, Domain Loss: 1.3342, Class Loss: 0.6206\n",
      "Epoch 23/50, Loss: 1.8769, Domain Loss: 1.3243, Class Loss: 0.5526\n",
      "Epoch 24/50, Loss: 1.8899, Domain Loss: 1.2982, Class Loss: 0.5917\n",
      "Epoch 25/50, Loss: 1.8366, Domain Loss: 1.2826, Class Loss: 0.5540\n",
      "Epoch 26/50, Loss: 1.7939, Domain Loss: 1.2604, Class Loss: 0.5335\n",
      "Epoch 27/50, Loss: 1.8462, Domain Loss: 1.2557, Class Loss: 0.5904\n",
      "Epoch 28/50, Loss: 1.7823, Domain Loss: 1.2481, Class Loss: 0.5342\n",
      "Epoch 29/50, Loss: 1.7536, Domain Loss: 1.2362, Class Loss: 0.5173\n",
      "Epoch 30/50, Loss: 1.7876, Domain Loss: 1.2464, Class Loss: 0.5412\n",
      "Epoch 31/50, Loss: 1.8811, Domain Loss: 1.3282, Class Loss: 0.5529\n",
      "Epoch 32/50, Loss: 1.8166, Domain Loss: 1.2870, Class Loss: 0.5296\n",
      "Epoch 33/50, Loss: 1.8194, Domain Loss: 1.2489, Class Loss: 0.5705\n",
      "Epoch 34/50, Loss: 1.7430, Domain Loss: 1.2448, Class Loss: 0.4982\n",
      "Epoch 35/50, Loss: 1.7834, Domain Loss: 1.2613, Class Loss: 0.5220\n",
      "Epoch 36/50, Loss: 1.8730, Domain Loss: 1.2665, Class Loss: 0.6066\n",
      "Epoch 37/50, Loss: 1.7521, Domain Loss: 1.2372, Class Loss: 0.5149\n",
      "Epoch 38/50, Loss: 1.7042, Domain Loss: 1.2371, Class Loss: 0.4671\n",
      "Epoch 39/50, Loss: 1.7269, Domain Loss: 1.2826, Class Loss: 0.4443\n",
      "Epoch 40/50, Loss: 1.6807, Domain Loss: 1.2509, Class Loss: 0.4298\n",
      "Epoch 41/50, Loss: 1.6665, Domain Loss: 1.2660, Class Loss: 0.4005\n",
      "Epoch 42/50, Loss: 1.6050, Domain Loss: 1.2716, Class Loss: 0.3334\n",
      "Epoch 43/50, Loss: 1.7187, Domain Loss: 1.2621, Class Loss: 0.4566\n",
      "Epoch 44/50, Loss: 1.5426, Domain Loss: 1.2288, Class Loss: 0.3139\n",
      "Epoch 45/50, Loss: 1.4503, Domain Loss: 1.2262, Class Loss: 0.2242\n",
      "Epoch 46/50, Loss: 1.4642, Domain Loss: 1.2296, Class Loss: 0.2346\n",
      "Epoch 47/50, Loss: 1.5280, Domain Loss: 1.1993, Class Loss: 0.3287\n",
      "Epoch 48/50, Loss: 1.4530, Domain Loss: 1.2163, Class Loss: 0.2367\n",
      "Epoch 49/50, Loss: 1.4136, Domain Loss: 1.2031, Class Loss: 0.2105\n",
      "Epoch 50/50, Loss: 1.5559, Domain Loss: 1.2288, Class Loss: 0.3271\n",
      "67.45\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.9630, Domain Loss: 2.1297, Class Loss: 1.8332\n",
      "Epoch 2/50, Loss: 2.4403, Domain Loss: 1.4074, Class Loss: 1.0329\n",
      "Epoch 3/50, Loss: 2.0558, Domain Loss: 1.3804, Class Loss: 0.6754\n",
      "Epoch 4/50, Loss: 2.1007, Domain Loss: 1.3537, Class Loss: 0.7470\n",
      "Epoch 5/50, Loss: 2.0423, Domain Loss: 1.3395, Class Loss: 0.7028\n",
      "Epoch 6/50, Loss: 1.9347, Domain Loss: 1.3273, Class Loss: 0.6074\n",
      "Epoch 7/50, Loss: 1.8912, Domain Loss: 1.2946, Class Loss: 0.5966\n",
      "Epoch 8/50, Loss: 1.8686, Domain Loss: 1.3252, Class Loss: 0.5434\n",
      "Epoch 9/50, Loss: 1.8772, Domain Loss: 1.3296, Class Loss: 0.5476\n",
      "Epoch 10/50, Loss: 2.3418, Domain Loss: 1.7883, Class Loss: 0.5536\n",
      "Epoch 11/50, Loss: 5.1069, Domain Loss: 4.0768, Class Loss: 1.0301\n",
      "Epoch 12/50, Loss: 3.2547, Domain Loss: 2.1567, Class Loss: 1.0979\n",
      "Epoch 13/50, Loss: 3.0051, Domain Loss: 1.8725, Class Loss: 1.1325\n",
      "Epoch 14/50, Loss: 2.1043, Domain Loss: 1.3631, Class Loss: 0.7412\n",
      "Epoch 15/50, Loss: 2.0430, Domain Loss: 1.3592, Class Loss: 0.6839\n",
      "Epoch 16/50, Loss: 1.9700, Domain Loss: 1.3586, Class Loss: 0.6115\n",
      "Epoch 17/50, Loss: 1.9451, Domain Loss: 1.3529, Class Loss: 0.5922\n",
      "Epoch 18/50, Loss: 1.9393, Domain Loss: 1.3634, Class Loss: 0.5759\n",
      "Epoch 19/50, Loss: 1.9388, Domain Loss: 1.3630, Class Loss: 0.5759\n",
      "Epoch 20/50, Loss: 1.9333, Domain Loss: 1.3580, Class Loss: 0.5753\n",
      "Epoch 21/50, Loss: 1.9736, Domain Loss: 1.3619, Class Loss: 0.6117\n",
      "Epoch 22/50, Loss: 1.9061, Domain Loss: 1.3557, Class Loss: 0.5504\n",
      "Epoch 23/50, Loss: 1.9085, Domain Loss: 1.3574, Class Loss: 0.5511\n",
      "Epoch 24/50, Loss: 1.8911, Domain Loss: 1.3539, Class Loss: 0.5372\n",
      "Epoch 25/50, Loss: 1.8395, Domain Loss: 1.3453, Class Loss: 0.4942\n",
      "Epoch 26/50, Loss: 1.8900, Domain Loss: 1.3463, Class Loss: 0.5436\n",
      "Epoch 27/50, Loss: 1.8313, Domain Loss: 1.3302, Class Loss: 0.5011\n",
      "Epoch 28/50, Loss: 1.8161, Domain Loss: 1.3176, Class Loss: 0.4985\n",
      "Epoch 29/50, Loss: 1.8073, Domain Loss: 1.3116, Class Loss: 0.4956\n",
      "Epoch 30/50, Loss: 1.7817, Domain Loss: 1.3071, Class Loss: 0.4746\n",
      "Epoch 31/50, Loss: 1.7845, Domain Loss: 1.3049, Class Loss: 0.4796\n",
      "Epoch 32/50, Loss: 1.9395, Domain Loss: 1.3671, Class Loss: 0.5724\n",
      "Epoch 33/50, Loss: 1.9353, Domain Loss: 1.3991, Class Loss: 0.5363\n",
      "Epoch 34/50, Loss: 1.8128, Domain Loss: 1.3599, Class Loss: 0.4529\n",
      "Epoch 35/50, Loss: 1.9081, Domain Loss: 1.4534, Class Loss: 0.4547\n",
      "Epoch 36/50, Loss: 1.8634, Domain Loss: 1.3672, Class Loss: 0.4962\n",
      "Epoch 37/50, Loss: 1.8155, Domain Loss: 1.3602, Class Loss: 0.4553\n",
      "Epoch 38/50, Loss: 1.8693, Domain Loss: 1.3577, Class Loss: 0.5115\n",
      "Epoch 39/50, Loss: 1.8785, Domain Loss: 1.3553, Class Loss: 0.5232\n",
      "Epoch 40/50, Loss: 1.7582, Domain Loss: 1.3514, Class Loss: 0.4068\n",
      "Epoch 41/50, Loss: 1.7150, Domain Loss: 1.3442, Class Loss: 0.3708\n",
      "Epoch 42/50, Loss: 1.6558, Domain Loss: 1.3382, Class Loss: 0.3177\n",
      "Epoch 43/50, Loss: 1.6491, Domain Loss: 1.3381, Class Loss: 0.3110\n",
      "Epoch 44/50, Loss: 1.6111, Domain Loss: 1.3150, Class Loss: 0.2961\n",
      "Epoch 45/50, Loss: 1.5555, Domain Loss: 1.3084, Class Loss: 0.2471\n",
      "Epoch 46/50, Loss: 1.5193, Domain Loss: 1.2911, Class Loss: 0.2282\n",
      "Epoch 47/50, Loss: 1.4884, Domain Loss: 1.2754, Class Loss: 0.2129\n",
      "Epoch 48/50, Loss: 1.5769, Domain Loss: 1.3216, Class Loss: 0.2553\n",
      "Epoch 49/50, Loss: 1.5625, Domain Loss: 1.3005, Class Loss: 0.2619\n",
      "Epoch 50/50, Loss: 1.5328, Domain Loss: 1.3008, Class Loss: 0.2320\n",
      "67.93\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.5688, Domain Loss: 1.8513, Class Loss: 1.7175\n",
      "Epoch 2/50, Loss: 2.5132, Domain Loss: 1.4898, Class Loss: 1.0233\n",
      "Epoch 3/50, Loss: 2.1749, Domain Loss: 1.4086, Class Loss: 0.7662\n",
      "Epoch 4/50, Loss: 2.1069, Domain Loss: 1.4164, Class Loss: 0.6904\n",
      "Epoch 5/50, Loss: 1.9899, Domain Loss: 1.3534, Class Loss: 0.6365\n",
      "Epoch 6/50, Loss: 1.9823, Domain Loss: 1.3401, Class Loss: 0.6423\n",
      "Epoch 7/50, Loss: 1.9816, Domain Loss: 1.3165, Class Loss: 0.6651\n",
      "Epoch 8/50, Loss: 1.9501, Domain Loss: 1.3422, Class Loss: 0.6079\n",
      "Epoch 9/50, Loss: 2.0337, Domain Loss: 1.3640, Class Loss: 0.6697\n",
      "Epoch 10/50, Loss: 1.9158, Domain Loss: 1.2966, Class Loss: 0.6192\n",
      "Epoch 11/50, Loss: 2.9950, Domain Loss: 1.5695, Class Loss: 1.4255\n",
      "Epoch 12/50, Loss: 2.3767, Domain Loss: 1.3661, Class Loss: 1.0105\n",
      "Epoch 13/50, Loss: 1.9787, Domain Loss: 1.3013, Class Loss: 0.6775\n",
      "Epoch 14/50, Loss: 1.9076, Domain Loss: 1.2949, Class Loss: 0.6127\n",
      "Epoch 15/50, Loss: 1.8755, Domain Loss: 1.2727, Class Loss: 0.6028\n",
      "Epoch 16/50, Loss: 1.8394, Domain Loss: 1.2569, Class Loss: 0.5824\n",
      "Epoch 17/50, Loss: 1.8171, Domain Loss: 1.2670, Class Loss: 0.5501\n",
      "Epoch 18/50, Loss: 1.8116, Domain Loss: 1.2840, Class Loss: 0.5276\n",
      "Epoch 19/50, Loss: 1.8281, Domain Loss: 1.3109, Class Loss: 0.5172\n",
      "Epoch 20/50, Loss: 1.8664, Domain Loss: 1.2968, Class Loss: 0.5696\n",
      "Epoch 21/50, Loss: 1.7878, Domain Loss: 1.2543, Class Loss: 0.5336\n",
      "Epoch 22/50, Loss: 1.7934, Domain Loss: 1.2700, Class Loss: 0.5234\n",
      "Epoch 23/50, Loss: 1.7694, Domain Loss: 1.2563, Class Loss: 0.5131\n",
      "Epoch 24/50, Loss: 1.8189, Domain Loss: 1.2965, Class Loss: 0.5224\n",
      "Epoch 25/50, Loss: 1.7712, Domain Loss: 1.2795, Class Loss: 0.4918\n",
      "Epoch 26/50, Loss: 1.8909, Domain Loss: 1.2812, Class Loss: 0.6097\n",
      "Epoch 27/50, Loss: 1.8913, Domain Loss: 1.2921, Class Loss: 0.5992\n",
      "Epoch 28/50, Loss: 1.8961, Domain Loss: 1.2780, Class Loss: 0.6181\n",
      "Epoch 29/50, Loss: 1.8485, Domain Loss: 1.2744, Class Loss: 0.5741\n",
      "Epoch 30/50, Loss: 1.7250, Domain Loss: 1.2632, Class Loss: 0.4618\n",
      "Epoch 31/50, Loss: 1.7198, Domain Loss: 1.2545, Class Loss: 0.4652\n",
      "Epoch 32/50, Loss: 1.8441, Domain Loss: 1.3626, Class Loss: 0.4815\n",
      "Epoch 33/50, Loss: 1.7638, Domain Loss: 1.3020, Class Loss: 0.4618\n",
      "Epoch 34/50, Loss: 1.7465, Domain Loss: 1.2733, Class Loss: 0.4732\n",
      "Epoch 35/50, Loss: 1.7474, Domain Loss: 1.2865, Class Loss: 0.4609\n",
      "Epoch 36/50, Loss: 1.7769, Domain Loss: 1.2524, Class Loss: 0.5244\n",
      "Epoch 37/50, Loss: 1.6438, Domain Loss: 1.2507, Class Loss: 0.3931\n",
      "Epoch 38/50, Loss: 1.5422, Domain Loss: 1.2243, Class Loss: 0.3179\n",
      "Epoch 39/50, Loss: 1.6185, Domain Loss: 1.2799, Class Loss: 0.3386\n",
      "Epoch 40/50, Loss: 1.5859, Domain Loss: 1.2335, Class Loss: 0.3524\n",
      "Epoch 41/50, Loss: 1.5392, Domain Loss: 1.2600, Class Loss: 0.2792\n",
      "Epoch 42/50, Loss: 1.4886, Domain Loss: 1.2507, Class Loss: 0.2380\n",
      "Epoch 43/50, Loss: 1.6219, Domain Loss: 1.2684, Class Loss: 0.3535\n",
      "Epoch 44/50, Loss: 1.4404, Domain Loss: 1.2303, Class Loss: 0.2100\n",
      "Epoch 45/50, Loss: 1.3902, Domain Loss: 1.2299, Class Loss: 0.1603\n",
      "Epoch 46/50, Loss: 1.4288, Domain Loss: 1.2322, Class Loss: 0.1966\n",
      "Epoch 47/50, Loss: 1.3613, Domain Loss: 1.2395, Class Loss: 0.1218\n",
      "Epoch 48/50, Loss: 1.3904, Domain Loss: 1.2383, Class Loss: 0.1521\n",
      "Epoch 49/50, Loss: 1.3800, Domain Loss: 1.2546, Class Loss: 0.1254\n",
      "Epoch 50/50, Loss: 1.3887, Domain Loss: 1.2539, Class Loss: 0.1348\n",
      "64.09\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.4850, Domain Loss: 1.7962, Class Loss: 1.6888\n",
      "Epoch 2/50, Loss: 2.4467, Domain Loss: 1.3778, Class Loss: 1.0689\n",
      "Epoch 3/50, Loss: 2.0353, Domain Loss: 1.3710, Class Loss: 0.6644\n",
      "Epoch 4/50, Loss: 2.0117, Domain Loss: 1.3498, Class Loss: 0.6619\n",
      "Epoch 5/50, Loss: 2.0148, Domain Loss: 1.3382, Class Loss: 0.6766\n",
      "Epoch 6/50, Loss: 1.9722, Domain Loss: 1.3552, Class Loss: 0.6171\n",
      "Epoch 7/50, Loss: 1.8619, Domain Loss: 1.2926, Class Loss: 0.5694\n",
      "Epoch 8/50, Loss: 1.8428, Domain Loss: 1.2644, Class Loss: 0.5784\n",
      "Epoch 9/50, Loss: 1.8517, Domain Loss: 1.2759, Class Loss: 0.5759\n",
      "Epoch 10/50, Loss: 1.8175, Domain Loss: 1.2736, Class Loss: 0.5439\n",
      "Epoch 11/50, Loss: 1.7533, Domain Loss: 1.2433, Class Loss: 0.5100\n",
      "Epoch 12/50, Loss: 1.7893, Domain Loss: 1.2552, Class Loss: 0.5341\n",
      "Epoch 13/50, Loss: 1.7994, Domain Loss: 1.2398, Class Loss: 0.5595\n",
      "Epoch 14/50, Loss: 1.8155, Domain Loss: 1.2434, Class Loss: 0.5721\n",
      "Epoch 15/50, Loss: 1.8364, Domain Loss: 1.2354, Class Loss: 0.6010\n",
      "Epoch 16/50, Loss: 1.7282, Domain Loss: 1.2350, Class Loss: 0.4932\n",
      "Epoch 17/50, Loss: 1.7036, Domain Loss: 1.2412, Class Loss: 0.4624\n",
      "Epoch 18/50, Loss: 1.8395, Domain Loss: 1.2712, Class Loss: 0.5683\n",
      "Epoch 19/50, Loss: 1.7752, Domain Loss: 1.2613, Class Loss: 0.5139\n",
      "Epoch 20/50, Loss: 1.7810, Domain Loss: 1.2519, Class Loss: 0.5291\n",
      "Epoch 21/50, Loss: 1.7034, Domain Loss: 1.2189, Class Loss: 0.4845\n",
      "Epoch 22/50, Loss: 3.4323, Domain Loss: 1.7342, Class Loss: 1.6980\n",
      "Epoch 23/50, Loss: 7.0846, Domain Loss: 2.3057, Class Loss: 4.7789\n",
      "Epoch 24/50, Loss: 1.9712, Domain Loss: 1.2950, Class Loss: 0.6762\n",
      "Epoch 25/50, Loss: 1.8750, Domain Loss: 1.2884, Class Loss: 0.5867\n",
      "Epoch 26/50, Loss: 1.8404, Domain Loss: 1.2767, Class Loss: 0.5637\n",
      "Epoch 27/50, Loss: 1.8361, Domain Loss: 1.2577, Class Loss: 0.5785\n",
      "Epoch 28/50, Loss: 1.8259, Domain Loss: 1.2675, Class Loss: 0.5584\n",
      "Epoch 29/50, Loss: 1.7316, Domain Loss: 1.2342, Class Loss: 0.4974\n",
      "Epoch 30/50, Loss: 1.8210, Domain Loss: 1.2634, Class Loss: 0.5576\n",
      "Epoch 31/50, Loss: 1.7805, Domain Loss: 1.2361, Class Loss: 0.5444\n",
      "Epoch 32/50, Loss: 1.7441, Domain Loss: 1.2472, Class Loss: 0.4969\n",
      "Epoch 33/50, Loss: 1.8080, Domain Loss: 1.2570, Class Loss: 0.5510\n",
      "Epoch 34/50, Loss: 1.7469, Domain Loss: 1.2409, Class Loss: 0.5060\n",
      "Epoch 35/50, Loss: 1.7596, Domain Loss: 1.2505, Class Loss: 0.5092\n",
      "Epoch 36/50, Loss: 1.6959, Domain Loss: 1.2303, Class Loss: 0.4656\n",
      "Epoch 37/50, Loss: 1.7131, Domain Loss: 1.2406, Class Loss: 0.4726\n",
      "Epoch 38/50, Loss: 1.7780, Domain Loss: 1.2728, Class Loss: 0.5052\n",
      "Epoch 39/50, Loss: 1.7406, Domain Loss: 1.2101, Class Loss: 0.5305\n",
      "Epoch 40/50, Loss: 1.7115, Domain Loss: 1.2401, Class Loss: 0.4714\n",
      "Epoch 41/50, Loss: 1.7360, Domain Loss: 1.2678, Class Loss: 0.4683\n",
      "Epoch 42/50, Loss: 1.8045, Domain Loss: 1.3030, Class Loss: 0.5015\n",
      "Epoch 43/50, Loss: 1.7039, Domain Loss: 1.2701, Class Loss: 0.4338\n",
      "Epoch 44/50, Loss: 1.6878, Domain Loss: 1.2760, Class Loss: 0.4118\n",
      "Epoch 45/50, Loss: 1.7566, Domain Loss: 1.3226, Class Loss: 0.4340\n",
      "Epoch 46/50, Loss: 2.1387, Domain Loss: 1.5515, Class Loss: 0.5871\n",
      "Epoch 47/50, Loss: 1.7642, Domain Loss: 1.3126, Class Loss: 0.4516\n",
      "Epoch 48/50, Loss: 1.8078, Domain Loss: 1.3667, Class Loss: 0.4411\n",
      "Epoch 49/50, Loss: 1.7004, Domain Loss: 1.3112, Class Loss: 0.3892\n",
      "Epoch 50/50, Loss: 1.4978, Domain Loss: 1.2188, Class Loss: 0.2790\n",
      "67.87\n",
      "\n",
      "\n",
      "Source performance:\n",
      "72.85 71.63 73.06 70.97 \n",
      "Target performance:\n",
      "59.61 59.92 58.64 54.17 \n",
      "\n",
      "Per-class target performance: 89.13 25.70 39.87 79.87 \n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 2.2181, Discrepancy Loss: 0.0622\n",
      "Validation Loss: 1.6424\n",
      "Epoch [2/50], Class Loss: 1.3909, Discrepancy Loss: 0.0347\n",
      "Validation Loss: 1.4827\n",
      "Epoch [3/50], Class Loss: 1.2771, Discrepancy Loss: 0.0280\n",
      "Validation Loss: 1.5970\n",
      "Epoch [4/50], Class Loss: 1.2175, Discrepancy Loss: 0.0278\n",
      "Validation Loss: 1.2071\n",
      "Epoch [5/50], Class Loss: 1.2372, Discrepancy Loss: 0.0373\n",
      "Validation Loss: 1.2324\n",
      "Epoch [6/50], Class Loss: 0.9999, Discrepancy Loss: 0.0331\n",
      "Validation Loss: 0.7078\n",
      "Epoch [7/50], Class Loss: 0.7170, Discrepancy Loss: 0.0235\n",
      "Validation Loss: 0.5359\n",
      "Epoch [8/50], Class Loss: 0.8553, Discrepancy Loss: 0.0195\n",
      "Validation Loss: 0.4301\n",
      "Epoch [9/50], Class Loss: 0.7894, Discrepancy Loss: 0.0229\n",
      "Validation Loss: 0.4972\n",
      "Epoch [10/50], Class Loss: 0.4686, Discrepancy Loss: 0.0158\n",
      "Validation Loss: 0.3971\n",
      "Epoch [11/50], Class Loss: 0.1125, Discrepancy Loss: 0.0090\n",
      "Validation Loss: 0.1925\n",
      "Epoch [12/50], Class Loss: 0.0830, Discrepancy Loss: 0.0066\n",
      "Validation Loss: 0.2097\n",
      "Epoch [13/50], Class Loss: 0.0847, Discrepancy Loss: 0.0053\n",
      "Validation Loss: 0.1938\n",
      "Epoch [14/50], Class Loss: 0.0647, Discrepancy Loss: 0.0052\n",
      "Validation Loss: 0.2059\n",
      "Epoch [15/50], Class Loss: 0.0490, Discrepancy Loss: 0.0047\n",
      "Validation Loss: 0.2010\n",
      "Epoch [16/50], Class Loss: 0.0281, Discrepancy Loss: 0.0054\n",
      "Validation Loss: 0.2337\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.16%, Precision: 96.21%, Recall: 96.24%, F1 Score: 96.17%\n",
      "Target Domain Performance - Accuracy: 54.02%, Precision: 52.91%, Recall: 51.93%, F1 Score: 44.59%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 2.2341, Discrepancy Loss: 0.0743\n",
      "Validation Loss: 1.2817\n",
      "Epoch [2/50], Class Loss: 1.5218, Discrepancy Loss: 0.0218\n",
      "Validation Loss: 1.4105\n",
      "Epoch [3/50], Class Loss: 1.3538, Discrepancy Loss: 0.0322\n",
      "Validation Loss: 1.2569\n",
      "Epoch [4/50], Class Loss: 1.2183, Discrepancy Loss: 0.0342\n",
      "Validation Loss: 1.2301\n",
      "Epoch [5/50], Class Loss: 1.2323, Discrepancy Loss: 0.0405\n",
      "Validation Loss: 1.1141\n",
      "Epoch [6/50], Class Loss: 1.1268, Discrepancy Loss: 0.0290\n",
      "Validation Loss: 1.0347\n",
      "Epoch [7/50], Class Loss: 0.9081, Discrepancy Loss: 0.0254\n",
      "Validation Loss: 0.5883\n",
      "Epoch [8/50], Class Loss: 0.6873, Discrepancy Loss: 0.0168\n",
      "Validation Loss: 2.1952\n",
      "Epoch [9/50], Class Loss: 0.5900, Discrepancy Loss: 0.0195\n",
      "Validation Loss: 0.5722\n",
      "Epoch [10/50], Class Loss: 0.5510, Discrepancy Loss: 0.0168\n",
      "Validation Loss: 0.1870\n",
      "Epoch [11/50], Class Loss: 0.0884, Discrepancy Loss: 0.0103\n",
      "Validation Loss: 0.2556\n",
      "Epoch [12/50], Class Loss: 0.0739, Discrepancy Loss: 0.0074\n",
      "Validation Loss: 0.2594\n",
      "Epoch [13/50], Class Loss: 0.0677, Discrepancy Loss: 0.0067\n",
      "Validation Loss: 0.2632\n",
      "Epoch [14/50], Class Loss: 0.0597, Discrepancy Loss: 0.0069\n",
      "Validation Loss: 0.1625\n",
      "Epoch [15/50], Class Loss: 0.0425, Discrepancy Loss: 0.0064\n",
      "Validation Loss: 0.2113\n",
      "Epoch [16/50], Class Loss: 0.0293, Discrepancy Loss: 0.0060\n",
      "Validation Loss: 0.1817\n",
      "Epoch [17/50], Class Loss: 0.0239, Discrepancy Loss: 0.0062\n",
      "Validation Loss: 0.1705\n",
      "Epoch [18/50], Class Loss: 0.0333, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.3987\n",
      "Epoch [19/50], Class Loss: 0.0238, Discrepancy Loss: 0.0080\n",
      "Validation Loss: 0.1659\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.48%, Precision: 97.50%, Recall: 97.46%, F1 Score: 97.48%\n",
      "Target Domain Performance - Accuracy: 53.48%, Precision: 39.68%, Recall: 51.35%, F1 Score: 43.72%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 2.3962, Discrepancy Loss: 0.0745\n",
      "Validation Loss: 1.3480\n",
      "Epoch [2/50], Class Loss: 1.3538, Discrepancy Loss: 0.0286\n",
      "Validation Loss: 1.3307\n",
      "Epoch [3/50], Class Loss: 1.2472, Discrepancy Loss: 0.0420\n",
      "Validation Loss: 1.4876\n",
      "Epoch [4/50], Class Loss: 1.1863, Discrepancy Loss: 0.0357\n",
      "Validation Loss: 1.0423\n",
      "Epoch [5/50], Class Loss: 1.1022, Discrepancy Loss: 0.0400\n",
      "Validation Loss: 0.9842\n",
      "Epoch [6/50], Class Loss: 1.2892, Discrepancy Loss: 0.0469\n",
      "Validation Loss: 1.1551\n",
      "Epoch [7/50], Class Loss: 0.7184, Discrepancy Loss: 0.0218\n",
      "Validation Loss: 0.3345\n",
      "Epoch [8/50], Class Loss: 0.7837, Discrepancy Loss: 0.0205\n",
      "Validation Loss: 0.3727\n",
      "Epoch [9/50], Class Loss: 0.7288, Discrepancy Loss: 0.0191\n",
      "Validation Loss: 1.4728\n",
      "Epoch [10/50], Class Loss: 0.3885, Discrepancy Loss: 0.0206\n",
      "Validation Loss: 0.2913\n",
      "Epoch [11/50], Class Loss: 0.0815, Discrepancy Loss: 0.0107\n",
      "Validation Loss: 0.2034\n",
      "Epoch [12/50], Class Loss: 0.0573, Discrepancy Loss: 0.0084\n",
      "Validation Loss: 0.2643\n",
      "Epoch [13/50], Class Loss: 0.0381, Discrepancy Loss: 0.0073\n",
      "Validation Loss: 0.2519\n",
      "Epoch [14/50], Class Loss: 0.0387, Discrepancy Loss: 0.0074\n",
      "Validation Loss: 0.2394\n",
      "Epoch [15/50], Class Loss: 0.0189, Discrepancy Loss: 0.0072\n",
      "Validation Loss: 0.3921\n",
      "Epoch [16/50], Class Loss: 0.0172, Discrepancy Loss: 0.0072\n",
      "Validation Loss: 0.2695\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.04%, Precision: 96.15%, Recall: 95.96%, F1 Score: 96.02%\n",
      "Target Domain Performance - Accuracy: 53.42%, Precision: 39.31%, Recall: 51.28%, F1 Score: 43.40%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 2.7840, Discrepancy Loss: 0.0998\n",
      "Validation Loss: 1.3483\n",
      "Epoch [2/50], Class Loss: 1.5075, Discrepancy Loss: 0.0308\n",
      "Validation Loss: 1.3252\n",
      "Epoch [3/50], Class Loss: 1.4512, Discrepancy Loss: 0.0452\n",
      "Validation Loss: 1.1614\n",
      "Epoch [4/50], Class Loss: 1.1872, Discrepancy Loss: 0.0383\n",
      "Validation Loss: 1.1850\n",
      "Epoch [5/50], Class Loss: 1.1460, Discrepancy Loss: 0.0396\n",
      "Validation Loss: 1.8697\n",
      "Epoch [6/50], Class Loss: 1.0343, Discrepancy Loss: 0.0441\n",
      "Validation Loss: 0.5393\n",
      "Epoch [7/50], Class Loss: 0.9337, Discrepancy Loss: 0.0218\n",
      "Validation Loss: 1.0862\n",
      "Epoch [8/50], Class Loss: 0.7901, Discrepancy Loss: 0.0310\n",
      "Validation Loss: 0.8900\n",
      "Epoch [9/50], Class Loss: 0.4477, Discrepancy Loss: 0.0155\n",
      "Validation Loss: 0.7504\n",
      "Epoch [10/50], Class Loss: 0.3251, Discrepancy Loss: 0.0152\n",
      "Validation Loss: 0.2373\n",
      "Epoch [11/50], Class Loss: 0.1062, Discrepancy Loss: 0.0096\n",
      "Validation Loss: 0.1768\n",
      "Epoch [12/50], Class Loss: 0.0748, Discrepancy Loss: 0.0074\n",
      "Validation Loss: 0.1671\n",
      "Epoch [13/50], Class Loss: 0.0559, Discrepancy Loss: 0.0059\n",
      "Validation Loss: 0.1883\n",
      "Epoch [14/50], Class Loss: 0.0558, Discrepancy Loss: 0.0058\n",
      "Validation Loss: 0.2115\n",
      "Epoch [15/50], Class Loss: 0.0511, Discrepancy Loss: 0.0054\n",
      "Validation Loss: 0.2251\n",
      "Epoch [16/50], Class Loss: 0.0327, Discrepancy Loss: 0.0044\n",
      "Validation Loss: 0.1604\n",
      "Epoch [17/50], Class Loss: 0.0197, Discrepancy Loss: 0.0041\n",
      "Validation Loss: 0.1726\n",
      "Epoch [18/50], Class Loss: 0.0138, Discrepancy Loss: 0.0040\n",
      "Validation Loss: 0.1716\n",
      "Epoch [19/50], Class Loss: 0.0237, Discrepancy Loss: 0.0042\n",
      "Validation Loss: 0.1952\n",
      "Epoch [20/50], Class Loss: 0.0143, Discrepancy Loss: 0.0042\n",
      "Validation Loss: 0.2525\n",
      "Epoch [21/50], Class Loss: 0.0079, Discrepancy Loss: 0.0044\n",
      "Validation Loss: 0.2070\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.06%, Precision: 97.08%, Recall: 97.03%, F1 Score: 97.05%\n",
      "Target Domain Performance - Accuracy: 53.24%, Precision: 39.18%, Recall: 51.09%, F1 Score: 43.26%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 2.2039, Discrepancy Loss: 0.0865\n",
      "Validation Loss: 1.3591\n",
      "Epoch [2/50], Class Loss: 1.5929, Discrepancy Loss: 0.0385\n",
      "Validation Loss: 1.3930\n",
      "Epoch [3/50], Class Loss: 1.3368, Discrepancy Loss: 0.0468\n",
      "Validation Loss: 2.2051\n",
      "Epoch [4/50], Class Loss: 1.2935, Discrepancy Loss: 0.0366\n",
      "Validation Loss: 1.1111\n",
      "Epoch [5/50], Class Loss: 1.2621, Discrepancy Loss: 0.0366\n",
      "Validation Loss: 1.8023\n",
      "Epoch [6/50], Class Loss: 1.1101, Discrepancy Loss: 0.0380\n",
      "Validation Loss: 0.8889\n",
      "Epoch [7/50], Class Loss: 0.7953, Discrepancy Loss: 0.0202\n",
      "Validation Loss: 0.4972\n",
      "Epoch [8/50], Class Loss: 0.6748, Discrepancy Loss: 0.0189\n",
      "Validation Loss: 0.3948\n",
      "Epoch [9/50], Class Loss: 0.4198, Discrepancy Loss: 0.0181\n",
      "Validation Loss: 1.5747\n",
      "Epoch [10/50], Class Loss: 0.5734, Discrepancy Loss: 0.0211\n",
      "Validation Loss: 0.5550\n",
      "Epoch [11/50], Class Loss: 0.1148, Discrepancy Loss: 0.0114\n",
      "Validation Loss: 0.2232\n",
      "Epoch [12/50], Class Loss: 0.0756, Discrepancy Loss: 0.0088\n",
      "Validation Loss: 0.2959\n",
      "Epoch [13/50], Class Loss: 0.0524, Discrepancy Loss: 0.0073\n",
      "Validation Loss: 0.2465\n",
      "Epoch [14/50], Class Loss: 0.0470, Discrepancy Loss: 0.0071\n",
      "Validation Loss: 0.2397\n",
      "Epoch [15/50], Class Loss: 0.0318, Discrepancy Loss: 0.0063\n",
      "Validation Loss: 0.2421\n",
      "Epoch [16/50], Class Loss: 0.0295, Discrepancy Loss: 0.0060\n",
      "Validation Loss: 0.2336\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.28%, Precision: 96.29%, Recall: 96.30%, F1 Score: 96.28%\n",
      "Target Domain Performance - Accuracy: 54.02%, Precision: 40.30%, Recall: 51.92%, F1 Score: 44.37%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 2.4859, Discrepancy Loss: 0.0699\n",
      "Validation Loss: 1.4190\n",
      "Epoch [2/50], Class Loss: 1.4583, Discrepancy Loss: 0.0499\n",
      "Validation Loss: 1.2849\n",
      "Epoch [3/50], Class Loss: 1.2099, Discrepancy Loss: 0.0447\n",
      "Validation Loss: 1.2700\n",
      "Epoch [4/50], Class Loss: 1.1752, Discrepancy Loss: 0.0438\n",
      "Validation Loss: 1.1981\n",
      "Epoch [5/50], Class Loss: 0.9549, Discrepancy Loss: 0.0364\n",
      "Validation Loss: 1.3583\n",
      "Epoch [6/50], Class Loss: 1.0456, Discrepancy Loss: 0.0268\n",
      "Validation Loss: 0.8075\n",
      "Epoch [7/50], Class Loss: 0.8722, Discrepancy Loss: 0.0181\n",
      "Validation Loss: 0.3895\n",
      "Epoch [8/50], Class Loss: 0.4513, Discrepancy Loss: 0.0103\n",
      "Validation Loss: 0.2747\n",
      "Epoch [9/50], Class Loss: 0.4134, Discrepancy Loss: 0.0116\n",
      "Validation Loss: 1.6338\n",
      "Epoch [10/50], Class Loss: 0.2925, Discrepancy Loss: 0.0129\n",
      "Validation Loss: 1.4196\n",
      "Epoch [11/50], Class Loss: 0.1345, Discrepancy Loss: 0.0061\n",
      "Validation Loss: 0.2002\n",
      "Epoch [12/50], Class Loss: 0.0863, Discrepancy Loss: 0.0053\n",
      "Validation Loss: 0.2406\n",
      "Epoch [13/50], Class Loss: 0.0643, Discrepancy Loss: 0.0035\n",
      "Validation Loss: 0.1732\n",
      "Epoch [14/50], Class Loss: 0.0677, Discrepancy Loss: 0.0033\n",
      "Validation Loss: 0.2700\n",
      "Epoch [15/50], Class Loss: 0.0654, Discrepancy Loss: 0.0031\n",
      "Validation Loss: 0.1940\n",
      "Epoch [16/50], Class Loss: 0.0496, Discrepancy Loss: 0.0032\n",
      "Validation Loss: 0.1804\n",
      "Epoch [17/50], Class Loss: 0.0467, Discrepancy Loss: 0.0033\n",
      "Validation Loss: 0.1794\n",
      "Epoch [18/50], Class Loss: 0.0352, Discrepancy Loss: 0.0028\n",
      "Validation Loss: 0.2398\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.58%, Precision: 96.64%, Recall: 96.68%, F1 Score: 96.58%\n",
      "Target Domain Performance - Accuracy: 55.28%, Precision: 66.83%, Recall: 53.26%, F1 Score: 46.30%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 2.0923, Discrepancy Loss: 0.0585\n",
      "Validation Loss: 1.8520\n",
      "Epoch [2/50], Class Loss: 1.5899, Discrepancy Loss: 0.0409\n",
      "Validation Loss: 1.9922\n",
      "Epoch [3/50], Class Loss: 1.2561, Discrepancy Loss: 0.0263\n",
      "Validation Loss: 1.3371\n",
      "Epoch [4/50], Class Loss: 1.2377, Discrepancy Loss: 0.0393\n",
      "Validation Loss: 1.5342\n",
      "Epoch [5/50], Class Loss: 1.1685, Discrepancy Loss: 0.0387\n",
      "Validation Loss: 1.0831\n",
      "Epoch [6/50], Class Loss: 1.0852, Discrepancy Loss: 0.0471\n",
      "Validation Loss: 4.7306\n",
      "Epoch [7/50], Class Loss: 1.2294, Discrepancy Loss: 0.0329\n",
      "Validation Loss: 1.1272\n",
      "Epoch [8/50], Class Loss: 0.8230, Discrepancy Loss: 0.0196\n",
      "Validation Loss: 0.5647\n",
      "Epoch [9/50], Class Loss: 0.5131, Discrepancy Loss: 0.0162\n",
      "Validation Loss: 0.4305\n",
      "Epoch [10/50], Class Loss: 0.6979, Discrepancy Loss: 0.0174\n",
      "Validation Loss: 0.7168\n",
      "Epoch [11/50], Class Loss: 0.1581, Discrepancy Loss: 0.0106\n",
      "Validation Loss: 0.2473\n",
      "Epoch [12/50], Class Loss: 0.1202, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.1945\n",
      "Epoch [13/50], Class Loss: 0.0865, Discrepancy Loss: 0.0047\n",
      "Validation Loss: 0.1786\n",
      "Epoch [14/50], Class Loss: 0.0810, Discrepancy Loss: 0.0042\n",
      "Validation Loss: 0.1827\n",
      "Epoch [15/50], Class Loss: 0.0601, Discrepancy Loss: 0.0045\n",
      "Validation Loss: 0.1660\n",
      "Epoch [16/50], Class Loss: 0.0589, Discrepancy Loss: 0.0043\n",
      "Validation Loss: 0.1736\n",
      "Epoch [17/50], Class Loss: 0.0405, Discrepancy Loss: 0.0045\n",
      "Validation Loss: 0.2350\n",
      "Epoch [18/50], Class Loss: 0.0387, Discrepancy Loss: 0.0046\n",
      "Validation Loss: 0.2394\n",
      "Epoch [19/50], Class Loss: 0.0266, Discrepancy Loss: 0.0041\n",
      "Validation Loss: 0.2700\n",
      "Epoch [20/50], Class Loss: 0.0301, Discrepancy Loss: 0.0047\n",
      "Validation Loss: 0.3107\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 95.68%, Precision: 95.98%, Recall: 95.56%, F1 Score: 95.65%\n",
      "Target Domain Performance - Accuracy: 53.06%, Precision: 38.85%, Recall: 50.90%, F1 Score: 42.95%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 2.6546, Discrepancy Loss: 0.0906\n",
      "Validation Loss: 1.5237\n",
      "Epoch [2/50], Class Loss: 1.6093, Discrepancy Loss: 0.0322\n",
      "Validation Loss: 1.6215\n",
      "Epoch [3/50], Class Loss: 1.3606, Discrepancy Loss: 0.0295\n",
      "Validation Loss: 1.1929\n",
      "Epoch [4/50], Class Loss: 1.1465, Discrepancy Loss: 0.0263\n",
      "Validation Loss: 1.2483\n",
      "Epoch [5/50], Class Loss: 1.2013, Discrepancy Loss: 0.0260\n",
      "Validation Loss: 1.1883\n",
      "Epoch [6/50], Class Loss: 1.0071, Discrepancy Loss: 0.0312\n",
      "Validation Loss: 0.9691\n",
      "Epoch [7/50], Class Loss: 1.0187, Discrepancy Loss: 0.0341\n",
      "Validation Loss: 0.5687\n",
      "Epoch [8/50], Class Loss: 0.5743, Discrepancy Loss: 0.0292\n",
      "Validation Loss: 0.6770\n",
      "Epoch [9/50], Class Loss: 0.7608, Discrepancy Loss: 0.0166\n",
      "Validation Loss: 1.0414\n",
      "Epoch [10/50], Class Loss: 0.6768, Discrepancy Loss: 0.0149\n",
      "Validation Loss: 0.4972\n",
      "Epoch [11/50], Class Loss: 0.1663, Discrepancy Loss: 0.0101\n",
      "Validation Loss: 0.2253\n",
      "Epoch [12/50], Class Loss: 0.1132, Discrepancy Loss: 0.0070\n",
      "Validation Loss: 0.2068\n",
      "Epoch [13/50], Class Loss: 0.0959, Discrepancy Loss: 0.0062\n",
      "Validation Loss: 0.2107\n",
      "Epoch [14/50], Class Loss: 0.0846, Discrepancy Loss: 0.0056\n",
      "Validation Loss: 0.1989\n",
      "Epoch [15/50], Class Loss: 0.0559, Discrepancy Loss: 0.0055\n",
      "Validation Loss: 0.2074\n",
      "Epoch [16/50], Class Loss: 0.0560, Discrepancy Loss: 0.0050\n",
      "Validation Loss: 0.2352\n",
      "Epoch [17/50], Class Loss: 0.0435, Discrepancy Loss: 0.0046\n",
      "Validation Loss: 0.2684\n",
      "Epoch [18/50], Class Loss: 0.0286, Discrepancy Loss: 0.0053\n",
      "Validation Loss: 0.2445\n",
      "Epoch [19/50], Class Loss: 0.0355, Discrepancy Loss: 0.0054\n",
      "Validation Loss: 0.2270\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.28%, Precision: 96.28%, Recall: 96.26%, F1 Score: 96.26%\n",
      "Target Domain Performance - Accuracy: 53.48%, Precision: 39.52%, Recall: 51.35%, F1 Score: 43.60%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 2.3583, Discrepancy Loss: 0.0584\n",
      "Validation Loss: 1.4627\n",
      "Epoch [2/50], Class Loss: 1.3516, Discrepancy Loss: 0.0331\n",
      "Validation Loss: 1.1810\n",
      "Epoch [3/50], Class Loss: 1.2438, Discrepancy Loss: 0.0227\n",
      "Validation Loss: 1.1260\n",
      "Epoch [4/50], Class Loss: 1.3883, Discrepancy Loss: 0.0274\n",
      "Validation Loss: 0.9370\n",
      "Epoch [5/50], Class Loss: 0.7916, Discrepancy Loss: 0.0160\n",
      "Validation Loss: 2.6550\n",
      "Epoch [6/50], Class Loss: 0.8437, Discrepancy Loss: 0.0214\n",
      "Validation Loss: 0.7929\n",
      "Epoch [7/50], Class Loss: 0.9189, Discrepancy Loss: 0.0231\n",
      "Validation Loss: 0.5193\n",
      "Epoch [8/50], Class Loss: 0.8291, Discrepancy Loss: 0.0262\n",
      "Validation Loss: 0.6081\n",
      "Epoch [9/50], Class Loss: 0.5091, Discrepancy Loss: 0.0248\n",
      "Validation Loss: 0.4269\n",
      "Epoch [10/50], Class Loss: 0.5360, Discrepancy Loss: 0.0133\n",
      "Validation Loss: 0.3645\n",
      "Epoch [11/50], Class Loss: 0.1084, Discrepancy Loss: 0.0073\n",
      "Validation Loss: 0.1615\n",
      "Epoch [12/50], Class Loss: 0.0915, Discrepancy Loss: 0.0051\n",
      "Validation Loss: 0.1466\n",
      "Epoch [13/50], Class Loss: 0.0694, Discrepancy Loss: 0.0043\n",
      "Validation Loss: 0.1995\n",
      "Epoch [14/50], Class Loss: 0.0712, Discrepancy Loss: 0.0037\n",
      "Validation Loss: 0.2094\n",
      "Epoch [15/50], Class Loss: 0.0669, Discrepancy Loss: 0.0040\n",
      "Validation Loss: 0.1748\n",
      "Epoch [16/50], Class Loss: 0.0555, Discrepancy Loss: 0.0032\n",
      "Validation Loss: 0.1548\n",
      "Epoch [17/50], Class Loss: 0.0527, Discrepancy Loss: 0.0038\n",
      "Validation Loss: 0.1546\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.30%, Precision: 97.30%, Recall: 97.30%, F1 Score: 97.30%\n",
      "Target Domain Performance - Accuracy: 54.08%, Precision: 65.56%, Recall: 51.99%, F1 Score: 44.74%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 2.2918, Discrepancy Loss: 0.0787\n",
      "Validation Loss: 1.9523\n",
      "Epoch [2/50], Class Loss: 1.4966, Discrepancy Loss: 0.0230\n",
      "Validation Loss: 1.2801\n",
      "Epoch [3/50], Class Loss: 1.3918, Discrepancy Loss: 0.0321\n",
      "Validation Loss: 1.5518\n",
      "Epoch [4/50], Class Loss: 1.1417, Discrepancy Loss: 0.0211\n",
      "Validation Loss: 1.1722\n",
      "Epoch [5/50], Class Loss: 1.0906, Discrepancy Loss: 0.0420\n",
      "Validation Loss: 1.1358\n",
      "Epoch [6/50], Class Loss: 0.9686, Discrepancy Loss: 0.0394\n",
      "Validation Loss: 1.1680\n",
      "Epoch [7/50], Class Loss: 1.2413, Discrepancy Loss: 0.0246\n",
      "Validation Loss: 0.7266\n",
      "Epoch [8/50], Class Loss: 0.7658, Discrepancy Loss: 0.0199\n",
      "Validation Loss: 2.7044\n",
      "Epoch [9/50], Class Loss: 0.8267, Discrepancy Loss: 0.0238\n",
      "Validation Loss: 1.0490\n",
      "Epoch [10/50], Class Loss: 0.4080, Discrepancy Loss: 0.0176\n",
      "Validation Loss: 0.7010\n",
      "Epoch [11/50], Class Loss: 0.1296, Discrepancy Loss: 0.0102\n",
      "Validation Loss: 0.2112\n",
      "Epoch [12/50], Class Loss: 0.0784, Discrepancy Loss: 0.0071\n",
      "Validation Loss: 0.2519\n",
      "Epoch [13/50], Class Loss: 0.0645, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.1914\n",
      "Epoch [14/50], Class Loss: 0.0741, Discrepancy Loss: 0.0063\n",
      "Validation Loss: 0.2022\n",
      "Epoch [15/50], Class Loss: 0.0403, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.1979\n",
      "Epoch [16/50], Class Loss: 0.0324, Discrepancy Loss: 0.0047\n",
      "Validation Loss: 0.2854\n",
      "Epoch [17/50], Class Loss: 0.0300, Discrepancy Loss: 0.0054\n",
      "Validation Loss: 0.2477\n",
      "Epoch [18/50], Class Loss: 0.0230, Discrepancy Loss: 0.0053\n",
      "Validation Loss: 0.2324\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.28%, Precision: 96.28%, Recall: 96.35%, F1 Score: 96.28%\n",
      "Target Domain Performance - Accuracy: 54.02%, Precision: 52.77%, Recall: 51.93%, F1 Score: 44.46%\n",
      "\n",
      "Source performance: 96.52% 96.57% 96.51% 96.51%\n",
      "Target performance: 53.81% 47.49% 51.70% 44.14%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.98%\n",
      "qpsk: 0.15%\n",
      "16qam: 6.74%\n",
      "16apsk: 99.93%\n",
      "SNR level: 10\n",
      "STAR\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 3.9945, Discrepancy Loss: 0.0743\n",
      "Epoch [2/50], Class Loss: 1.1729, Discrepancy Loss: 0.1029\n",
      "Epoch [3/50], Class Loss: 1.0490, Discrepancy Loss: 0.1018\n",
      "Epoch [4/50], Class Loss: 1.8366, Discrepancy Loss: 0.1099\n",
      "Epoch [5/50], Class Loss: 0.9142, Discrepancy Loss: 0.1083\n",
      "Epoch [6/50], Class Loss: 0.7640, Discrepancy Loss: 0.1107\n",
      "Epoch [7/50], Class Loss: 0.8505, Discrepancy Loss: 0.1171\n",
      "Epoch [8/50], Class Loss: 0.7136, Discrepancy Loss: 0.0911\n",
      "Epoch [9/50], Class Loss: 0.5782, Discrepancy Loss: 0.0922\n",
      "Epoch [10/50], Class Loss: 0.4166, Discrepancy Loss: 0.0758\n",
      "Epoch [11/50], Class Loss: 0.2415, Discrepancy Loss: 0.0692\n",
      "Epoch [12/50], Class Loss: 0.2148, Discrepancy Loss: 0.0602\n",
      "Epoch [13/50], Class Loss: 0.1867, Discrepancy Loss: 0.0585\n",
      "Epoch [14/50], Class Loss: 0.1775, Discrepancy Loss: 0.0565\n",
      "Epoch [15/50], Class Loss: 0.1543, Discrepancy Loss: 0.0548\n",
      "Epoch [16/50], Class Loss: 0.1452, Discrepancy Loss: 0.0563\n",
      "Epoch [17/50], Class Loss: 0.1374, Discrepancy Loss: 0.0596\n",
      "Epoch [18/50], Class Loss: 0.1445, Discrepancy Loss: 0.0613\n",
      "Epoch [19/50], Class Loss: 0.1343, Discrepancy Loss: 0.0665\n",
      "Epoch [20/50], Class Loss: 0.1639, Discrepancy Loss: 0.0647\n",
      "Epoch [21/50], Class Loss: 0.1400, Discrepancy Loss: 0.0664\n",
      "Epoch [22/50], Class Loss: 0.1251, Discrepancy Loss: 0.0644\n",
      "Epoch [23/50], Class Loss: 0.1211, Discrepancy Loss: 0.0673\n",
      "Epoch [24/50], Class Loss: 0.1096, Discrepancy Loss: 0.0630\n",
      "Epoch [25/50], Class Loss: 0.1101, Discrepancy Loss: 0.0687\n",
      "Epoch [26/50], Class Loss: 0.1001, Discrepancy Loss: 0.0716\n",
      "Epoch [27/50], Class Loss: 0.1030, Discrepancy Loss: 0.0713\n",
      "Epoch [28/50], Class Loss: 0.1044, Discrepancy Loss: 0.0692\n",
      "Epoch [29/50], Class Loss: 0.0995, Discrepancy Loss: 0.0708\n",
      "Epoch [30/50], Class Loss: 0.1204, Discrepancy Loss: 0.0625\n",
      "Epoch [31/50], Class Loss: 0.1167, Discrepancy Loss: 0.0708\n",
      "Epoch [32/50], Class Loss: 0.1094, Discrepancy Loss: 0.0792\n",
      "Epoch [33/50], Class Loss: 0.1104, Discrepancy Loss: 0.0697\n",
      "Epoch [34/50], Class Loss: 0.1012, Discrepancy Loss: 0.0667\n",
      "Epoch [35/50], Class Loss: 0.1094, Discrepancy Loss: 0.0817\n",
      "Epoch [36/50], Class Loss: 0.1110, Discrepancy Loss: 0.0712\n",
      "Epoch [37/50], Class Loss: 0.1246, Discrepancy Loss: 0.0731\n",
      "Epoch [38/50], Class Loss: 0.1197, Discrepancy Loss: 0.0719\n",
      "Epoch [39/50], Class Loss: 0.0928, Discrepancy Loss: 0.0737\n",
      "Epoch [40/50], Class Loss: 0.1010, Discrepancy Loss: 0.0679\n",
      "Epoch [41/50], Class Loss: 0.0966, Discrepancy Loss: 0.0760\n",
      "Epoch [42/50], Class Loss: 0.0935, Discrepancy Loss: 0.0723\n",
      "Epoch [43/50], Class Loss: 0.1107, Discrepancy Loss: 0.0752\n",
      "Epoch [44/50], Class Loss: 0.1076, Discrepancy Loss: 0.0750\n",
      "Epoch [45/50], Class Loss: 0.0983, Discrepancy Loss: 0.0741\n",
      "Epoch [46/50], Class Loss: 0.1132, Discrepancy Loss: 0.0752\n",
      "Epoch [47/50], Class Loss: 0.1058, Discrepancy Loss: 0.0744\n",
      "Epoch [48/50], Class Loss: 0.0963, Discrepancy Loss: 0.0724\n",
      "Epoch [49/50], Class Loss: 0.1019, Discrepancy Loss: 0.0684\n",
      "Epoch [50/50], Class Loss: 0.0975, Discrepancy Loss: 0.0719\n",
      "Source Domain Performance - Accuracy: 83.69%, Precision: 86.57%, Recall: 84.23%, F1 Score: 83.17%\n",
      "Target Domain Performance - Accuracy: 63.19%, Precision: 68.83%, Recall: 61.78%, F1 Score: 56.38%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 4.2005, Discrepancy Loss: 0.0815\n",
      "Epoch [2/50], Class Loss: 1.0875, Discrepancy Loss: 0.0886\n",
      "Epoch [3/50], Class Loss: 1.0047, Discrepancy Loss: 0.0978\n",
      "Epoch [4/50], Class Loss: 0.8887, Discrepancy Loss: 0.1147\n",
      "Epoch [5/50], Class Loss: 0.7985, Discrepancy Loss: 0.1116\n",
      "Epoch [6/50], Class Loss: 0.7193, Discrepancy Loss: 0.0953\n",
      "Epoch [7/50], Class Loss: 0.4545, Discrepancy Loss: 0.0757\n",
      "Epoch [8/50], Class Loss: 0.2531, Discrepancy Loss: 0.0573\n",
      "Epoch [9/50], Class Loss: 0.1472, Discrepancy Loss: 0.0496\n",
      "Epoch [10/50], Class Loss: 0.1551, Discrepancy Loss: 0.0477\n",
      "Epoch [11/50], Class Loss: 0.1285, Discrepancy Loss: 0.0441\n",
      "Epoch [12/50], Class Loss: 0.0915, Discrepancy Loss: 0.0446\n",
      "Epoch [13/50], Class Loss: 0.0646, Discrepancy Loss: 0.0468\n",
      "Epoch [14/50], Class Loss: 0.0642, Discrepancy Loss: 0.0474\n",
      "Epoch [15/50], Class Loss: 0.0718, Discrepancy Loss: 0.0515\n",
      "Epoch [16/50], Class Loss: 0.0714, Discrepancy Loss: 0.0466\n",
      "Epoch [17/50], Class Loss: 0.0544, Discrepancy Loss: 0.0498\n",
      "Epoch [18/50], Class Loss: 0.0652, Discrepancy Loss: 0.0470\n",
      "Epoch [19/50], Class Loss: 0.0594, Discrepancy Loss: 0.0526\n",
      "Epoch [20/50], Class Loss: 0.0671, Discrepancy Loss: 0.0574\n",
      "Epoch [21/50], Class Loss: 0.0525, Discrepancy Loss: 0.0523\n",
      "Epoch [22/50], Class Loss: 0.0415, Discrepancy Loss: 0.0474\n",
      "Epoch [23/50], Class Loss: 0.0662, Discrepancy Loss: 0.0503\n",
      "Epoch [24/50], Class Loss: 0.0478, Discrepancy Loss: 0.0546\n",
      "Epoch [25/50], Class Loss: 0.0515, Discrepancy Loss: 0.0528\n",
      "Epoch [26/50], Class Loss: 0.0504, Discrepancy Loss: 0.0515\n",
      "Epoch [27/50], Class Loss: 0.0840, Discrepancy Loss: 0.0527\n",
      "Epoch [28/50], Class Loss: 0.0400, Discrepancy Loss: 0.0504\n",
      "Epoch [29/50], Class Loss: 0.0505, Discrepancy Loss: 0.0535\n",
      "Epoch [30/50], Class Loss: 0.0536, Discrepancy Loss: 0.0575\n",
      "Epoch [31/50], Class Loss: 0.0452, Discrepancy Loss: 0.0515\n",
      "Epoch [32/50], Class Loss: 0.0488, Discrepancy Loss: 0.0527\n",
      "Epoch [33/50], Class Loss: 0.0510, Discrepancy Loss: 0.0494\n",
      "Epoch [34/50], Class Loss: 0.0455, Discrepancy Loss: 0.0553\n",
      "Epoch [35/50], Class Loss: 0.0412, Discrepancy Loss: 0.0561\n",
      "Epoch [36/50], Class Loss: 0.0376, Discrepancy Loss: 0.0549\n",
      "Epoch [37/50], Class Loss: 0.0409, Discrepancy Loss: 0.0560\n",
      "Epoch [38/50], Class Loss: 0.0474, Discrepancy Loss: 0.0519\n",
      "Epoch [39/50], Class Loss: 0.0456, Discrepancy Loss: 0.0530\n",
      "Epoch [40/50], Class Loss: 0.0578, Discrepancy Loss: 0.0560\n",
      "Epoch [41/50], Class Loss: 0.0409, Discrepancy Loss: 0.0614\n",
      "Epoch [42/50], Class Loss: 0.0462, Discrepancy Loss: 0.0534\n",
      "Epoch [43/50], Class Loss: 0.0461, Discrepancy Loss: 0.0552\n",
      "Epoch [44/50], Class Loss: 0.0423, Discrepancy Loss: 0.0541\n",
      "Epoch [45/50], Class Loss: 0.0438, Discrepancy Loss: 0.0527\n",
      "Epoch [46/50], Class Loss: 0.0375, Discrepancy Loss: 0.0558\n",
      "Epoch [47/50], Class Loss: 0.0521, Discrepancy Loss: 0.0550\n",
      "Epoch [48/50], Class Loss: 0.0379, Discrepancy Loss: 0.0582\n",
      "Epoch [49/50], Class Loss: 0.0426, Discrepancy Loss: 0.0528\n",
      "Epoch [50/50], Class Loss: 0.0468, Discrepancy Loss: 0.0596\n",
      "Source Domain Performance - Accuracy: 77.64%, Precision: 81.44%, Recall: 78.46%, F1 Score: 75.62%\n",
      "Target Domain Performance - Accuracy: 74.40%, Precision: 78.48%, Recall: 73.31%, F1 Score: 72.70%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 3.6173, Discrepancy Loss: 0.0959\n",
      "Epoch [2/50], Class Loss: 1.1583, Discrepancy Loss: 0.1169\n",
      "Epoch [3/50], Class Loss: 1.0349, Discrepancy Loss: 0.1171\n",
      "Epoch [4/50], Class Loss: 1.0201, Discrepancy Loss: 0.0963\n",
      "Epoch [5/50], Class Loss: 1.1842, Discrepancy Loss: 0.1249\n",
      "Epoch [6/50], Class Loss: 0.7033, Discrepancy Loss: 0.1119\n",
      "Epoch [7/50], Class Loss: 0.3582, Discrepancy Loss: 0.0721\n",
      "Epoch [8/50], Class Loss: 0.2593, Discrepancy Loss: 0.0682\n",
      "Epoch [9/50], Class Loss: 0.2183, Discrepancy Loss: 0.0593\n",
      "Epoch [10/50], Class Loss: 0.1591, Discrepancy Loss: 0.0530\n",
      "Epoch [11/50], Class Loss: 0.1606, Discrepancy Loss: 0.0543\n",
      "Epoch [12/50], Class Loss: 0.1004, Discrepancy Loss: 0.0465\n",
      "Epoch [13/50], Class Loss: 0.0906, Discrepancy Loss: 0.0441\n",
      "Epoch [14/50], Class Loss: 0.0960, Discrepancy Loss: 0.0522\n",
      "Epoch [15/50], Class Loss: 0.0883, Discrepancy Loss: 0.0486\n",
      "Epoch [16/50], Class Loss: 0.1000, Discrepancy Loss: 0.0486\n",
      "Epoch [17/50], Class Loss: 0.1007, Discrepancy Loss: 0.0462\n",
      "Epoch [18/50], Class Loss: 0.0892, Discrepancy Loss: 0.0445\n",
      "Epoch [19/50], Class Loss: 0.1271, Discrepancy Loss: 0.0484\n",
      "Epoch [20/50], Class Loss: 0.1056, Discrepancy Loss: 0.0450\n",
      "Epoch [21/50], Class Loss: 0.0683, Discrepancy Loss: 0.0502\n",
      "Epoch [22/50], Class Loss: 0.0749, Discrepancy Loss: 0.0529\n",
      "Epoch [23/50], Class Loss: 0.0666, Discrepancy Loss: 0.0496\n",
      "Epoch [24/50], Class Loss: 0.0762, Discrepancy Loss: 0.0514\n",
      "Epoch [25/50], Class Loss: 0.0838, Discrepancy Loss: 0.0464\n",
      "Epoch [26/50], Class Loss: 0.0974, Discrepancy Loss: 0.0524\n",
      "Epoch [27/50], Class Loss: 0.0654, Discrepancy Loss: 0.0483\n",
      "Epoch [28/50], Class Loss: 0.0727, Discrepancy Loss: 0.0457\n",
      "Epoch [29/50], Class Loss: 0.0759, Discrepancy Loss: 0.0499\n",
      "Epoch [30/50], Class Loss: 0.0718, Discrepancy Loss: 0.0488\n",
      "Epoch [31/50], Class Loss: 0.0688, Discrepancy Loss: 0.0503\n",
      "Epoch [32/50], Class Loss: 0.0794, Discrepancy Loss: 0.0472\n",
      "Epoch [33/50], Class Loss: 0.0876, Discrepancy Loss: 0.0469\n",
      "Epoch [34/50], Class Loss: 0.0796, Discrepancy Loss: 0.0498\n",
      "Epoch [35/50], Class Loss: 0.0666, Discrepancy Loss: 0.0484\n",
      "Epoch [36/50], Class Loss: 0.0767, Discrepancy Loss: 0.0527\n",
      "Epoch [37/50], Class Loss: 0.0713, Discrepancy Loss: 0.0442\n",
      "Epoch [38/50], Class Loss: 0.0704, Discrepancy Loss: 0.0503\n",
      "Epoch [39/50], Class Loss: 0.0819, Discrepancy Loss: 0.0517\n",
      "Epoch [40/50], Class Loss: 0.0652, Discrepancy Loss: 0.0481\n",
      "Epoch [41/50], Class Loss: 0.0659, Discrepancy Loss: 0.0470\n",
      "Epoch [42/50], Class Loss: 0.0664, Discrepancy Loss: 0.0480\n",
      "Epoch [43/50], Class Loss: 0.0694, Discrepancy Loss: 0.0443\n",
      "Epoch [44/50], Class Loss: 0.0721, Discrepancy Loss: 0.0513\n",
      "Epoch [45/50], Class Loss: 0.0548, Discrepancy Loss: 0.0492\n",
      "Epoch [46/50], Class Loss: 0.0956, Discrepancy Loss: 0.0494\n",
      "Epoch [47/50], Class Loss: 0.0614, Discrepancy Loss: 0.0482\n",
      "Epoch [48/50], Class Loss: 0.0754, Discrepancy Loss: 0.0544\n",
      "Epoch [49/50], Class Loss: 0.0654, Discrepancy Loss: 0.0496\n",
      "Epoch [50/50], Class Loss: 0.0772, Discrepancy Loss: 0.0533\n",
      "Source Domain Performance - Accuracy: 76.02%, Precision: 79.19%, Recall: 76.86%, F1 Score: 73.67%\n",
      "Target Domain Performance - Accuracy: 74.82%, Precision: 79.40%, Recall: 73.82%, F1 Score: 72.88%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 4.2976, Discrepancy Loss: 0.0840\n",
      "Epoch [2/50], Class Loss: 1.4189, Discrepancy Loss: 0.1298\n",
      "Epoch [3/50], Class Loss: 1.0261, Discrepancy Loss: 0.1056\n",
      "Epoch [4/50], Class Loss: 0.9080, Discrepancy Loss: 0.1080\n",
      "Epoch [5/50], Class Loss: 1.1779, Discrepancy Loss: 0.1114\n",
      "Epoch [6/50], Class Loss: 0.8658, Discrepancy Loss: 0.1089\n",
      "Epoch [7/50], Class Loss: 0.6710, Discrepancy Loss: 0.0926\n",
      "Epoch [8/50], Class Loss: 0.3987, Discrepancy Loss: 0.0693\n",
      "Epoch [9/50], Class Loss: 0.2371, Discrepancy Loss: 0.0565\n",
      "Epoch [10/50], Class Loss: 0.7876, Discrepancy Loss: 0.0958\n",
      "Epoch [11/50], Class Loss: 0.3007, Discrepancy Loss: 0.0693\n",
      "Epoch [12/50], Class Loss: 0.2737, Discrepancy Loss: 0.0680\n",
      "Epoch [13/50], Class Loss: 0.2215, Discrepancy Loss: 0.0702\n",
      "Epoch [14/50], Class Loss: 0.2107, Discrepancy Loss: 0.0626\n",
      "Epoch [15/50], Class Loss: 0.1882, Discrepancy Loss: 0.0602\n",
      "Epoch [16/50], Class Loss: 0.1945, Discrepancy Loss: 0.0550\n",
      "Epoch [17/50], Class Loss: 0.1551, Discrepancy Loss: 0.0673\n",
      "Epoch [18/50], Class Loss: 0.1667, Discrepancy Loss: 0.0552\n",
      "Epoch [19/50], Class Loss: 0.1390, Discrepancy Loss: 0.0559\n",
      "Epoch [20/50], Class Loss: 0.1354, Discrepancy Loss: 0.0583\n",
      "Epoch [21/50], Class Loss: 0.1286, Discrepancy Loss: 0.0551\n",
      "Epoch [22/50], Class Loss: 0.1066, Discrepancy Loss: 0.0601\n",
      "Epoch [23/50], Class Loss: 0.1222, Discrepancy Loss: 0.0570\n",
      "Epoch [24/50], Class Loss: 0.1189, Discrepancy Loss: 0.0555\n",
      "Epoch [25/50], Class Loss: 0.1254, Discrepancy Loss: 0.0594\n",
      "Epoch [26/50], Class Loss: 0.1405, Discrepancy Loss: 0.0506\n",
      "Epoch [27/50], Class Loss: 0.1085, Discrepancy Loss: 0.0567\n",
      "Epoch [28/50], Class Loss: 0.1142, Discrepancy Loss: 0.0619\n",
      "Epoch [29/50], Class Loss: 0.1307, Discrepancy Loss: 0.0510\n",
      "Epoch [30/50], Class Loss: 0.1140, Discrepancy Loss: 0.0544\n",
      "Epoch [31/50], Class Loss: 0.1251, Discrepancy Loss: 0.0545\n",
      "Epoch [32/50], Class Loss: 0.1147, Discrepancy Loss: 0.0599\n",
      "Epoch [33/50], Class Loss: 0.1309, Discrepancy Loss: 0.0529\n",
      "Epoch [34/50], Class Loss: 0.1060, Discrepancy Loss: 0.0510\n",
      "Epoch [35/50], Class Loss: 0.1042, Discrepancy Loss: 0.0546\n",
      "Epoch [36/50], Class Loss: 0.1261, Discrepancy Loss: 0.0529\n",
      "Epoch [37/50], Class Loss: 0.1275, Discrepancy Loss: 0.0569\n",
      "Epoch [38/50], Class Loss: 0.1339, Discrepancy Loss: 0.0566\n",
      "Epoch [39/50], Class Loss: 0.1100, Discrepancy Loss: 0.0507\n",
      "Epoch [40/50], Class Loss: 0.1337, Discrepancy Loss: 0.0564\n",
      "Epoch [41/50], Class Loss: 0.1042, Discrepancy Loss: 0.0554\n",
      "Epoch [42/50], Class Loss: 0.1046, Discrepancy Loss: 0.0497\n",
      "Epoch [43/50], Class Loss: 0.1115, Discrepancy Loss: 0.0571\n",
      "Epoch [44/50], Class Loss: 0.1039, Discrepancy Loss: 0.0599\n",
      "Epoch [45/50], Class Loss: 0.1099, Discrepancy Loss: 0.0597\n",
      "Epoch [46/50], Class Loss: 0.1346, Discrepancy Loss: 0.0554\n",
      "Epoch [47/50], Class Loss: 0.1152, Discrepancy Loss: 0.0531\n",
      "Epoch [48/50], Class Loss: 0.1058, Discrepancy Loss: 0.0604\n",
      "Epoch [49/50], Class Loss: 0.1245, Discrepancy Loss: 0.0503\n",
      "Epoch [50/50], Class Loss: 0.1130, Discrepancy Loss: 0.0519\n",
      "Source Domain Performance - Accuracy: 81.24%, Precision: 84.94%, Recall: 81.92%, F1 Score: 80.13%\n",
      "Target Domain Performance - Accuracy: 65.71%, Precision: 74.58%, Recall: 64.31%, F1 Score: 60.71%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 4.6423, Discrepancy Loss: 0.0733\n",
      "Epoch [2/50], Class Loss: 1.2575, Discrepancy Loss: 0.1075\n",
      "Epoch [3/50], Class Loss: 0.9210, Discrepancy Loss: 0.0914\n",
      "Epoch [4/50], Class Loss: 0.8896, Discrepancy Loss: 0.0978\n",
      "Epoch [5/50], Class Loss: 0.7599, Discrepancy Loss: 0.1000\n",
      "Epoch [6/50], Class Loss: 0.6668, Discrepancy Loss: 0.0834\n",
      "Epoch [7/50], Class Loss: 0.5592, Discrepancy Loss: 0.0714\n",
      "Epoch [8/50], Class Loss: 0.4165, Discrepancy Loss: 0.0612\n",
      "Epoch [9/50], Class Loss: 0.2493, Discrepancy Loss: 0.0610\n",
      "Epoch [10/50], Class Loss: 0.1918, Discrepancy Loss: 0.0543\n",
      "Epoch [11/50], Class Loss: 0.1414, Discrepancy Loss: 0.0484\n",
      "Epoch [12/50], Class Loss: 0.0975, Discrepancy Loss: 0.0497\n",
      "Epoch [13/50], Class Loss: 0.0879, Discrepancy Loss: 0.0466\n",
      "Epoch [14/50], Class Loss: 0.0935, Discrepancy Loss: 0.0458\n",
      "Epoch [15/50], Class Loss: 0.0753, Discrepancy Loss: 0.0475\n",
      "Epoch [16/50], Class Loss: 0.0804, Discrepancy Loss: 0.0451\n",
      "Epoch [17/50], Class Loss: 0.0753, Discrepancy Loss: 0.0431\n",
      "Epoch [18/50], Class Loss: 0.0875, Discrepancy Loss: 0.0468\n",
      "Epoch [19/50], Class Loss: 0.0693, Discrepancy Loss: 0.0486\n",
      "Epoch [20/50], Class Loss: 0.0733, Discrepancy Loss: 0.0512\n",
      "Epoch [21/50], Class Loss: 0.0651, Discrepancy Loss: 0.0473\n",
      "Epoch [22/50], Class Loss: 0.0560, Discrepancy Loss: 0.0545\n",
      "Epoch [23/50], Class Loss: 0.0529, Discrepancy Loss: 0.0461\n",
      "Epoch [24/50], Class Loss: 0.0543, Discrepancy Loss: 0.0521\n",
      "Epoch [25/50], Class Loss: 0.0500, Discrepancy Loss: 0.0461\n",
      "Epoch [26/50], Class Loss: 0.0610, Discrepancy Loss: 0.0518\n",
      "Epoch [27/50], Class Loss: 0.0597, Discrepancy Loss: 0.0505\n",
      "Epoch [28/50], Class Loss: 0.0548, Discrepancy Loss: 0.0485\n",
      "Epoch [29/50], Class Loss: 0.0612, Discrepancy Loss: 0.0558\n",
      "Epoch [30/50], Class Loss: 0.0615, Discrepancy Loss: 0.0587\n",
      "Epoch [31/50], Class Loss: 0.0548, Discrepancy Loss: 0.0480\n",
      "Epoch [32/50], Class Loss: 0.0491, Discrepancy Loss: 0.0577\n",
      "Epoch [33/50], Class Loss: 0.0783, Discrepancy Loss: 0.0475\n",
      "Epoch [34/50], Class Loss: 0.0588, Discrepancy Loss: 0.0555\n",
      "Epoch [35/50], Class Loss: 0.0541, Discrepancy Loss: 0.0550\n",
      "Epoch [36/50], Class Loss: 0.0580, Discrepancy Loss: 0.0512\n",
      "Epoch [37/50], Class Loss: 0.0531, Discrepancy Loss: 0.0566\n",
      "Epoch [38/50], Class Loss: 0.0545, Discrepancy Loss: 0.0513\n",
      "Epoch [39/50], Class Loss: 0.0553, Discrepancy Loss: 0.0514\n",
      "Epoch [40/50], Class Loss: 0.0621, Discrepancy Loss: 0.0521\n",
      "Epoch [41/50], Class Loss: 0.0493, Discrepancy Loss: 0.0586\n",
      "Epoch [42/50], Class Loss: 0.0478, Discrepancy Loss: 0.0547\n",
      "Epoch [43/50], Class Loss: 0.0699, Discrepancy Loss: 0.0546\n",
      "Epoch [44/50], Class Loss: 0.0564, Discrepancy Loss: 0.0530\n",
      "Epoch [45/50], Class Loss: 0.0597, Discrepancy Loss: 0.0501\n",
      "Epoch [46/50], Class Loss: 0.0608, Discrepancy Loss: 0.0522\n",
      "Epoch [47/50], Class Loss: 0.0500, Discrepancy Loss: 0.0556\n",
      "Epoch [48/50], Class Loss: 0.0529, Discrepancy Loss: 0.0498\n",
      "Epoch [49/50], Class Loss: 0.0594, Discrepancy Loss: 0.0560\n",
      "Epoch [50/50], Class Loss: 0.0477, Discrepancy Loss: 0.0596\n",
      "Source Domain Performance - Accuracy: 84.89%, Precision: 88.18%, Recall: 85.49%, F1 Score: 84.30%\n",
      "Target Domain Performance - Accuracy: 67.57%, Precision: 73.65%, Recall: 66.11%, F1 Score: 64.44%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 4.6183, Discrepancy Loss: 0.0761\n",
      "Epoch [2/50], Class Loss: 1.6256, Discrepancy Loss: 0.1001\n",
      "Epoch [3/50], Class Loss: 0.9986, Discrepancy Loss: 0.0969\n",
      "Epoch [4/50], Class Loss: 0.9075, Discrepancy Loss: 0.0993\n",
      "Epoch [5/50], Class Loss: 0.7398, Discrepancy Loss: 0.0896\n",
      "Epoch [6/50], Class Loss: 0.8523, Discrepancy Loss: 0.1004\n",
      "Epoch [7/50], Class Loss: 0.4700, Discrepancy Loss: 0.0762\n",
      "Epoch [8/50], Class Loss: 0.2769, Discrepancy Loss: 0.0531\n",
      "Epoch [9/50], Class Loss: 0.2314, Discrepancy Loss: 0.0569\n",
      "Epoch [10/50], Class Loss: 0.2587, Discrepancy Loss: 0.0562\n",
      "Epoch [11/50], Class Loss: 0.1201, Discrepancy Loss: 0.0530\n",
      "Epoch [12/50], Class Loss: 0.1102, Discrepancy Loss: 0.0525\n",
      "Epoch [13/50], Class Loss: 0.1209, Discrepancy Loss: 0.0490\n",
      "Epoch [14/50], Class Loss: 0.0958, Discrepancy Loss: 0.0526\n",
      "Epoch [15/50], Class Loss: 0.0737, Discrepancy Loss: 0.0522\n",
      "Epoch [16/50], Class Loss: 0.0935, Discrepancy Loss: 0.0476\n",
      "Epoch [17/50], Class Loss: 0.0868, Discrepancy Loss: 0.0480\n",
      "Epoch [18/50], Class Loss: 0.0926, Discrepancy Loss: 0.0488\n",
      "Epoch [19/50], Class Loss: 0.0840, Discrepancy Loss: 0.0499\n",
      "Epoch [20/50], Class Loss: 0.0922, Discrepancy Loss: 0.0489\n",
      "Epoch [21/50], Class Loss: 0.0797, Discrepancy Loss: 0.0491\n",
      "Epoch [22/50], Class Loss: 0.0970, Discrepancy Loss: 0.0485\n",
      "Epoch [23/50], Class Loss: 0.0760, Discrepancy Loss: 0.0484\n",
      "Epoch [24/50], Class Loss: 0.1065, Discrepancy Loss: 0.0477\n",
      "Epoch [25/50], Class Loss: 0.0775, Discrepancy Loss: 0.0449\n",
      "Epoch [26/50], Class Loss: 0.0696, Discrepancy Loss: 0.0482\n",
      "Epoch [27/50], Class Loss: 0.0667, Discrepancy Loss: 0.0468\n",
      "Epoch [28/50], Class Loss: 0.0884, Discrepancy Loss: 0.0500\n",
      "Epoch [29/50], Class Loss: 0.0765, Discrepancy Loss: 0.0500\n",
      "Epoch [30/50], Class Loss: 0.0621, Discrepancy Loss: 0.0500\n",
      "Epoch [31/50], Class Loss: 0.0691, Discrepancy Loss: 0.0433\n",
      "Epoch [32/50], Class Loss: 0.0623, Discrepancy Loss: 0.0498\n",
      "Epoch [33/50], Class Loss: 0.0898, Discrepancy Loss: 0.0459\n",
      "Epoch [34/50], Class Loss: 0.0594, Discrepancy Loss: 0.0481\n",
      "Epoch [35/50], Class Loss: 0.0662, Discrepancy Loss: 0.0440\n",
      "Epoch [36/50], Class Loss: 0.0548, Discrepancy Loss: 0.0476\n",
      "Epoch [37/50], Class Loss: 0.0547, Discrepancy Loss: 0.0492\n",
      "Epoch [38/50], Class Loss: 0.0666, Discrepancy Loss: 0.0509\n",
      "Epoch [39/50], Class Loss: 0.0572, Discrepancy Loss: 0.0510\n",
      "Epoch [40/50], Class Loss: 0.0564, Discrepancy Loss: 0.0485\n",
      "Epoch [41/50], Class Loss: 0.0644, Discrepancy Loss: 0.0512\n",
      "Epoch [42/50], Class Loss: 0.0773, Discrepancy Loss: 0.0529\n",
      "Epoch [43/50], Class Loss: 0.0591, Discrepancy Loss: 0.0485\n",
      "Epoch [44/50], Class Loss: 0.0544, Discrepancy Loss: 0.0482\n",
      "Epoch [45/50], Class Loss: 0.0541, Discrepancy Loss: 0.0489\n",
      "Epoch [46/50], Class Loss: 0.0610, Discrepancy Loss: 0.0493\n",
      "Epoch [47/50], Class Loss: 0.0596, Discrepancy Loss: 0.0522\n",
      "Epoch [48/50], Class Loss: 0.0667, Discrepancy Loss: 0.0478\n",
      "Epoch [49/50], Class Loss: 0.1090, Discrepancy Loss: 0.0533\n",
      "Epoch [50/50], Class Loss: 0.0567, Discrepancy Loss: 0.0523\n",
      "Source Domain Performance - Accuracy: 76.98%, Precision: 80.95%, Recall: 77.87%, F1 Score: 74.47%\n",
      "Target Domain Performance - Accuracy: 71.82%, Precision: 76.28%, Recall: 70.61%, F1 Score: 69.68%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 4.0000, Discrepancy Loss: 0.0684\n",
      "Epoch [2/50], Class Loss: 1.2082, Discrepancy Loss: 0.1064\n",
      "Epoch [3/50], Class Loss: 1.0717, Discrepancy Loss: 0.1102\n",
      "Epoch [4/50], Class Loss: 0.9291, Discrepancy Loss: 0.1052\n",
      "Epoch [5/50], Class Loss: 0.8020, Discrepancy Loss: 0.0984\n",
      "Epoch [6/50], Class Loss: 0.7696, Discrepancy Loss: 0.0953\n",
      "Epoch [7/50], Class Loss: 0.6868, Discrepancy Loss: 0.0935\n",
      "Epoch [8/50], Class Loss: 0.3218, Discrepancy Loss: 0.0724\n",
      "Epoch [9/50], Class Loss: 0.1751, Discrepancy Loss: 0.0479\n",
      "Epoch [10/50], Class Loss: 0.2212, Discrepancy Loss: 0.0511\n",
      "Epoch [11/50], Class Loss: 0.1629, Discrepancy Loss: 0.0542\n",
      "Epoch [12/50], Class Loss: 0.1380, Discrepancy Loss: 0.0578\n",
      "Epoch [13/50], Class Loss: 0.1101, Discrepancy Loss: 0.0530\n",
      "Epoch [14/50], Class Loss: 0.1084, Discrepancy Loss: 0.0572\n",
      "Epoch [15/50], Class Loss: 0.0932, Discrepancy Loss: 0.0572\n",
      "Epoch [16/50], Class Loss: 0.1161, Discrepancy Loss: 0.0559\n",
      "Epoch [17/50], Class Loss: 0.1076, Discrepancy Loss: 0.0472\n",
      "Epoch [18/50], Class Loss: 0.0980, Discrepancy Loss: 0.0486\n",
      "Epoch [19/50], Class Loss: 0.0871, Discrepancy Loss: 0.0455\n",
      "Epoch [20/50], Class Loss: 0.0814, Discrepancy Loss: 0.0435\n",
      "Epoch [21/50], Class Loss: 0.0855, Discrepancy Loss: 0.0467\n",
      "Epoch [22/50], Class Loss: 0.0791, Discrepancy Loss: 0.0510\n",
      "Epoch [23/50], Class Loss: 0.0761, Discrepancy Loss: 0.0461\n",
      "Epoch [24/50], Class Loss: 0.0878, Discrepancy Loss: 0.0506\n",
      "Epoch [25/50], Class Loss: 0.0582, Discrepancy Loss: 0.0493\n",
      "Epoch [26/50], Class Loss: 0.0829, Discrepancy Loss: 0.0469\n",
      "Epoch [27/50], Class Loss: 0.0809, Discrepancy Loss: 0.0472\n",
      "Epoch [28/50], Class Loss: 0.0884, Discrepancy Loss: 0.0449\n",
      "Epoch [29/50], Class Loss: 0.0747, Discrepancy Loss: 0.0515\n",
      "Epoch [30/50], Class Loss: 0.0761, Discrepancy Loss: 0.0510\n",
      "Epoch [31/50], Class Loss: 0.0670, Discrepancy Loss: 0.0484\n",
      "Epoch [32/50], Class Loss: 0.0648, Discrepancy Loss: 0.0476\n",
      "Epoch [33/50], Class Loss: 0.0893, Discrepancy Loss: 0.0532\n",
      "Epoch [34/50], Class Loss: 0.0639, Discrepancy Loss: 0.0548\n",
      "Epoch [35/50], Class Loss: 0.0580, Discrepancy Loss: 0.0437\n",
      "Epoch [36/50], Class Loss: 0.0631, Discrepancy Loss: 0.0479\n",
      "Epoch [37/50], Class Loss: 0.0758, Discrepancy Loss: 0.0469\n",
      "Epoch [38/50], Class Loss: 0.0681, Discrepancy Loss: 0.0498\n",
      "Epoch [39/50], Class Loss: 0.0748, Discrepancy Loss: 0.0515\n",
      "Epoch [40/50], Class Loss: 0.0658, Discrepancy Loss: 0.0476\n",
      "Epoch [41/50], Class Loss: 0.0683, Discrepancy Loss: 0.0528\n",
      "Epoch [42/50], Class Loss: 0.0710, Discrepancy Loss: 0.0529\n",
      "Epoch [43/50], Class Loss: 0.0627, Discrepancy Loss: 0.0503\n",
      "Epoch [44/50], Class Loss: 0.0672, Discrepancy Loss: 0.0430\n",
      "Epoch [45/50], Class Loss: 0.0583, Discrepancy Loss: 0.0503\n",
      "Epoch [46/50], Class Loss: 0.0636, Discrepancy Loss: 0.0519\n",
      "Epoch [47/50], Class Loss: 0.0873, Discrepancy Loss: 0.0488\n",
      "Epoch [48/50], Class Loss: 0.0593, Discrepancy Loss: 0.0469\n",
      "Epoch [49/50], Class Loss: 0.0645, Discrepancy Loss: 0.0470\n",
      "Epoch [50/50], Class Loss: 0.0648, Discrepancy Loss: 0.0512\n",
      "Source Domain Performance - Accuracy: 84.89%, Precision: 88.07%, Recall: 85.48%, F1 Score: 84.32%\n",
      "Target Domain Performance - Accuracy: 65.95%, Precision: 73.17%, Recall: 64.46%, F1 Score: 62.11%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 4.4083, Discrepancy Loss: 0.0547\n",
      "Epoch [2/50], Class Loss: 1.2512, Discrepancy Loss: 0.0944\n",
      "Epoch [3/50], Class Loss: 0.9775, Discrepancy Loss: 0.1127\n",
      "Epoch [4/50], Class Loss: 0.8963, Discrepancy Loss: 0.1116\n",
      "Epoch [5/50], Class Loss: 0.9176, Discrepancy Loss: 0.1171\n",
      "Epoch [6/50], Class Loss: 0.7728, Discrepancy Loss: 0.1128\n",
      "Epoch [7/50], Class Loss: 0.6836, Discrepancy Loss: 0.0939\n",
      "Epoch [8/50], Class Loss: 0.4694, Discrepancy Loss: 0.0865\n",
      "Epoch [9/50], Class Loss: 0.2943, Discrepancy Loss: 0.0576\n",
      "Epoch [10/50], Class Loss: 0.2659, Discrepancy Loss: 0.0594\n",
      "Epoch [11/50], Class Loss: 0.1532, Discrepancy Loss: 0.0606\n",
      "Epoch [12/50], Class Loss: 0.1252, Discrepancy Loss: 0.0544\n",
      "Epoch [13/50], Class Loss: 0.1538, Discrepancy Loss: 0.0533\n",
      "Epoch [14/50], Class Loss: 0.1304, Discrepancy Loss: 0.0524\n",
      "Epoch [15/50], Class Loss: 0.1117, Discrepancy Loss: 0.0491\n",
      "Epoch [16/50], Class Loss: 0.1072, Discrepancy Loss: 0.0483\n",
      "Epoch [17/50], Class Loss: 0.1003, Discrepancy Loss: 0.0490\n",
      "Epoch [18/50], Class Loss: 0.0998, Discrepancy Loss: 0.0461\n",
      "Epoch [19/50], Class Loss: 0.0988, Discrepancy Loss: 0.0541\n",
      "Epoch [20/50], Class Loss: 0.1131, Discrepancy Loss: 0.0516\n",
      "Epoch [21/50], Class Loss: 0.0899, Discrepancy Loss: 0.0517\n",
      "Epoch [22/50], Class Loss: 0.1218, Discrepancy Loss: 0.0561\n",
      "Epoch [23/50], Class Loss: 0.0955, Discrepancy Loss: 0.0555\n",
      "Epoch [24/50], Class Loss: 0.0857, Discrepancy Loss: 0.0570\n",
      "Epoch [25/50], Class Loss: 0.0954, Discrepancy Loss: 0.0515\n",
      "Epoch [26/50], Class Loss: 0.0871, Discrepancy Loss: 0.0546\n",
      "Epoch [27/50], Class Loss: 0.0920, Discrepancy Loss: 0.0535\n",
      "Epoch [28/50], Class Loss: 0.0708, Discrepancy Loss: 0.0516\n",
      "Epoch [29/50], Class Loss: 0.1068, Discrepancy Loss: 0.0587\n",
      "Epoch [30/50], Class Loss: 0.0743, Discrepancy Loss: 0.0591\n",
      "Epoch [31/50], Class Loss: 0.0880, Discrepancy Loss: 0.0575\n",
      "Epoch [32/50], Class Loss: 0.0680, Discrepancy Loss: 0.0582\n",
      "Epoch [33/50], Class Loss: 0.0768, Discrepancy Loss: 0.0572\n",
      "Epoch [34/50], Class Loss: 0.0728, Discrepancy Loss: 0.0547\n",
      "Epoch [35/50], Class Loss: 0.0776, Discrepancy Loss: 0.0548\n",
      "Epoch [36/50], Class Loss: 0.0928, Discrepancy Loss: 0.0583\n",
      "Epoch [37/50], Class Loss: 0.0779, Discrepancy Loss: 0.0579\n",
      "Epoch [38/50], Class Loss: 0.0885, Discrepancy Loss: 0.0552\n",
      "Epoch [39/50], Class Loss: 0.0970, Discrepancy Loss: 0.0580\n",
      "Epoch [40/50], Class Loss: 0.0976, Discrepancy Loss: 0.0627\n",
      "Epoch [41/50], Class Loss: 0.0860, Discrepancy Loss: 0.0604\n",
      "Epoch [42/50], Class Loss: 0.0838, Discrepancy Loss: 0.0583\n",
      "Epoch [43/50], Class Loss: 0.0790, Discrepancy Loss: 0.0574\n",
      "Epoch [44/50], Class Loss: 0.0907, Discrepancy Loss: 0.0544\n",
      "Epoch [45/50], Class Loss: 0.0808, Discrepancy Loss: 0.0539\n",
      "Epoch [46/50], Class Loss: 0.0923, Discrepancy Loss: 0.0621\n",
      "Epoch [47/50], Class Loss: 0.0953, Discrepancy Loss: 0.0563\n",
      "Epoch [48/50], Class Loss: 0.0775, Discrepancy Loss: 0.0610\n",
      "Epoch [49/50], Class Loss: 0.0771, Discrepancy Loss: 0.0546\n",
      "Epoch [50/50], Class Loss: 0.0860, Discrepancy Loss: 0.0577\n",
      "Source Domain Performance - Accuracy: 77.64%, Precision: 80.68%, Recall: 78.29%, F1 Score: 76.30%\n",
      "Target Domain Performance - Accuracy: 70.44%, Precision: 76.14%, Recall: 69.38%, F1 Score: 66.49%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 5.0747, Discrepancy Loss: 0.0474\n",
      "Epoch [2/50], Class Loss: 1.1063, Discrepancy Loss: 0.1007\n",
      "Epoch [3/50], Class Loss: 0.9532, Discrepancy Loss: 0.0979\n",
      "Epoch [4/50], Class Loss: 0.8895, Discrepancy Loss: 0.1086\n",
      "Epoch [5/50], Class Loss: 0.7170, Discrepancy Loss: 0.0893\n",
      "Epoch [6/50], Class Loss: 0.4337, Discrepancy Loss: 0.0764\n",
      "Epoch [7/50], Class Loss: 0.2836, Discrepancy Loss: 0.0611\n",
      "Epoch [8/50], Class Loss: 0.2840, Discrepancy Loss: 0.0591\n",
      "Epoch [9/50], Class Loss: 0.2031, Discrepancy Loss: 0.0473\n",
      "Epoch [10/50], Class Loss: 0.1554, Discrepancy Loss: 0.0509\n",
      "Epoch [11/50], Class Loss: 0.0901, Discrepancy Loss: 0.0497\n",
      "Epoch [12/50], Class Loss: 0.1016, Discrepancy Loss: 0.0520\n",
      "Epoch [13/50], Class Loss: 0.0909, Discrepancy Loss: 0.0476\n",
      "Epoch [14/50], Class Loss: 0.0737, Discrepancy Loss: 0.0489\n",
      "Epoch [15/50], Class Loss: 0.0645, Discrepancy Loss: 0.0457\n",
      "Epoch [16/50], Class Loss: 0.0669, Discrepancy Loss: 0.0450\n",
      "Epoch [17/50], Class Loss: 0.0746, Discrepancy Loss: 0.0413\n",
      "Epoch [18/50], Class Loss: 0.0658, Discrepancy Loss: 0.0455\n",
      "Epoch [19/50], Class Loss: 0.0697, Discrepancy Loss: 0.0479\n",
      "Epoch [20/50], Class Loss: 0.0611, Discrepancy Loss: 0.0494\n",
      "Epoch [21/50], Class Loss: 0.0579, Discrepancy Loss: 0.0464\n",
      "Epoch [22/50], Class Loss: 0.0624, Discrepancy Loss: 0.0460\n",
      "Epoch [23/50], Class Loss: 0.0552, Discrepancy Loss: 0.0480\n",
      "Epoch [24/50], Class Loss: 0.0580, Discrepancy Loss: 0.0478\n",
      "Epoch [25/50], Class Loss: 0.0555, Discrepancy Loss: 0.0475\n",
      "Epoch [26/50], Class Loss: 0.0739, Discrepancy Loss: 0.0476\n",
      "Epoch [27/50], Class Loss: 0.0800, Discrepancy Loss: 0.0513\n",
      "Epoch [28/50], Class Loss: 0.0472, Discrepancy Loss: 0.0450\n",
      "Epoch [29/50], Class Loss: 0.0528, Discrepancy Loss: 0.0461\n",
      "Epoch [30/50], Class Loss: 0.0584, Discrepancy Loss: 0.0446\n",
      "Epoch [31/50], Class Loss: 0.0486, Discrepancy Loss: 0.0516\n",
      "Epoch [32/50], Class Loss: 0.0660, Discrepancy Loss: 0.0448\n",
      "Epoch [33/50], Class Loss: 0.0532, Discrepancy Loss: 0.0464\n",
      "Epoch [34/50], Class Loss: 0.0607, Discrepancy Loss: 0.0465\n",
      "Epoch [35/50], Class Loss: 0.0491, Discrepancy Loss: 0.0467\n",
      "Epoch [36/50], Class Loss: 0.0534, Discrepancy Loss: 0.0489\n",
      "Epoch [37/50], Class Loss: 0.0875, Discrepancy Loss: 0.0494\n",
      "Epoch [38/50], Class Loss: 0.0540, Discrepancy Loss: 0.0468\n",
      "Epoch [39/50], Class Loss: 0.0431, Discrepancy Loss: 0.0475\n",
      "Epoch [40/50], Class Loss: 0.0555, Discrepancy Loss: 0.0445\n",
      "Epoch [41/50], Class Loss: 0.0539, Discrepancy Loss: 0.0448\n",
      "Epoch [42/50], Class Loss: 0.0494, Discrepancy Loss: 0.0444\n",
      "Epoch [43/50], Class Loss: 0.0424, Discrepancy Loss: 0.0441\n",
      "Epoch [44/50], Class Loss: 0.0605, Discrepancy Loss: 0.0457\n",
      "Epoch [45/50], Class Loss: 0.0529, Discrepancy Loss: 0.0468\n",
      "Epoch [46/50], Class Loss: 0.0522, Discrepancy Loss: 0.0507\n",
      "Epoch [47/50], Class Loss: 0.0518, Discrepancy Loss: 0.0475\n",
      "Epoch [48/50], Class Loss: 0.0560, Discrepancy Loss: 0.0484\n",
      "Epoch [49/50], Class Loss: 0.0625, Discrepancy Loss: 0.0500\n",
      "Epoch [50/50], Class Loss: 0.0571, Discrepancy Loss: 0.0440\n",
      "Source Domain Performance - Accuracy: 82.31%, Precision: 85.59%, Recall: 82.93%, F1 Score: 81.49%\n",
      "Target Domain Performance - Accuracy: 69.48%, Precision: 76.84%, Recall: 68.23%, F1 Score: 66.09%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 4.2176, Discrepancy Loss: 0.0863\n",
      "Epoch [2/50], Class Loss: 1.1481, Discrepancy Loss: 0.1089\n",
      "Epoch [3/50], Class Loss: 0.8848, Discrepancy Loss: 0.0991\n",
      "Epoch [4/50], Class Loss: 0.9395, Discrepancy Loss: 0.0987\n",
      "Epoch [5/50], Class Loss: 0.7798, Discrepancy Loss: 0.0901\n",
      "Epoch [6/50], Class Loss: 0.8271, Discrepancy Loss: 0.1161\n",
      "Epoch [7/50], Class Loss: 0.8587, Discrepancy Loss: 0.1177\n",
      "Epoch [8/50], Class Loss: 0.6935, Discrepancy Loss: 0.1086\n",
      "Epoch [9/50], Class Loss: 0.4258, Discrepancy Loss: 0.0800\n",
      "Epoch [10/50], Class Loss: 0.3250, Discrepancy Loss: 0.0623\n",
      "Epoch [11/50], Class Loss: 0.1642, Discrepancy Loss: 0.0569\n",
      "Epoch [12/50], Class Loss: 0.1504, Discrepancy Loss: 0.0538\n",
      "Epoch [13/50], Class Loss: 0.1448, Discrepancy Loss: 0.0474\n",
      "Epoch [14/50], Class Loss: 0.1234, Discrepancy Loss: 0.0507\n",
      "Epoch [15/50], Class Loss: 0.1174, Discrepancy Loss: 0.0472\n",
      "Epoch [16/50], Class Loss: 0.1064, Discrepancy Loss: 0.0452\n",
      "Epoch [17/50], Class Loss: 0.1141, Discrepancy Loss: 0.0427\n",
      "Epoch [18/50], Class Loss: 0.1170, Discrepancy Loss: 0.0464\n",
      "Epoch [19/50], Class Loss: 0.1156, Discrepancy Loss: 0.0439\n",
      "Epoch [20/50], Class Loss: 0.0926, Discrepancy Loss: 0.0453\n",
      "Epoch [21/50], Class Loss: 0.0812, Discrepancy Loss: 0.0448\n",
      "Epoch [22/50], Class Loss: 0.0698, Discrepancy Loss: 0.0402\n",
      "Epoch [23/50], Class Loss: 0.0886, Discrepancy Loss: 0.0437\n",
      "Epoch [24/50], Class Loss: 0.0786, Discrepancy Loss: 0.0463\n",
      "Epoch [25/50], Class Loss: 0.1288, Discrepancy Loss: 0.0467\n",
      "Epoch [26/50], Class Loss: 0.0865, Discrepancy Loss: 0.0440\n",
      "Epoch [27/50], Class Loss: 0.0716, Discrepancy Loss: 0.0437\n",
      "Epoch [28/50], Class Loss: 0.0766, Discrepancy Loss: 0.0445\n",
      "Epoch [29/50], Class Loss: 0.1052, Discrepancy Loss: 0.0493\n",
      "Epoch [30/50], Class Loss: 0.1008, Discrepancy Loss: 0.0459\n",
      "Epoch [31/50], Class Loss: 0.0715, Discrepancy Loss: 0.0447\n",
      "Epoch [32/50], Class Loss: 0.0801, Discrepancy Loss: 0.0445\n",
      "Epoch [33/50], Class Loss: 0.0757, Discrepancy Loss: 0.0452\n",
      "Epoch [34/50], Class Loss: 0.0637, Discrepancy Loss: 0.0444\n",
      "Epoch [35/50], Class Loss: 0.0822, Discrepancy Loss: 0.0459\n",
      "Epoch [36/50], Class Loss: 0.0794, Discrepancy Loss: 0.0450\n",
      "Epoch [37/50], Class Loss: 0.0742, Discrepancy Loss: 0.0444\n",
      "Epoch [38/50], Class Loss: 0.1029, Discrepancy Loss: 0.0498\n",
      "Epoch [39/50], Class Loss: 0.0728, Discrepancy Loss: 0.0455\n",
      "Epoch [40/50], Class Loss: 0.0823, Discrepancy Loss: 0.0448\n",
      "Epoch [41/50], Class Loss: 0.0711, Discrepancy Loss: 0.0459\n",
      "Epoch [42/50], Class Loss: 0.0657, Discrepancy Loss: 0.0415\n",
      "Epoch [43/50], Class Loss: 0.0762, Discrepancy Loss: 0.0450\n",
      "Epoch [44/50], Class Loss: 0.0786, Discrepancy Loss: 0.0418\n",
      "Epoch [45/50], Class Loss: 0.0815, Discrepancy Loss: 0.0447\n",
      "Epoch [46/50], Class Loss: 0.0798, Discrepancy Loss: 0.0452\n",
      "Epoch [47/50], Class Loss: 0.0806, Discrepancy Loss: 0.0447\n",
      "Epoch [48/50], Class Loss: 0.0806, Discrepancy Loss: 0.0477\n",
      "Epoch [49/50], Class Loss: 0.0763, Discrepancy Loss: 0.0447\n",
      "Epoch [50/50], Class Loss: 0.0768, Discrepancy Loss: 0.0434\n",
      "Source Domain Performance - Accuracy: 84.77%, Precision: 88.11%, Recall: 85.37%, F1 Score: 84.16%\n",
      "Target Domain Performance - Accuracy: 64.21%, Precision: 72.81%, Recall: 62.70%, F1 Score: 58.92%\n",
      "\n",
      "Source performance: 81.01% 84.37% 81.69% 79.76%\n",
      "Target performance: 68.76% 75.02% 67.47% 65.04%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.95%\n",
      "qpsk: 25.09%\n",
      "16qam: 46.23%\n",
      "16apsk: 98.62%\n",
      "SNR level: 14\n",
      "SNR level: 14\n",
      "CORAL\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 1.1705, CORAL Loss: 0.0342\n",
      "Validation Loss: 0.6357\n",
      "Epoch [2/50], Class Loss: 0.4983, CORAL Loss: 0.0291\n",
      "Validation Loss: 0.6426\n",
      "Epoch [3/50], Class Loss: 0.5286, CORAL Loss: 0.0196\n",
      "Validation Loss: 0.5408\n",
      "Epoch [4/50], Class Loss: 0.4512, CORAL Loss: 0.0199\n",
      "Validation Loss: 0.4390\n",
      "Epoch [5/50], Class Loss: 0.4397, CORAL Loss: 0.0143\n",
      "Validation Loss: 0.5207\n",
      "Epoch [6/50], Class Loss: 0.4652, CORAL Loss: 0.0187\n",
      "Validation Loss: 0.4440\n",
      "Epoch [7/50], Class Loss: 0.4210, CORAL Loss: 0.0165\n",
      "Validation Loss: 0.4944\n",
      "Epoch [8/50], Class Loss: 0.4347, CORAL Loss: 0.0158\n",
      "Validation Loss: 0.4814\n",
      "Epoch [9/50], Class Loss: 0.3891, CORAL Loss: 0.0226\n",
      "Validation Loss: 0.4603\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 80.16%, Precision: 81.12%, Recall: 79.96%, F1 Score: 79.71%\n",
      "Target Domain Performance - Accuracy: 62.53%, Precision: 66.89%, Recall: 62.10%, F1 Score: 62.70%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 1.0066, CORAL Loss: 0.0247\n",
      "Validation Loss: 1.2086\n",
      "Epoch [2/50], Class Loss: 0.5512, CORAL Loss: 0.0316\n",
      "Validation Loss: 0.4685\n",
      "Epoch [3/50], Class Loss: 0.4708, CORAL Loss: 0.0168\n",
      "Validation Loss: 0.4661\n",
      "Epoch [4/50], Class Loss: 0.4768, CORAL Loss: 0.0176\n",
      "Validation Loss: 0.4628\n",
      "Epoch [5/50], Class Loss: 0.4503, CORAL Loss: 0.0129\n",
      "Validation Loss: 0.4462\n",
      "Epoch [6/50], Class Loss: 0.4920, CORAL Loss: 0.0191\n",
      "Validation Loss: 0.4349\n",
      "Epoch [7/50], Class Loss: 0.4355, CORAL Loss: 0.0150\n",
      "Validation Loss: 0.5360\n",
      "Epoch [8/50], Class Loss: 0.4274, CORAL Loss: 0.0150\n",
      "Validation Loss: 0.4528\n",
      "Epoch [9/50], Class Loss: 0.4065, CORAL Loss: 0.0155\n",
      "Validation Loss: 0.4386\n",
      "Epoch [10/50], Class Loss: 0.3735, CORAL Loss: 0.0144\n",
      "Validation Loss: 0.4877\n",
      "Epoch [11/50], Class Loss: 0.3152, CORAL Loss: 0.0173\n",
      "Validation Loss: 0.4297\n",
      "Epoch [12/50], Class Loss: 0.2930, CORAL Loss: 0.0171\n",
      "Validation Loss: 0.4331\n",
      "Epoch [13/50], Class Loss: 0.2729, CORAL Loss: 0.0187\n",
      "Validation Loss: 0.4435\n",
      "Epoch [14/50], Class Loss: 0.2611, CORAL Loss: 0.0256\n",
      "Validation Loss: 0.4056\n",
      "Epoch [15/50], Class Loss: 0.2366, CORAL Loss: 0.0189\n",
      "Validation Loss: 0.3884\n",
      "Epoch [16/50], Class Loss: 0.2178, CORAL Loss: 0.0223\n",
      "Validation Loss: 0.3885\n",
      "Epoch [17/50], Class Loss: 0.1905, CORAL Loss: 0.0202\n",
      "Validation Loss: 0.3318\n",
      "Epoch [18/50], Class Loss: 0.1738, CORAL Loss: 0.0292\n",
      "Validation Loss: 0.3123\n",
      "Epoch [19/50], Class Loss: 0.1578, CORAL Loss: 0.0251\n",
      "Validation Loss: 0.2775\n",
      "Epoch [20/50], Class Loss: 0.1415, CORAL Loss: 0.0243\n",
      "Validation Loss: 0.2788\n",
      "Epoch [21/50], Class Loss: 0.1178, CORAL Loss: 0.0223\n",
      "Validation Loss: 0.2449\n",
      "Epoch [22/50], Class Loss: 0.1092, CORAL Loss: 0.0203\n",
      "Validation Loss: 0.2465\n",
      "Epoch [23/50], Class Loss: 0.1085, CORAL Loss: 0.0228\n",
      "Validation Loss: 0.2409\n",
      "Epoch [24/50], Class Loss: 0.1068, CORAL Loss: 0.0239\n",
      "Validation Loss: 0.2373\n",
      "Epoch [25/50], Class Loss: 0.1031, CORAL Loss: 0.0231\n",
      "Validation Loss: 0.2316\n",
      "Epoch [26/50], Class Loss: 0.1022, CORAL Loss: 0.0203\n",
      "Validation Loss: 0.2247\n",
      "Epoch [27/50], Class Loss: 0.0968, CORAL Loss: 0.0247\n",
      "Validation Loss: 0.2271\n",
      "Epoch [28/50], Class Loss: 0.0975, CORAL Loss: 0.0242\n",
      "Validation Loss: 0.2252\n",
      "Epoch [29/50], Class Loss: 0.0974, CORAL Loss: 0.0259\n",
      "Validation Loss: 0.2193\n",
      "Epoch [30/50], Class Loss: 0.0936, CORAL Loss: 0.0175\n",
      "Validation Loss: 0.2174\n",
      "Epoch [31/50], Class Loss: 0.0911, CORAL Loss: 0.0280\n",
      "Validation Loss: 0.2153\n",
      "Epoch [32/50], Class Loss: 0.0910, CORAL Loss: 0.0254\n",
      "Validation Loss: 0.2173\n",
      "Epoch [33/50], Class Loss: 0.0910, CORAL Loss: 0.0224\n",
      "Validation Loss: 0.2199\n",
      "Epoch [34/50], Class Loss: 0.0890, CORAL Loss: 0.0208\n",
      "Validation Loss: 0.2141\n",
      "Epoch [35/50], Class Loss: 0.0878, CORAL Loss: 0.0216\n",
      "Validation Loss: 0.2149\n",
      "Epoch [36/50], Class Loss: 0.0905, CORAL Loss: 0.0199\n",
      "Validation Loss: 0.2160\n",
      "Epoch [37/50], Class Loss: 0.0908, CORAL Loss: 0.0230\n",
      "Validation Loss: 0.2159\n",
      "Epoch [38/50], Class Loss: 0.0899, CORAL Loss: 0.0284\n",
      "Validation Loss: 0.2131\n",
      "Epoch [39/50], Class Loss: 0.0897, CORAL Loss: 0.0229\n",
      "Validation Loss: 0.2130\n",
      "Epoch [40/50], Class Loss: 0.0909, CORAL Loss: 0.0243\n",
      "Validation Loss: 0.2139\n",
      "Epoch [41/50], Class Loss: 0.0894, CORAL Loss: 0.0233\n",
      "Validation Loss: 0.2135\n",
      "Epoch [42/50], Class Loss: 0.0908, CORAL Loss: 0.0242\n",
      "Validation Loss: 0.2134\n",
      "Epoch [43/50], Class Loss: 0.0887, CORAL Loss: 0.0228\n",
      "Validation Loss: 0.2135\n",
      "Epoch [44/50], Class Loss: 0.0891, CORAL Loss: 0.0202\n",
      "Validation Loss: 0.2135\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 91.43%, Precision: 91.16%, Recall: 91.16%, F1 Score: 91.16%\n",
      "Target Domain Performance - Accuracy: 61.27%, Precision: 66.03%, Recall: 62.08%, F1 Score: 60.16%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 0.9744, CORAL Loss: 0.0348\n",
      "Validation Loss: 0.7771\n",
      "Epoch [2/50], Class Loss: 0.5109, CORAL Loss: 0.0275\n",
      "Validation Loss: 0.4609\n",
      "Epoch [3/50], Class Loss: 0.4755, CORAL Loss: 0.0188\n",
      "Validation Loss: 0.4421\n",
      "Epoch [4/50], Class Loss: 0.4847, CORAL Loss: 0.0193\n",
      "Validation Loss: 0.4925\n",
      "Epoch [5/50], Class Loss: 0.4783, CORAL Loss: 0.0150\n",
      "Validation Loss: 0.5782\n",
      "Epoch [6/50], Class Loss: 0.4586, CORAL Loss: 0.0125\n",
      "Validation Loss: 0.4473\n",
      "Epoch [7/50], Class Loss: 0.4301, CORAL Loss: 0.0138\n",
      "Validation Loss: 0.4360\n",
      "Epoch [8/50], Class Loss: 0.4380, CORAL Loss: 0.0149\n",
      "Validation Loss: 0.5652\n",
      "Epoch [9/50], Class Loss: 0.3995, CORAL Loss: 0.0169\n",
      "Validation Loss: 0.4834\n",
      "Epoch [10/50], Class Loss: 0.3730, CORAL Loss: 0.0193\n",
      "Validation Loss: 0.5107\n",
      "Epoch [11/50], Class Loss: 0.2756, CORAL Loss: 0.0207\n",
      "Validation Loss: 0.4148\n",
      "Epoch [12/50], Class Loss: 0.2571, CORAL Loss: 0.0257\n",
      "Validation Loss: 0.4092\n",
      "Epoch [13/50], Class Loss: 0.2371, CORAL Loss: 0.0267\n",
      "Validation Loss: 0.3980\n",
      "Epoch [14/50], Class Loss: 0.2232, CORAL Loss: 0.0343\n",
      "Validation Loss: 0.3810\n",
      "Epoch [15/50], Class Loss: 0.2062, CORAL Loss: 0.0283\n",
      "Validation Loss: 0.3666\n",
      "Epoch [16/50], Class Loss: 0.1874, CORAL Loss: 0.0323\n",
      "Validation Loss: 0.3428\n",
      "Epoch [17/50], Class Loss: 0.1662, CORAL Loss: 0.0313\n",
      "Validation Loss: 0.3808\n",
      "Epoch [18/50], Class Loss: 0.1455, CORAL Loss: 0.0292\n",
      "Validation Loss: 0.2869\n",
      "Epoch [19/50], Class Loss: 0.1233, CORAL Loss: 0.0362\n",
      "Validation Loss: 0.3723\n",
      "Epoch [20/50], Class Loss: 0.1039, CORAL Loss: 0.0304\n",
      "Validation Loss: 0.2382\n",
      "Epoch [21/50], Class Loss: 0.0860, CORAL Loss: 0.0314\n",
      "Validation Loss: 0.2306\n",
      "Epoch [22/50], Class Loss: 0.0822, CORAL Loss: 0.0336\n",
      "Validation Loss: 0.2365\n",
      "Epoch [23/50], Class Loss: 0.0834, CORAL Loss: 0.0296\n",
      "Validation Loss: 0.2259\n",
      "Epoch [24/50], Class Loss: 0.0794, CORAL Loss: 0.0366\n",
      "Validation Loss: 0.2232\n",
      "Epoch [25/50], Class Loss: 0.0760, CORAL Loss: 0.0281\n",
      "Validation Loss: 0.2254\n",
      "Epoch [26/50], Class Loss: 0.0774, CORAL Loss: 0.0308\n",
      "Validation Loss: 0.2255\n",
      "Epoch [27/50], Class Loss: 0.0749, CORAL Loss: 0.0362\n",
      "Validation Loss: 0.2151\n",
      "Epoch [28/50], Class Loss: 0.0703, CORAL Loss: 0.0323\n",
      "Validation Loss: 0.2232\n",
      "Epoch [29/50], Class Loss: 0.0695, CORAL Loss: 0.0326\n",
      "Validation Loss: 0.2072\n",
      "Epoch [30/50], Class Loss: 0.0677, CORAL Loss: 0.0341\n",
      "Validation Loss: 0.2025\n",
      "Epoch [31/50], Class Loss: 0.0695, CORAL Loss: 0.0337\n",
      "Validation Loss: 0.2087\n",
      "Epoch [32/50], Class Loss: 0.0668, CORAL Loss: 0.0263\n",
      "Validation Loss: 0.2068\n",
      "Epoch [33/50], Class Loss: 0.0658, CORAL Loss: 0.0297\n",
      "Validation Loss: 0.2066\n",
      "Epoch [34/50], Class Loss: 0.0663, CORAL Loss: 0.0294\n",
      "Validation Loss: 0.2078\n",
      "Epoch [35/50], Class Loss: 0.0674, CORAL Loss: 0.0316\n",
      "Validation Loss: 0.2068\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 91.97%, Precision: 91.72%, Recall: 91.72%, F1 Score: 91.72%\n",
      "Target Domain Performance - Accuracy: 61.03%, Precision: 65.82%, Recall: 61.83%, F1 Score: 60.00%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 1.0235, CORAL Loss: 0.0244\n",
      "Validation Loss: 0.4815\n",
      "Epoch [2/50], Class Loss: 0.5260, CORAL Loss: 0.0242\n",
      "Validation Loss: 0.4515\n",
      "Epoch [3/50], Class Loss: 0.4728, CORAL Loss: 0.0170\n",
      "Validation Loss: 0.4569\n",
      "Epoch [4/50], Class Loss: 0.4818, CORAL Loss: 0.0171\n",
      "Validation Loss: 0.6373\n",
      "Epoch [5/50], Class Loss: 0.4502, CORAL Loss: 0.0115\n",
      "Validation Loss: 0.4531\n",
      "Epoch [6/50], Class Loss: 0.4554, CORAL Loss: 0.0144\n",
      "Validation Loss: 0.4389\n",
      "Epoch [7/50], Class Loss: 0.4315, CORAL Loss: 0.0143\n",
      "Validation Loss: 0.4345\n",
      "Epoch [8/50], Class Loss: 0.4518, CORAL Loss: 0.0123\n",
      "Validation Loss: 0.4342\n",
      "Epoch [9/50], Class Loss: 0.4005, CORAL Loss: 0.0168\n",
      "Validation Loss: 0.4995\n",
      "Epoch [10/50], Class Loss: 0.4401, CORAL Loss: 0.0173\n",
      "Validation Loss: 0.4888\n",
      "Epoch [11/50], Class Loss: 0.3363, CORAL Loss: 0.0192\n",
      "Validation Loss: 0.4181\n",
      "Epoch [12/50], Class Loss: 0.3069, CORAL Loss: 0.0185\n",
      "Validation Loss: 0.4202\n",
      "Epoch [13/50], Class Loss: 0.2907, CORAL Loss: 0.0209\n",
      "Validation Loss: 0.3972\n",
      "Epoch [14/50], Class Loss: 0.2648, CORAL Loss: 0.0226\n",
      "Validation Loss: 0.3905\n",
      "Epoch [15/50], Class Loss: 0.2551, CORAL Loss: 0.0240\n",
      "Validation Loss: 0.3804\n",
      "Epoch [16/50], Class Loss: 0.2285, CORAL Loss: 0.0305\n",
      "Validation Loss: 0.3896\n",
      "Epoch [17/50], Class Loss: 0.2115, CORAL Loss: 0.0255\n",
      "Validation Loss: 0.3433\n",
      "Epoch [18/50], Class Loss: 0.1976, CORAL Loss: 0.0241\n",
      "Validation Loss: 0.2988\n",
      "Epoch [19/50], Class Loss: 0.1712, CORAL Loss: 0.0324\n",
      "Validation Loss: 0.2774\n",
      "Epoch [20/50], Class Loss: 0.1555, CORAL Loss: 0.0273\n",
      "Validation Loss: 0.2606\n",
      "Epoch [21/50], Class Loss: 0.1265, CORAL Loss: 0.0242\n",
      "Validation Loss: 0.2575\n",
      "Epoch [22/50], Class Loss: 0.1211, CORAL Loss: 0.0269\n",
      "Validation Loss: 0.2475\n",
      "Epoch [23/50], Class Loss: 0.1222, CORAL Loss: 0.0319\n",
      "Validation Loss: 0.2439\n",
      "Epoch [24/50], Class Loss: 0.1197, CORAL Loss: 0.0291\n",
      "Validation Loss: 0.2426\n",
      "Epoch [25/50], Class Loss: 0.1188, CORAL Loss: 0.0244\n",
      "Validation Loss: 0.2339\n",
      "Epoch [26/50], Class Loss: 0.1131, CORAL Loss: 0.0261\n",
      "Validation Loss: 0.2506\n",
      "Epoch [27/50], Class Loss: 0.1129, CORAL Loss: 0.0288\n",
      "Validation Loss: 0.2283\n",
      "Epoch [28/50], Class Loss: 0.1077, CORAL Loss: 0.0260\n",
      "Validation Loss: 0.2273\n",
      "Epoch [29/50], Class Loss: 0.1091, CORAL Loss: 0.0301\n",
      "Validation Loss: 0.2269\n",
      "Epoch [30/50], Class Loss: 0.1064, CORAL Loss: 0.0264\n",
      "Validation Loss: 0.2225\n",
      "Epoch [31/50], Class Loss: 0.1029, CORAL Loss: 0.0257\n",
      "Validation Loss: 0.2239\n",
      "Epoch [32/50], Class Loss: 0.1022, CORAL Loss: 0.0285\n",
      "Validation Loss: 0.2205\n",
      "Epoch [33/50], Class Loss: 0.1016, CORAL Loss: 0.0273\n",
      "Validation Loss: 0.2230\n",
      "Epoch [34/50], Class Loss: 0.1040, CORAL Loss: 0.0269\n",
      "Validation Loss: 0.2210\n",
      "Epoch [35/50], Class Loss: 0.1017, CORAL Loss: 0.0318\n",
      "Validation Loss: 0.2201\n",
      "Epoch [36/50], Class Loss: 0.1006, CORAL Loss: 0.0237\n",
      "Validation Loss: 0.2191\n",
      "Epoch [37/50], Class Loss: 0.1026, CORAL Loss: 0.0292\n",
      "Validation Loss: 0.2198\n",
      "Epoch [38/50], Class Loss: 0.1003, CORAL Loss: 0.0280\n",
      "Validation Loss: 0.2159\n",
      "Epoch [39/50], Class Loss: 0.1023, CORAL Loss: 0.0321\n",
      "Validation Loss: 0.2177\n",
      "Epoch [40/50], Class Loss: 0.1018, CORAL Loss: 0.0267\n",
      "Validation Loss: 0.2187\n",
      "Epoch [41/50], Class Loss: 0.1039, CORAL Loss: 0.0365\n",
      "Validation Loss: 0.2190\n",
      "Epoch [42/50], Class Loss: 0.1013, CORAL Loss: 0.0272\n",
      "Validation Loss: 0.2190\n",
      "Epoch [43/50], Class Loss: 0.1014, CORAL Loss: 0.0277\n",
      "Validation Loss: 0.2189\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 90.71%, Precision: 90.39%, Recall: 90.39%, F1 Score: 90.37%\n",
      "Target Domain Performance - Accuracy: 61.27%, Precision: 65.61%, Recall: 62.01%, F1 Score: 60.42%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 0.8556, CORAL Loss: 0.0181\n",
      "Validation Loss: 0.5385\n",
      "Epoch [2/50], Class Loss: 0.4882, CORAL Loss: 0.0207\n",
      "Validation Loss: 0.4719\n",
      "Epoch [3/50], Class Loss: 0.4874, CORAL Loss: 0.0107\n",
      "Validation Loss: 0.4545\n",
      "Epoch [4/50], Class Loss: 0.4645, CORAL Loss: 0.0165\n",
      "Validation Loss: 0.4597\n",
      "Epoch [5/50], Class Loss: 0.4844, CORAL Loss: 0.0107\n",
      "Validation Loss: 0.4513\n",
      "Epoch [6/50], Class Loss: 0.4286, CORAL Loss: 0.0128\n",
      "Validation Loss: 0.4407\n",
      "Epoch [7/50], Class Loss: 0.4113, CORAL Loss: 0.0116\n",
      "Validation Loss: 0.4888\n",
      "Epoch [8/50], Class Loss: 0.4263, CORAL Loss: 0.0173\n",
      "Validation Loss: 0.5757\n",
      "Epoch [9/50], Class Loss: 0.3727, CORAL Loss: 0.0172\n",
      "Validation Loss: 0.4634\n",
      "Epoch [10/50], Class Loss: 0.2944, CORAL Loss: 0.0204\n",
      "Validation Loss: 0.6457\n",
      "Epoch [11/50], Class Loss: 0.1764, CORAL Loss: 0.0242\n",
      "Validation Loss: 0.2281\n",
      "Epoch [12/50], Class Loss: 0.1439, CORAL Loss: 0.0283\n",
      "Validation Loss: 0.2076\n",
      "Epoch [13/50], Class Loss: 0.1241, CORAL Loss: 0.0250\n",
      "Validation Loss: 0.1907\n",
      "Epoch [14/50], Class Loss: 0.0991, CORAL Loss: 0.0208\n",
      "Validation Loss: 0.1654\n",
      "Epoch [15/50], Class Loss: 0.0870, CORAL Loss: 0.0270\n",
      "Validation Loss: 0.1411\n",
      "Epoch [16/50], Class Loss: 0.0753, CORAL Loss: 0.0259\n",
      "Validation Loss: 0.1282\n",
      "Epoch [17/50], Class Loss: 0.0612, CORAL Loss: 0.0225\n",
      "Validation Loss: 0.1339\n",
      "Epoch [18/50], Class Loss: 0.0474, CORAL Loss: 0.0197\n",
      "Validation Loss: 0.1035\n",
      "Epoch [19/50], Class Loss: 0.0444, CORAL Loss: 0.0251\n",
      "Validation Loss: 0.0990\n",
      "Epoch [20/50], Class Loss: 0.0438, CORAL Loss: 0.0212\n",
      "Validation Loss: 0.0916\n",
      "Epoch [21/50], Class Loss: 0.0321, CORAL Loss: 0.0230\n",
      "Validation Loss: 0.0927\n",
      "Epoch [22/50], Class Loss: 0.0302, CORAL Loss: 0.0191\n",
      "Validation Loss: 0.0917\n",
      "Epoch [23/50], Class Loss: 0.0301, CORAL Loss: 0.0216\n",
      "Validation Loss: 0.0848\n",
      "Epoch [24/50], Class Loss: 0.0306, CORAL Loss: 0.0180\n",
      "Validation Loss: 0.0860\n",
      "Epoch [25/50], Class Loss: 0.0280, CORAL Loss: 0.0204\n",
      "Validation Loss: 0.0939\n",
      "Epoch [26/50], Class Loss: 0.0268, CORAL Loss: 0.0199\n",
      "Validation Loss: 0.0894\n",
      "Epoch [27/50], Class Loss: 0.0294, CORAL Loss: 0.0202\n",
      "Validation Loss: 0.0905\n",
      "Epoch [28/50], Class Loss: 0.0286, CORAL Loss: 0.0204\n",
      "Validation Loss: 0.0908\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.76%, Precision: 96.67%, Recall: 96.65%, F1 Score: 96.65%\n",
      "Target Domain Performance - Accuracy: 55.04%, Precision: 63.90%, Recall: 56.36%, F1 Score: 50.45%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 0.9679, CORAL Loss: 0.0264\n",
      "Validation Loss: 0.5059\n",
      "Epoch [2/50], Class Loss: 0.5026, CORAL Loss: 0.0247\n",
      "Validation Loss: 0.5943\n",
      "Epoch [3/50], Class Loss: 0.4842, CORAL Loss: 0.0167\n",
      "Validation Loss: 0.4456\n",
      "Epoch [4/50], Class Loss: 0.4594, CORAL Loss: 0.0163\n",
      "Validation Loss: 0.5037\n",
      "Epoch [5/50], Class Loss: 0.4467, CORAL Loss: 0.0131\n",
      "Validation Loss: 0.4741\n",
      "Epoch [6/50], Class Loss: 0.4308, CORAL Loss: 0.0159\n",
      "Validation Loss: 0.5661\n",
      "Epoch [7/50], Class Loss: 0.4479, CORAL Loss: 0.0161\n",
      "Validation Loss: 0.5172\n",
      "Epoch [8/50], Class Loss: 0.4242, CORAL Loss: 0.0172\n",
      "Validation Loss: 0.4673\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 79.56%, Precision: 79.90%, Recall: 79.25%, F1 Score: 78.88%\n",
      "Target Domain Performance - Accuracy: 62.71%, Precision: 66.23%, Recall: 62.37%, F1 Score: 62.93%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 0.9634, CORAL Loss: 0.0313\n",
      "Validation Loss: 0.5159\n",
      "Epoch [2/50], Class Loss: 0.4995, CORAL Loss: 0.0287\n",
      "Validation Loss: 0.7812\n",
      "Epoch [3/50], Class Loss: 0.4952, CORAL Loss: 0.0217\n",
      "Validation Loss: 0.5138\n",
      "Epoch [4/50], Class Loss: 0.5044, CORAL Loss: 0.0184\n",
      "Validation Loss: 0.4434\n",
      "Epoch [5/50], Class Loss: 0.4435, CORAL Loss: 0.0145\n",
      "Validation Loss: 0.5537\n",
      "Epoch [6/50], Class Loss: 0.4326, CORAL Loss: 0.0160\n",
      "Validation Loss: 0.4589\n",
      "Epoch [7/50], Class Loss: 0.4143, CORAL Loss: 0.0161\n",
      "Validation Loss: 0.4673\n",
      "Epoch [8/50], Class Loss: 0.4066, CORAL Loss: 0.0167\n",
      "Validation Loss: 0.4341\n",
      "Epoch [9/50], Class Loss: 0.3993, CORAL Loss: 0.0204\n",
      "Validation Loss: 0.4529\n",
      "Epoch [10/50], Class Loss: 0.3613, CORAL Loss: 0.0223\n",
      "Validation Loss: 0.6477\n",
      "Epoch [11/50], Class Loss: 0.2695, CORAL Loss: 0.0219\n",
      "Validation Loss: 0.4569\n",
      "Epoch [12/50], Class Loss: 0.2419, CORAL Loss: 0.0260\n",
      "Validation Loss: 0.4627\n",
      "Epoch [13/50], Class Loss: 0.2178, CORAL Loss: 0.0224\n",
      "Validation Loss: 0.4406\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 83.03%, Precision: 82.34%, Recall: 82.56%, F1 Score: 82.38%\n",
      "Target Domain Performance - Accuracy: 60.67%, Precision: 63.23%, Recall: 60.85%, F1 Score: 61.40%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 1.0461, CORAL Loss: 0.0325\n",
      "Validation Loss: 0.5119\n",
      "Epoch [2/50], Class Loss: 0.5191, CORAL Loss: 0.0332\n",
      "Validation Loss: 0.4925\n",
      "Epoch [3/50], Class Loss: 0.4937, CORAL Loss: 0.0239\n",
      "Validation Loss: 0.4893\n",
      "Epoch [4/50], Class Loss: 0.4646, CORAL Loss: 0.0166\n",
      "Validation Loss: 0.5247\n",
      "Epoch [5/50], Class Loss: 0.4360, CORAL Loss: 0.0148\n",
      "Validation Loss: 0.4350\n",
      "Epoch [6/50], Class Loss: 0.4381, CORAL Loss: 0.0166\n",
      "Validation Loss: 0.6671\n",
      "Epoch [7/50], Class Loss: 0.4500, CORAL Loss: 0.0157\n",
      "Validation Loss: 0.4368\n",
      "Epoch [8/50], Class Loss: 0.4280, CORAL Loss: 0.0179\n",
      "Validation Loss: 0.4661\n",
      "Epoch [9/50], Class Loss: 0.4028, CORAL Loss: 0.0147\n",
      "Validation Loss: 0.4334\n",
      "Epoch [10/50], Class Loss: 0.3395, CORAL Loss: 0.0345\n",
      "Validation Loss: 0.4587\n",
      "Epoch [11/50], Class Loss: 0.2675, CORAL Loss: 0.0142\n",
      "Validation Loss: 0.4371\n",
      "Epoch [12/50], Class Loss: 0.2414, CORAL Loss: 0.0196\n",
      "Validation Loss: 0.4416\n",
      "Epoch [13/50], Class Loss: 0.2249, CORAL Loss: 0.0239\n",
      "Validation Loss: 0.4358\n",
      "Epoch [14/50], Class Loss: 0.2085, CORAL Loss: 0.0236\n",
      "Validation Loss: 0.4581\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 82.31%, Precision: 81.56%, Recall: 81.76%, F1 Score: 81.59%\n",
      "Target Domain Performance - Accuracy: 60.91%, Precision: 63.75%, Recall: 61.21%, F1 Score: 61.29%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.0213, CORAL Loss: 0.0222\n",
      "Validation Loss: 0.6886\n",
      "Epoch [2/50], Class Loss: 0.5082, CORAL Loss: 0.0317\n",
      "Validation Loss: 0.5156\n",
      "Epoch [3/50], Class Loss: 0.4921, CORAL Loss: 0.0223\n",
      "Validation Loss: 0.4656\n",
      "Epoch [4/50], Class Loss: 0.4735, CORAL Loss: 0.0175\n",
      "Validation Loss: 0.5147\n",
      "Epoch [5/50], Class Loss: 0.4498, CORAL Loss: 0.0150\n",
      "Validation Loss: 0.5016\n",
      "Epoch [6/50], Class Loss: 0.4573, CORAL Loss: 0.0139\n",
      "Validation Loss: 0.4339\n",
      "Epoch [7/50], Class Loss: 0.4939, CORAL Loss: 0.0180\n",
      "Validation Loss: 0.4909\n",
      "Epoch [8/50], Class Loss: 0.4205, CORAL Loss: 0.0147\n",
      "Validation Loss: 0.4439\n",
      "Epoch [9/50], Class Loss: 0.4314, CORAL Loss: 0.0143\n",
      "Validation Loss: 0.4328\n",
      "Epoch [10/50], Class Loss: 0.3750, CORAL Loss: 0.0164\n",
      "Validation Loss: 0.5363\n",
      "Epoch [11/50], Class Loss: 0.3115, CORAL Loss: 0.0160\n",
      "Validation Loss: 0.4437\n",
      "Epoch [12/50], Class Loss: 0.2945, CORAL Loss: 0.0154\n",
      "Validation Loss: 0.4509\n",
      "Epoch [13/50], Class Loss: 0.2874, CORAL Loss: 0.0152\n",
      "Validation Loss: 0.4519\n",
      "Epoch [14/50], Class Loss: 0.2714, CORAL Loss: 0.0159\n",
      "Validation Loss: 0.4531\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 81.06%, Precision: 80.48%, Recall: 80.62%, F1 Score: 80.43%\n",
      "Target Domain Performance - Accuracy: 60.01%, Precision: 62.85%, Recall: 59.89%, F1 Score: 60.58%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 0.9796, CORAL Loss: 0.0329\n",
      "Validation Loss: 0.4905\n",
      "Epoch [2/50], Class Loss: 0.5015, CORAL Loss: 0.0246\n",
      "Validation Loss: 0.5465\n",
      "Epoch [3/50], Class Loss: 0.4826, CORAL Loss: 0.0182\n",
      "Validation Loss: 0.4368\n",
      "Epoch [4/50], Class Loss: 0.4720, CORAL Loss: 0.0175\n",
      "Validation Loss: 0.4474\n",
      "Epoch [5/50], Class Loss: 0.4345, CORAL Loss: 0.0119\n",
      "Validation Loss: 0.4679\n",
      "Epoch [6/50], Class Loss: 0.4593, CORAL Loss: 0.0154\n",
      "Validation Loss: 0.6831\n",
      "Epoch [7/50], Class Loss: 0.4667, CORAL Loss: 0.0178\n",
      "Validation Loss: 0.4729\n",
      "Epoch [8/50], Class Loss: 0.4074, CORAL Loss: 0.0133\n",
      "Validation Loss: 0.5187\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 78.84%, Precision: 77.78%, Recall: 78.15%, F1 Score: 77.71%\n",
      "Target Domain Performance - Accuracy: 57.25%, Precision: 58.38%, Recall: 57.80%, F1 Score: 56.85%\n",
      "\n",
      "Source performance: 85.58% 85.31% 85.22% 85.06%\n",
      "Target performance: 60.27% 64.27% 60.65% 59.68%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.88%\n",
      "qpsk: 34.57%\n",
      "16qam: 42.34%\n",
      "16apsk: 65.80%\n",
      "SNR level: 14\n",
      "JAN\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 1.1276, JMMD Loss: 0.1085\n",
      "Validation Loss: 0.5512\n",
      "Epoch [2/50], Class Loss: 0.4878, JMMD Loss: 0.1047\n",
      "Validation Loss: 0.4508\n",
      "Epoch [3/50], Class Loss: 0.4649, JMMD Loss: 0.0979\n",
      "Validation Loss: 0.4346\n",
      "Epoch [4/50], Class Loss: 0.4487, JMMD Loss: 0.0996\n",
      "Validation Loss: 0.4603\n",
      "Epoch [5/50], Class Loss: 0.4473, JMMD Loss: 0.0877\n",
      "Validation Loss: 0.4240\n",
      "Epoch [6/50], Class Loss: 0.4212, JMMD Loss: 0.0960\n",
      "Validation Loss: 0.5126\n",
      "Epoch [7/50], Class Loss: 0.4517, JMMD Loss: 0.0825\n",
      "Validation Loss: 0.4379\n",
      "Epoch [8/50], Class Loss: 0.4052, JMMD Loss: 0.0776\n",
      "Validation Loss: 0.4268\n",
      "Epoch [9/50], Class Loss: 0.4043, JMMD Loss: 0.0826\n",
      "Validation Loss: 0.4788\n",
      "Epoch [10/50], Class Loss: 0.3409, JMMD Loss: 0.0842\n",
      "Validation Loss: 0.3187\n",
      "Epoch [11/50], Class Loss: 0.1916, JMMD Loss: 0.1038\n",
      "Validation Loss: 0.2562\n",
      "Epoch [12/50], Class Loss: 0.1593, JMMD Loss: 0.1072\n",
      "Validation Loss: 0.2165\n",
      "Epoch [13/50], Class Loss: 0.1364, JMMD Loss: 0.1339\n",
      "Validation Loss: 0.1937\n",
      "Epoch [14/50], Class Loss: 0.1067, JMMD Loss: 0.1320\n",
      "Validation Loss: 0.1706\n",
      "Epoch [15/50], Class Loss: 0.0888, JMMD Loss: 0.1414\n",
      "Validation Loss: 0.1436\n",
      "Epoch [16/50], Class Loss: 0.0702, JMMD Loss: 0.1745\n",
      "Validation Loss: 0.1778\n",
      "Epoch [17/50], Class Loss: 0.0541, JMMD Loss: 0.1687\n",
      "Validation Loss: 0.1109\n",
      "Epoch [18/50], Class Loss: 0.0413, JMMD Loss: 0.1706\n",
      "Validation Loss: 0.1136\n",
      "Epoch [19/50], Class Loss: 0.0373, JMMD Loss: 0.1801\n",
      "Validation Loss: 0.1097\n",
      "Epoch [20/50], Class Loss: 0.0307, JMMD Loss: 0.1780\n",
      "Validation Loss: 0.1428\n",
      "Epoch [21/50], Class Loss: 0.0235, JMMD Loss: 0.1729\n",
      "Validation Loss: 0.0955\n",
      "Epoch [22/50], Class Loss: 0.0224, JMMD Loss: 0.1731\n",
      "Validation Loss: 0.0944\n",
      "Epoch [23/50], Class Loss: 0.0232, JMMD Loss: 0.1775\n",
      "Validation Loss: 0.0929\n",
      "Epoch [24/50], Class Loss: 0.0228, JMMD Loss: 0.1725\n",
      "Validation Loss: 0.0921\n",
      "Epoch [25/50], Class Loss: 0.0218, JMMD Loss: 0.1755\n",
      "Validation Loss: 0.0962\n",
      "Epoch [26/50], Class Loss: 0.0219, JMMD Loss: 0.1767\n",
      "Validation Loss: 0.0957\n",
      "Epoch [27/50], Class Loss: 0.0199, JMMD Loss: 0.1705\n",
      "Validation Loss: 0.0937\n",
      "Epoch [28/50], Class Loss: 0.0204, JMMD Loss: 0.1773\n",
      "Validation Loss: 0.0987\n",
      "Epoch [29/50], Class Loss: 0.0206, JMMD Loss: 0.1729\n",
      "Validation Loss: 0.0920\n",
      "Epoch [30/50], Class Loss: 0.0198, JMMD Loss: 0.1649\n",
      "Validation Loss: 0.0967\n",
      "Epoch [31/50], Class Loss: 0.0201, JMMD Loss: 0.1808\n",
      "Validation Loss: 0.0951\n",
      "Epoch [32/50], Class Loss: 0.0193, JMMD Loss: 0.1797\n",
      "Validation Loss: 0.0941\n",
      "Epoch [33/50], Class Loss: 0.0187, JMMD Loss: 0.1736\n",
      "Validation Loss: 0.0942\n",
      "Epoch [34/50], Class Loss: 0.0188, JMMD Loss: 0.1711\n",
      "Validation Loss: 0.0944\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.70%, Precision: 96.60%, Recall: 96.59%, F1 Score: 96.60%\n",
      "Target Domain Performance - Accuracy: 59.83%, Precision: 67.31%, Recall: 60.95%, F1 Score: 57.33%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 0.9499, JMMD Loss: 0.1068\n",
      "Validation Loss: 0.4796\n",
      "Epoch [2/50], Class Loss: 0.5226, JMMD Loss: 0.1089\n",
      "Validation Loss: 0.5309\n",
      "Epoch [3/50], Class Loss: 0.4637, JMMD Loss: 0.1046\n",
      "Validation Loss: 0.4616\n",
      "Epoch [4/50], Class Loss: 0.4399, JMMD Loss: 0.0993\n",
      "Validation Loss: 0.4471\n",
      "Epoch [5/50], Class Loss: 0.4982, JMMD Loss: 0.1019\n",
      "Validation Loss: 0.6161\n",
      "Epoch [6/50], Class Loss: 0.4353, JMMD Loss: 0.0965\n",
      "Validation Loss: 0.4295\n",
      "Epoch [7/50], Class Loss: 0.4277, JMMD Loss: 0.0891\n",
      "Validation Loss: 0.4511\n",
      "Epoch [8/50], Class Loss: 0.3861, JMMD Loss: 0.0775\n",
      "Validation Loss: 0.5158\n",
      "Epoch [9/50], Class Loss: 0.4472, JMMD Loss: 0.0816\n",
      "Validation Loss: 0.6799\n",
      "Epoch [10/50], Class Loss: 0.3682, JMMD Loss: 0.0855\n",
      "Validation Loss: 0.4660\n",
      "Epoch [11/50], Class Loss: 0.2816, JMMD Loss: 0.0758\n",
      "Validation Loss: 0.4197\n",
      "Epoch [12/50], Class Loss: 0.2611, JMMD Loss: 0.0827\n",
      "Validation Loss: 0.4508\n",
      "Epoch [13/50], Class Loss: 0.2472, JMMD Loss: 0.0632\n",
      "Validation Loss: 0.4207\n",
      "Epoch [14/50], Class Loss: 0.2197, JMMD Loss: 0.0688\n",
      "Validation Loss: 0.4049\n",
      "Epoch [15/50], Class Loss: 0.1953, JMMD Loss: 0.0769\n",
      "Validation Loss: 0.4395\n",
      "Epoch [16/50], Class Loss: 0.1820, JMMD Loss: 0.0784\n",
      "Validation Loss: 0.3948\n",
      "Epoch [17/50], Class Loss: 0.1552, JMMD Loss: 0.0802\n",
      "Validation Loss: 0.3827\n",
      "Epoch [18/50], Class Loss: 0.1289, JMMD Loss: 0.0792\n",
      "Validation Loss: 0.3470\n",
      "Epoch [19/50], Class Loss: 0.1066, JMMD Loss: 0.0787\n",
      "Validation Loss: 0.3346\n",
      "Epoch [20/50], Class Loss: 0.0895, JMMD Loss: 0.0748\n",
      "Validation Loss: 0.3247\n",
      "Epoch [21/50], Class Loss: 0.0719, JMMD Loss: 0.0917\n",
      "Validation Loss: 0.3176\n",
      "Epoch [22/50], Class Loss: 0.0691, JMMD Loss: 0.0726\n",
      "Validation Loss: 0.3124\n",
      "Epoch [23/50], Class Loss: 0.0667, JMMD Loss: 0.0814\n",
      "Validation Loss: 0.3174\n",
      "Epoch [24/50], Class Loss: 0.0649, JMMD Loss: 0.0860\n",
      "Validation Loss: 0.3095\n",
      "Epoch [25/50], Class Loss: 0.0635, JMMD Loss: 0.0766\n",
      "Validation Loss: 0.3114\n",
      "Epoch [26/50], Class Loss: 0.0605, JMMD Loss: 0.0749\n",
      "Validation Loss: 0.3213\n",
      "Epoch [27/50], Class Loss: 0.0601, JMMD Loss: 0.0931\n",
      "Validation Loss: 0.3041\n",
      "Epoch [28/50], Class Loss: 0.0575, JMMD Loss: 0.0794\n",
      "Validation Loss: 0.3052\n",
      "Epoch [29/50], Class Loss: 0.0564, JMMD Loss: 0.0832\n",
      "Validation Loss: 0.3110\n",
      "Epoch [30/50], Class Loss: 0.0551, JMMD Loss: 0.0815\n",
      "Validation Loss: 0.3001\n",
      "Epoch [31/50], Class Loss: 0.0520, JMMD Loss: 0.0784\n",
      "Validation Loss: 0.3002\n",
      "Epoch [32/50], Class Loss: 0.0519, JMMD Loss: 0.0872\n",
      "Validation Loss: 0.3039\n",
      "Epoch [33/50], Class Loss: 0.0538, JMMD Loss: 0.0748\n",
      "Validation Loss: 0.3028\n",
      "Epoch [34/50], Class Loss: 0.0507, JMMD Loss: 0.0866\n",
      "Validation Loss: 0.3031\n",
      "Epoch [35/50], Class Loss: 0.0523, JMMD Loss: 0.0786\n",
      "Validation Loss: 0.3035\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 89.27%, Precision: 88.89%, Recall: 88.89%, F1 Score: 88.85%\n",
      "Target Domain Performance - Accuracy: 67.33%, Precision: 70.45%, Recall: 67.39%, F1 Score: 67.99%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 1.0478, JMMD Loss: 0.0934\n",
      "Validation Loss: 0.4630\n",
      "Epoch [2/50], Class Loss: 0.4783, JMMD Loss: 0.0983\n",
      "Validation Loss: 0.4447\n",
      "Epoch [3/50], Class Loss: 0.4532, JMMD Loss: 0.1114\n",
      "Validation Loss: 0.4711\n",
      "Epoch [4/50], Class Loss: 0.4751, JMMD Loss: 0.0931\n",
      "Validation Loss: 0.4338\n",
      "Epoch [5/50], Class Loss: 0.4431, JMMD Loss: 0.0985\n",
      "Validation Loss: 0.4391\n",
      "Epoch [6/50], Class Loss: 0.4174, JMMD Loss: 0.0842\n",
      "Validation Loss: 0.4946\n",
      "Epoch [7/50], Class Loss: 0.4134, JMMD Loss: 0.1115\n",
      "Validation Loss: 0.4784\n",
      "Epoch [8/50], Class Loss: 0.4311, JMMD Loss: 0.0803\n",
      "Validation Loss: 0.4145\n",
      "Epoch [9/50], Class Loss: 0.3581, JMMD Loss: 0.0673\n",
      "Validation Loss: 0.4674\n",
      "Epoch [10/50], Class Loss: 0.3093, JMMD Loss: 0.0820\n",
      "Validation Loss: 0.3658\n",
      "Epoch [11/50], Class Loss: 0.1969, JMMD Loss: 0.0931\n",
      "Validation Loss: 0.2276\n",
      "Epoch [12/50], Class Loss: 0.1523, JMMD Loss: 0.0953\n",
      "Validation Loss: 0.2028\n",
      "Epoch [13/50], Class Loss: 0.1267, JMMD Loss: 0.1129\n",
      "Validation Loss: 0.1923\n",
      "Epoch [14/50], Class Loss: 0.1112, JMMD Loss: 0.1246\n",
      "Validation Loss: 0.1508\n",
      "Epoch [15/50], Class Loss: 0.0960, JMMD Loss: 0.1426\n",
      "Validation Loss: 0.1434\n",
      "Epoch [16/50], Class Loss: 0.0755, JMMD Loss: 0.1535\n",
      "Validation Loss: 0.1168\n",
      "Epoch [17/50], Class Loss: 0.0618, JMMD Loss: 0.1608\n",
      "Validation Loss: 0.1127\n",
      "Epoch [18/50], Class Loss: 0.0561, JMMD Loss: 0.1732\n",
      "Validation Loss: 0.1139\n",
      "Epoch [19/50], Class Loss: 0.0483, JMMD Loss: 0.1714\n",
      "Validation Loss: 0.1180\n",
      "Epoch [20/50], Class Loss: 0.0388, JMMD Loss: 0.1669\n",
      "Validation Loss: 0.1157\n",
      "Epoch [21/50], Class Loss: 0.0312, JMMD Loss: 0.1617\n",
      "Validation Loss: 0.0919\n",
      "Epoch [22/50], Class Loss: 0.0313, JMMD Loss: 0.1727\n",
      "Validation Loss: 0.0901\n",
      "Epoch [23/50], Class Loss: 0.0295, JMMD Loss: 0.1753\n",
      "Validation Loss: 0.0888\n",
      "Epoch [24/50], Class Loss: 0.0299, JMMD Loss: 0.1770\n",
      "Validation Loss: 0.0885\n",
      "Epoch [25/50], Class Loss: 0.0304, JMMD Loss: 0.1729\n",
      "Validation Loss: 0.0886\n",
      "Epoch [26/50], Class Loss: 0.0289, JMMD Loss: 0.1801\n",
      "Validation Loss: 0.0889\n",
      "Epoch [27/50], Class Loss: 0.0302, JMMD Loss: 0.1789\n",
      "Validation Loss: 0.0902\n",
      "Epoch [28/50], Class Loss: 0.0272, JMMD Loss: 0.1786\n",
      "Validation Loss: 0.0918\n",
      "Epoch [29/50], Class Loss: 0.0269, JMMD Loss: 0.1670\n",
      "Validation Loss: 0.0865\n",
      "Epoch [30/50], Class Loss: 0.0260, JMMD Loss: 0.1713\n",
      "Validation Loss: 0.0897\n",
      "Epoch [31/50], Class Loss: 0.0253, JMMD Loss: 0.1856\n",
      "Validation Loss: 0.0877\n",
      "Epoch [32/50], Class Loss: 0.0263, JMMD Loss: 0.1772\n",
      "Validation Loss: 0.0881\n",
      "Epoch [33/50], Class Loss: 0.0270, JMMD Loss: 0.1885\n",
      "Validation Loss: 0.0876\n",
      "Epoch [34/50], Class Loss: 0.0272, JMMD Loss: 0.1840\n",
      "Validation Loss: 0.0872\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.88%, Precision: 96.79%, Recall: 96.80%, F1 Score: 96.79%\n",
      "Target Domain Performance - Accuracy: 59.89%, Precision: 67.25%, Recall: 61.03%, F1 Score: 57.38%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 1.0521, JMMD Loss: 0.0943\n",
      "Validation Loss: 0.4863\n",
      "Epoch [2/50], Class Loss: 0.4792, JMMD Loss: 0.1053\n",
      "Validation Loss: 0.4372\n",
      "Epoch [3/50], Class Loss: 0.4760, JMMD Loss: 0.0991\n",
      "Validation Loss: 0.6091\n",
      "Epoch [4/50], Class Loss: 0.4895, JMMD Loss: 0.1012\n",
      "Validation Loss: 0.4759\n",
      "Epoch [5/50], Class Loss: 0.4554, JMMD Loss: 0.0955\n",
      "Validation Loss: 0.4607\n",
      "Epoch [6/50], Class Loss: 0.4251, JMMD Loss: 0.0909\n",
      "Validation Loss: 0.4312\n",
      "Epoch [7/50], Class Loss: 0.4455, JMMD Loss: 0.0977\n",
      "Validation Loss: 1.6190\n",
      "Epoch [8/50], Class Loss: 0.4590, JMMD Loss: 0.0972\n",
      "Validation Loss: 0.4416\n",
      "Epoch [9/50], Class Loss: 0.3893, JMMD Loss: 0.0929\n",
      "Validation Loss: 0.4625\n",
      "Epoch [10/50], Class Loss: 0.3485, JMMD Loss: 0.0770\n",
      "Validation Loss: 0.4448\n",
      "Epoch [11/50], Class Loss: 0.2557, JMMD Loss: 0.0801\n",
      "Validation Loss: 0.3366\n",
      "Epoch [12/50], Class Loss: 0.2221, JMMD Loss: 0.0953\n",
      "Validation Loss: 0.3553\n",
      "Epoch [13/50], Class Loss: 0.2045, JMMD Loss: 0.0926\n",
      "Validation Loss: 0.2973\n",
      "Epoch [14/50], Class Loss: 0.1727, JMMD Loss: 0.0966\n",
      "Validation Loss: 0.2499\n",
      "Epoch [15/50], Class Loss: 0.1491, JMMD Loss: 0.1046\n",
      "Validation Loss: 0.2290\n",
      "Epoch [16/50], Class Loss: 0.1323, JMMD Loss: 0.1113\n",
      "Validation Loss: 0.2181\n",
      "Epoch [17/50], Class Loss: 0.1107, JMMD Loss: 0.1238\n",
      "Validation Loss: 0.1955\n",
      "Epoch [18/50], Class Loss: 0.0953, JMMD Loss: 0.1238\n",
      "Validation Loss: 0.1693\n",
      "Epoch [19/50], Class Loss: 0.0742, JMMD Loss: 0.1354\n",
      "Validation Loss: 0.1604\n",
      "Epoch [20/50], Class Loss: 0.0679, JMMD Loss: 0.1347\n",
      "Validation Loss: 0.1538\n",
      "Epoch [21/50], Class Loss: 0.0530, JMMD Loss: 0.1306\n",
      "Validation Loss: 0.1543\n",
      "Epoch [22/50], Class Loss: 0.0541, JMMD Loss: 0.1385\n",
      "Validation Loss: 0.1572\n",
      "Epoch [23/50], Class Loss: 0.0487, JMMD Loss: 0.1409\n",
      "Validation Loss: 0.1581\n",
      "Epoch [24/50], Class Loss: 0.0486, JMMD Loss: 0.1340\n",
      "Validation Loss: 0.1446\n",
      "Epoch [25/50], Class Loss: 0.0471, JMMD Loss: 0.1420\n",
      "Validation Loss: 0.1566\n",
      "Epoch [26/50], Class Loss: 0.0465, JMMD Loss: 0.1402\n",
      "Validation Loss: 0.1468\n",
      "Epoch [27/50], Class Loss: 0.0457, JMMD Loss: 0.1482\n",
      "Validation Loss: 0.1490\n",
      "Epoch [28/50], Class Loss: 0.0441, JMMD Loss: 0.1414\n",
      "Validation Loss: 0.1479\n",
      "Epoch [29/50], Class Loss: 0.0465, JMMD Loss: 0.1416\n",
      "Validation Loss: 0.1480\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 94.84%, Precision: 94.69%, Recall: 94.65%, F1 Score: 94.66%\n",
      "Target Domain Performance - Accuracy: 61.21%, Precision: 66.68%, Recall: 62.08%, F1 Score: 59.87%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 0.8808, JMMD Loss: 0.0993\n",
      "Validation Loss: 0.6347\n",
      "Epoch [2/50], Class Loss: 0.5188, JMMD Loss: 0.1033\n",
      "Validation Loss: 0.4713\n",
      "Epoch [3/50], Class Loss: 0.4541, JMMD Loss: 0.1040\n",
      "Validation Loss: 0.5285\n",
      "Epoch [4/50], Class Loss: 0.4576, JMMD Loss: 0.1077\n",
      "Validation Loss: 0.4547\n",
      "Epoch [5/50], Class Loss: 0.4371, JMMD Loss: 0.0880\n",
      "Validation Loss: 0.4253\n",
      "Epoch [6/50], Class Loss: 0.3989, JMMD Loss: 0.0783\n",
      "Validation Loss: 0.5946\n",
      "Epoch [7/50], Class Loss: 0.4492, JMMD Loss: 0.0801\n",
      "Validation Loss: 0.4138\n",
      "Epoch [8/50], Class Loss: 0.3928, JMMD Loss: 0.0945\n",
      "Validation Loss: 0.4206\n",
      "Epoch [9/50], Class Loss: 0.4080, JMMD Loss: 0.0840\n",
      "Validation Loss: 0.4122\n",
      "Epoch [10/50], Class Loss: 0.1974, JMMD Loss: 0.1151\n",
      "Validation Loss: 0.1467\n",
      "Epoch [11/50], Class Loss: 0.0757, JMMD Loss: 0.1449\n",
      "Validation Loss: 0.1171\n",
      "Epoch [12/50], Class Loss: 0.0619, JMMD Loss: 0.1677\n",
      "Validation Loss: 0.1020\n",
      "Epoch [13/50], Class Loss: 0.0521, JMMD Loss: 0.1709\n",
      "Validation Loss: 0.0937\n",
      "Epoch [14/50], Class Loss: 0.0432, JMMD Loss: 0.1698\n",
      "Validation Loss: 0.1004\n",
      "Epoch [15/50], Class Loss: 0.0408, JMMD Loss: 0.1828\n",
      "Validation Loss: 0.1072\n",
      "Epoch [16/50], Class Loss: 0.0324, JMMD Loss: 0.1778\n",
      "Validation Loss: 0.0807\n",
      "Epoch [17/50], Class Loss: 0.0281, JMMD Loss: 0.1789\n",
      "Validation Loss: 0.0830\n",
      "Epoch [18/50], Class Loss: 0.0221, JMMD Loss: 0.1926\n",
      "Validation Loss: 0.0808\n",
      "Epoch [19/50], Class Loss: 0.0227, JMMD Loss: 0.1840\n",
      "Validation Loss: 0.0758\n",
      "Epoch [20/50], Class Loss: 0.0176, JMMD Loss: 0.1907\n",
      "Validation Loss: 0.0803\n",
      "Epoch [21/50], Class Loss: 0.0154, JMMD Loss: 0.2050\n",
      "Validation Loss: 0.0755\n",
      "Epoch [22/50], Class Loss: 0.0145, JMMD Loss: 0.2040\n",
      "Validation Loss: 0.0734\n",
      "Epoch [23/50], Class Loss: 0.0137, JMMD Loss: 0.1879\n",
      "Validation Loss: 0.0745\n",
      "Epoch [24/50], Class Loss: 0.0137, JMMD Loss: 0.1987\n",
      "Validation Loss: 0.0736\n",
      "Epoch [25/50], Class Loss: 0.0145, JMMD Loss: 0.1885\n",
      "Validation Loss: 0.0738\n",
      "Epoch [26/50], Class Loss: 0.0137, JMMD Loss: 0.1951\n",
      "Validation Loss: 0.0752\n",
      "Epoch [27/50], Class Loss: 0.0140, JMMD Loss: 0.1892\n",
      "Validation Loss: 0.0750\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.54%, Precision: 97.47%, Recall: 97.46%, F1 Score: 97.46%\n",
      "Target Domain Performance - Accuracy: 60.55%, Precision: 69.01%, Recall: 61.66%, F1 Score: 58.08%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 0.9110, JMMD Loss: 0.1007\n",
      "Validation Loss: 0.4752\n",
      "Epoch [2/50], Class Loss: 0.4677, JMMD Loss: 0.0937\n",
      "Validation Loss: 0.5636\n",
      "Epoch [3/50], Class Loss: 0.4691, JMMD Loss: 0.1053\n",
      "Validation Loss: 0.4945\n",
      "Epoch [4/50], Class Loss: 0.4443, JMMD Loss: 0.1065\n",
      "Validation Loss: 0.4762\n",
      "Epoch [5/50], Class Loss: 0.4426, JMMD Loss: 0.0998\n",
      "Validation Loss: 0.4412\n",
      "Epoch [6/50], Class Loss: 0.4258, JMMD Loss: 0.0900\n",
      "Validation Loss: 0.5280\n",
      "Epoch [7/50], Class Loss: 0.4117, JMMD Loss: 0.0832\n",
      "Validation Loss: 0.4658\n",
      "Epoch [8/50], Class Loss: 0.5061, JMMD Loss: 0.0765\n",
      "Validation Loss: 0.6148\n",
      "Epoch [9/50], Class Loss: 0.3886, JMMD Loss: 0.1077\n",
      "Validation Loss: 0.4278\n",
      "Epoch [10/50], Class Loss: 0.2669, JMMD Loss: 0.0945\n",
      "Validation Loss: 0.6732\n",
      "Epoch [11/50], Class Loss: 0.1391, JMMD Loss: 0.0959\n",
      "Validation Loss: 0.2034\n",
      "Epoch [12/50], Class Loss: 0.0992, JMMD Loss: 0.1057\n",
      "Validation Loss: 0.1870\n",
      "Epoch [13/50], Class Loss: 0.0839, JMMD Loss: 0.1007\n",
      "Validation Loss: 0.1705\n",
      "Epoch [14/50], Class Loss: 0.0685, JMMD Loss: 0.1100\n",
      "Validation Loss: 0.1634\n",
      "Epoch [15/50], Class Loss: 0.0573, JMMD Loss: 0.1197\n",
      "Validation Loss: 0.1468\n",
      "Epoch [16/50], Class Loss: 0.0475, JMMD Loss: 0.1202\n",
      "Validation Loss: 0.1447\n",
      "Epoch [17/50], Class Loss: 0.0410, JMMD Loss: 0.1219\n",
      "Validation Loss: 0.1323\n",
      "Epoch [18/50], Class Loss: 0.0337, JMMD Loss: 0.1206\n",
      "Validation Loss: 0.1489\n",
      "Epoch [19/50], Class Loss: 0.0286, JMMD Loss: 0.1402\n",
      "Validation Loss: 0.1220\n",
      "Epoch [20/50], Class Loss: 0.0226, JMMD Loss: 0.1193\n",
      "Validation Loss: 0.1088\n",
      "Epoch [21/50], Class Loss: 0.0186, JMMD Loss: 0.1296\n",
      "Validation Loss: 0.1145\n",
      "Epoch [22/50], Class Loss: 0.0193, JMMD Loss: 0.1268\n",
      "Validation Loss: 0.1161\n",
      "Epoch [23/50], Class Loss: 0.0194, JMMD Loss: 0.1473\n",
      "Validation Loss: 0.1120\n",
      "Epoch [24/50], Class Loss: 0.0172, JMMD Loss: 0.1212\n",
      "Validation Loss: 0.1120\n",
      "Epoch [25/50], Class Loss: 0.0181, JMMD Loss: 0.1264\n",
      "Validation Loss: 0.1101\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 95.68%, Precision: 95.54%, Recall: 95.53%, F1 Score: 95.54%\n",
      "Target Domain Performance - Accuracy: 64.45%, Precision: 70.24%, Recall: 65.28%, F1 Score: 63.50%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 0.9415, JMMD Loss: 0.0939\n",
      "Validation Loss: 0.4655\n",
      "Epoch [2/50], Class Loss: 0.5181, JMMD Loss: 0.1037\n",
      "Validation Loss: 0.6437\n",
      "Epoch [3/50], Class Loss: 0.4806, JMMD Loss: 0.1009\n",
      "Validation Loss: 0.4768\n",
      "Epoch [4/50], Class Loss: 0.4637, JMMD Loss: 0.0928\n",
      "Validation Loss: 0.4620\n",
      "Epoch [5/50], Class Loss: 0.4559, JMMD Loss: 0.0860\n",
      "Validation Loss: 0.4386\n",
      "Epoch [6/50], Class Loss: 0.4314, JMMD Loss: 0.0979\n",
      "Validation Loss: 0.6179\n",
      "Epoch [7/50], Class Loss: 0.4364, JMMD Loss: 0.0896\n",
      "Validation Loss: 0.4595\n",
      "Epoch [8/50], Class Loss: 0.3737, JMMD Loss: 0.0827\n",
      "Validation Loss: 0.4406\n",
      "Epoch [9/50], Class Loss: 0.3602, JMMD Loss: 0.0757\n",
      "Validation Loss: 0.4828\n",
      "Epoch [10/50], Class Loss: 0.3974, JMMD Loss: 0.1239\n",
      "Validation Loss: 0.1930\n",
      "Epoch [11/50], Class Loss: 0.1158, JMMD Loss: 0.1526\n",
      "Validation Loss: 0.1378\n",
      "Epoch [12/50], Class Loss: 0.0890, JMMD Loss: 0.2030\n",
      "Validation Loss: 0.1153\n",
      "Epoch [13/50], Class Loss: 0.0736, JMMD Loss: 0.2116\n",
      "Validation Loss: 0.1370\n",
      "Epoch [14/50], Class Loss: 0.0665, JMMD Loss: 0.2286\n",
      "Validation Loss: 0.0976\n",
      "Epoch [15/50], Class Loss: 0.0570, JMMD Loss: 0.2359\n",
      "Validation Loss: 0.0891\n",
      "Epoch [16/50], Class Loss: 0.0507, JMMD Loss: 0.2334\n",
      "Validation Loss: 0.0818\n",
      "Epoch [17/50], Class Loss: 0.0398, JMMD Loss: 0.2458\n",
      "Validation Loss: 0.0726\n",
      "Epoch [18/50], Class Loss: 0.0400, JMMD Loss: 0.2410\n",
      "Validation Loss: 0.0727\n",
      "Epoch [19/50], Class Loss: 0.0318, JMMD Loss: 0.2459\n",
      "Validation Loss: 0.0694\n",
      "Epoch [20/50], Class Loss: 0.0279, JMMD Loss: 0.2538\n",
      "Validation Loss: 0.0752\n",
      "Epoch [21/50], Class Loss: 0.0223, JMMD Loss: 0.2434\n",
      "Validation Loss: 0.0681\n",
      "Epoch [22/50], Class Loss: 0.0216, JMMD Loss: 0.2460\n",
      "Validation Loss: 0.0662\n",
      "Epoch [23/50], Class Loss: 0.0219, JMMD Loss: 0.2532\n",
      "Validation Loss: 0.0657\n",
      "Epoch [24/50], Class Loss: 0.0214, JMMD Loss: 0.2401\n",
      "Validation Loss: 0.0674\n",
      "Epoch [25/50], Class Loss: 0.0208, JMMD Loss: 0.2470\n",
      "Validation Loss: 0.0663\n",
      "Epoch [26/50], Class Loss: 0.0203, JMMD Loss: 0.2448\n",
      "Validation Loss: 0.0680\n",
      "Epoch [27/50], Class Loss: 0.0208, JMMD Loss: 0.2640\n",
      "Validation Loss: 0.0640\n",
      "Epoch [28/50], Class Loss: 0.0202, JMMD Loss: 0.2522\n",
      "Validation Loss: 0.0649\n",
      "Epoch [29/50], Class Loss: 0.0186, JMMD Loss: 0.2466\n",
      "Validation Loss: 0.0641\n",
      "Epoch [30/50], Class Loss: 0.0209, JMMD Loss: 0.2413\n",
      "Validation Loss: 0.0653\n",
      "Epoch [31/50], Class Loss: 0.0176, JMMD Loss: 0.2427\n",
      "Validation Loss: 0.0652\n",
      "Epoch [32/50], Class Loss: 0.0181, JMMD Loss: 0.2494\n",
      "Validation Loss: 0.0649\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.90%, Precision: 97.84%, Recall: 97.85%, F1 Score: 97.84%\n",
      "Target Domain Performance - Accuracy: 56.53%, Precision: 65.29%, Recall: 57.83%, F1 Score: 52.62%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 0.9395, JMMD Loss: 0.1021\n",
      "Validation Loss: 0.4743\n",
      "Epoch [2/50], Class Loss: 0.4814, JMMD Loss: 0.1062\n",
      "Validation Loss: 0.4692\n",
      "Epoch [3/50], Class Loss: 0.5053, JMMD Loss: 0.0907\n",
      "Validation Loss: 0.4948\n",
      "Epoch [4/50], Class Loss: 0.4410, JMMD Loss: 0.1049\n",
      "Validation Loss: 0.4440\n",
      "Epoch [5/50], Class Loss: 0.4542, JMMD Loss: 0.0898\n",
      "Validation Loss: 0.5199\n",
      "Epoch [6/50], Class Loss: 0.4257, JMMD Loss: 0.0865\n",
      "Validation Loss: 0.4525\n",
      "Epoch [7/50], Class Loss: 0.3997, JMMD Loss: 0.0860\n",
      "Validation Loss: 0.7553\n",
      "Epoch [8/50], Class Loss: 0.4251, JMMD Loss: 0.0780\n",
      "Validation Loss: 0.4221\n",
      "Epoch [9/50], Class Loss: 0.3667, JMMD Loss: 0.0880\n",
      "Validation Loss: 0.3786\n",
      "Epoch [10/50], Class Loss: 0.2987, JMMD Loss: 0.1165\n",
      "Validation Loss: 0.4630\n",
      "Epoch [11/50], Class Loss: 0.1355, JMMD Loss: 0.1414\n",
      "Validation Loss: 0.1573\n",
      "Epoch [12/50], Class Loss: 0.0982, JMMD Loss: 0.1567\n",
      "Validation Loss: 0.1353\n",
      "Epoch [13/50], Class Loss: 0.0808, JMMD Loss: 0.1669\n",
      "Validation Loss: 0.1209\n",
      "Epoch [14/50], Class Loss: 0.0668, JMMD Loss: 0.1805\n",
      "Validation Loss: 0.1096\n",
      "Epoch [15/50], Class Loss: 0.0579, JMMD Loss: 0.1798\n",
      "Validation Loss: 0.0960\n",
      "Epoch [16/50], Class Loss: 0.0453, JMMD Loss: 0.1948\n",
      "Validation Loss: 0.1042\n",
      "Epoch [17/50], Class Loss: 0.0366, JMMD Loss: 0.1925\n",
      "Validation Loss: 0.0814\n",
      "Epoch [18/50], Class Loss: 0.0311, JMMD Loss: 0.1922\n",
      "Validation Loss: 0.0821\n",
      "Epoch [19/50], Class Loss: 0.0245, JMMD Loss: 0.2001\n",
      "Validation Loss: 0.0727\n",
      "Epoch [20/50], Class Loss: 0.0252, JMMD Loss: 0.1981\n",
      "Validation Loss: 0.0762\n",
      "Epoch [21/50], Class Loss: 0.0180, JMMD Loss: 0.1976\n",
      "Validation Loss: 0.0778\n",
      "Epoch [22/50], Class Loss: 0.0163, JMMD Loss: 0.2042\n",
      "Validation Loss: 0.0745\n",
      "Epoch [23/50], Class Loss: 0.0164, JMMD Loss: 0.2121\n",
      "Validation Loss: 0.0721\n",
      "Epoch [24/50], Class Loss: 0.0153, JMMD Loss: 0.1969\n",
      "Validation Loss: 0.0738\n",
      "Epoch [25/50], Class Loss: 0.0155, JMMD Loss: 0.1972\n",
      "Validation Loss: 0.0715\n",
      "Epoch [26/50], Class Loss: 0.0163, JMMD Loss: 0.2038\n",
      "Validation Loss: 0.0734\n",
      "Epoch [27/50], Class Loss: 0.0146, JMMD Loss: 0.1927\n",
      "Validation Loss: 0.0723\n",
      "Epoch [28/50], Class Loss: 0.0156, JMMD Loss: 0.2079\n",
      "Validation Loss: 0.0707\n",
      "Epoch [29/50], Class Loss: 0.0134, JMMD Loss: 0.2032\n",
      "Validation Loss: 0.0745\n",
      "Epoch [30/50], Class Loss: 0.0144, JMMD Loss: 0.1996\n",
      "Validation Loss: 0.0731\n",
      "Epoch [31/50], Class Loss: 0.0147, JMMD Loss: 0.2043\n",
      "Validation Loss: 0.0720\n",
      "Epoch [32/50], Class Loss: 0.0144, JMMD Loss: 0.2077\n",
      "Validation Loss: 0.0720\n",
      "Epoch [33/50], Class Loss: 0.0143, JMMD Loss: 0.2028\n",
      "Validation Loss: 0.0716\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.30%, Precision: 97.22%, Recall: 97.22%, F1 Score: 97.22%\n",
      "Target Domain Performance - Accuracy: 59.65%, Precision: 67.94%, Recall: 60.83%, F1 Score: 57.00%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 0.9724, JMMD Loss: 0.1101\n",
      "Validation Loss: 0.5589\n",
      "Epoch [2/50], Class Loss: 0.5487, JMMD Loss: 0.1106\n",
      "Validation Loss: 0.5376\n",
      "Epoch [3/50], Class Loss: 0.4747, JMMD Loss: 0.1102\n",
      "Validation Loss: 0.4699\n",
      "Epoch [4/50], Class Loss: 0.4501, JMMD Loss: 0.0952\n",
      "Validation Loss: 0.4645\n",
      "Epoch [5/50], Class Loss: 0.4496, JMMD Loss: 0.1047\n",
      "Validation Loss: 0.4286\n",
      "Epoch [6/50], Class Loss: 0.4449, JMMD Loss: 0.0881\n",
      "Validation Loss: 0.4597\n",
      "Epoch [7/50], Class Loss: 0.4322, JMMD Loss: 0.0955\n",
      "Validation Loss: 0.4436\n",
      "Epoch [8/50], Class Loss: 0.5508, JMMD Loss: 0.0774\n",
      "Validation Loss: 0.5639\n",
      "Epoch [9/50], Class Loss: 0.4175, JMMD Loss: 0.0968\n",
      "Validation Loss: 0.4245\n",
      "Epoch [10/50], Class Loss: 0.3889, JMMD Loss: 0.0938\n",
      "Validation Loss: 0.4245\n",
      "Epoch [11/50], Class Loss: 0.3213, JMMD Loss: 0.0812\n",
      "Validation Loss: 0.4089\n",
      "Epoch [12/50], Class Loss: 0.3000, JMMD Loss: 0.0897\n",
      "Validation Loss: 0.4042\n",
      "Epoch [13/50], Class Loss: 0.2851, JMMD Loss: 0.0772\n",
      "Validation Loss: 0.3964\n",
      "Epoch [14/50], Class Loss: 0.2647, JMMD Loss: 0.0847\n",
      "Validation Loss: 0.3997\n",
      "Epoch [15/50], Class Loss: 0.2573, JMMD Loss: 0.0770\n",
      "Validation Loss: 0.3863\n",
      "Epoch [16/50], Class Loss: 0.2248, JMMD Loss: 0.0767\n",
      "Validation Loss: 0.3487\n",
      "Epoch [17/50], Class Loss: 0.2028, JMMD Loss: 0.0705\n",
      "Validation Loss: 0.3855\n",
      "Epoch [18/50], Class Loss: 0.1870, JMMD Loss: 0.0863\n",
      "Validation Loss: 0.3602\n",
      "Epoch [19/50], Class Loss: 0.1588, JMMD Loss: 0.0953\n",
      "Validation Loss: 0.3806\n",
      "Epoch [20/50], Class Loss: 0.1396, JMMD Loss: 0.0980\n",
      "Validation Loss: 0.2742\n",
      "Epoch [21/50], Class Loss: 0.1139, JMMD Loss: 0.0965\n",
      "Validation Loss: 0.2604\n",
      "Epoch [22/50], Class Loss: 0.1142, JMMD Loss: 0.1003\n",
      "Validation Loss: 0.2564\n",
      "Epoch [23/50], Class Loss: 0.1092, JMMD Loss: 0.1029\n",
      "Validation Loss: 0.2546\n",
      "Epoch [24/50], Class Loss: 0.1058, JMMD Loss: 0.1022\n",
      "Validation Loss: 0.2526\n",
      "Epoch [25/50], Class Loss: 0.1035, JMMD Loss: 0.1016\n",
      "Validation Loss: 0.2540\n",
      "Epoch [26/50], Class Loss: 0.1019, JMMD Loss: 0.0921\n",
      "Validation Loss: 0.2475\n",
      "Epoch [27/50], Class Loss: 0.0974, JMMD Loss: 0.1023\n",
      "Validation Loss: 0.2474\n",
      "Epoch [28/50], Class Loss: 0.0981, JMMD Loss: 0.0948\n",
      "Validation Loss: 0.2399\n",
      "Epoch [29/50], Class Loss: 0.0965, JMMD Loss: 0.1017\n",
      "Validation Loss: 0.2435\n",
      "Epoch [30/50], Class Loss: 0.0947, JMMD Loss: 0.1081\n",
      "Validation Loss: 0.2368\n",
      "Epoch [31/50], Class Loss: 0.0973, JMMD Loss: 0.0998\n",
      "Validation Loss: 0.2397\n",
      "Epoch [32/50], Class Loss: 0.0893, JMMD Loss: 0.1099\n",
      "Validation Loss: 0.2400\n",
      "Epoch [33/50], Class Loss: 0.0887, JMMD Loss: 0.0949\n",
      "Validation Loss: 0.2397\n",
      "Epoch [34/50], Class Loss: 0.0893, JMMD Loss: 0.1017\n",
      "Validation Loss: 0.2402\n",
      "Epoch [35/50], Class Loss: 0.0889, JMMD Loss: 0.1050\n",
      "Validation Loss: 0.2401\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 90.59%, Precision: 90.30%, Recall: 90.29%, F1 Score: 90.28%\n",
      "Target Domain Performance - Accuracy: 63.25%, Precision: 67.11%, Recall: 63.76%, F1 Score: 63.06%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 1.0290, JMMD Loss: 0.1093\n",
      "Validation Loss: 0.4715\n",
      "Epoch [2/50], Class Loss: 0.5053, JMMD Loss: 0.0899\n",
      "Validation Loss: 0.5732\n",
      "Epoch [3/50], Class Loss: 0.4695, JMMD Loss: 0.0979\n",
      "Validation Loss: 0.4699\n",
      "Epoch [4/50], Class Loss: 0.4561, JMMD Loss: 0.0910\n",
      "Validation Loss: 0.5712\n",
      "Epoch [5/50], Class Loss: 0.4531, JMMD Loss: 0.0914\n",
      "Validation Loss: 0.4346\n",
      "Epoch [6/50], Class Loss: 0.4149, JMMD Loss: 0.0919\n",
      "Validation Loss: 0.4287\n",
      "Epoch [7/50], Class Loss: 0.4679, JMMD Loss: 0.0858\n",
      "Validation Loss: 0.4556\n",
      "Epoch [8/50], Class Loss: 0.4207, JMMD Loss: 0.0943\n",
      "Validation Loss: 0.4979\n",
      "Epoch [9/50], Class Loss: 0.3431, JMMD Loss: 0.0987\n",
      "Validation Loss: 0.6934\n",
      "Epoch [10/50], Class Loss: 0.3090, JMMD Loss: 0.1084\n",
      "Validation Loss: 0.3483\n",
      "Epoch [11/50], Class Loss: 0.1410, JMMD Loss: 0.1231\n",
      "Validation Loss: 0.1879\n",
      "Epoch [12/50], Class Loss: 0.1132, JMMD Loss: 0.1565\n",
      "Validation Loss: 0.1583\n",
      "Epoch [13/50], Class Loss: 0.0953, JMMD Loss: 0.1722\n",
      "Validation Loss: 0.1386\n",
      "Epoch [14/50], Class Loss: 0.0821, JMMD Loss: 0.1824\n",
      "Validation Loss: 0.1268\n",
      "Epoch [15/50], Class Loss: 0.0705, JMMD Loss: 0.1807\n",
      "Validation Loss: 0.1236\n",
      "Epoch [16/50], Class Loss: 0.0567, JMMD Loss: 0.1995\n",
      "Validation Loss: 0.1383\n",
      "Epoch [17/50], Class Loss: 0.0502, JMMD Loss: 0.2031\n",
      "Validation Loss: 0.1072\n",
      "Epoch [18/50], Class Loss: 0.0456, JMMD Loss: 0.1952\n",
      "Validation Loss: 0.1021\n",
      "Epoch [19/50], Class Loss: 0.0354, JMMD Loss: 0.2177\n",
      "Validation Loss: 0.1060\n",
      "Epoch [20/50], Class Loss: 0.0297, JMMD Loss: 0.1995\n",
      "Validation Loss: 0.0882\n",
      "Epoch [21/50], Class Loss: 0.0248, JMMD Loss: 0.2020\n",
      "Validation Loss: 0.0858\n",
      "Epoch [22/50], Class Loss: 0.0237, JMMD Loss: 0.1992\n",
      "Validation Loss: 0.0869\n",
      "Epoch [23/50], Class Loss: 0.0222, JMMD Loss: 0.1985\n",
      "Validation Loss: 0.0857\n",
      "Epoch [24/50], Class Loss: 0.0263, JMMD Loss: 0.2038\n",
      "Validation Loss: 0.0900\n",
      "Epoch [25/50], Class Loss: 0.0237, JMMD Loss: 0.2139\n",
      "Validation Loss: 0.0858\n",
      "Epoch [26/50], Class Loss: 0.0226, JMMD Loss: 0.2021\n",
      "Validation Loss: 0.0883\n",
      "Epoch [27/50], Class Loss: 0.0220, JMMD Loss: 0.1937\n",
      "Validation Loss: 0.0863\n",
      "Epoch [28/50], Class Loss: 0.0210, JMMD Loss: 0.2019\n",
      "Validation Loss: 0.0894\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 96.82%, Precision: 96.73%, Recall: 96.72%, F1 Score: 96.72%\n",
      "Target Domain Performance - Accuracy: 58.69%, Precision: 66.55%, Recall: 59.89%, F1 Score: 55.38%\n",
      "\n",
      "Source performance: 95.35% 95.21% 95.20% 95.19%\n",
      "Target performance: 61.14% 67.78% 62.07% 59.22%\n",
      "\n",
      "Per-Class Accuracy on Target Domain (Mean over runs):\n",
      "  Class 0: 99.76%\n",
      "  Class 1: 23.37%\n",
      "  Class 2: 36.62%\n",
      "  Class 3: 88.52%\n",
      "SNR level: 14\n",
      "BASE\n",
      "\n",
      "Run 1/10\n",
      "Epoch 1/50, Train Loss: 0.9072, Train Acc: 0.6015, Val Loss: 0.5534, Val Acc: 0.7284\n",
      "Epoch 2/50, Train Loss: 0.4995, Train Acc: 0.7885, Val Loss: 0.5039, Val Acc: 0.7704\n",
      "Epoch 3/50, Train Loss: 0.4801, Train Acc: 0.7971, Val Loss: 0.4535, Val Acc: 0.8010\n",
      "Epoch 4/50, Train Loss: 0.4545, Train Acc: 0.8061, Val Loss: 0.5346, Val Acc: 0.7806\n",
      "Epoch 5/50, Train Loss: 0.4234, Train Acc: 0.8283, Val Loss: 0.4393, Val Acc: 0.8177\n",
      "Epoch 6/50, Train Loss: 0.4509, Train Acc: 0.8107, Val Loss: 0.3307, Val Acc: 0.8765\n",
      "Epoch 7/50, Train Loss: 0.3214, Train Acc: 0.8704, Val Loss: 0.4531, Val Acc: 0.8225\n",
      "Epoch 8/50, Train Loss: 0.1974, Train Acc: 0.9249, Val Loss: 0.2493, Val Acc: 0.9173\n",
      "Epoch 9/50, Train Loss: 0.1415, Train Acc: 0.9516, Val Loss: 0.0591, Val Acc: 0.9754\n",
      "Epoch 10/50, Train Loss: 0.1319, Train Acc: 0.9610, Val Loss: 0.1371, Val Acc: 0.9592\n",
      "Epoch 11/50, Train Loss: 0.0141, Train Acc: 0.9957, Val Loss: 0.0466, Val Acc: 0.9838\n",
      "Epoch 12/50, Train Loss: 0.0098, Train Acc: 0.9966, Val Loss: 0.0582, Val Acc: 0.9814\n",
      "Epoch 13/50, Train Loss: 0.0071, Train Acc: 0.9978, Val Loss: 0.0373, Val Acc: 0.9856\n",
      "Epoch 14/50, Train Loss: 0.0061, Train Acc: 0.9982, Val Loss: 0.0393, Val Acc: 0.9862\n",
      "Epoch 15/50, Train Loss: 0.0045, Train Acc: 0.9982, Val Loss: 0.0413, Val Acc: 0.9856\n",
      "Epoch 16/50, Train Loss: 0.0029, Train Acc: 0.9990, Val Loss: 0.0467, Val Acc: 0.9838\n",
      "Epoch 17/50, Train Loss: 0.0025, Train Acc: 0.9994, Val Loss: 0.0473, Val Acc: 0.9832\n",
      "Epoch 18/50, Train Loss: 0.0025, Train Acc: 0.9994, Val Loss: 0.0409, Val Acc: 0.9868\n",
      "Early stopping!\n",
      "\n",
      "Run 2/10\n",
      "Epoch 1/50, Train Loss: 0.8351, Train Acc: 0.6471, Val Loss: 0.6197, Val Acc: 0.7554\n",
      "Epoch 2/50, Train Loss: 0.5042, Train Acc: 0.7831, Val Loss: 0.4937, Val Acc: 0.7974\n",
      "Epoch 3/50, Train Loss: 0.4606, Train Acc: 0.8092, Val Loss: 0.4860, Val Acc: 0.7758\n",
      "Epoch 4/50, Train Loss: 0.4422, Train Acc: 0.8163, Val Loss: 0.5096, Val Acc: 0.7956\n",
      "Epoch 5/50, Train Loss: 0.4583, Train Acc: 0.8088, Val Loss: 0.4037, Val Acc: 0.8489\n",
      "Epoch 6/50, Train Loss: 0.3778, Train Acc: 0.8440, Val Loss: 0.3825, Val Acc: 0.8507\n",
      "Epoch 7/50, Train Loss: 0.2595, Train Acc: 0.8992, Val Loss: 0.3580, Val Acc: 0.8531\n",
      "Epoch 8/50, Train Loss: 0.1516, Train Acc: 0.9400, Val Loss: 0.0813, Val Acc: 0.9718\n",
      "Epoch 9/50, Train Loss: 0.1588, Train Acc: 0.9465, Val Loss: 0.1858, Val Acc: 0.9341\n",
      "Epoch 10/50, Train Loss: 0.1202, Train Acc: 0.9609, Val Loss: 0.0558, Val Acc: 0.9790\n",
      "Epoch 11/50, Train Loss: 0.0108, Train Acc: 0.9955, Val Loss: 0.0422, Val Acc: 0.9838\n",
      "Epoch 12/50, Train Loss: 0.0073, Train Acc: 0.9976, Val Loss: 0.0293, Val Acc: 0.9904\n",
      "Epoch 13/50, Train Loss: 0.0053, Train Acc: 0.9982, Val Loss: 0.0429, Val Acc: 0.9862\n",
      "Epoch 14/50, Train Loss: 0.0044, Train Acc: 0.9988, Val Loss: 0.0287, Val Acc: 0.9928\n",
      "Epoch 15/50, Train Loss: 0.0029, Train Acc: 0.9990, Val Loss: 0.0337, Val Acc: 0.9874\n",
      "Epoch 16/50, Train Loss: 0.0048, Train Acc: 0.9988, Val Loss: 0.0412, Val Acc: 0.9880\n",
      "Epoch 17/50, Train Loss: 0.0022, Train Acc: 0.9993, Val Loss: 0.0364, Val Acc: 0.9892\n",
      "Epoch 18/50, Train Loss: 0.0025, Train Acc: 0.9994, Val Loss: 0.0323, Val Acc: 0.9910\n",
      "Epoch 19/50, Train Loss: 0.0014, Train Acc: 0.9996, Val Loss: 0.0347, Val Acc: 0.9904\n",
      "Early stopping!\n",
      "\n",
      "Run 3/10\n",
      "Epoch 1/50, Train Loss: 0.9257, Train Acc: 0.6069, Val Loss: 0.4945, Val Acc: 0.7776\n",
      "Epoch 2/50, Train Loss: 0.4822, Train Acc: 0.7962, Val Loss: 0.4539, Val Acc: 0.8177\n",
      "Epoch 3/50, Train Loss: 0.4805, Train Acc: 0.8013, Val Loss: 0.4203, Val Acc: 0.8303\n",
      "Epoch 4/50, Train Loss: 0.4533, Train Acc: 0.8115, Val Loss: 0.4422, Val Acc: 0.8339\n",
      "Epoch 5/50, Train Loss: 0.4246, Train Acc: 0.8232, Val Loss: 0.3855, Val Acc: 0.8459\n",
      "Epoch 6/50, Train Loss: 0.4035, Train Acc: 0.8301, Val Loss: 0.3173, Val Acc: 0.8747\n",
      "Epoch 7/50, Train Loss: 0.2338, Train Acc: 0.9058, Val Loss: 0.2009, Val Acc: 0.9293\n",
      "Epoch 8/50, Train Loss: 0.2558, Train Acc: 0.9136, Val Loss: 0.5258, Val Acc: 0.8291\n",
      "Epoch 9/50, Train Loss: 0.1551, Train Acc: 0.9433, Val Loss: 0.0899, Val Acc: 0.9682\n",
      "Epoch 10/50, Train Loss: 0.0580, Train Acc: 0.9813, Val Loss: 0.0352, Val Acc: 0.9868\n",
      "Epoch 11/50, Train Loss: 0.0129, Train Acc: 0.9955, Val Loss: 0.0355, Val Acc: 0.9874\n",
      "Epoch 12/50, Train Loss: 0.0108, Train Acc: 0.9960, Val Loss: 0.0314, Val Acc: 0.9898\n",
      "Epoch 13/50, Train Loss: 0.0084, Train Acc: 0.9975, Val Loss: 0.0304, Val Acc: 0.9910\n",
      "Epoch 14/50, Train Loss: 0.0063, Train Acc: 0.9981, Val Loss: 0.0324, Val Acc: 0.9910\n",
      "Epoch 15/50, Train Loss: 0.0059, Train Acc: 0.9981, Val Loss: 0.0337, Val Acc: 0.9910\n",
      "Epoch 16/50, Train Loss: 0.0045, Train Acc: 0.9988, Val Loss: 0.0347, Val Acc: 0.9916\n",
      "Epoch 17/50, Train Loss: 0.0042, Train Acc: 0.9987, Val Loss: 0.0600, Val Acc: 0.9850\n",
      "Epoch 18/50, Train Loss: 0.0036, Train Acc: 0.9988, Val Loss: 0.0343, Val Acc: 0.9916\n",
      "Early stopping!\n",
      "\n",
      "Run 4/10\n",
      "Epoch 1/50, Train Loss: 0.8257, Train Acc: 0.6225, Val Loss: 0.4824, Val Acc: 0.7884\n",
      "Epoch 2/50, Train Loss: 0.5147, Train Acc: 0.7782, Val Loss: 0.6557, Val Acc: 0.7236\n",
      "Epoch 3/50, Train Loss: 0.5496, Train Acc: 0.7597, Val Loss: 0.4674, Val Acc: 0.8004\n",
      "Epoch 4/50, Train Loss: 0.5358, Train Acc: 0.7641, Val Loss: 0.5301, Val Acc: 0.7524\n",
      "Epoch 5/50, Train Loss: 0.4598, Train Acc: 0.8115, Val Loss: 0.4221, Val Acc: 0.8291\n",
      "Epoch 6/50, Train Loss: 0.4369, Train Acc: 0.8202, Val Loss: 0.4925, Val Acc: 0.7812\n",
      "Epoch 7/50, Train Loss: 0.3444, Train Acc: 0.8629, Val Loss: 0.2750, Val Acc: 0.8993\n",
      "Epoch 8/50, Train Loss: 0.3505, Train Acc: 0.8796, Val Loss: 0.3685, Val Acc: 0.8615\n",
      "Epoch 9/50, Train Loss: 0.1813, Train Acc: 0.9390, Val Loss: 0.3589, Val Acc: 0.8777\n",
      "Epoch 10/50, Train Loss: 0.1104, Train Acc: 0.9598, Val Loss: 0.0860, Val Acc: 0.9664\n",
      "Epoch 11/50, Train Loss: 0.0184, Train Acc: 0.9942, Val Loss: 0.0558, Val Acc: 0.9820\n",
      "Epoch 12/50, Train Loss: 0.0129, Train Acc: 0.9967, Val Loss: 0.0591, Val Acc: 0.9832\n",
      "Epoch 13/50, Train Loss: 0.0083, Train Acc: 0.9979, Val Loss: 0.0355, Val Acc: 0.9868\n",
      "Epoch 14/50, Train Loss: 0.0086, Train Acc: 0.9975, Val Loss: 0.0604, Val Acc: 0.9820\n",
      "Epoch 15/50, Train Loss: 0.0064, Train Acc: 0.9979, Val Loss: 0.0387, Val Acc: 0.9874\n",
      "Epoch 16/50, Train Loss: 0.0065, Train Acc: 0.9979, Val Loss: 0.0414, Val Acc: 0.9874\n",
      "Epoch 17/50, Train Loss: 0.0043, Train Acc: 0.9987, Val Loss: 0.0366, Val Acc: 0.9844\n",
      "Epoch 18/50, Train Loss: 0.0028, Train Acc: 0.9988, Val Loss: 0.0463, Val Acc: 0.9868\n",
      "Early stopping!\n",
      "\n",
      "Run 5/10\n",
      "Epoch 1/50, Train Loss: 0.9166, Train Acc: 0.6504, Val Loss: 0.4986, Val Acc: 0.7986\n",
      "Epoch 2/50, Train Loss: 0.4904, Train Acc: 0.7957, Val Loss: 0.4428, Val Acc: 0.8118\n",
      "Epoch 3/50, Train Loss: 0.4488, Train Acc: 0.8131, Val Loss: 0.7268, Val Acc: 0.7056\n",
      "Epoch 4/50, Train Loss: 0.4809, Train Acc: 0.7977, Val Loss: 0.4178, Val Acc: 0.8207\n",
      "Epoch 5/50, Train Loss: 0.4267, Train Acc: 0.8250, Val Loss: 0.4511, Val Acc: 0.8004\n",
      "Epoch 6/50, Train Loss: 0.4083, Train Acc: 0.8431, Val Loss: 0.7371, Val Acc: 0.7458\n",
      "Epoch 7/50, Train Loss: 0.4331, Train Acc: 0.8451, Val Loss: 0.4568, Val Acc: 0.8106\n",
      "Epoch 8/50, Train Loss: 0.0985, Train Acc: 0.9633, Val Loss: 0.1445, Val Acc: 0.9580\n",
      "Epoch 9/50, Train Loss: 0.1442, Train Acc: 0.9529, Val Loss: 0.0420, Val Acc: 0.9838\n",
      "Epoch 10/50, Train Loss: 0.2009, Train Acc: 0.9490, Val Loss: 0.0997, Val Acc: 0.9658\n",
      "Epoch 11/50, Train Loss: 0.0159, Train Acc: 0.9946, Val Loss: 0.0400, Val Acc: 0.9874\n",
      "Epoch 12/50, Train Loss: 0.0104, Train Acc: 0.9961, Val Loss: 0.0371, Val Acc: 0.9856\n",
      "Epoch 13/50, Train Loss: 0.0074, Train Acc: 0.9973, Val Loss: 0.0406, Val Acc: 0.9868\n",
      "Epoch 14/50, Train Loss: 0.0076, Train Acc: 0.9973, Val Loss: 0.0460, Val Acc: 0.9862\n",
      "Epoch 15/50, Train Loss: 0.0073, Train Acc: 0.9975, Val Loss: 0.0380, Val Acc: 0.9874\n",
      "Epoch 16/50, Train Loss: 0.0042, Train Acc: 0.9991, Val Loss: 0.0889, Val Acc: 0.9724\n",
      "Epoch 17/50, Train Loss: 0.0041, Train Acc: 0.9990, Val Loss: 0.0376, Val Acc: 0.9886\n",
      "Early stopping!\n",
      "\n",
      "Run 6/10\n",
      "Epoch 1/50, Train Loss: 0.9161, Train Acc: 0.6362, Val Loss: 0.5300, Val Acc: 0.7782\n",
      "Epoch 2/50, Train Loss: 0.5610, Train Acc: 0.7543, Val Loss: 0.4806, Val Acc: 0.8088\n",
      "Epoch 3/50, Train Loss: 0.5499, Train Acc: 0.7642, Val Loss: 0.8100, Val Acc: 0.6241\n",
      "Epoch 4/50, Train Loss: 0.4669, Train Acc: 0.8050, Val Loss: 0.5106, Val Acc: 0.7752\n",
      "Epoch 5/50, Train Loss: 0.4940, Train Acc: 0.7938, Val Loss: 0.4804, Val Acc: 0.8004\n",
      "Epoch 6/50, Train Loss: 0.4605, Train Acc: 0.8032, Val Loss: 0.4511, Val Acc: 0.8135\n",
      "Epoch 7/50, Train Loss: 0.4318, Train Acc: 0.8238, Val Loss: 0.5415, Val Acc: 0.7722\n",
      "Epoch 8/50, Train Loss: 0.4316, Train Acc: 0.8302, Val Loss: 0.4688, Val Acc: 0.8183\n",
      "Epoch 9/50, Train Loss: 0.1960, Train Acc: 0.9208, Val Loss: 0.1023, Val Acc: 0.9586\n",
      "Epoch 10/50, Train Loss: 0.1745, Train Acc: 0.9382, Val Loss: 0.1008, Val Acc: 0.9616\n",
      "Epoch 11/50, Train Loss: 0.0389, Train Acc: 0.9864, Val Loss: 0.0856, Val Acc: 0.9742\n",
      "Epoch 12/50, Train Loss: 0.0242, Train Acc: 0.9919, Val Loss: 0.0374, Val Acc: 0.9838\n",
      "Epoch 13/50, Train Loss: 0.0224, Train Acc: 0.9909, Val Loss: 0.0378, Val Acc: 0.9838\n",
      "Epoch 14/50, Train Loss: 0.0169, Train Acc: 0.9936, Val Loss: 0.0444, Val Acc: 0.9832\n",
      "Epoch 15/50, Train Loss: 0.0170, Train Acc: 0.9936, Val Loss: 0.0400, Val Acc: 0.9826\n",
      "Epoch 16/50, Train Loss: 0.0133, Train Acc: 0.9948, Val Loss: 0.0354, Val Acc: 0.9868\n",
      "Epoch 17/50, Train Loss: 0.0105, Train Acc: 0.9967, Val Loss: 0.0348, Val Acc: 0.9862\n",
      "Epoch 18/50, Train Loss: 0.0107, Train Acc: 0.9969, Val Loss: 0.0382, Val Acc: 0.9874\n",
      "Epoch 19/50, Train Loss: 0.0074, Train Acc: 0.9981, Val Loss: 0.0446, Val Acc: 0.9874\n",
      "Epoch 20/50, Train Loss: 0.0062, Train Acc: 0.9976, Val Loss: 0.0553, Val Acc: 0.9850\n",
      "Epoch 21/50, Train Loss: 0.0034, Train Acc: 0.9990, Val Loss: 0.0453, Val Acc: 0.9886\n",
      "Epoch 22/50, Train Loss: 0.0033, Train Acc: 0.9994, Val Loss: 0.0400, Val Acc: 0.9874\n",
      "Early stopping!\n",
      "\n",
      "Run 7/10\n",
      "Epoch 1/50, Train Loss: 0.8962, Train Acc: 0.5964, Val Loss: 0.8383, Val Acc: 0.6511\n",
      "Epoch 2/50, Train Loss: 0.5219, Train Acc: 0.7755, Val Loss: 0.5638, Val Acc: 0.7560\n",
      "Epoch 3/50, Train Loss: 0.4791, Train Acc: 0.7983, Val Loss: 0.4716, Val Acc: 0.8082\n",
      "Epoch 4/50, Train Loss: 0.4473, Train Acc: 0.8196, Val Loss: 0.4772, Val Acc: 0.8082\n",
      "Epoch 5/50, Train Loss: 0.4709, Train Acc: 0.8016, Val Loss: 0.4328, Val Acc: 0.8309\n",
      "Epoch 6/50, Train Loss: 0.3839, Train Acc: 0.8424, Val Loss: 0.8096, Val Acc: 0.7098\n",
      "Epoch 7/50, Train Loss: 0.3889, Train Acc: 0.8500, Val Loss: 0.2175, Val Acc: 0.9173\n",
      "Epoch 8/50, Train Loss: 0.2258, Train Acc: 0.9255, Val Loss: 0.1110, Val Acc: 0.9580\n",
      "Epoch 9/50, Train Loss: 0.1584, Train Acc: 0.9474, Val Loss: 0.2089, Val Acc: 0.9371\n",
      "Epoch 10/50, Train Loss: 0.0907, Train Acc: 0.9702, Val Loss: 1.0814, Val Acc: 0.7842\n",
      "Epoch 11/50, Train Loss: 0.0531, Train Acc: 0.9853, Val Loss: 0.0475, Val Acc: 0.9814\n",
      "Epoch 12/50, Train Loss: 0.0073, Train Acc: 0.9978, Val Loss: 0.0460, Val Acc: 0.9832\n",
      "Epoch 13/50, Train Loss: 0.0092, Train Acc: 0.9966, Val Loss: 0.0505, Val Acc: 0.9832\n",
      "Epoch 14/50, Train Loss: 0.0055, Train Acc: 0.9985, Val Loss: 0.0510, Val Acc: 0.9838\n",
      "Epoch 15/50, Train Loss: 0.0040, Train Acc: 0.9988, Val Loss: 0.0505, Val Acc: 0.9826\n",
      "Epoch 16/50, Train Loss: 0.0030, Train Acc: 0.9987, Val Loss: 0.0447, Val Acc: 0.9862\n",
      "Epoch 17/50, Train Loss: 0.0044, Train Acc: 0.9987, Val Loss: 0.0523, Val Acc: 0.9796\n",
      "Epoch 18/50, Train Loss: 0.0012, Train Acc: 0.9997, Val Loss: 0.0558, Val Acc: 0.9856\n",
      "Epoch 19/50, Train Loss: 0.0015, Train Acc: 0.9996, Val Loss: 0.0670, Val Acc: 0.9832\n",
      "Epoch 20/50, Train Loss: 0.0010, Train Acc: 0.9997, Val Loss: 0.0632, Val Acc: 0.9850\n",
      "Epoch 21/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0550, Val Acc: 0.9856\n",
      "Early stopping!\n",
      "\n",
      "Run 8/10\n",
      "Epoch 1/50, Train Loss: 0.8717, Train Acc: 0.6371, Val Loss: 0.8324, Val Acc: 0.6565\n",
      "Epoch 2/50, Train Loss: 0.5390, Train Acc: 0.7762, Val Loss: 0.5218, Val Acc: 0.7818\n",
      "Epoch 3/50, Train Loss: 0.4908, Train Acc: 0.7887, Val Loss: 0.4359, Val Acc: 0.8195\n",
      "Epoch 4/50, Train Loss: 0.4841, Train Acc: 0.7884, Val Loss: 0.4493, Val Acc: 0.8141\n",
      "Epoch 5/50, Train Loss: 0.4506, Train Acc: 0.8124, Val Loss: 0.4354, Val Acc: 0.8225\n",
      "Epoch 6/50, Train Loss: 0.3596, Train Acc: 0.8571, Val Loss: 0.4996, Val Acc: 0.8189\n",
      "Epoch 7/50, Train Loss: 0.2756, Train Acc: 0.8982, Val Loss: 0.4019, Val Acc: 0.8615\n",
      "Epoch 8/50, Train Loss: 0.1318, Train Acc: 0.9537, Val Loss: 0.3019, Val Acc: 0.8945\n",
      "Epoch 9/50, Train Loss: 0.1513, Train Acc: 0.9514, Val Loss: 0.0638, Val Acc: 0.9730\n",
      "Epoch 10/50, Train Loss: 0.2986, Train Acc: 0.9244, Val Loss: 0.0746, Val Acc: 0.9766\n",
      "Epoch 11/50, Train Loss: 0.0136, Train Acc: 0.9952, Val Loss: 0.0415, Val Acc: 0.9874\n",
      "Epoch 12/50, Train Loss: 0.0090, Train Acc: 0.9969, Val Loss: 0.0413, Val Acc: 0.9886\n",
      "Epoch 13/50, Train Loss: 0.0061, Train Acc: 0.9976, Val Loss: 0.0670, Val Acc: 0.9826\n",
      "Epoch 14/50, Train Loss: 0.0044, Train Acc: 0.9990, Val Loss: 0.0461, Val Acc: 0.9892\n",
      "Epoch 15/50, Train Loss: 0.0048, Train Acc: 0.9981, Val Loss: 0.0690, Val Acc: 0.9850\n",
      "Epoch 16/50, Train Loss: 0.0028, Train Acc: 0.9993, Val Loss: 0.0482, Val Acc: 0.9892\n",
      "Epoch 17/50, Train Loss: 0.0013, Train Acc: 0.9997, Val Loss: 0.0457, Val Acc: 0.9892\n",
      "Early stopping!\n",
      "\n",
      "Run 9/10\n",
      "Epoch 1/50, Train Loss: 0.9865, Train Acc: 0.5961, Val Loss: 0.6230, Val Acc: 0.6733\n",
      "Epoch 2/50, Train Loss: 0.4925, Train Acc: 0.7875, Val Loss: 0.4221, Val Acc: 0.8279\n",
      "Epoch 3/50, Train Loss: 0.4945, Train Acc: 0.7924, Val Loss: 0.4188, Val Acc: 0.8261\n",
      "Epoch 4/50, Train Loss: 0.4588, Train Acc: 0.8091, Val Loss: 0.4375, Val Acc: 0.8249\n",
      "Epoch 5/50, Train Loss: 0.4374, Train Acc: 0.8214, Val Loss: 0.5089, Val Acc: 0.7962\n",
      "Epoch 6/50, Train Loss: 0.4053, Train Acc: 0.8350, Val Loss: 0.3685, Val Acc: 0.8489\n",
      "Epoch 7/50, Train Loss: 0.3717, Train Acc: 0.8590, Val Loss: 0.2034, Val Acc: 0.9227\n",
      "Epoch 8/50, Train Loss: 0.2232, Train Acc: 0.9168, Val Loss: 0.1468, Val Acc: 0.9454\n",
      "Epoch 9/50, Train Loss: 0.2531, Train Acc: 0.9132, Val Loss: 0.0836, Val Acc: 0.9682\n",
      "Epoch 10/50, Train Loss: 0.1824, Train Acc: 0.9454, Val Loss: 0.0809, Val Acc: 0.9730\n",
      "Epoch 11/50, Train Loss: 0.0204, Train Acc: 0.9930, Val Loss: 0.0363, Val Acc: 0.9868\n",
      "Epoch 12/50, Train Loss: 0.0201, Train Acc: 0.9925, Val Loss: 0.0749, Val Acc: 0.9724\n",
      "Epoch 13/50, Train Loss: 0.0131, Train Acc: 0.9955, Val Loss: 0.0371, Val Acc: 0.9868\n",
      "Epoch 14/50, Train Loss: 0.0104, Train Acc: 0.9957, Val Loss: 0.0356, Val Acc: 0.9880\n",
      "Epoch 15/50, Train Loss: 0.0091, Train Acc: 0.9966, Val Loss: 0.0489, Val Acc: 0.9868\n",
      "Epoch 16/50, Train Loss: 0.0088, Train Acc: 0.9970, Val Loss: 0.0614, Val Acc: 0.9778\n",
      "Epoch 17/50, Train Loss: 0.0075, Train Acc: 0.9975, Val Loss: 0.0375, Val Acc: 0.9886\n",
      "Epoch 18/50, Train Loss: 0.0055, Train Acc: 0.9982, Val Loss: 0.0402, Val Acc: 0.9850\n",
      "Epoch 19/50, Train Loss: 0.0039, Train Acc: 0.9990, Val Loss: 0.0389, Val Acc: 0.9868\n",
      "Early stopping!\n",
      "\n",
      "Run 10/10\n",
      "Epoch 1/50, Train Loss: 0.8872, Train Acc: 0.6312, Val Loss: 0.7499, Val Acc: 0.6751\n",
      "Epoch 2/50, Train Loss: 0.5711, Train Acc: 0.7452, Val Loss: 0.4754, Val Acc: 0.7980\n",
      "Epoch 3/50, Train Loss: 0.5146, Train Acc: 0.7816, Val Loss: 0.5496, Val Acc: 0.7548\n",
      "Epoch 4/50, Train Loss: 0.4663, Train Acc: 0.8088, Val Loss: 0.4640, Val Acc: 0.7950\n",
      "Epoch 5/50, Train Loss: 0.4680, Train Acc: 0.8023, Val Loss: 0.4266, Val Acc: 0.8135\n",
      "Epoch 6/50, Train Loss: 0.4102, Train Acc: 0.8275, Val Loss: 0.4123, Val Acc: 0.8303\n",
      "Epoch 7/50, Train Loss: 0.3615, Train Acc: 0.8535, Val Loss: 0.4128, Val Acc: 0.8213\n",
      "Epoch 8/50, Train Loss: 0.3084, Train Acc: 0.8832, Val Loss: 0.1132, Val Acc: 0.9478\n",
      "Epoch 9/50, Train Loss: 0.1565, Train Acc: 0.9417, Val Loss: 0.2174, Val Acc: 0.9376\n",
      "Epoch 10/50, Train Loss: 0.0943, Train Acc: 0.9703, Val Loss: 0.0633, Val Acc: 0.9820\n",
      "Epoch 11/50, Train Loss: 0.0131, Train Acc: 0.9963, Val Loss: 0.0469, Val Acc: 0.9856\n",
      "Epoch 12/50, Train Loss: 0.0115, Train Acc: 0.9961, Val Loss: 0.0545, Val Acc: 0.9814\n",
      "Epoch 13/50, Train Loss: 0.0092, Train Acc: 0.9964, Val Loss: 0.0506, Val Acc: 0.9868\n",
      "Epoch 14/50, Train Loss: 0.0071, Train Acc: 0.9976, Val Loss: 0.0360, Val Acc: 0.9904\n",
      "Epoch 15/50, Train Loss: 0.0098, Train Acc: 0.9966, Val Loss: 0.0370, Val Acc: 0.9886\n",
      "Epoch 16/50, Train Loss: 0.0048, Train Acc: 0.9990, Val Loss: 0.0451, Val Acc: 0.9868\n",
      "Epoch 17/50, Train Loss: 0.0065, Train Acc: 0.9984, Val Loss: 0.0451, Val Acc: 0.9880\n",
      "Epoch 18/50, Train Loss: 0.0034, Train Acc: 0.9994, Val Loss: 0.0349, Val Acc: 0.9898\n",
      "Epoch 19/50, Train Loss: 0.0035, Train Acc: 0.9994, Val Loss: 0.0359, Val Acc: 0.9910\n",
      "Epoch 20/50, Train Loss: 0.0024, Train Acc: 0.9994, Val Loss: 0.0558, Val Acc: 0.9892\n",
      "Epoch 21/50, Train Loss: 0.0026, Train Acc: 0.9993, Val Loss: 0.0369, Val Acc: 0.9904\n",
      "Epoch 22/50, Train Loss: 0.0019, Train Acc: 0.9996, Val Loss: 0.0362, Val Acc: 0.9910\n",
      "Epoch 23/50, Train Loss: 0.0014, Train Acc: 0.9997, Val Loss: 0.0371, Val Acc: 0.9910\n",
      "Early stopping!\n",
      "\n",
      "Source performance: 98.84 98.81 98.81 98.81\n",
      "Target performance: 55.43 65.87 56.85 51.47\n",
      "\n",
      "bpsk: 100.00\n",
      "qpsk: 14.38\n",
      "16qam: 13.86\n",
      "16apsk: 99.17\n",
      "SNR level: 14\n",
      "DANN\n",
      "Epoch 1/50, Loss: 4.1315, Domain Loss: 2.2324, Class Loss: 1.8991\n",
      "Epoch 2/50, Loss: 2.3793, Domain Loss: 1.4307, Class Loss: 0.9486\n",
      "Epoch 3/50, Loss: 1.9652, Domain Loss: 1.4160, Class Loss: 0.5492\n",
      "Epoch 4/50, Loss: 1.9334, Domain Loss: 1.3903, Class Loss: 0.5431\n",
      "Epoch 5/50, Loss: 1.8699, Domain Loss: 1.3819, Class Loss: 0.4880\n",
      "Epoch 6/50, Loss: 1.8494, Domain Loss: 1.3744, Class Loss: 0.4750\n",
      "Epoch 7/50, Loss: 1.8289, Domain Loss: 1.3677, Class Loss: 0.4612\n",
      "Epoch 8/50, Loss: 1.7991, Domain Loss: 1.3626, Class Loss: 0.4365\n",
      "Epoch 9/50, Loss: 1.7973, Domain Loss: 1.3605, Class Loss: 0.4368\n",
      "Epoch 10/50, Loss: 1.8058, Domain Loss: 1.3573, Class Loss: 0.4485\n",
      "Epoch 11/50, Loss: 1.8055, Domain Loss: 1.3652, Class Loss: 0.4403\n",
      "Epoch 12/50, Loss: 1.7537, Domain Loss: 1.3386, Class Loss: 0.4151\n",
      "Epoch 13/50, Loss: 1.7975, Domain Loss: 1.3592, Class Loss: 0.4383\n",
      "Epoch 14/50, Loss: 1.8784, Domain Loss: 1.4598, Class Loss: 0.4185\n",
      "Epoch 15/50, Loss: 2.7675, Domain Loss: 1.5228, Class Loss: 1.2447\n",
      "Epoch 16/50, Loss: 1.9394, Domain Loss: 1.3786, Class Loss: 0.5609\n",
      "Epoch 17/50, Loss: 1.8690, Domain Loss: 1.3875, Class Loss: 0.4815\n",
      "Epoch 18/50, Loss: 1.8070, Domain Loss: 1.3568, Class Loss: 0.4502\n",
      "Epoch 19/50, Loss: 1.7983, Domain Loss: 1.3548, Class Loss: 0.4435\n",
      "Epoch 20/50, Loss: 1.7926, Domain Loss: 1.3495, Class Loss: 0.4431\n",
      "Epoch 21/50, Loss: 1.7635, Domain Loss: 1.3463, Class Loss: 0.4172\n",
      "Epoch 22/50, Loss: 1.7929, Domain Loss: 1.3409, Class Loss: 0.4520\n",
      "Epoch 23/50, Loss: 1.7501, Domain Loss: 1.3399, Class Loss: 0.4102\n",
      "Epoch 24/50, Loss: 1.7846, Domain Loss: 1.3392, Class Loss: 0.4454\n",
      "Epoch 25/50, Loss: 1.7992, Domain Loss: 1.3353, Class Loss: 0.4639\n",
      "Epoch 26/50, Loss: 1.7313, Domain Loss: 1.3340, Class Loss: 0.3973\n",
      "Epoch 27/50, Loss: 1.7520, Domain Loss: 1.3313, Class Loss: 0.4208\n",
      "Epoch 28/50, Loss: 1.7633, Domain Loss: 1.3351, Class Loss: 0.4281\n",
      "Epoch 29/50, Loss: 1.7233, Domain Loss: 1.3376, Class Loss: 0.3857\n",
      "Epoch 30/50, Loss: 1.7420, Domain Loss: 1.3196, Class Loss: 0.4224\n",
      "Epoch 31/50, Loss: 1.7000, Domain Loss: 1.3136, Class Loss: 0.3864\n",
      "Epoch 32/50, Loss: 1.7175, Domain Loss: 1.3273, Class Loss: 0.3902\n",
      "Epoch 33/50, Loss: 1.7256, Domain Loss: 1.3318, Class Loss: 0.3938\n",
      "Epoch 34/50, Loss: 1.7157, Domain Loss: 1.3561, Class Loss: 0.3595\n",
      "Epoch 35/50, Loss: 1.7325, Domain Loss: 1.3325, Class Loss: 0.3999\n",
      "Epoch 36/50, Loss: 1.7007, Domain Loss: 1.3248, Class Loss: 0.3760\n",
      "Epoch 37/50, Loss: 1.6974, Domain Loss: 1.3305, Class Loss: 0.3669\n",
      "Epoch 38/50, Loss: 1.7463, Domain Loss: 1.3379, Class Loss: 0.4084\n",
      "Epoch 39/50, Loss: 1.7514, Domain Loss: 1.3334, Class Loss: 0.4180\n",
      "Epoch 40/50, Loss: 1.7837, Domain Loss: 1.3640, Class Loss: 0.4196\n",
      "Epoch 41/50, Loss: 1.7880, Domain Loss: 1.3547, Class Loss: 0.4333\n",
      "Epoch 42/50, Loss: 1.7429, Domain Loss: 1.3488, Class Loss: 0.3940\n",
      "Epoch 43/50, Loss: 1.6915, Domain Loss: 1.3438, Class Loss: 0.3478\n",
      "Epoch 44/50, Loss: 1.7232, Domain Loss: 1.3476, Class Loss: 0.3757\n",
      "Epoch 45/50, Loss: 1.6663, Domain Loss: 1.3324, Class Loss: 0.3339\n",
      "Epoch 46/50, Loss: 1.6700, Domain Loss: 1.3392, Class Loss: 0.3308\n",
      "Epoch 47/50, Loss: 1.8097, Domain Loss: 1.3229, Class Loss: 0.4868\n",
      "Epoch 48/50, Loss: 1.6806, Domain Loss: 1.3225, Class Loss: 0.3581\n",
      "Epoch 49/50, Loss: 1.6247, Domain Loss: 1.3152, Class Loss: 0.3095\n",
      "Epoch 50/50, Loss: 1.6726, Domain Loss: 1.3221, Class Loss: 0.3505\n",
      "62.35\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8314, Domain Loss: 2.0188, Class Loss: 1.8126\n",
      "Epoch 2/50, Loss: 2.3471, Domain Loss: 1.3897, Class Loss: 0.9573\n",
      "Epoch 3/50, Loss: 1.9754, Domain Loss: 1.4437, Class Loss: 0.5317\n",
      "Epoch 4/50, Loss: 1.9000, Domain Loss: 1.3910, Class Loss: 0.5090\n",
      "Epoch 5/50, Loss: 1.8933, Domain Loss: 1.3608, Class Loss: 0.5325\n",
      "Epoch 6/50, Loss: 1.8355, Domain Loss: 1.3680, Class Loss: 0.4675\n",
      "Epoch 7/50, Loss: 1.8409, Domain Loss: 1.3553, Class Loss: 0.4856\n",
      "Epoch 8/50, Loss: 1.8161, Domain Loss: 1.3470, Class Loss: 0.4690\n",
      "Epoch 9/50, Loss: 1.8042, Domain Loss: 1.3505, Class Loss: 0.4537\n",
      "Epoch 10/50, Loss: 1.8211, Domain Loss: 1.3255, Class Loss: 0.4956\n",
      "Epoch 11/50, Loss: 1.7633, Domain Loss: 1.3110, Class Loss: 0.4523\n",
      "Epoch 12/50, Loss: 1.7869, Domain Loss: 1.3321, Class Loss: 0.4548\n",
      "Epoch 13/50, Loss: 1.7784, Domain Loss: 1.3334, Class Loss: 0.4450\n",
      "Epoch 14/50, Loss: 1.7710, Domain Loss: 1.3174, Class Loss: 0.4536\n",
      "Epoch 15/50, Loss: 1.7310, Domain Loss: 1.3033, Class Loss: 0.4276\n",
      "Epoch 16/50, Loss: 1.7325, Domain Loss: 1.3048, Class Loss: 0.4276\n",
      "Epoch 17/50, Loss: 1.7305, Domain Loss: 1.3159, Class Loss: 0.4146\n",
      "Epoch 18/50, Loss: 1.7610, Domain Loss: 1.3410, Class Loss: 0.4199\n",
      "Epoch 19/50, Loss: 4.2094, Domain Loss: 2.2831, Class Loss: 1.9263\n",
      "Epoch 20/50, Loss: 2.1695, Domain Loss: 1.4792, Class Loss: 0.6903\n",
      "Epoch 21/50, Loss: 1.8238, Domain Loss: 1.3528, Class Loss: 0.4710\n",
      "Epoch 22/50, Loss: 1.7896, Domain Loss: 1.3511, Class Loss: 0.4385\n",
      "Epoch 23/50, Loss: 1.8226, Domain Loss: 1.3474, Class Loss: 0.4752\n",
      "Epoch 24/50, Loss: 1.7699, Domain Loss: 1.3438, Class Loss: 0.4261\n",
      "Epoch 25/50, Loss: 1.7432, Domain Loss: 1.3415, Class Loss: 0.4016\n",
      "Epoch 26/50, Loss: 1.7745, Domain Loss: 1.3413, Class Loss: 0.4331\n",
      "Epoch 27/50, Loss: 1.7564, Domain Loss: 1.3436, Class Loss: 0.4128\n",
      "Epoch 28/50, Loss: 1.7329, Domain Loss: 1.3404, Class Loss: 0.3925\n",
      "Epoch 29/50, Loss: 1.7415, Domain Loss: 1.3375, Class Loss: 0.4040\n",
      "Epoch 30/50, Loss: 1.7297, Domain Loss: 1.3367, Class Loss: 0.3930\n",
      "Epoch 31/50, Loss: 1.7279, Domain Loss: 1.3366, Class Loss: 0.3913\n",
      "Epoch 32/50, Loss: 1.7038, Domain Loss: 1.3321, Class Loss: 0.3717\n",
      "Epoch 33/50, Loss: 1.7284, Domain Loss: 1.3319, Class Loss: 0.3965\n",
      "Epoch 34/50, Loss: 1.7367, Domain Loss: 1.3392, Class Loss: 0.3974\n",
      "Epoch 35/50, Loss: 1.6801, Domain Loss: 1.3230, Class Loss: 0.3571\n",
      "Epoch 36/50, Loss: 1.6873, Domain Loss: 1.3317, Class Loss: 0.3556\n",
      "Epoch 37/50, Loss: 1.6865, Domain Loss: 1.3244, Class Loss: 0.3620\n",
      "Epoch 38/50, Loss: 1.7539, Domain Loss: 1.3430, Class Loss: 0.4109\n",
      "Epoch 39/50, Loss: 1.7043, Domain Loss: 1.3537, Class Loss: 0.3506\n",
      "Epoch 40/50, Loss: 1.6808, Domain Loss: 1.3246, Class Loss: 0.3563\n",
      "Epoch 41/50, Loss: 1.6802, Domain Loss: 1.3246, Class Loss: 0.3556\n",
      "Epoch 42/50, Loss: 1.7012, Domain Loss: 1.3321, Class Loss: 0.3692\n",
      "Epoch 43/50, Loss: 1.6488, Domain Loss: 1.3239, Class Loss: 0.3249\n",
      "Epoch 44/50, Loss: 1.6323, Domain Loss: 1.3271, Class Loss: 0.3052\n",
      "Epoch 45/50, Loss: 1.6341, Domain Loss: 1.3296, Class Loss: 0.3045\n",
      "Epoch 46/50, Loss: 1.6604, Domain Loss: 1.3254, Class Loss: 0.3350\n",
      "Epoch 47/50, Loss: 1.6094, Domain Loss: 1.3266, Class Loss: 0.2828\n",
      "Epoch 48/50, Loss: 1.5929, Domain Loss: 1.3375, Class Loss: 0.2554\n",
      "Epoch 49/50, Loss: 1.6522, Domain Loss: 1.3439, Class Loss: 0.3083\n",
      "Epoch 50/50, Loss: 1.6306, Domain Loss: 1.3040, Class Loss: 0.3266\n",
      "67.99\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8138, Domain Loss: 2.0222, Class Loss: 1.7916\n",
      "Epoch 2/50, Loss: 2.2605, Domain Loss: 1.4082, Class Loss: 0.8523\n",
      "Epoch 3/50, Loss: 1.9295, Domain Loss: 1.4094, Class Loss: 0.5201\n",
      "Epoch 4/50, Loss: 1.8813, Domain Loss: 1.3885, Class Loss: 0.4929\n",
      "Epoch 5/50, Loss: 1.8453, Domain Loss: 1.3772, Class Loss: 0.4681\n",
      "Epoch 6/50, Loss: 1.8613, Domain Loss: 1.3781, Class Loss: 0.4832\n",
      "Epoch 7/50, Loss: 1.8687, Domain Loss: 1.3750, Class Loss: 0.4937\n",
      "Epoch 8/50, Loss: 1.8378, Domain Loss: 1.3742, Class Loss: 0.4636\n",
      "Epoch 9/50, Loss: 1.8544, Domain Loss: 1.3694, Class Loss: 0.4850\n",
      "Epoch 10/50, Loss: 1.8354, Domain Loss: 1.3600, Class Loss: 0.4754\n",
      "Epoch 11/50, Loss: 1.8155, Domain Loss: 1.3574, Class Loss: 0.4580\n",
      "Epoch 12/50, Loss: 1.8622, Domain Loss: 1.3483, Class Loss: 0.5139\n",
      "Epoch 13/50, Loss: 1.7855, Domain Loss: 1.3447, Class Loss: 0.4408\n",
      "Epoch 14/50, Loss: 1.8018, Domain Loss: 1.3447, Class Loss: 0.4571\n",
      "Epoch 15/50, Loss: 1.7837, Domain Loss: 1.3376, Class Loss: 0.4461\n",
      "Epoch 16/50, Loss: 1.8055, Domain Loss: 1.3430, Class Loss: 0.4625\n",
      "Epoch 17/50, Loss: 1.7675, Domain Loss: 1.3343, Class Loss: 0.4332\n",
      "Epoch 18/50, Loss: 1.7535, Domain Loss: 1.3265, Class Loss: 0.4270\n",
      "Epoch 19/50, Loss: 1.8335, Domain Loss: 1.3345, Class Loss: 0.4990\n",
      "Epoch 20/50, Loss: 1.7784, Domain Loss: 1.3143, Class Loss: 0.4641\n",
      "Epoch 21/50, Loss: 1.7223, Domain Loss: 1.3144, Class Loss: 0.4079\n",
      "Epoch 22/50, Loss: 1.7292, Domain Loss: 1.3238, Class Loss: 0.4054\n",
      "Epoch 23/50, Loss: 1.7651, Domain Loss: 1.3420, Class Loss: 0.4231\n",
      "Epoch 24/50, Loss: 1.7127, Domain Loss: 1.2975, Class Loss: 0.4152\n",
      "Epoch 25/50, Loss: 1.7091, Domain Loss: 1.3311, Class Loss: 0.3780\n",
      "Epoch 26/50, Loss: 2.5117, Domain Loss: 1.4991, Class Loss: 1.0126\n",
      "Epoch 27/50, Loss: 1.8954, Domain Loss: 1.3891, Class Loss: 0.5063\n",
      "Epoch 28/50, Loss: 1.8528, Domain Loss: 1.3874, Class Loss: 0.4654\n",
      "Epoch 29/50, Loss: 1.8133, Domain Loss: 1.3868, Class Loss: 0.4266\n",
      "Epoch 30/50, Loss: 1.8309, Domain Loss: 1.3849, Class Loss: 0.4460\n",
      "Epoch 31/50, Loss: 1.8210, Domain Loss: 1.3838, Class Loss: 0.4372\n",
      "Epoch 32/50, Loss: 1.7901, Domain Loss: 1.3819, Class Loss: 0.4082\n",
      "Epoch 33/50, Loss: 1.7900, Domain Loss: 1.3814, Class Loss: 0.4085\n",
      "Epoch 34/50, Loss: 1.8047, Domain Loss: 1.3798, Class Loss: 0.4248\n",
      "Epoch 35/50, Loss: 1.8244, Domain Loss: 1.3810, Class Loss: 0.4433\n",
      "Epoch 36/50, Loss: 1.7972, Domain Loss: 1.3764, Class Loss: 0.4209\n",
      "Epoch 37/50, Loss: 1.7540, Domain Loss: 1.3796, Class Loss: 0.3745\n",
      "Epoch 38/50, Loss: 1.7502, Domain Loss: 1.3783, Class Loss: 0.3720\n",
      "Epoch 39/50, Loss: 1.7676, Domain Loss: 1.3786, Class Loss: 0.3890\n",
      "Epoch 40/50, Loss: 1.7444, Domain Loss: 1.3770, Class Loss: 0.3674\n",
      "Epoch 41/50, Loss: 1.7410, Domain Loss: 1.3707, Class Loss: 0.3703\n",
      "Epoch 42/50, Loss: 1.7264, Domain Loss: 1.3715, Class Loss: 0.3549\n",
      "Epoch 43/50, Loss: 1.7289, Domain Loss: 1.3643, Class Loss: 0.3647\n",
      "Epoch 44/50, Loss: 1.7312, Domain Loss: 1.3672, Class Loss: 0.3641\n",
      "Epoch 45/50, Loss: 1.6799, Domain Loss: 1.3541, Class Loss: 0.3258\n",
      "Epoch 46/50, Loss: 1.7158, Domain Loss: 1.3966, Class Loss: 0.3193\n",
      "Epoch 47/50, Loss: 1.8150, Domain Loss: 1.3924, Class Loss: 0.4225\n",
      "Epoch 48/50, Loss: 1.7309, Domain Loss: 1.3887, Class Loss: 0.3422\n",
      "Epoch 49/50, Loss: 1.6875, Domain Loss: 1.3865, Class Loss: 0.3010\n",
      "Epoch 50/50, Loss: 1.6595, Domain Loss: 1.3778, Class Loss: 0.2817\n",
      "61.87\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.4386, Domain Loss: 1.6296, Class Loss: 1.8091\n",
      "Epoch 2/50, Loss: 2.2450, Domain Loss: 1.3949, Class Loss: 0.8501\n",
      "Epoch 3/50, Loss: 1.9507, Domain Loss: 1.3859, Class Loss: 0.5648\n",
      "Epoch 4/50, Loss: 1.9074, Domain Loss: 1.3729, Class Loss: 0.5346\n",
      "Epoch 5/50, Loss: 1.8898, Domain Loss: 1.3687, Class Loss: 0.5212\n",
      "Epoch 6/50, Loss: 1.8566, Domain Loss: 1.3821, Class Loss: 0.4745\n",
      "Epoch 7/50, Loss: 1.8370, Domain Loss: 1.3721, Class Loss: 0.4650\n",
      "Epoch 8/50, Loss: 1.8245, Domain Loss: 1.3533, Class Loss: 0.4711\n",
      "Epoch 9/50, Loss: 1.8750, Domain Loss: 1.3579, Class Loss: 0.5171\n",
      "Epoch 10/50, Loss: 1.8279, Domain Loss: 1.3426, Class Loss: 0.4853\n",
      "Epoch 11/50, Loss: 1.7801, Domain Loss: 1.3258, Class Loss: 0.4543\n",
      "Epoch 12/50, Loss: 1.7518, Domain Loss: 1.3144, Class Loss: 0.4374\n",
      "Epoch 13/50, Loss: 1.7625, Domain Loss: 1.3097, Class Loss: 0.4528\n",
      "Epoch 14/50, Loss: 1.8321, Domain Loss: 1.3349, Class Loss: 0.4972\n",
      "Epoch 15/50, Loss: 1.8263, Domain Loss: 1.3480, Class Loss: 0.4783\n",
      "Epoch 16/50, Loss: 1.8072, Domain Loss: 1.3283, Class Loss: 0.4789\n",
      "Epoch 17/50, Loss: 1.7407, Domain Loss: 1.3070, Class Loss: 0.4336\n",
      "Epoch 18/50, Loss: 1.6969, Domain Loss: 1.2922, Class Loss: 0.4048\n",
      "Epoch 19/50, Loss: 1.7153, Domain Loss: 1.2916, Class Loss: 0.4237\n",
      "Epoch 20/50, Loss: 1.6700, Domain Loss: 1.2814, Class Loss: 0.3886\n",
      "Epoch 21/50, Loss: 1.6978, Domain Loss: 1.2880, Class Loss: 0.4099\n",
      "Epoch 22/50, Loss: 1.7169, Domain Loss: 1.2850, Class Loss: 0.4319\n",
      "Epoch 23/50, Loss: 1.7273, Domain Loss: 1.3176, Class Loss: 0.4097\n",
      "Epoch 24/50, Loss: 1.8969, Domain Loss: 1.2960, Class Loss: 0.6009\n",
      "Epoch 25/50, Loss: 1.7160, Domain Loss: 1.2851, Class Loss: 0.4309\n",
      "Epoch 26/50, Loss: 1.6757, Domain Loss: 1.2802, Class Loss: 0.3956\n",
      "Epoch 27/50, Loss: 1.6683, Domain Loss: 1.2805, Class Loss: 0.3878\n",
      "Epoch 28/50, Loss: 1.6619, Domain Loss: 1.2907, Class Loss: 0.3712\n",
      "Epoch 29/50, Loss: 1.6838, Domain Loss: 1.2909, Class Loss: 0.3929\n",
      "Epoch 30/50, Loss: 1.6906, Domain Loss: 1.2891, Class Loss: 0.4015\n",
      "Epoch 31/50, Loss: 1.7038, Domain Loss: 1.3067, Class Loss: 0.3971\n",
      "Epoch 32/50, Loss: 1.7102, Domain Loss: 1.3060, Class Loss: 0.4042\n",
      "Epoch 33/50, Loss: 1.6893, Domain Loss: 1.2944, Class Loss: 0.3949\n",
      "Epoch 34/50, Loss: 1.6682, Domain Loss: 1.2830, Class Loss: 0.3852\n",
      "Epoch 35/50, Loss: 1.6955, Domain Loss: 1.3002, Class Loss: 0.3954\n",
      "Epoch 36/50, Loss: 1.6876, Domain Loss: 1.3154, Class Loss: 0.3722\n",
      "Epoch 37/50, Loss: 1.7036, Domain Loss: 1.3039, Class Loss: 0.3997\n",
      "Epoch 38/50, Loss: 1.7005, Domain Loss: 1.3134, Class Loss: 0.3871\n",
      "Epoch 39/50, Loss: 1.6781, Domain Loss: 1.3001, Class Loss: 0.3780\n",
      "Epoch 40/50, Loss: 1.6852, Domain Loss: 1.2833, Class Loss: 0.4020\n",
      "Epoch 41/50, Loss: 1.6530, Domain Loss: 1.2730, Class Loss: 0.3800\n",
      "Epoch 42/50, Loss: 1.7124, Domain Loss: 1.3018, Class Loss: 0.4106\n",
      "Epoch 43/50, Loss: 1.7863, Domain Loss: 1.3760, Class Loss: 0.4103\n",
      "Epoch 44/50, Loss: 1.7612, Domain Loss: 1.3387, Class Loss: 0.4225\n",
      "Epoch 45/50, Loss: 1.6903, Domain Loss: 1.3241, Class Loss: 0.3662\n",
      "Epoch 46/50, Loss: 1.7095, Domain Loss: 1.3367, Class Loss: 0.3728\n",
      "Epoch 47/50, Loss: 1.6984, Domain Loss: 1.3443, Class Loss: 0.3541\n",
      "Epoch 48/50, Loss: 2.5092, Domain Loss: 1.3547, Class Loss: 1.1545\n",
      "Epoch 49/50, Loss: 1.7071, Domain Loss: 1.2628, Class Loss: 0.4443\n",
      "Epoch 50/50, Loss: 1.5843, Domain Loss: 1.2102, Class Loss: 0.3741\n",
      "61.63\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.2927, Domain Loss: 1.5201, Class Loss: 1.7726\n",
      "Epoch 2/50, Loss: 2.3288, Domain Loss: 1.4139, Class Loss: 0.9150\n",
      "Epoch 3/50, Loss: 1.9406, Domain Loss: 1.4026, Class Loss: 0.5379\n",
      "Epoch 4/50, Loss: 1.9676, Domain Loss: 1.3826, Class Loss: 0.5850\n",
      "Epoch 5/50, Loss: 1.8790, Domain Loss: 1.3650, Class Loss: 0.5140\n",
      "Epoch 6/50, Loss: 1.8099, Domain Loss: 1.3580, Class Loss: 0.4519\n",
      "Epoch 7/50, Loss: 1.8272, Domain Loss: 1.3304, Class Loss: 0.4968\n",
      "Epoch 8/50, Loss: 1.8544, Domain Loss: 1.3608, Class Loss: 0.4936\n",
      "Epoch 9/50, Loss: 1.8194, Domain Loss: 1.3387, Class Loss: 0.4807\n",
      "Epoch 10/50, Loss: 1.8015, Domain Loss: 1.3212, Class Loss: 0.4803\n",
      "Epoch 11/50, Loss: 1.8163, Domain Loss: 1.3171, Class Loss: 0.4992\n",
      "Epoch 12/50, Loss: 1.8103, Domain Loss: 1.3407, Class Loss: 0.4696\n",
      "Epoch 13/50, Loss: 1.7719, Domain Loss: 1.3436, Class Loss: 0.4283\n",
      "Epoch 14/50, Loss: 1.7555, Domain Loss: 1.3093, Class Loss: 0.4462\n",
      "Epoch 15/50, Loss: 1.7833, Domain Loss: 1.3137, Class Loss: 0.4696\n",
      "Epoch 16/50, Loss: 1.8830, Domain Loss: 1.3038, Class Loss: 0.5792\n",
      "Epoch 17/50, Loss: 1.7114, Domain Loss: 1.2857, Class Loss: 0.4256\n",
      "Epoch 18/50, Loss: 1.7026, Domain Loss: 1.2801, Class Loss: 0.4225\n",
      "Epoch 19/50, Loss: 1.6822, Domain Loss: 1.2799, Class Loss: 0.4023\n",
      "Epoch 20/50, Loss: 1.7397, Domain Loss: 1.2920, Class Loss: 0.4478\n",
      "Epoch 21/50, Loss: 1.7265, Domain Loss: 1.2697, Class Loss: 0.4568\n",
      "Epoch 22/50, Loss: 1.6893, Domain Loss: 1.2829, Class Loss: 0.4064\n",
      "Epoch 23/50, Loss: 1.7449, Domain Loss: 1.3372, Class Loss: 0.4076\n",
      "Epoch 24/50, Loss: 1.7408, Domain Loss: 1.3196, Class Loss: 0.4213\n",
      "Epoch 25/50, Loss: 1.7185, Domain Loss: 1.3067, Class Loss: 0.4118\n",
      "Epoch 26/50, Loss: 1.6936, Domain Loss: 1.2919, Class Loss: 0.4017\n",
      "Epoch 27/50, Loss: 1.6950, Domain Loss: 1.3086, Class Loss: 0.3864\n",
      "Epoch 28/50, Loss: 1.7235, Domain Loss: 1.2905, Class Loss: 0.4330\n",
      "Epoch 29/50, Loss: 1.6873, Domain Loss: 1.2841, Class Loss: 0.4031\n",
      "Epoch 30/50, Loss: 1.6803, Domain Loss: 1.2949, Class Loss: 0.3854\n",
      "Epoch 31/50, Loss: 1.7422, Domain Loss: 1.3022, Class Loss: 0.4400\n",
      "Epoch 32/50, Loss: 1.7379, Domain Loss: 1.3012, Class Loss: 0.4367\n",
      "Epoch 33/50, Loss: 1.7158, Domain Loss: 1.3333, Class Loss: 0.3824\n",
      "Epoch 34/50, Loss: 2.0834, Domain Loss: 1.3839, Class Loss: 0.6995\n",
      "Epoch 35/50, Loss: 1.8965, Domain Loss: 1.3524, Class Loss: 0.5441\n",
      "Epoch 36/50, Loss: 1.7285, Domain Loss: 1.2935, Class Loss: 0.4351\n",
      "Epoch 37/50, Loss: 1.6485, Domain Loss: 1.2620, Class Loss: 0.3865\n",
      "Epoch 38/50, Loss: 1.6313, Domain Loss: 1.2509, Class Loss: 0.3804\n",
      "Epoch 39/50, Loss: 1.6111, Domain Loss: 1.2528, Class Loss: 0.3582\n",
      "Epoch 40/50, Loss: 1.6299, Domain Loss: 1.2550, Class Loss: 0.3749\n",
      "Epoch 41/50, Loss: 1.6335, Domain Loss: 1.2578, Class Loss: 0.3756\n",
      "Epoch 42/50, Loss: 1.6435, Domain Loss: 1.2888, Class Loss: 0.3547\n",
      "Epoch 43/50, Loss: 1.7028, Domain Loss: 1.3316, Class Loss: 0.3711\n",
      "Epoch 44/50, Loss: 1.7582, Domain Loss: 1.3708, Class Loss: 0.3874\n",
      "Epoch 45/50, Loss: 1.6898, Domain Loss: 1.3689, Class Loss: 0.3209\n",
      "Epoch 46/50, Loss: 1.7963, Domain Loss: 1.4320, Class Loss: 0.3643\n",
      "Epoch 47/50, Loss: 1.7025, Domain Loss: 1.3979, Class Loss: 0.3046\n",
      "Epoch 48/50, Loss: 1.7111, Domain Loss: 1.3600, Class Loss: 0.3511\n",
      "Epoch 49/50, Loss: 1.6776, Domain Loss: 1.3456, Class Loss: 0.3319\n",
      "Epoch 50/50, Loss: 1.6247, Domain Loss: 1.3215, Class Loss: 0.3032\n",
      "66.67\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.2379, Domain Loss: 2.1943, Class Loss: 2.0436\n",
      "Epoch 2/50, Loss: 2.4093, Domain Loss: 1.4165, Class Loss: 0.9928\n",
      "Epoch 3/50, Loss: 2.1002, Domain Loss: 1.4209, Class Loss: 0.6792\n",
      "Epoch 4/50, Loss: 1.8990, Domain Loss: 1.3842, Class Loss: 0.5147\n",
      "Epoch 5/50, Loss: 1.8557, Domain Loss: 1.3664, Class Loss: 0.4893\n",
      "Epoch 6/50, Loss: 1.8342, Domain Loss: 1.3593, Class Loss: 0.4749\n",
      "Epoch 7/50, Loss: 1.7973, Domain Loss: 1.3450, Class Loss: 0.4523\n",
      "Epoch 8/50, Loss: 1.8003, Domain Loss: 1.3511, Class Loss: 0.4492\n",
      "Epoch 9/50, Loss: 1.8467, Domain Loss: 1.3479, Class Loss: 0.4988\n",
      "Epoch 10/50, Loss: 1.8842, Domain Loss: 1.3453, Class Loss: 0.5389\n",
      "Epoch 11/50, Loss: 1.7601, Domain Loss: 1.3217, Class Loss: 0.4383\n",
      "Epoch 12/50, Loss: 1.7667, Domain Loss: 1.3363, Class Loss: 0.4304\n",
      "Epoch 13/50, Loss: 1.7849, Domain Loss: 1.3178, Class Loss: 0.4671\n",
      "Epoch 14/50, Loss: 1.7629, Domain Loss: 1.3338, Class Loss: 0.4291\n",
      "Epoch 15/50, Loss: 1.7815, Domain Loss: 1.3504, Class Loss: 0.4311\n",
      "Epoch 16/50, Loss: 1.7850, Domain Loss: 1.3544, Class Loss: 0.4306\n",
      "Epoch 17/50, Loss: 1.7389, Domain Loss: 1.3370, Class Loss: 0.4019\n",
      "Epoch 18/50, Loss: 1.7550, Domain Loss: 1.3119, Class Loss: 0.4430\n",
      "Epoch 19/50, Loss: 1.7341, Domain Loss: 1.3152, Class Loss: 0.4189\n",
      "Epoch 20/50, Loss: 1.7323, Domain Loss: 1.3001, Class Loss: 0.4322\n",
      "Epoch 21/50, Loss: 1.7107, Domain Loss: 1.3087, Class Loss: 0.4020\n",
      "Epoch 22/50, Loss: 1.7880, Domain Loss: 1.3631, Class Loss: 0.4248\n",
      "Epoch 23/50, Loss: 1.9564, Domain Loss: 1.5480, Class Loss: 0.4083\n",
      "Epoch 24/50, Loss: 2.2755, Domain Loss: 1.5155, Class Loss: 0.7600\n",
      "Epoch 25/50, Loss: 1.7798, Domain Loss: 1.3709, Class Loss: 0.4089\n",
      "Epoch 26/50, Loss: 1.7953, Domain Loss: 1.3647, Class Loss: 0.4307\n",
      "Epoch 27/50, Loss: 1.7555, Domain Loss: 1.3652, Class Loss: 0.3903\n",
      "Epoch 28/50, Loss: 1.7768, Domain Loss: 1.3578, Class Loss: 0.4190\n",
      "Epoch 29/50, Loss: 1.8095, Domain Loss: 1.3567, Class Loss: 0.4528\n",
      "Epoch 30/50, Loss: 1.8194, Domain Loss: 1.3677, Class Loss: 0.4517\n",
      "Epoch 31/50, Loss: 1.7749, Domain Loss: 1.3534, Class Loss: 0.4215\n",
      "Epoch 32/50, Loss: 1.7303, Domain Loss: 1.3475, Class Loss: 0.3828\n",
      "Epoch 33/50, Loss: 1.7390, Domain Loss: 1.3451, Class Loss: 0.3939\n",
      "Epoch 34/50, Loss: 1.7353, Domain Loss: 1.3422, Class Loss: 0.3931\n",
      "Epoch 35/50, Loss: 1.7403, Domain Loss: 1.3425, Class Loss: 0.3978\n",
      "Epoch 36/50, Loss: 1.7032, Domain Loss: 1.3373, Class Loss: 0.3659\n",
      "Epoch 37/50, Loss: 1.6927, Domain Loss: 1.3185, Class Loss: 0.3742\n",
      "Epoch 38/50, Loss: 1.6982, Domain Loss: 1.3125, Class Loss: 0.3857\n",
      "Epoch 39/50, Loss: 1.6850, Domain Loss: 1.3040, Class Loss: 0.3810\n",
      "Epoch 40/50, Loss: 1.6630, Domain Loss: 1.2923, Class Loss: 0.3707\n",
      "Epoch 41/50, Loss: 1.6711, Domain Loss: 1.2938, Class Loss: 0.3773\n",
      "Epoch 42/50, Loss: 1.6474, Domain Loss: 1.2903, Class Loss: 0.3571\n",
      "Epoch 43/50, Loss: 1.6315, Domain Loss: 1.2678, Class Loss: 0.3637\n",
      "Epoch 44/50, Loss: 1.6638, Domain Loss: 1.2834, Class Loss: 0.3803\n",
      "Epoch 45/50, Loss: 1.6485, Domain Loss: 1.2871, Class Loss: 0.3613\n",
      "Epoch 46/50, Loss: 1.6009, Domain Loss: 1.2730, Class Loss: 0.3279\n",
      "Epoch 47/50, Loss: 1.6403, Domain Loss: 1.2788, Class Loss: 0.3616\n",
      "Epoch 48/50, Loss: 1.6780, Domain Loss: 1.2567, Class Loss: 0.4213\n",
      "Epoch 49/50, Loss: 1.6400, Domain Loss: 1.2853, Class Loss: 0.3547\n",
      "Epoch 50/50, Loss: 1.6584, Domain Loss: 1.2967, Class Loss: 0.3617\n",
      "55.88\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.3229, Domain Loss: 2.3899, Class Loss: 1.9330\n",
      "Epoch 2/50, Loss: 2.3867, Domain Loss: 1.3895, Class Loss: 0.9972\n",
      "Epoch 3/50, Loss: 1.9486, Domain Loss: 1.4020, Class Loss: 0.5466\n",
      "Epoch 4/50, Loss: 1.9032, Domain Loss: 1.3939, Class Loss: 0.5093\n",
      "Epoch 5/50, Loss: 1.8552, Domain Loss: 1.3745, Class Loss: 0.4806\n",
      "Epoch 6/50, Loss: 1.8550, Domain Loss: 1.3668, Class Loss: 0.4882\n",
      "Epoch 7/50, Loss: 1.8186, Domain Loss: 1.3642, Class Loss: 0.4544\n",
      "Epoch 8/50, Loss: 1.8740, Domain Loss: 1.3530, Class Loss: 0.5210\n",
      "Epoch 9/50, Loss: 1.8166, Domain Loss: 1.3598, Class Loss: 0.4567\n",
      "Epoch 10/50, Loss: 1.7965, Domain Loss: 1.3371, Class Loss: 0.4594\n",
      "Epoch 11/50, Loss: 1.7504, Domain Loss: 1.3340, Class Loss: 0.4164\n",
      "Epoch 12/50, Loss: 1.7996, Domain Loss: 1.3489, Class Loss: 0.4507\n",
      "Epoch 13/50, Loss: 1.7878, Domain Loss: 1.3433, Class Loss: 0.4446\n",
      "Epoch 14/50, Loss: 1.8030, Domain Loss: 1.3514, Class Loss: 0.4516\n",
      "Epoch 15/50, Loss: 1.7777, Domain Loss: 1.3425, Class Loss: 0.4352\n",
      "Epoch 16/50, Loss: 1.7686, Domain Loss: 1.3254, Class Loss: 0.4432\n",
      "Epoch 17/50, Loss: 1.7562, Domain Loss: 1.3157, Class Loss: 0.4405\n",
      "Epoch 18/50, Loss: 1.7558, Domain Loss: 1.3281, Class Loss: 0.4277\n",
      "Epoch 19/50, Loss: 1.7914, Domain Loss: 1.3256, Class Loss: 0.4658\n",
      "Epoch 20/50, Loss: 1.8082, Domain Loss: 1.3389, Class Loss: 0.4693\n",
      "Epoch 21/50, Loss: 1.8283, Domain Loss: 1.3379, Class Loss: 0.4904\n",
      "Epoch 22/50, Loss: 1.7495, Domain Loss: 1.3427, Class Loss: 0.4068\n",
      "Epoch 23/50, Loss: 1.7113, Domain Loss: 1.3123, Class Loss: 0.3990\n",
      "Epoch 24/50, Loss: 1.7417, Domain Loss: 1.3321, Class Loss: 0.4095\n",
      "Epoch 25/50, Loss: 1.7221, Domain Loss: 1.3284, Class Loss: 0.3936\n",
      "Epoch 26/50, Loss: 1.6992, Domain Loss: 1.3376, Class Loss: 0.3615\n",
      "Epoch 27/50, Loss: 1.8378, Domain Loss: 1.3970, Class Loss: 0.4409\n",
      "Epoch 28/50, Loss: 5.4677, Domain Loss: 1.8861, Class Loss: 3.5816\n",
      "Epoch 29/50, Loss: 2.0408, Domain Loss: 1.4218, Class Loss: 0.6190\n",
      "Epoch 30/50, Loss: 1.8788, Domain Loss: 1.3781, Class Loss: 0.5007\n",
      "Epoch 31/50, Loss: 1.8424, Domain Loss: 1.3750, Class Loss: 0.4675\n",
      "Epoch 32/50, Loss: 1.8420, Domain Loss: 1.3731, Class Loss: 0.4688\n",
      "Epoch 33/50, Loss: 1.8512, Domain Loss: 1.3728, Class Loss: 0.4785\n",
      "Epoch 34/50, Loss: 1.8805, Domain Loss: 1.3717, Class Loss: 0.5089\n",
      "Epoch 35/50, Loss: 1.9418, Domain Loss: 1.4628, Class Loss: 0.4790\n",
      "Epoch 36/50, Loss: 1.8608, Domain Loss: 1.4020, Class Loss: 0.4588\n",
      "Epoch 37/50, Loss: 1.8090, Domain Loss: 1.3737, Class Loss: 0.4353\n",
      "Epoch 38/50, Loss: 1.8197, Domain Loss: 1.3721, Class Loss: 0.4476\n",
      "Epoch 39/50, Loss: 1.8034, Domain Loss: 1.3688, Class Loss: 0.4345\n",
      "Epoch 40/50, Loss: 1.8274, Domain Loss: 1.3682, Class Loss: 0.4592\n",
      "Epoch 41/50, Loss: 1.8376, Domain Loss: 1.3679, Class Loss: 0.4698\n",
      "Epoch 42/50, Loss: 1.8003, Domain Loss: 1.3653, Class Loss: 0.4350\n",
      "Epoch 43/50, Loss: 1.8055, Domain Loss: 1.3631, Class Loss: 0.4424\n",
      "Epoch 44/50, Loss: 1.7601, Domain Loss: 1.3606, Class Loss: 0.3995\n",
      "Epoch 45/50, Loss: 1.7905, Domain Loss: 1.3613, Class Loss: 0.4292\n",
      "Epoch 46/50, Loss: 1.7997, Domain Loss: 1.3580, Class Loss: 0.4417\n",
      "Epoch 47/50, Loss: 1.7816, Domain Loss: 1.3545, Class Loss: 0.4271\n",
      "Epoch 48/50, Loss: 1.7346, Domain Loss: 1.3584, Class Loss: 0.3761\n",
      "Epoch 49/50, Loss: 1.7791, Domain Loss: 1.3553, Class Loss: 0.4239\n",
      "Epoch 50/50, Loss: 1.7579, Domain Loss: 1.3556, Class Loss: 0.4023\n",
      "64.03\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.9420, Domain Loss: 2.6808, Class Loss: 2.2612\n",
      "Epoch 2/50, Loss: 2.6071, Domain Loss: 1.4346, Class Loss: 1.1725\n",
      "Epoch 3/50, Loss: 2.0895, Domain Loss: 1.4543, Class Loss: 0.6352\n",
      "Epoch 4/50, Loss: 1.9227, Domain Loss: 1.3981, Class Loss: 0.5246\n",
      "Epoch 5/50, Loss: 1.8547, Domain Loss: 1.3601, Class Loss: 0.4946\n",
      "Epoch 6/50, Loss: 1.8226, Domain Loss: 1.3487, Class Loss: 0.4739\n",
      "Epoch 7/50, Loss: 1.8114, Domain Loss: 1.3641, Class Loss: 0.4473\n",
      "Epoch 8/50, Loss: 1.8782, Domain Loss: 1.3460, Class Loss: 0.5322\n",
      "Epoch 9/50, Loss: 1.8239, Domain Loss: 1.3602, Class Loss: 0.4637\n",
      "Epoch 10/50, Loss: 1.9005, Domain Loss: 1.3981, Class Loss: 0.5025\n",
      "Epoch 11/50, Loss: 2.2179, Domain Loss: 1.7727, Class Loss: 0.4453\n",
      "Epoch 12/50, Loss: 1.9122, Domain Loss: 1.3872, Class Loss: 0.5250\n",
      "Epoch 13/50, Loss: 1.8924, Domain Loss: 1.3871, Class Loss: 0.5053\n",
      "Epoch 14/50, Loss: 1.8405, Domain Loss: 1.3870, Class Loss: 0.4535\n",
      "Epoch 15/50, Loss: 1.8346, Domain Loss: 1.3869, Class Loss: 0.4478\n",
      "Epoch 16/50, Loss: 1.8182, Domain Loss: 1.3867, Class Loss: 0.4315\n",
      "Epoch 17/50, Loss: 1.8347, Domain Loss: 1.3867, Class Loss: 0.4481\n",
      "Epoch 18/50, Loss: 1.7977, Domain Loss: 1.3866, Class Loss: 0.4111\n",
      "Epoch 19/50, Loss: 1.8178, Domain Loss: 1.3870, Class Loss: 0.4308\n",
      "Epoch 20/50, Loss: 1.8066, Domain Loss: 1.3865, Class Loss: 0.4201\n",
      "Epoch 21/50, Loss: 1.7949, Domain Loss: 1.3864, Class Loss: 0.4084\n",
      "Epoch 22/50, Loss: 1.8226, Domain Loss: 1.3864, Class Loss: 0.4362\n",
      "Epoch 23/50, Loss: 1.7947, Domain Loss: 1.3864, Class Loss: 0.4083\n",
      "Epoch 24/50, Loss: 1.7787, Domain Loss: 1.3864, Class Loss: 0.3923\n",
      "Epoch 25/50, Loss: 1.8431, Domain Loss: 1.4608, Class Loss: 0.3822\n",
      "Epoch 26/50, Loss: 1.7843, Domain Loss: 1.3863, Class Loss: 0.3980\n",
      "Epoch 27/50, Loss: 1.7659, Domain Loss: 1.3863, Class Loss: 0.3796\n",
      "Epoch 28/50, Loss: 1.9034, Domain Loss: 1.5156, Class Loss: 0.3878\n",
      "Epoch 29/50, Loss: 1.8583, Domain Loss: 1.3863, Class Loss: 0.4720\n",
      "Epoch 30/50, Loss: 1.7906, Domain Loss: 1.3863, Class Loss: 0.4043\n",
      "Epoch 31/50, Loss: 1.7645, Domain Loss: 1.3863, Class Loss: 0.3782\n",
      "Epoch 32/50, Loss: 1.7622, Domain Loss: 1.3863, Class Loss: 0.3759\n",
      "Epoch 33/50, Loss: 1.7584, Domain Loss: 1.3863, Class Loss: 0.3721\n",
      "Epoch 34/50, Loss: 1.7182, Domain Loss: 1.3863, Class Loss: 0.3319\n",
      "Epoch 35/50, Loss: 1.7701, Domain Loss: 1.3863, Class Loss: 0.3838\n",
      "Epoch 36/50, Loss: 1.7363, Domain Loss: 1.3863, Class Loss: 0.3500\n",
      "Epoch 37/50, Loss: 1.7581, Domain Loss: 1.4068, Class Loss: 0.3513\n",
      "Epoch 38/50, Loss: 1.8693, Domain Loss: 1.3863, Class Loss: 0.4830\n",
      "Epoch 39/50, Loss: 1.7408, Domain Loss: 1.3863, Class Loss: 0.3545\n",
      "Epoch 40/50, Loss: 1.7021, Domain Loss: 1.3863, Class Loss: 0.3158\n",
      "Epoch 41/50, Loss: 1.6371, Domain Loss: 1.3863, Class Loss: 0.2508\n",
      "Epoch 42/50, Loss: 1.7578, Domain Loss: 1.4294, Class Loss: 0.3284\n",
      "Epoch 43/50, Loss: 1.6723, Domain Loss: 1.4132, Class Loss: 0.2591\n",
      "Epoch 44/50, Loss: 1.5660, Domain Loss: 1.3863, Class Loss: 0.1797\n",
      "Epoch 45/50, Loss: 1.5372, Domain Loss: 1.3877, Class Loss: 0.1496\n",
      "Epoch 46/50, Loss: 1.5391, Domain Loss: 1.3864, Class Loss: 0.1526\n",
      "Epoch 47/50, Loss: 1.6504, Domain Loss: 1.4284, Class Loss: 0.2220\n",
      "Epoch 48/50, Loss: 1.6670, Domain Loss: 1.3863, Class Loss: 0.2807\n",
      "Epoch 49/50, Loss: 1.4955, Domain Loss: 1.3863, Class Loss: 0.1091\n",
      "Epoch 50/50, Loss: 1.4873, Domain Loss: 1.3863, Class Loss: 0.1009\n",
      "67.21\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.4878, Domain Loss: 2.2096, Class Loss: 2.2782\n",
      "Epoch 2/50, Loss: 2.3171, Domain Loss: 1.4256, Class Loss: 0.8915\n",
      "Epoch 3/50, Loss: 1.8845, Domain Loss: 1.4082, Class Loss: 0.4763\n",
      "Epoch 4/50, Loss: 1.8927, Domain Loss: 1.3772, Class Loss: 0.5155\n",
      "Epoch 5/50, Loss: 1.9249, Domain Loss: 1.3652, Class Loss: 0.5597\n",
      "Epoch 6/50, Loss: 1.8475, Domain Loss: 1.3619, Class Loss: 0.4856\n",
      "Epoch 7/50, Loss: 1.8777, Domain Loss: 1.3837, Class Loss: 0.4940\n",
      "Epoch 8/50, Loss: 1.8861, Domain Loss: 1.3767, Class Loss: 0.5094\n",
      "Epoch 9/50, Loss: 1.8374, Domain Loss: 1.3580, Class Loss: 0.4794\n",
      "Epoch 10/50, Loss: 1.8316, Domain Loss: 1.3728, Class Loss: 0.4589\n",
      "Epoch 11/50, Loss: 1.9722, Domain Loss: 1.4929, Class Loss: 0.4793\n",
      "Epoch 12/50, Loss: 2.0564, Domain Loss: 1.4774, Class Loss: 0.5790\n",
      "Epoch 13/50, Loss: 1.9786, Domain Loss: 1.4321, Class Loss: 0.5465\n",
      "Epoch 14/50, Loss: 1.8089, Domain Loss: 1.3515, Class Loss: 0.4574\n",
      "Epoch 15/50, Loss: 1.9254, Domain Loss: 1.4824, Class Loss: 0.4431\n",
      "Epoch 16/50, Loss: 10.2155, Domain Loss: 9.1744, Class Loss: 1.0412\n",
      "Epoch 17/50, Loss: 9.1252, Domain Loss: 7.7827, Class Loss: 1.3425\n",
      "Epoch 18/50, Loss: 2.6085, Domain Loss: 1.5511, Class Loss: 1.0574\n",
      "Epoch 19/50, Loss: 2.3364, Domain Loss: 1.3872, Class Loss: 0.9491\n",
      "Epoch 20/50, Loss: 2.1397, Domain Loss: 1.3869, Class Loss: 0.7528\n",
      "Epoch 21/50, Loss: 2.0444, Domain Loss: 1.3868, Class Loss: 0.6576\n",
      "Epoch 22/50, Loss: 1.9576, Domain Loss: 1.3868, Class Loss: 0.5708\n",
      "Epoch 23/50, Loss: 1.9312, Domain Loss: 1.3867, Class Loss: 0.5445\n",
      "Epoch 24/50, Loss: 1.8632, Domain Loss: 1.3866, Class Loss: 0.4765\n",
      "Epoch 25/50, Loss: 1.8044, Domain Loss: 1.3866, Class Loss: 0.4178\n",
      "Epoch 26/50, Loss: 1.8163, Domain Loss: 1.3865, Class Loss: 0.4298\n",
      "Epoch 27/50, Loss: 1.8908, Domain Loss: 1.3865, Class Loss: 0.5043\n",
      "Epoch 28/50, Loss: 1.8635, Domain Loss: 1.3865, Class Loss: 0.4770\n",
      "Epoch 29/50, Loss: 1.8234, Domain Loss: 1.3864, Class Loss: 0.4370\n",
      "Epoch 30/50, Loss: 1.8217, Domain Loss: 1.3864, Class Loss: 0.4352\n",
      "Epoch 31/50, Loss: 1.8028, Domain Loss: 1.3864, Class Loss: 0.4164\n",
      "Epoch 32/50, Loss: 1.8036, Domain Loss: 1.3864, Class Loss: 0.4172\n",
      "Epoch 33/50, Loss: 1.8356, Domain Loss: 1.3864, Class Loss: 0.4493\n",
      "Epoch 34/50, Loss: 1.8226, Domain Loss: 1.3864, Class Loss: 0.4362\n",
      "Epoch 35/50, Loss: 1.7976, Domain Loss: 1.3863, Class Loss: 0.4113\n",
      "Epoch 36/50, Loss: 1.8016, Domain Loss: 1.3863, Class Loss: 0.4153\n",
      "Epoch 37/50, Loss: 1.8392, Domain Loss: 1.3863, Class Loss: 0.4528\n",
      "Epoch 38/50, Loss: 1.8127, Domain Loss: 1.3863, Class Loss: 0.4263\n",
      "Epoch 39/50, Loss: 1.8014, Domain Loss: 1.3863, Class Loss: 0.4151\n",
      "Epoch 40/50, Loss: 1.8163, Domain Loss: 1.3863, Class Loss: 0.4300\n",
      "Epoch 41/50, Loss: 1.7939, Domain Loss: 1.3863, Class Loss: 0.4076\n",
      "Epoch 42/50, Loss: 1.7706, Domain Loss: 1.3863, Class Loss: 0.3843\n",
      "Epoch 43/50, Loss: 1.8158, Domain Loss: 1.3863, Class Loss: 0.4295\n",
      "Epoch 44/50, Loss: 1.7767, Domain Loss: 1.3863, Class Loss: 0.3904\n",
      "Epoch 45/50, Loss: 1.7864, Domain Loss: 1.3863, Class Loss: 0.4001\n",
      "Epoch 46/50, Loss: 1.7909, Domain Loss: 1.3863, Class Loss: 0.4046\n",
      "Epoch 47/50, Loss: 1.8022, Domain Loss: 1.3863, Class Loss: 0.4159\n",
      "Epoch 48/50, Loss: 1.8031, Domain Loss: 1.3863, Class Loss: 0.4168\n",
      "Epoch 49/50, Loss: 1.7710, Domain Loss: 1.3863, Class Loss: 0.3847\n",
      "Epoch 50/50, Loss: 1.7562, Domain Loss: 1.3863, Class Loss: 0.3699\n",
      "62.71\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.5445, Domain Loss: 1.8135, Class Loss: 1.7310\n",
      "Epoch 2/50, Loss: 2.1521, Domain Loss: 1.4297, Class Loss: 0.7224\n",
      "Epoch 3/50, Loss: 1.9422, Domain Loss: 1.4189, Class Loss: 0.5233\n",
      "Epoch 4/50, Loss: 2.0090, Domain Loss: 1.3799, Class Loss: 0.6292\n",
      "Epoch 5/50, Loss: 1.8968, Domain Loss: 1.3718, Class Loss: 0.5249\n",
      "Epoch 6/50, Loss: 1.8198, Domain Loss: 1.3707, Class Loss: 0.4492\n",
      "Epoch 7/50, Loss: 1.8373, Domain Loss: 1.3629, Class Loss: 0.4744\n",
      "Epoch 8/50, Loss: 1.8252, Domain Loss: 1.3610, Class Loss: 0.4642\n",
      "Epoch 9/50, Loss: 1.8578, Domain Loss: 1.3545, Class Loss: 0.5033\n",
      "Epoch 10/50, Loss: 1.7790, Domain Loss: 1.3468, Class Loss: 0.4322\n",
      "Epoch 11/50, Loss: 1.8037, Domain Loss: 1.3453, Class Loss: 0.4585\n",
      "Epoch 12/50, Loss: 1.7965, Domain Loss: 1.3445, Class Loss: 0.4520\n",
      "Epoch 13/50, Loss: 1.7693, Domain Loss: 1.3502, Class Loss: 0.4190\n",
      "Epoch 14/50, Loss: 1.7515, Domain Loss: 1.3286, Class Loss: 0.4228\n",
      "Epoch 15/50, Loss: 1.7763, Domain Loss: 1.3329, Class Loss: 0.4434\n",
      "Epoch 16/50, Loss: 1.7504, Domain Loss: 1.3309, Class Loss: 0.4195\n",
      "Epoch 17/50, Loss: 1.7544, Domain Loss: 1.3357, Class Loss: 0.4188\n",
      "Epoch 18/50, Loss: 1.7720, Domain Loss: 1.3347, Class Loss: 0.4372\n",
      "Epoch 19/50, Loss: 1.7229, Domain Loss: 1.3241, Class Loss: 0.3988\n",
      "Epoch 20/50, Loss: 1.8157, Domain Loss: 1.3419, Class Loss: 0.4738\n",
      "Epoch 21/50, Loss: 1.7869, Domain Loss: 1.3683, Class Loss: 0.4186\n",
      "Epoch 22/50, Loss: 4.2649, Domain Loss: 1.6977, Class Loss: 2.5673\n",
      "Epoch 23/50, Loss: 2.2537, Domain Loss: 1.4346, Class Loss: 0.8191\n",
      "Epoch 24/50, Loss: 1.9025, Domain Loss: 1.3622, Class Loss: 0.5403\n",
      "Epoch 25/50, Loss: 1.8998, Domain Loss: 1.3592, Class Loss: 0.5406\n",
      "Epoch 26/50, Loss: 1.8483, Domain Loss: 1.3579, Class Loss: 0.4904\n",
      "Epoch 27/50, Loss: 1.8128, Domain Loss: 1.3554, Class Loss: 0.4574\n",
      "Epoch 28/50, Loss: 1.8500, Domain Loss: 1.3540, Class Loss: 0.4960\n",
      "Epoch 29/50, Loss: 1.8401, Domain Loss: 1.3539, Class Loss: 0.4862\n",
      "Epoch 30/50, Loss: 1.7979, Domain Loss: 1.3520, Class Loss: 0.4460\n",
      "Epoch 31/50, Loss: 1.7656, Domain Loss: 1.3508, Class Loss: 0.4148\n",
      "Epoch 32/50, Loss: 1.8142, Domain Loss: 1.3465, Class Loss: 0.4678\n",
      "Epoch 33/50, Loss: 1.7855, Domain Loss: 1.3430, Class Loss: 0.4425\n",
      "Epoch 34/50, Loss: 1.7948, Domain Loss: 1.3425, Class Loss: 0.4522\n",
      "Epoch 35/50, Loss: 1.7897, Domain Loss: 1.3430, Class Loss: 0.4467\n",
      "Epoch 36/50, Loss: 1.7957, Domain Loss: 1.3417, Class Loss: 0.4540\n",
      "Epoch 37/50, Loss: 1.7908, Domain Loss: 1.3431, Class Loss: 0.4477\n",
      "Epoch 38/50, Loss: 1.7814, Domain Loss: 1.3443, Class Loss: 0.4371\n",
      "Epoch 39/50, Loss: 1.7721, Domain Loss: 1.3393, Class Loss: 0.4327\n",
      "Epoch 40/50, Loss: 1.7812, Domain Loss: 1.3473, Class Loss: 0.4339\n",
      "Epoch 41/50, Loss: 1.7694, Domain Loss: 1.3427, Class Loss: 0.4267\n",
      "Epoch 42/50, Loss: 1.7613, Domain Loss: 1.3459, Class Loss: 0.4154\n",
      "Epoch 43/50, Loss: 1.7494, Domain Loss: 1.3449, Class Loss: 0.4045\n",
      "Epoch 44/50, Loss: 1.7995, Domain Loss: 1.3355, Class Loss: 0.4640\n",
      "Epoch 45/50, Loss: 1.8406, Domain Loss: 1.3358, Class Loss: 0.5048\n",
      "Epoch 46/50, Loss: 1.7736, Domain Loss: 1.3373, Class Loss: 0.4363\n",
      "Epoch 47/50, Loss: 1.7350, Domain Loss: 1.3274, Class Loss: 0.4076\n",
      "Epoch 48/50, Loss: 1.7525, Domain Loss: 1.3361, Class Loss: 0.4163\n",
      "Epoch 49/50, Loss: 1.7469, Domain Loss: 1.3338, Class Loss: 0.4131\n",
      "Epoch 50/50, Loss: 1.7815, Domain Loss: 1.3293, Class Loss: 0.4522\n",
      "63.79\n",
      "\n",
      "\n",
      "Source performance:\n",
      "81.14 81.17 80.66 80.41 \n",
      "Target performance:\n",
      "63.41 65.65 63.42 63.46 \n",
      "\n",
      "Per-class target performance: 99.83 49.72 49.43 54.69 \n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 1.7761, Discrepancy Loss: 0.0664\n",
      "Validation Loss: 1.2306\n",
      "Epoch [2/50], Class Loss: 1.1336, Discrepancy Loss: 0.0472\n",
      "Validation Loss: 1.1017\n",
      "Epoch [3/50], Class Loss: 0.9911, Discrepancy Loss: 0.0410\n",
      "Validation Loss: 1.4122\n",
      "Epoch [4/50], Class Loss: 1.0030, Discrepancy Loss: 0.0465\n",
      "Validation Loss: 1.2958\n",
      "Epoch [5/50], Class Loss: 0.9985, Discrepancy Loss: 0.0406\n",
      "Validation Loss: 0.9086\n",
      "Epoch [6/50], Class Loss: 0.9500, Discrepancy Loss: 0.0364\n",
      "Validation Loss: 1.3987\n",
      "Epoch [7/50], Class Loss: 0.8368, Discrepancy Loss: 0.0300\n",
      "Validation Loss: 1.2491\n",
      "Epoch [8/50], Class Loss: 0.6000, Discrepancy Loss: 0.0218\n",
      "Validation Loss: 1.7940\n",
      "Epoch [9/50], Class Loss: 0.7271, Discrepancy Loss: 0.0154\n",
      "Validation Loss: 0.7969\n",
      "Epoch [10/50], Class Loss: 0.2719, Discrepancy Loss: 0.0128\n",
      "Validation Loss: 0.1239\n",
      "Epoch [11/50], Class Loss: 0.0443, Discrepancy Loss: 0.0100\n",
      "Validation Loss: 0.0926\n",
      "Epoch [12/50], Class Loss: 0.0377, Discrepancy Loss: 0.0074\n",
      "Validation Loss: 0.1183\n",
      "Epoch [13/50], Class Loss: 0.0329, Discrepancy Loss: 0.0059\n",
      "Validation Loss: 0.0643\n",
      "Epoch [14/50], Class Loss: 0.0326, Discrepancy Loss: 0.0058\n",
      "Validation Loss: 0.1240\n",
      "Epoch [15/50], Class Loss: 0.0225, Discrepancy Loss: 0.0052\n",
      "Validation Loss: 0.0655\n",
      "Epoch [16/50], Class Loss: 0.0161, Discrepancy Loss: 0.0055\n",
      "Validation Loss: 0.0733\n",
      "Epoch [17/50], Class Loss: 0.0175, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.1113\n",
      "Epoch [18/50], Class Loss: 0.0146, Discrepancy Loss: 0.0061\n",
      "Validation Loss: 0.1447\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 97.66%, Precision: 97.67%, Recall: 97.58%, F1 Score: 97.59%\n",
      "Target Domain Performance - Accuracy: 64.69%, Precision: 71.69%, Recall: 65.79%, F1 Score: 63.30%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 2.2658, Discrepancy Loss: 0.1026\n",
      "Validation Loss: 1.2012\n",
      "Epoch [2/50], Class Loss: 1.1111, Discrepancy Loss: 0.0462\n",
      "Validation Loss: 1.2476\n",
      "Epoch [3/50], Class Loss: 0.9641, Discrepancy Loss: 0.0481\n",
      "Validation Loss: 0.8972\n",
      "Epoch [4/50], Class Loss: 0.9622, Discrepancy Loss: 0.0377\n",
      "Validation Loss: 0.8471\n",
      "Epoch [5/50], Class Loss: 0.9256, Discrepancy Loss: 0.0356\n",
      "Validation Loss: 0.9010\n",
      "Epoch [6/50], Class Loss: 0.8712, Discrepancy Loss: 0.0459\n",
      "Validation Loss: 1.0287\n",
      "Epoch [7/50], Class Loss: 0.8067, Discrepancy Loss: 0.0370\n",
      "Validation Loss: 0.8041\n",
      "Epoch [8/50], Class Loss: 0.6593, Discrepancy Loss: 0.0356\n",
      "Validation Loss: 0.7613\n",
      "Epoch [9/50], Class Loss: 0.5758, Discrepancy Loss: 0.0210\n",
      "Validation Loss: 0.4019\n",
      "Epoch [10/50], Class Loss: 0.3734, Discrepancy Loss: 0.0152\n",
      "Validation Loss: 0.2217\n",
      "Epoch [11/50], Class Loss: 0.0591, Discrepancy Loss: 0.0089\n",
      "Validation Loss: 0.0964\n",
      "Epoch [12/50], Class Loss: 0.0407, Discrepancy Loss: 0.0068\n",
      "Validation Loss: 0.1474\n",
      "Epoch [13/50], Class Loss: 0.0318, Discrepancy Loss: 0.0061\n",
      "Validation Loss: 0.0983\n",
      "Epoch [14/50], Class Loss: 0.0396, Discrepancy Loss: 0.0063\n",
      "Validation Loss: 0.0983\n",
      "Epoch [15/50], Class Loss: 0.0280, Discrepancy Loss: 0.0050\n",
      "Validation Loss: 0.1078\n",
      "Epoch [16/50], Class Loss: 0.0315, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.0868\n",
      "Epoch [17/50], Class Loss: 0.0227, Discrepancy Loss: 0.0055\n",
      "Validation Loss: 0.0932\n",
      "Epoch [18/50], Class Loss: 0.0262, Discrepancy Loss: 0.0062\n",
      "Validation Loss: 0.0936\n",
      "Epoch [19/50], Class Loss: 0.0167, Discrepancy Loss: 0.0059\n",
      "Validation Loss: 0.1001\n",
      "Epoch [20/50], Class Loss: 0.0211, Discrepancy Loss: 0.0059\n",
      "Validation Loss: 0.2603\n",
      "Epoch [21/50], Class Loss: 0.0146, Discrepancy Loss: 0.0058\n",
      "Validation Loss: 0.0942\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.68%, Precision: 98.64%, Recall: 98.65%, F1 Score: 98.64%\n",
      "Target Domain Performance - Accuracy: 54.38%, Precision: 65.15%, Recall: 55.83%, F1 Score: 50.06%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 1.9595, Discrepancy Loss: 0.0730\n",
      "Validation Loss: 1.0417\n",
      "Epoch [2/50], Class Loss: 1.0178, Discrepancy Loss: 0.0371\n",
      "Validation Loss: 0.9324\n",
      "Epoch [3/50], Class Loss: 1.0009, Discrepancy Loss: 0.0376\n",
      "Validation Loss: 0.9567\n",
      "Epoch [4/50], Class Loss: 0.9301, Discrepancy Loss: 0.0273\n",
      "Validation Loss: 0.9566\n",
      "Epoch [5/50], Class Loss: 0.8987, Discrepancy Loss: 0.0350\n",
      "Validation Loss: 0.8768\n",
      "Epoch [6/50], Class Loss: 0.8227, Discrepancy Loss: 0.0260\n",
      "Validation Loss: 0.7127\n",
      "Epoch [7/50], Class Loss: 0.5713, Discrepancy Loss: 0.0213\n",
      "Validation Loss: 0.3531\n",
      "Epoch [8/50], Class Loss: 0.5509, Discrepancy Loss: 0.0176\n",
      "Validation Loss: 0.5617\n",
      "Epoch [9/50], Class Loss: 0.3384, Discrepancy Loss: 0.0217\n",
      "Validation Loss: 1.1570\n",
      "Epoch [10/50], Class Loss: 0.2300, Discrepancy Loss: 0.0153\n",
      "Validation Loss: 1.1366\n",
      "Epoch [11/50], Class Loss: 0.1052, Discrepancy Loss: 0.0140\n",
      "Validation Loss: 0.0750\n",
      "Epoch [12/50], Class Loss: 0.0286, Discrepancy Loss: 0.0092\n",
      "Validation Loss: 0.0842\n",
      "Epoch [13/50], Class Loss: 0.0304, Discrepancy Loss: 0.0080\n",
      "Validation Loss: 0.0764\n",
      "Epoch [14/50], Class Loss: 0.0236, Discrepancy Loss: 0.0064\n",
      "Validation Loss: 0.0802\n",
      "Epoch [15/50], Class Loss: 0.0264, Discrepancy Loss: 0.0064\n",
      "Validation Loss: 0.1257\n",
      "Epoch [16/50], Class Loss: 0.0242, Discrepancy Loss: 0.0061\n",
      "Validation Loss: 0.0811\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.68%, Precision: 98.64%, Recall: 98.64%, F1 Score: 98.64%\n",
      "Target Domain Performance - Accuracy: 55.46%, Precision: 65.90%, Recall: 56.87%, F1 Score: 51.52%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 1.9099, Discrepancy Loss: 0.0702\n",
      "Validation Loss: 1.1090\n",
      "Epoch [2/50], Class Loss: 1.1777, Discrepancy Loss: 0.0452\n",
      "Validation Loss: 1.1569\n",
      "Epoch [3/50], Class Loss: 0.9855, Discrepancy Loss: 0.0434\n",
      "Validation Loss: 0.9911\n",
      "Epoch [4/50], Class Loss: 1.0486, Discrepancy Loss: 0.0600\n",
      "Validation Loss: 1.0025\n",
      "Epoch [5/50], Class Loss: 0.9501, Discrepancy Loss: 0.0309\n",
      "Validation Loss: 0.8709\n",
      "Epoch [6/50], Class Loss: 0.9811, Discrepancy Loss: 0.0438\n",
      "Validation Loss: 0.9341\n",
      "Epoch [7/50], Class Loss: 0.8947, Discrepancy Loss: 0.0485\n",
      "Validation Loss: 0.8789\n",
      "Epoch [8/50], Class Loss: 0.7598, Discrepancy Loss: 0.0319\n",
      "Validation Loss: 0.8249\n",
      "Epoch [9/50], Class Loss: 0.5590, Discrepancy Loss: 0.0235\n",
      "Validation Loss: 0.4098\n",
      "Epoch [10/50], Class Loss: 0.5872, Discrepancy Loss: 0.0204\n",
      "Validation Loss: 0.5575\n",
      "Epoch [11/50], Class Loss: 0.1121, Discrepancy Loss: 0.0116\n",
      "Validation Loss: 0.1078\n",
      "Epoch [12/50], Class Loss: 0.0610, Discrepancy Loss: 0.0075\n",
      "Validation Loss: 0.1012\n",
      "Epoch [13/50], Class Loss: 0.0503, Discrepancy Loss: 0.0065\n",
      "Validation Loss: 0.1031\n",
      "Epoch [14/50], Class Loss: 0.0407, Discrepancy Loss: 0.0060\n",
      "Validation Loss: 0.1319\n",
      "Epoch [15/50], Class Loss: 0.0413, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.1134\n",
      "Epoch [16/50], Class Loss: 0.0335, Discrepancy Loss: 0.0055\n",
      "Validation Loss: 0.0909\n",
      "Epoch [17/50], Class Loss: 0.0303, Discrepancy Loss: 0.0060\n",
      "Validation Loss: 0.0964\n",
      "Epoch [18/50], Class Loss: 0.0210, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.1391\n",
      "Epoch [19/50], Class Loss: 0.0199, Discrepancy Loss: 0.0054\n",
      "Validation Loss: 0.0981\n",
      "Epoch [20/50], Class Loss: 0.0181, Discrepancy Loss: 0.0056\n",
      "Validation Loss: 0.1007\n",
      "Epoch [21/50], Class Loss: 0.0088, Discrepancy Loss: 0.0054\n",
      "Validation Loss: 0.1014\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.38%, Precision: 98.33%, Recall: 98.33%, F1 Score: 98.33%\n",
      "Target Domain Performance - Accuracy: 54.50%, Precision: 65.61%, Recall: 55.94%, F1 Score: 49.97%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 2.0952, Discrepancy Loss: 0.0648\n",
      "Validation Loss: 1.0418\n",
      "Epoch [2/50], Class Loss: 1.2119, Discrepancy Loss: 0.0468\n",
      "Validation Loss: 0.9784\n",
      "Epoch [3/50], Class Loss: 1.1194, Discrepancy Loss: 0.0375\n",
      "Validation Loss: 1.2374\n",
      "Epoch [4/50], Class Loss: 1.0202, Discrepancy Loss: 0.0290\n",
      "Validation Loss: 0.9491\n",
      "Epoch [5/50], Class Loss: 0.9201, Discrepancy Loss: 0.0317\n",
      "Validation Loss: 0.8677\n",
      "Epoch [6/50], Class Loss: 0.9962, Discrepancy Loss: 0.0392\n",
      "Validation Loss: 1.2582\n",
      "Epoch [7/50], Class Loss: 1.1558, Discrepancy Loss: 0.0313\n",
      "Validation Loss: 0.9614\n",
      "Epoch [8/50], Class Loss: 0.8642, Discrepancy Loss: 0.0325\n",
      "Validation Loss: 1.2367\n",
      "Epoch [9/50], Class Loss: 0.8383, Discrepancy Loss: 0.0296\n",
      "Validation Loss: 1.5278\n",
      "Epoch [10/50], Class Loss: 1.0530, Discrepancy Loss: 0.0252\n",
      "Validation Loss: 0.3317\n",
      "Epoch [11/50], Class Loss: 0.1428, Discrepancy Loss: 0.0142\n",
      "Validation Loss: 0.1848\n",
      "Epoch [12/50], Class Loss: 0.0849, Discrepancy Loss: 0.0096\n",
      "Validation Loss: 0.1211\n",
      "Epoch [13/50], Class Loss: 0.0681, Discrepancy Loss: 0.0079\n",
      "Validation Loss: 0.1325\n",
      "Epoch [14/50], Class Loss: 0.0508, Discrepancy Loss: 0.0075\n",
      "Validation Loss: 0.1107\n",
      "Epoch [15/50], Class Loss: 0.0381, Discrepancy Loss: 0.0066\n",
      "Validation Loss: 0.1655\n",
      "Epoch [16/50], Class Loss: 0.0321, Discrepancy Loss: 0.0067\n",
      "Validation Loss: 0.0998\n",
      "Epoch [17/50], Class Loss: 0.0191, Discrepancy Loss: 0.0066\n",
      "Validation Loss: 0.2185\n",
      "Epoch [18/50], Class Loss: 0.0176, Discrepancy Loss: 0.0067\n",
      "Validation Loss: 0.1563\n",
      "Epoch [19/50], Class Loss: 0.0122, Discrepancy Loss: 0.0073\n",
      "Validation Loss: 0.1092\n",
      "Epoch [20/50], Class Loss: 0.0143, Discrepancy Loss: 0.0076\n",
      "Validation Loss: 0.1087\n",
      "Epoch [21/50], Class Loss: 0.0057, Discrepancy Loss: 0.0076\n",
      "Validation Loss: 0.1122\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.02%, Precision: 97.95%, Recall: 97.95%, F1 Score: 97.95%\n",
      "Target Domain Performance - Accuracy: 55.58%, Precision: 65.76%, Recall: 57.01%, F1 Score: 51.64%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 1.7767, Discrepancy Loss: 0.0682\n",
      "Validation Loss: 1.8375\n",
      "Epoch [2/50], Class Loss: 1.0991, Discrepancy Loss: 0.0335\n",
      "Validation Loss: 1.1782\n",
      "Epoch [3/50], Class Loss: 0.9693, Discrepancy Loss: 0.0312\n",
      "Validation Loss: 1.0206\n",
      "Epoch [4/50], Class Loss: 0.9749, Discrepancy Loss: 0.0282\n",
      "Validation Loss: 1.2365\n",
      "Epoch [5/50], Class Loss: 0.9141, Discrepancy Loss: 0.0237\n",
      "Validation Loss: 0.8685\n",
      "Epoch [6/50], Class Loss: 0.8343, Discrepancy Loss: 0.0246\n",
      "Validation Loss: 0.9062\n",
      "Epoch [7/50], Class Loss: 0.9871, Discrepancy Loss: 0.0332\n",
      "Validation Loss: 0.7561\n",
      "Epoch [8/50], Class Loss: 0.6938, Discrepancy Loss: 0.0258\n",
      "Validation Loss: 0.5098\n",
      "Epoch [9/50], Class Loss: 0.4785, Discrepancy Loss: 0.0150\n",
      "Validation Loss: 0.2140\n",
      "Epoch [10/50], Class Loss: 0.7155, Discrepancy Loss: 0.0148\n",
      "Validation Loss: 0.1519\n",
      "Epoch [11/50], Class Loss: 0.0597, Discrepancy Loss: 0.0099\n",
      "Validation Loss: 0.1035\n",
      "Epoch [12/50], Class Loss: 0.0519, Discrepancy Loss: 0.0069\n",
      "Validation Loss: 0.1216\n",
      "Epoch [13/50], Class Loss: 0.0502, Discrepancy Loss: 0.0059\n",
      "Validation Loss: 0.1327\n",
      "Epoch [14/50], Class Loss: 0.0312, Discrepancy Loss: 0.0061\n",
      "Validation Loss: 0.1035\n",
      "Epoch [15/50], Class Loss: 0.0329, Discrepancy Loss: 0.0060\n",
      "Validation Loss: 0.1094\n",
      "Epoch [16/50], Class Loss: 0.0239, Discrepancy Loss: 0.0054\n",
      "Validation Loss: 0.1122\n",
      "Epoch [17/50], Class Loss: 0.0256, Discrepancy Loss: 0.0053\n",
      "Validation Loss: 0.1224\n",
      "Epoch [18/50], Class Loss: 0.0181, Discrepancy Loss: 0.0058\n",
      "Validation Loss: 0.1305\n",
      "Epoch [19/50], Class Loss: 0.0176, Discrepancy Loss: 0.0057\n",
      "Validation Loss: 0.1188\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.44%, Precision: 98.39%, Recall: 98.40%, F1 Score: 98.39%\n",
      "Target Domain Performance - Accuracy: 56.24%, Precision: 66.19%, Recall: 57.65%, F1 Score: 52.55%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 1.8139, Discrepancy Loss: 0.0675\n",
      "Validation Loss: 1.9652\n",
      "Epoch [2/50], Class Loss: 1.1095, Discrepancy Loss: 0.0276\n",
      "Validation Loss: 1.2005\n",
      "Epoch [3/50], Class Loss: 1.0280, Discrepancy Loss: 0.0289\n",
      "Validation Loss: 1.0914\n",
      "Epoch [4/50], Class Loss: 0.9125, Discrepancy Loss: 0.0343\n",
      "Validation Loss: 0.8270\n",
      "Epoch [5/50], Class Loss: 1.0278, Discrepancy Loss: 0.0355\n",
      "Validation Loss: 0.8200\n",
      "Epoch [6/50], Class Loss: 0.7474, Discrepancy Loss: 0.0255\n",
      "Validation Loss: 0.5449\n",
      "Epoch [7/50], Class Loss: 0.5342, Discrepancy Loss: 0.0171\n",
      "Validation Loss: 0.3263\n",
      "Epoch [8/50], Class Loss: 0.1966, Discrepancy Loss: 0.0116\n",
      "Validation Loss: 1.1453\n",
      "Epoch [9/50], Class Loss: 0.3187, Discrepancy Loss: 0.0133\n",
      "Validation Loss: 0.2934\n",
      "Epoch [10/50], Class Loss: 0.1888, Discrepancy Loss: 0.0143\n",
      "Validation Loss: 0.1318\n",
      "Epoch [11/50], Class Loss: 0.0304, Discrepancy Loss: 0.0107\n",
      "Validation Loss: 0.0815\n",
      "Epoch [12/50], Class Loss: 0.0189, Discrepancy Loss: 0.0084\n",
      "Validation Loss: 0.0829\n",
      "Epoch [13/50], Class Loss: 0.0243, Discrepancy Loss: 0.0073\n",
      "Validation Loss: 0.1535\n",
      "Epoch [14/50], Class Loss: 0.0300, Discrepancy Loss: 0.0062\n",
      "Validation Loss: 0.1021\n",
      "Epoch [15/50], Class Loss: 0.0161, Discrepancy Loss: 0.0069\n",
      "Validation Loss: 0.0750\n",
      "Epoch [16/50], Class Loss: 0.0136, Discrepancy Loss: 0.0059\n",
      "Validation Loss: 0.0899\n",
      "Epoch [17/50], Class Loss: 0.0121, Discrepancy Loss: 0.0058\n",
      "Validation Loss: 0.0971\n",
      "Epoch [18/50], Class Loss: 0.0286, Discrepancy Loss: 0.0068\n",
      "Validation Loss: 0.1232\n",
      "Epoch [19/50], Class Loss: 0.0206, Discrepancy Loss: 0.0064\n",
      "Validation Loss: 0.1116\n",
      "Epoch [20/50], Class Loss: 0.0104, Discrepancy Loss: 0.0063\n",
      "Validation Loss: 0.0828\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.74%, Precision: 98.71%, Recall: 98.72%, F1 Score: 98.71%\n",
      "Target Domain Performance - Accuracy: 59.89%, Precision: 68.97%, Recall: 61.16%, F1 Score: 57.32%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 2.0605, Discrepancy Loss: 0.0808\n",
      "Validation Loss: 1.0639\n",
      "Epoch [2/50], Class Loss: 1.0295, Discrepancy Loss: 0.0340\n",
      "Validation Loss: 0.9445\n",
      "Epoch [3/50], Class Loss: 0.9403, Discrepancy Loss: 0.0409\n",
      "Validation Loss: 0.9924\n",
      "Epoch [4/50], Class Loss: 0.9155, Discrepancy Loss: 0.0315\n",
      "Validation Loss: 1.4517\n",
      "Epoch [5/50], Class Loss: 0.9351, Discrepancy Loss: 0.0403\n",
      "Validation Loss: 1.2370\n",
      "Epoch [6/50], Class Loss: 0.9033, Discrepancy Loss: 0.0351\n",
      "Validation Loss: 1.1025\n",
      "Epoch [7/50], Class Loss: 0.7171, Discrepancy Loss: 0.0245\n",
      "Validation Loss: 2.9526\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 66.43%, Precision: 69.04%, Recall: 65.22%, F1 Score: 63.81%\n",
      "Target Domain Performance - Accuracy: 46.46%, Precision: 36.53%, Recall: 48.14%, F1 Score: 37.63%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.9630, Discrepancy Loss: 0.0873\n",
      "Validation Loss: 1.4198\n",
      "Epoch [2/50], Class Loss: 1.0267, Discrepancy Loss: 0.0277\n",
      "Validation Loss: 0.9777\n",
      "Epoch [3/50], Class Loss: 0.9992, Discrepancy Loss: 0.0339\n",
      "Validation Loss: 0.9576\n",
      "Epoch [4/50], Class Loss: 0.9687, Discrepancy Loss: 0.0415\n",
      "Validation Loss: 0.9507\n",
      "Epoch [5/50], Class Loss: 0.8928, Discrepancy Loss: 0.0307\n",
      "Validation Loss: 0.9505\n",
      "Epoch [6/50], Class Loss: 0.9195, Discrepancy Loss: 0.0457\n",
      "Validation Loss: 0.8664\n",
      "Epoch [7/50], Class Loss: 0.8762, Discrepancy Loss: 0.0338\n",
      "Validation Loss: 1.6689\n",
      "Epoch [8/50], Class Loss: 0.5972, Discrepancy Loss: 0.0231\n",
      "Validation Loss: 0.3324\n",
      "Epoch [9/50], Class Loss: 0.4927, Discrepancy Loss: 0.0165\n",
      "Validation Loss: 0.1807\n",
      "Epoch [10/50], Class Loss: 0.3487, Discrepancy Loss: 0.0154\n",
      "Validation Loss: 0.1724\n",
      "Epoch [11/50], Class Loss: 0.0461, Discrepancy Loss: 0.0102\n",
      "Validation Loss: 0.0935\n",
      "Epoch [12/50], Class Loss: 0.0329, Discrepancy Loss: 0.0074\n",
      "Validation Loss: 0.1345\n",
      "Epoch [13/50], Class Loss: 0.0291, Discrepancy Loss: 0.0053\n",
      "Validation Loss: 0.1573\n",
      "Epoch [14/50], Class Loss: 0.0232, Discrepancy Loss: 0.0052\n",
      "Validation Loss: 0.1784\n",
      "Epoch [15/50], Class Loss: 0.0216, Discrepancy Loss: 0.0048\n",
      "Validation Loss: 0.0867\n",
      "Epoch [16/50], Class Loss: 0.0169, Discrepancy Loss: 0.0049\n",
      "Validation Loss: 0.1104\n",
      "Epoch [17/50], Class Loss: 0.0227, Discrepancy Loss: 0.0048\n",
      "Validation Loss: 0.0924\n",
      "Epoch [18/50], Class Loss: 0.0115, Discrepancy Loss: 0.0048\n",
      "Validation Loss: 0.1012\n",
      "Epoch [19/50], Class Loss: 0.0158, Discrepancy Loss: 0.0049\n",
      "Validation Loss: 0.1088\n",
      "Epoch [20/50], Class Loss: 0.0131, Discrepancy Loss: 0.0042\n",
      "Validation Loss: 0.1028\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.74%, Precision: 98.70%, Recall: 98.71%, F1 Score: 98.70%\n",
      "Target Domain Performance - Accuracy: 54.32%, Precision: 65.13%, Recall: 55.78%, F1 Score: 49.88%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 2.0046, Discrepancy Loss: 0.0725\n",
      "Validation Loss: 1.0669\n",
      "Epoch [2/50], Class Loss: 1.1137, Discrepancy Loss: 0.0372\n",
      "Validation Loss: 0.9674\n",
      "Epoch [3/50], Class Loss: 0.9492, Discrepancy Loss: 0.0291\n",
      "Validation Loss: 1.0068\n",
      "Epoch [4/50], Class Loss: 0.9872, Discrepancy Loss: 0.0375\n",
      "Validation Loss: 0.9905\n",
      "Epoch [5/50], Class Loss: 0.9166, Discrepancy Loss: 0.0318\n",
      "Validation Loss: 1.1502\n",
      "Epoch [6/50], Class Loss: 0.9410, Discrepancy Loss: 0.0523\n",
      "Validation Loss: 0.8450\n",
      "Epoch [7/50], Class Loss: 0.8093, Discrepancy Loss: 0.0517\n",
      "Validation Loss: 2.1026\n",
      "Epoch [8/50], Class Loss: 0.6808, Discrepancy Loss: 0.0251\n",
      "Validation Loss: 0.3966\n",
      "Epoch [9/50], Class Loss: 0.4256, Discrepancy Loss: 0.0197\n",
      "Validation Loss: 1.3965\n",
      "Epoch [10/50], Class Loss: 0.4885, Discrepancy Loss: 0.0205\n",
      "Validation Loss: 0.1327\n",
      "Epoch [11/50], Class Loss: 0.0476, Discrepancy Loss: 0.0095\n",
      "Validation Loss: 0.0829\n",
      "Epoch [12/50], Class Loss: 0.0322, Discrepancy Loss: 0.0070\n",
      "Validation Loss: 0.0761\n",
      "Epoch [13/50], Class Loss: 0.0290, Discrepancy Loss: 0.0055\n",
      "Validation Loss: 0.0875\n",
      "Epoch [14/50], Class Loss: 0.0239, Discrepancy Loss: 0.0049\n",
      "Validation Loss: 0.0809\n",
      "Epoch [15/50], Class Loss: 0.0235, Discrepancy Loss: 0.0052\n",
      "Validation Loss: 0.0822\n",
      "Epoch [16/50], Class Loss: 0.0216, Discrepancy Loss: 0.0048\n",
      "Validation Loss: 0.0876\n",
      "Epoch [17/50], Class Loss: 0.0246, Discrepancy Loss: 0.0047\n",
      "Validation Loss: 0.0854\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 98.44%, Precision: 98.39%, Recall: 98.40%, F1 Score: 98.40%\n",
      "Target Domain Performance - Accuracy: 56.65%, Precision: 66.83%, Recall: 58.04%, F1 Score: 52.98%\n",
      "\n",
      "Source performance: 95.22% 95.45% 95.06% 94.92%\n",
      "Target performance: 55.82% 63.78% 57.22% 51.68%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.05%\n",
      "qpsk: 15.06%\n",
      "16qam: 15.66%\n",
      "16apsk: 99.12%\n",
      "SNR level: 14\n",
      "STAR\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 2.4276, Discrepancy Loss: 0.1134\n",
      "Epoch [2/50], Class Loss: 0.9719, Discrepancy Loss: 0.1013\n",
      "Epoch [3/50], Class Loss: 0.8946, Discrepancy Loss: 0.1027\n",
      "Epoch [4/50], Class Loss: 0.8708, Discrepancy Loss: 0.1121\n",
      "Epoch [5/50], Class Loss: 0.7992, Discrepancy Loss: 0.1183\n",
      "Epoch [6/50], Class Loss: 0.7598, Discrepancy Loss: 0.1197\n",
      "Epoch [7/50], Class Loss: 0.7230, Discrepancy Loss: 0.1072\n",
      "Epoch [8/50], Class Loss: 0.6589, Discrepancy Loss: 0.0982\n",
      "Epoch [9/50], Class Loss: 0.6441, Discrepancy Loss: 0.1064\n",
      "Epoch [10/50], Class Loss: 0.5750, Discrepancy Loss: 0.0953\n",
      "Epoch [11/50], Class Loss: 0.5616, Discrepancy Loss: 0.0935\n",
      "Epoch [12/50], Class Loss: 0.4851, Discrepancy Loss: 0.0923\n",
      "Epoch [13/50], Class Loss: 0.4159, Discrepancy Loss: 0.0829\n",
      "Epoch [14/50], Class Loss: 0.3117, Discrepancy Loss: 0.0768\n",
      "Epoch [15/50], Class Loss: 0.2483, Discrepancy Loss: 0.0748\n",
      "Epoch [16/50], Class Loss: 0.1895, Discrepancy Loss: 0.0756\n",
      "Epoch [17/50], Class Loss: 0.1927, Discrepancy Loss: 0.0696\n",
      "Epoch [18/50], Class Loss: 0.1867, Discrepancy Loss: 0.0755\n",
      "Epoch [19/50], Class Loss: 0.1549, Discrepancy Loss: 0.0763\n",
      "Epoch [20/50], Class Loss: 0.1304, Discrepancy Loss: 0.0726\n",
      "Epoch [21/50], Class Loss: 0.1081, Discrepancy Loss: 0.0624\n",
      "Epoch [22/50], Class Loss: 0.0962, Discrepancy Loss: 0.0651\n",
      "Epoch [23/50], Class Loss: 0.1218, Discrepancy Loss: 0.0659\n",
      "Epoch [24/50], Class Loss: 0.1111, Discrepancy Loss: 0.0698\n",
      "Epoch [25/50], Class Loss: 0.0967, Discrepancy Loss: 0.0630\n",
      "Epoch [26/50], Class Loss: 0.1009, Discrepancy Loss: 0.0697\n",
      "Epoch [27/50], Class Loss: 0.0913, Discrepancy Loss: 0.0634\n",
      "Epoch [28/50], Class Loss: 0.1065, Discrepancy Loss: 0.0718\n",
      "Epoch [29/50], Class Loss: 0.0960, Discrepancy Loss: 0.0649\n",
      "Epoch [30/50], Class Loss: 0.0842, Discrepancy Loss: 0.0656\n",
      "Epoch [31/50], Class Loss: 0.1051, Discrepancy Loss: 0.0624\n",
      "Epoch [32/50], Class Loss: 0.1016, Discrepancy Loss: 0.0624\n",
      "Epoch [33/50], Class Loss: 0.0830, Discrepancy Loss: 0.0679\n",
      "Epoch [34/50], Class Loss: 0.0798, Discrepancy Loss: 0.0651\n",
      "Epoch [35/50], Class Loss: 0.0987, Discrepancy Loss: 0.0702\n",
      "Epoch [36/50], Class Loss: 0.1152, Discrepancy Loss: 0.0674\n",
      "Epoch [37/50], Class Loss: 0.0873, Discrepancy Loss: 0.0692\n",
      "Epoch [38/50], Class Loss: 0.0811, Discrepancy Loss: 0.0656\n",
      "Epoch [39/50], Class Loss: 0.0791, Discrepancy Loss: 0.0691\n",
      "Epoch [40/50], Class Loss: 0.0727, Discrepancy Loss: 0.0737\n",
      "Epoch [41/50], Class Loss: 0.0981, Discrepancy Loss: 0.0663\n",
      "Epoch [42/50], Class Loss: 0.1174, Discrepancy Loss: 0.0640\n",
      "Epoch [43/50], Class Loss: 0.0814, Discrepancy Loss: 0.0607\n",
      "Epoch [44/50], Class Loss: 0.0841, Discrepancy Loss: 0.0642\n",
      "Epoch [45/50], Class Loss: 0.0834, Discrepancy Loss: 0.0620\n",
      "Epoch [46/50], Class Loss: 0.0653, Discrepancy Loss: 0.0674\n",
      "Epoch [47/50], Class Loss: 0.0861, Discrepancy Loss: 0.0714\n",
      "Epoch [48/50], Class Loss: 0.0943, Discrepancy Loss: 0.0652\n",
      "Epoch [49/50], Class Loss: 0.0851, Discrepancy Loss: 0.0645\n",
      "Epoch [50/50], Class Loss: 0.0968, Discrepancy Loss: 0.0700\n",
      "Source Domain Performance - Accuracy: 87.59%, Precision: 88.59%, Recall: 87.13%, F1 Score: 86.90%\n",
      "Target Domain Performance - Accuracy: 71.34%, Precision: 74.82%, Recall: 71.96%, F1 Score: 71.38%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 2.7807, Discrepancy Loss: 0.1093\n",
      "Epoch [2/50], Class Loss: 1.1855, Discrepancy Loss: 0.1149\n",
      "Epoch [3/50], Class Loss: 0.8718, Discrepancy Loss: 0.1162\n",
      "Epoch [4/50], Class Loss: 0.8690, Discrepancy Loss: 0.1078\n",
      "Epoch [5/50], Class Loss: 0.7612, Discrepancy Loss: 0.1069\n",
      "Epoch [6/50], Class Loss: 0.7557, Discrepancy Loss: 0.0940\n",
      "Epoch [7/50], Class Loss: 0.7295, Discrepancy Loss: 0.0998\n",
      "Epoch [8/50], Class Loss: 0.7263, Discrepancy Loss: 0.0910\n",
      "Epoch [9/50], Class Loss: 0.6389, Discrepancy Loss: 0.0915\n",
      "Epoch [10/50], Class Loss: 0.5985, Discrepancy Loss: 0.0910\n",
      "Epoch [11/50], Class Loss: 0.5005, Discrepancy Loss: 0.0827\n",
      "Epoch [12/50], Class Loss: 0.4274, Discrepancy Loss: 0.0765\n",
      "Epoch [13/50], Class Loss: 0.3392, Discrepancy Loss: 0.0675\n",
      "Epoch [14/50], Class Loss: 0.2745, Discrepancy Loss: 0.0645\n",
      "Epoch [15/50], Class Loss: 0.2466, Discrepancy Loss: 0.0645\n",
      "Epoch [16/50], Class Loss: 0.2222, Discrepancy Loss: 0.0586\n",
      "Epoch [17/50], Class Loss: 0.1951, Discrepancy Loss: 0.0497\n",
      "Epoch [18/50], Class Loss: 0.1721, Discrepancy Loss: 0.0565\n",
      "Epoch [19/50], Class Loss: 0.1510, Discrepancy Loss: 0.0528\n",
      "Epoch [20/50], Class Loss: 0.1225, Discrepancy Loss: 0.0563\n",
      "Epoch [21/50], Class Loss: 0.0933, Discrepancy Loss: 0.0522\n",
      "Epoch [22/50], Class Loss: 0.0902, Discrepancy Loss: 0.0543\n",
      "Epoch [23/50], Class Loss: 0.0906, Discrepancy Loss: 0.0562\n",
      "Epoch [24/50], Class Loss: 0.0681, Discrepancy Loss: 0.0549\n",
      "Epoch [25/50], Class Loss: 0.0767, Discrepancy Loss: 0.0615\n",
      "Epoch [26/50], Class Loss: 0.0685, Discrepancy Loss: 0.0647\n",
      "Epoch [27/50], Class Loss: 0.0819, Discrepancy Loss: 0.0610\n",
      "Epoch [28/50], Class Loss: 0.0852, Discrepancy Loss: 0.0626\n",
      "Epoch [29/50], Class Loss: 0.0721, Discrepancy Loss: 0.0647\n",
      "Epoch [30/50], Class Loss: 0.0789, Discrepancy Loss: 0.0715\n",
      "Epoch [31/50], Class Loss: 0.0763, Discrepancy Loss: 0.0703\n",
      "Epoch [32/50], Class Loss: 0.0682, Discrepancy Loss: 0.0677\n",
      "Epoch [33/50], Class Loss: 0.0734, Discrepancy Loss: 0.0703\n",
      "Epoch [34/50], Class Loss: 0.0841, Discrepancy Loss: 0.0704\n",
      "Epoch [35/50], Class Loss: 0.0752, Discrepancy Loss: 0.0618\n",
      "Epoch [36/50], Class Loss: 0.0621, Discrepancy Loss: 0.0671\n",
      "Epoch [37/50], Class Loss: 0.0677, Discrepancy Loss: 0.0708\n",
      "Epoch [38/50], Class Loss: 0.0665, Discrepancy Loss: 0.0717\n",
      "Epoch [39/50], Class Loss: 0.0876, Discrepancy Loss: 0.0695\n",
      "Epoch [40/50], Class Loss: 0.0712, Discrepancy Loss: 0.0733\n",
      "Epoch [41/50], Class Loss: 0.0674, Discrepancy Loss: 0.0722\n",
      "Epoch [42/50], Class Loss: 0.0625, Discrepancy Loss: 0.0660\n",
      "Epoch [43/50], Class Loss: 0.0638, Discrepancy Loss: 0.0703\n",
      "Epoch [44/50], Class Loss: 0.0706, Discrepancy Loss: 0.0703\n",
      "Epoch [45/50], Class Loss: 0.0684, Discrepancy Loss: 0.0705\n",
      "Epoch [46/50], Class Loss: 0.0655, Discrepancy Loss: 0.0722\n",
      "Epoch [47/50], Class Loss: 0.0896, Discrepancy Loss: 0.0681\n",
      "Epoch [48/50], Class Loss: 0.0698, Discrepancy Loss: 0.0686\n",
      "Epoch [49/50], Class Loss: 0.0639, Discrepancy Loss: 0.0683\n",
      "Epoch [50/50], Class Loss: 0.0942, Discrepancy Loss: 0.0702\n",
      "Source Domain Performance - Accuracy: 92.45%, Precision: 93.31%, Recall: 92.05%, F1 Score: 92.03%\n",
      "Target Domain Performance - Accuracy: 63.01%, Precision: 68.51%, Recall: 63.95%, F1 Score: 62.01%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 2.7175, Discrepancy Loss: 0.0959\n",
      "Epoch [2/50], Class Loss: 1.0267, Discrepancy Loss: 0.1024\n",
      "Epoch [3/50], Class Loss: 0.9029, Discrepancy Loss: 0.1126\n",
      "Epoch [4/50], Class Loss: 0.8346, Discrepancy Loss: 0.1007\n",
      "Epoch [5/50], Class Loss: 0.7230, Discrepancy Loss: 0.0940\n",
      "Epoch [6/50], Class Loss: 0.7113, Discrepancy Loss: 0.1019\n",
      "Epoch [7/50], Class Loss: 0.6769, Discrepancy Loss: 0.0963\n",
      "Epoch [8/50], Class Loss: 0.6084, Discrepancy Loss: 0.1081\n",
      "Epoch [9/50], Class Loss: 0.5923, Discrepancy Loss: 0.0937\n",
      "Epoch [10/50], Class Loss: 0.4534, Discrepancy Loss: 0.0878\n",
      "Epoch [11/50], Class Loss: 0.2238, Discrepancy Loss: 0.0698\n",
      "Epoch [12/50], Class Loss: 0.1826, Discrepancy Loss: 0.0596\n",
      "Epoch [13/50], Class Loss: 0.1362, Discrepancy Loss: 0.0544\n",
      "Epoch [14/50], Class Loss: 0.1061, Discrepancy Loss: 0.0493\n",
      "Epoch [15/50], Class Loss: 0.1056, Discrepancy Loss: 0.0478\n",
      "Epoch [16/50], Class Loss: 0.1191, Discrepancy Loss: 0.0452\n",
      "Epoch [17/50], Class Loss: 0.0828, Discrepancy Loss: 0.0491\n",
      "Epoch [18/50], Class Loss: 0.1256, Discrepancy Loss: 0.0413\n",
      "Epoch [19/50], Class Loss: 0.0909, Discrepancy Loss: 0.0515\n",
      "Epoch [20/50], Class Loss: 0.0628, Discrepancy Loss: 0.0502\n",
      "Epoch [21/50], Class Loss: 0.0547, Discrepancy Loss: 0.0496\n",
      "Epoch [22/50], Class Loss: 0.0458, Discrepancy Loss: 0.0524\n",
      "Epoch [23/50], Class Loss: 0.0403, Discrepancy Loss: 0.0461\n",
      "Epoch [24/50], Class Loss: 0.0409, Discrepancy Loss: 0.0473\n",
      "Epoch [25/50], Class Loss: 0.0455, Discrepancy Loss: 0.0434\n",
      "Epoch [26/50], Class Loss: 0.0505, Discrepancy Loss: 0.0445\n",
      "Epoch [27/50], Class Loss: 0.0549, Discrepancy Loss: 0.0491\n",
      "Epoch [28/50], Class Loss: 0.0390, Discrepancy Loss: 0.0450\n",
      "Epoch [29/50], Class Loss: 0.0581, Discrepancy Loss: 0.0420\n",
      "Epoch [30/50], Class Loss: 0.0385, Discrepancy Loss: 0.0485\n",
      "Epoch [31/50], Class Loss: 0.0417, Discrepancy Loss: 0.0509\n",
      "Epoch [32/50], Class Loss: 0.0417, Discrepancy Loss: 0.0498\n",
      "Epoch [33/50], Class Loss: 0.0487, Discrepancy Loss: 0.0464\n",
      "Epoch [34/50], Class Loss: 0.0422, Discrepancy Loss: 0.0466\n",
      "Epoch [35/50], Class Loss: 0.0521, Discrepancy Loss: 0.0553\n",
      "Epoch [36/50], Class Loss: 0.0394, Discrepancy Loss: 0.0507\n",
      "Epoch [37/50], Class Loss: 0.0522, Discrepancy Loss: 0.0474\n",
      "Epoch [38/50], Class Loss: 0.0450, Discrepancy Loss: 0.0492\n",
      "Epoch [39/50], Class Loss: 0.0365, Discrepancy Loss: 0.0500\n",
      "Epoch [40/50], Class Loss: 0.0412, Discrepancy Loss: 0.0498\n",
      "Epoch [41/50], Class Loss: 0.0479, Discrepancy Loss: 0.0559\n",
      "Epoch [42/50], Class Loss: 0.0427, Discrepancy Loss: 0.0485\n",
      "Epoch [43/50], Class Loss: 0.0434, Discrepancy Loss: 0.0554\n",
      "Epoch [44/50], Class Loss: 0.0438, Discrepancy Loss: 0.0526\n",
      "Epoch [45/50], Class Loss: 0.0503, Discrepancy Loss: 0.0545\n",
      "Epoch [46/50], Class Loss: 0.0433, Discrepancy Loss: 0.0491\n",
      "Epoch [47/50], Class Loss: 0.0452, Discrepancy Loss: 0.0504\n",
      "Epoch [48/50], Class Loss: 0.0386, Discrepancy Loss: 0.0535\n",
      "Epoch [49/50], Class Loss: 0.0493, Discrepancy Loss: 0.0495\n",
      "Epoch [50/50], Class Loss: 0.0528, Discrepancy Loss: 0.0516\n",
      "Source Domain Performance - Accuracy: 94.12%, Precision: 94.61%, Recall: 93.84%, F1 Score: 93.86%\n",
      "Target Domain Performance - Accuracy: 68.53%, Precision: 73.86%, Recall: 69.45%, F1 Score: 67.95%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 2.4262, Discrepancy Loss: 0.0959\n",
      "Epoch [2/50], Class Loss: 0.9779, Discrepancy Loss: 0.1127\n",
      "Epoch [3/50], Class Loss: 0.8682, Discrepancy Loss: 0.1084\n",
      "Epoch [4/50], Class Loss: 0.9667, Discrepancy Loss: 0.0991\n",
      "Epoch [5/50], Class Loss: 0.8176, Discrepancy Loss: 0.0960\n",
      "Epoch [6/50], Class Loss: 0.7554, Discrepancy Loss: 0.1077\n",
      "Epoch [7/50], Class Loss: 0.6675, Discrepancy Loss: 0.1008\n",
      "Epoch [8/50], Class Loss: 0.6681, Discrepancy Loss: 0.0953\n",
      "Epoch [9/50], Class Loss: 0.6178, Discrepancy Loss: 0.1025\n",
      "Epoch [10/50], Class Loss: 0.6039, Discrepancy Loss: 0.0827\n",
      "Epoch [11/50], Class Loss: 0.4996, Discrepancy Loss: 0.0826\n",
      "Epoch [12/50], Class Loss: 0.4550, Discrepancy Loss: 0.0799\n",
      "Epoch [13/50], Class Loss: 0.3996, Discrepancy Loss: 0.0733\n",
      "Epoch [14/50], Class Loss: 0.3221, Discrepancy Loss: 0.0664\n",
      "Epoch [15/50], Class Loss: 0.2582, Discrepancy Loss: 0.0617\n",
      "Epoch [16/50], Class Loss: 0.2187, Discrepancy Loss: 0.0659\n",
      "Epoch [17/50], Class Loss: 0.2040, Discrepancy Loss: 0.0603\n",
      "Epoch [18/50], Class Loss: 0.1874, Discrepancy Loss: 0.0620\n",
      "Epoch [19/50], Class Loss: 0.1729, Discrepancy Loss: 0.0651\n",
      "Epoch [20/50], Class Loss: 0.1589, Discrepancy Loss: 0.0615\n",
      "Epoch [21/50], Class Loss: 0.1060, Discrepancy Loss: 0.0636\n",
      "Epoch [22/50], Class Loss: 0.0936, Discrepancy Loss: 0.0657\n",
      "Epoch [23/50], Class Loss: 0.0985, Discrepancy Loss: 0.0681\n",
      "Epoch [24/50], Class Loss: 0.0951, Discrepancy Loss: 0.0681\n",
      "Epoch [25/50], Class Loss: 0.0949, Discrepancy Loss: 0.0711\n",
      "Epoch [26/50], Class Loss: 0.0882, Discrepancy Loss: 0.0737\n",
      "Epoch [27/50], Class Loss: 0.0931, Discrepancy Loss: 0.0693\n",
      "Epoch [28/50], Class Loss: 0.0925, Discrepancy Loss: 0.0741\n",
      "Epoch [29/50], Class Loss: 0.0821, Discrepancy Loss: 0.0799\n",
      "Epoch [30/50], Class Loss: 0.0936, Discrepancy Loss: 0.0750\n",
      "Epoch [31/50], Class Loss: 0.0831, Discrepancy Loss: 0.0820\n",
      "Epoch [32/50], Class Loss: 0.0836, Discrepancy Loss: 0.0801\n",
      "Epoch [33/50], Class Loss: 0.0849, Discrepancy Loss: 0.0824\n",
      "Epoch [34/50], Class Loss: 0.0814, Discrepancy Loss: 0.0781\n",
      "Epoch [35/50], Class Loss: 0.0856, Discrepancy Loss: 0.0831\n",
      "Epoch [36/50], Class Loss: 0.0783, Discrepancy Loss: 0.0784\n",
      "Epoch [37/50], Class Loss: 0.0877, Discrepancy Loss: 0.0885\n",
      "Epoch [38/50], Class Loss: 0.0824, Discrepancy Loss: 0.0807\n",
      "Epoch [39/50], Class Loss: 0.0792, Discrepancy Loss: 0.0835\n",
      "Epoch [40/50], Class Loss: 0.0828, Discrepancy Loss: 0.0824\n",
      "Epoch [41/50], Class Loss: 0.0931, Discrepancy Loss: 0.0865\n",
      "Epoch [42/50], Class Loss: 0.1052, Discrepancy Loss: 0.0850\n",
      "Epoch [43/50], Class Loss: 0.0865, Discrepancy Loss: 0.0899\n",
      "Epoch [44/50], Class Loss: 0.0830, Discrepancy Loss: 0.0866\n",
      "Epoch [45/50], Class Loss: 0.0801, Discrepancy Loss: 0.0828\n",
      "Epoch [46/50], Class Loss: 0.0796, Discrepancy Loss: 0.0782\n",
      "Epoch [47/50], Class Loss: 0.0713, Discrepancy Loss: 0.0898\n",
      "Epoch [48/50], Class Loss: 0.0804, Discrepancy Loss: 0.0797\n",
      "Epoch [49/50], Class Loss: 0.0827, Discrepancy Loss: 0.0852\n",
      "Epoch [50/50], Class Loss: 0.0913, Discrepancy Loss: 0.0796\n",
      "Source Domain Performance - Accuracy: 90.83%, Precision: 91.63%, Recall: 90.42%, F1 Score: 90.34%\n",
      "Target Domain Performance - Accuracy: 64.39%, Precision: 69.35%, Recall: 65.02%, F1 Score: 63.78%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 2.4230, Discrepancy Loss: 0.1069\n",
      "Epoch [2/50], Class Loss: 1.0176, Discrepancy Loss: 0.1016\n",
      "Epoch [3/50], Class Loss: 0.8209, Discrepancy Loss: 0.1041\n",
      "Epoch [4/50], Class Loss: 0.7664, Discrepancy Loss: 0.0969\n",
      "Epoch [5/50], Class Loss: 0.9038, Discrepancy Loss: 0.1095\n",
      "Epoch [6/50], Class Loss: 0.7740, Discrepancy Loss: 0.1030\n",
      "Epoch [7/50], Class Loss: 0.7889, Discrepancy Loss: 0.0983\n",
      "Epoch [8/50], Class Loss: 0.7034, Discrepancy Loss: 0.0970\n",
      "Epoch [9/50], Class Loss: 0.6367, Discrepancy Loss: 0.0808\n",
      "Epoch [10/50], Class Loss: 0.6179, Discrepancy Loss: 0.0875\n",
      "Epoch [11/50], Class Loss: 0.5242, Discrepancy Loss: 0.0825\n",
      "Epoch [12/50], Class Loss: 0.4746, Discrepancy Loss: 0.0827\n",
      "Epoch [13/50], Class Loss: 0.4480, Discrepancy Loss: 0.0774\n",
      "Epoch [14/50], Class Loss: 0.3847, Discrepancy Loss: 0.0692\n",
      "Epoch [15/50], Class Loss: 0.3217, Discrepancy Loss: 0.0647\n",
      "Epoch [16/50], Class Loss: 0.2739, Discrepancy Loss: 0.0579\n",
      "Epoch [17/50], Class Loss: 0.2350, Discrepancy Loss: 0.0593\n",
      "Epoch [18/50], Class Loss: 0.2440, Discrepancy Loss: 0.0521\n",
      "Epoch [19/50], Class Loss: 0.1761, Discrepancy Loss: 0.0596\n",
      "Epoch [20/50], Class Loss: 0.1528, Discrepancy Loss: 0.0570\n",
      "Epoch [21/50], Class Loss: 0.1666, Discrepancy Loss: 0.0576\n",
      "Epoch [22/50], Class Loss: 0.1267, Discrepancy Loss: 0.0559\n",
      "Epoch [23/50], Class Loss: 0.1232, Discrepancy Loss: 0.0506\n",
      "Epoch [24/50], Class Loss: 0.1162, Discrepancy Loss: 0.0543\n",
      "Epoch [25/50], Class Loss: 0.1143, Discrepancy Loss: 0.0507\n",
      "Epoch [26/50], Class Loss: 0.1268, Discrepancy Loss: 0.0564\n",
      "Epoch [27/50], Class Loss: 0.1132, Discrepancy Loss: 0.0526\n",
      "Epoch [28/50], Class Loss: 0.1146, Discrepancy Loss: 0.0484\n",
      "Epoch [29/50], Class Loss: 0.0901, Discrepancy Loss: 0.0547\n",
      "Epoch [30/50], Class Loss: 0.1038, Discrepancy Loss: 0.0524\n",
      "Epoch [31/50], Class Loss: 0.0970, Discrepancy Loss: 0.0535\n",
      "Epoch [32/50], Class Loss: 0.1027, Discrepancy Loss: 0.0532\n",
      "Epoch [33/50], Class Loss: 0.1008, Discrepancy Loss: 0.0576\n",
      "Epoch [34/50], Class Loss: 0.0945, Discrepancy Loss: 0.0553\n",
      "Epoch [35/50], Class Loss: 0.0994, Discrepancy Loss: 0.0542\n",
      "Epoch [36/50], Class Loss: 0.0982, Discrepancy Loss: 0.0569\n",
      "Epoch [37/50], Class Loss: 0.1034, Discrepancy Loss: 0.0544\n",
      "Epoch [38/50], Class Loss: 0.1173, Discrepancy Loss: 0.0543\n",
      "Epoch [39/50], Class Loss: 0.0945, Discrepancy Loss: 0.0574\n",
      "Epoch [40/50], Class Loss: 0.0982, Discrepancy Loss: 0.0537\n",
      "Epoch [41/50], Class Loss: 0.0902, Discrepancy Loss: 0.0518\n",
      "Epoch [42/50], Class Loss: 0.0998, Discrepancy Loss: 0.0530\n",
      "Epoch [43/50], Class Loss: 0.0902, Discrepancy Loss: 0.0534\n",
      "Epoch [44/50], Class Loss: 0.0918, Discrepancy Loss: 0.0529\n",
      "Epoch [45/50], Class Loss: 0.0983, Discrepancy Loss: 0.0538\n",
      "Epoch [46/50], Class Loss: 0.0975, Discrepancy Loss: 0.0536\n",
      "Epoch [47/50], Class Loss: 0.0990, Discrepancy Loss: 0.0523\n",
      "Epoch [48/50], Class Loss: 0.1037, Discrepancy Loss: 0.0551\n",
      "Epoch [49/50], Class Loss: 0.0946, Discrepancy Loss: 0.0573\n",
      "Epoch [50/50], Class Loss: 0.1035, Discrepancy Loss: 0.0519\n",
      "Source Domain Performance - Accuracy: 88.01%, Precision: 89.59%, Recall: 87.44%, F1 Score: 87.17%\n",
      "Target Domain Performance - Accuracy: 66.67%, Precision: 70.91%, Recall: 67.20%, F1 Score: 67.00%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 2.6124, Discrepancy Loss: 0.0954\n",
      "Epoch [2/50], Class Loss: 1.0353, Discrepancy Loss: 0.1093\n",
      "Epoch [3/50], Class Loss: 0.8639, Discrepancy Loss: 0.1013\n",
      "Epoch [4/50], Class Loss: 0.8498, Discrepancy Loss: 0.1102\n",
      "Epoch [5/50], Class Loss: 0.9070, Discrepancy Loss: 0.1073\n",
      "Epoch [6/50], Class Loss: 0.7465, Discrepancy Loss: 0.1155\n",
      "Epoch [7/50], Class Loss: 0.7404, Discrepancy Loss: 0.0943\n",
      "Epoch [8/50], Class Loss: 0.6326, Discrepancy Loss: 0.0964\n",
      "Epoch [9/50], Class Loss: 0.6124, Discrepancy Loss: 0.0868\n",
      "Epoch [10/50], Class Loss: 0.5943, Discrepancy Loss: 0.0819\n",
      "Epoch [11/50], Class Loss: 0.4974, Discrepancy Loss: 0.0979\n",
      "Epoch [12/50], Class Loss: 0.4574, Discrepancy Loss: 0.0865\n",
      "Epoch [13/50], Class Loss: 0.3650, Discrepancy Loss: 0.0635\n",
      "Epoch [14/50], Class Loss: 0.2582, Discrepancy Loss: 0.0644\n",
      "Epoch [15/50], Class Loss: 0.1897, Discrepancy Loss: 0.0527\n",
      "Epoch [16/50], Class Loss: 0.1673, Discrepancy Loss: 0.0541\n",
      "Epoch [17/50], Class Loss: 0.1270, Discrepancy Loss: 0.0494\n",
      "Epoch [18/50], Class Loss: 0.1628, Discrepancy Loss: 0.0546\n",
      "Epoch [19/50], Class Loss: 0.0991, Discrepancy Loss: 0.0497\n",
      "Epoch [20/50], Class Loss: 0.1029, Discrepancy Loss: 0.0475\n",
      "Epoch [21/50], Class Loss: 0.0734, Discrepancy Loss: 0.0460\n",
      "Epoch [22/50], Class Loss: 0.0689, Discrepancy Loss: 0.0471\n",
      "Epoch [23/50], Class Loss: 0.0756, Discrepancy Loss: 0.0474\n",
      "Epoch [24/50], Class Loss: 0.0821, Discrepancy Loss: 0.0502\n",
      "Epoch [25/50], Class Loss: 0.0799, Discrepancy Loss: 0.0476\n",
      "Epoch [26/50], Class Loss: 0.0709, Discrepancy Loss: 0.0455\n",
      "Epoch [27/50], Class Loss: 0.0739, Discrepancy Loss: 0.0495\n",
      "Epoch [28/50], Class Loss: 0.0751, Discrepancy Loss: 0.0456\n",
      "Epoch [29/50], Class Loss: 0.0674, Discrepancy Loss: 0.0448\n",
      "Epoch [30/50], Class Loss: 0.0650, Discrepancy Loss: 0.0455\n",
      "Epoch [31/50], Class Loss: 0.0688, Discrepancy Loss: 0.0478\n",
      "Epoch [32/50], Class Loss: 0.0580, Discrepancy Loss: 0.0479\n",
      "Epoch [33/50], Class Loss: 0.0678, Discrepancy Loss: 0.0454\n",
      "Epoch [34/50], Class Loss: 0.0842, Discrepancy Loss: 0.0467\n",
      "Epoch [35/50], Class Loss: 0.0582, Discrepancy Loss: 0.0489\n",
      "Epoch [36/50], Class Loss: 0.0648, Discrepancy Loss: 0.0471\n",
      "Epoch [37/50], Class Loss: 0.0602, Discrepancy Loss: 0.0442\n",
      "Epoch [38/50], Class Loss: 0.0628, Discrepancy Loss: 0.0508\n",
      "Epoch [39/50], Class Loss: 0.0701, Discrepancy Loss: 0.0439\n",
      "Epoch [40/50], Class Loss: 0.0599, Discrepancy Loss: 0.0510\n",
      "Epoch [41/50], Class Loss: 0.0595, Discrepancy Loss: 0.0512\n",
      "Epoch [42/50], Class Loss: 0.0613, Discrepancy Loss: 0.0473\n",
      "Epoch [43/50], Class Loss: 0.0654, Discrepancy Loss: 0.0450\n",
      "Epoch [44/50], Class Loss: 0.0558, Discrepancy Loss: 0.0452\n",
      "Epoch [45/50], Class Loss: 0.0559, Discrepancy Loss: 0.0498\n",
      "Epoch [46/50], Class Loss: 0.0597, Discrepancy Loss: 0.0496\n",
      "Epoch [47/50], Class Loss: 0.0575, Discrepancy Loss: 0.0524\n",
      "Epoch [48/50], Class Loss: 0.0570, Discrepancy Loss: 0.0533\n",
      "Epoch [49/50], Class Loss: 0.0600, Discrepancy Loss: 0.0476\n",
      "Epoch [50/50], Class Loss: 0.0616, Discrepancy Loss: 0.0460\n",
      "Source Domain Performance - Accuracy: 93.59%, Precision: 94.14%, Recall: 93.26%, F1 Score: 93.28%\n",
      "Target Domain Performance - Accuracy: 69.24%, Precision: 73.27%, Recall: 69.81%, F1 Score: 69.48%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 2.9344, Discrepancy Loss: 0.0942\n",
      "Epoch [2/50], Class Loss: 0.9442, Discrepancy Loss: 0.1009\n",
      "Epoch [3/50], Class Loss: 0.8985, Discrepancy Loss: 0.0918\n",
      "Epoch [4/50], Class Loss: 0.8730, Discrepancy Loss: 0.1025\n",
      "Epoch [5/50], Class Loss: 0.8201, Discrepancy Loss: 0.1082\n",
      "Epoch [6/50], Class Loss: 0.7852, Discrepancy Loss: 0.1036\n",
      "Epoch [7/50], Class Loss: 0.7347, Discrepancy Loss: 0.0914\n",
      "Epoch [8/50], Class Loss: 0.6605, Discrepancy Loss: 0.0926\n",
      "Epoch [9/50], Class Loss: 0.6643, Discrepancy Loss: 0.0970\n",
      "Epoch [10/50], Class Loss: 0.6602, Discrepancy Loss: 0.0837\n",
      "Epoch [11/50], Class Loss: 0.6288, Discrepancy Loss: 0.0671\n",
      "Epoch [12/50], Class Loss: 0.5268, Discrepancy Loss: 0.0810\n",
      "Epoch [13/50], Class Loss: 0.3423, Discrepancy Loss: 0.0807\n",
      "Epoch [14/50], Class Loss: 0.2980, Discrepancy Loss: 0.0647\n",
      "Epoch [15/50], Class Loss: 0.2640, Discrepancy Loss: 0.0607\n",
      "Epoch [16/50], Class Loss: 0.2185, Discrepancy Loss: 0.0590\n",
      "Epoch [17/50], Class Loss: 0.2081, Discrepancy Loss: 0.0658\n",
      "Epoch [18/50], Class Loss: 0.1763, Discrepancy Loss: 0.0581\n",
      "Epoch [19/50], Class Loss: 0.1688, Discrepancy Loss: 0.0561\n",
      "Epoch [20/50], Class Loss: 0.1150, Discrepancy Loss: 0.0539\n",
      "Epoch [21/50], Class Loss: 0.1027, Discrepancy Loss: 0.0525\n",
      "Epoch [22/50], Class Loss: 0.0878, Discrepancy Loss: 0.0563\n",
      "Epoch [23/50], Class Loss: 0.0865, Discrepancy Loss: 0.0534\n",
      "Epoch [24/50], Class Loss: 0.0926, Discrepancy Loss: 0.0561\n",
      "Epoch [25/50], Class Loss: 0.0861, Discrepancy Loss: 0.0565\n",
      "Epoch [26/50], Class Loss: 0.1022, Discrepancy Loss: 0.0621\n",
      "Epoch [27/50], Class Loss: 0.0786, Discrepancy Loss: 0.0463\n",
      "Epoch [28/50], Class Loss: 0.0863, Discrepancy Loss: 0.0591\n",
      "Epoch [29/50], Class Loss: 0.0795, Discrepancy Loss: 0.0609\n",
      "Epoch [30/50], Class Loss: 0.0805, Discrepancy Loss: 0.0608\n",
      "Epoch [31/50], Class Loss: 0.0736, Discrepancy Loss: 0.0610\n",
      "Epoch [32/50], Class Loss: 0.0728, Discrepancy Loss: 0.0584\n",
      "Epoch [33/50], Class Loss: 0.0767, Discrepancy Loss: 0.0566\n",
      "Epoch [34/50], Class Loss: 0.0774, Discrepancy Loss: 0.0557\n",
      "Epoch [35/50], Class Loss: 0.0709, Discrepancy Loss: 0.0573\n",
      "Epoch [36/50], Class Loss: 0.0732, Discrepancy Loss: 0.0583\n",
      "Epoch [37/50], Class Loss: 0.0633, Discrepancy Loss: 0.0630\n",
      "Epoch [38/50], Class Loss: 0.0672, Discrepancy Loss: 0.0678\n",
      "Epoch [39/50], Class Loss: 0.0735, Discrepancy Loss: 0.0592\n",
      "Epoch [40/50], Class Loss: 0.0608, Discrepancy Loss: 0.0629\n",
      "Epoch [41/50], Class Loss: 0.0824, Discrepancy Loss: 0.0676\n",
      "Epoch [42/50], Class Loss: 0.0716, Discrepancy Loss: 0.0621\n",
      "Epoch [43/50], Class Loss: 0.0726, Discrepancy Loss: 0.0602\n",
      "Epoch [44/50], Class Loss: 0.0755, Discrepancy Loss: 0.0603\n",
      "Epoch [45/50], Class Loss: 0.0946, Discrepancy Loss: 0.0611\n",
      "Epoch [46/50], Class Loss: 0.0753, Discrepancy Loss: 0.0572\n",
      "Epoch [47/50], Class Loss: 0.0728, Discrepancy Loss: 0.0606\n",
      "Epoch [48/50], Class Loss: 0.0720, Discrepancy Loss: 0.0607\n",
      "Epoch [49/50], Class Loss: 0.0709, Discrepancy Loss: 0.0640\n",
      "Epoch [50/50], Class Loss: 0.0919, Discrepancy Loss: 0.0632\n",
      "Source Domain Performance - Accuracy: 88.97%, Precision: 90.35%, Recall: 88.45%, F1 Score: 88.27%\n",
      "Target Domain Performance - Accuracy: 69.42%, Precision: 73.07%, Recall: 69.91%, F1 Score: 69.85%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 3.1146, Discrepancy Loss: 0.0997\n",
      "Epoch [2/50], Class Loss: 0.9093, Discrepancy Loss: 0.1128\n",
      "Epoch [3/50], Class Loss: 0.8140, Discrepancy Loss: 0.1043\n",
      "Epoch [4/50], Class Loss: 0.8299, Discrepancy Loss: 0.1116\n",
      "Epoch [5/50], Class Loss: 0.7287, Discrepancy Loss: 0.1071\n",
      "Epoch [6/50], Class Loss: 0.7234, Discrepancy Loss: 0.1102\n",
      "Epoch [7/50], Class Loss: 0.7892, Discrepancy Loss: 0.0981\n",
      "Epoch [8/50], Class Loss: 0.6879, Discrepancy Loss: 0.0924\n",
      "Epoch [9/50], Class Loss: 0.6892, Discrepancy Loss: 0.1011\n",
      "Epoch [10/50], Class Loss: 0.4487, Discrepancy Loss: 0.0803\n",
      "Epoch [11/50], Class Loss: 0.1873, Discrepancy Loss: 0.0662\n",
      "Epoch [12/50], Class Loss: 0.1291, Discrepancy Loss: 0.0594\n",
      "Epoch [13/50], Class Loss: 0.1166, Discrepancy Loss: 0.0548\n",
      "Epoch [14/50], Class Loss: 0.1129, Discrepancy Loss: 0.0567\n",
      "Epoch [15/50], Class Loss: 0.1111, Discrepancy Loss: 0.0561\n",
      "Epoch [16/50], Class Loss: 0.1000, Discrepancy Loss: 0.0566\n",
      "Epoch [17/50], Class Loss: 0.0912, Discrepancy Loss: 0.0477\n",
      "Epoch [18/50], Class Loss: 0.0726, Discrepancy Loss: 0.0455\n",
      "Epoch [19/50], Class Loss: 0.0661, Discrepancy Loss: 0.0510\n",
      "Epoch [20/50], Class Loss: 0.0650, Discrepancy Loss: 0.0440\n",
      "Epoch [21/50], Class Loss: 0.0578, Discrepancy Loss: 0.0455\n",
      "Epoch [22/50], Class Loss: 0.0531, Discrepancy Loss: 0.0464\n",
      "Epoch [23/50], Class Loss: 0.0444, Discrepancy Loss: 0.0477\n",
      "Epoch [24/50], Class Loss: 0.0534, Discrepancy Loss: 0.0464\n",
      "Epoch [25/50], Class Loss: 0.0463, Discrepancy Loss: 0.0438\n",
      "Epoch [26/50], Class Loss: 0.0506, Discrepancy Loss: 0.0445\n",
      "Epoch [27/50], Class Loss: 0.0496, Discrepancy Loss: 0.0434\n",
      "Epoch [28/50], Class Loss: 0.0432, Discrepancy Loss: 0.0441\n",
      "Epoch [29/50], Class Loss: 0.0390, Discrepancy Loss: 0.0433\n",
      "Epoch [30/50], Class Loss: 0.0413, Discrepancy Loss: 0.0438\n",
      "Epoch [31/50], Class Loss: 0.0547, Discrepancy Loss: 0.0458\n",
      "Epoch [32/50], Class Loss: 0.0383, Discrepancy Loss: 0.0497\n",
      "Epoch [33/50], Class Loss: 0.0500, Discrepancy Loss: 0.0388\n",
      "Epoch [34/50], Class Loss: 0.0442, Discrepancy Loss: 0.0443\n",
      "Epoch [35/50], Class Loss: 0.0475, Discrepancy Loss: 0.0480\n",
      "Epoch [36/50], Class Loss: 0.0383, Discrepancy Loss: 0.0453\n",
      "Epoch [37/50], Class Loss: 0.0451, Discrepancy Loss: 0.0432\n",
      "Epoch [38/50], Class Loss: 0.0508, Discrepancy Loss: 0.0426\n",
      "Epoch [39/50], Class Loss: 0.0384, Discrepancy Loss: 0.0449\n",
      "Epoch [40/50], Class Loss: 0.0360, Discrepancy Loss: 0.0467\n",
      "Epoch [41/50], Class Loss: 0.0429, Discrepancy Loss: 0.0475\n",
      "Epoch [42/50], Class Loss: 0.0461, Discrepancy Loss: 0.0465\n",
      "Epoch [43/50], Class Loss: 0.0532, Discrepancy Loss: 0.0480\n",
      "Epoch [44/50], Class Loss: 0.0423, Discrepancy Loss: 0.0434\n",
      "Epoch [45/50], Class Loss: 0.0441, Discrepancy Loss: 0.0449\n",
      "Epoch [46/50], Class Loss: 0.0494, Discrepancy Loss: 0.0428\n",
      "Epoch [47/50], Class Loss: 0.0499, Discrepancy Loss: 0.0501\n",
      "Epoch [48/50], Class Loss: 0.0488, Discrepancy Loss: 0.0434\n",
      "Epoch [49/50], Class Loss: 0.0463, Discrepancy Loss: 0.0422\n",
      "Epoch [50/50], Class Loss: 0.0418, Discrepancy Loss: 0.0409\n",
      "Source Domain Performance - Accuracy: 92.27%, Precision: 93.00%, Recall: 91.90%, F1 Score: 91.87%\n",
      "Target Domain Performance - Accuracy: 76.26%, Precision: 78.87%, Recall: 76.81%, F1 Score: 76.43%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 3.0793, Discrepancy Loss: 0.1020\n",
      "Epoch [2/50], Class Loss: 0.9627, Discrepancy Loss: 0.1141\n",
      "Epoch [3/50], Class Loss: 0.8387, Discrepancy Loss: 0.0947\n",
      "Epoch [4/50], Class Loss: 0.7295, Discrepancy Loss: 0.1041\n",
      "Epoch [5/50], Class Loss: 0.7495, Discrepancy Loss: 0.0892\n",
      "Epoch [6/50], Class Loss: 0.7463, Discrepancy Loss: 0.1010\n",
      "Epoch [7/50], Class Loss: 0.6771, Discrepancy Loss: 0.0916\n",
      "Epoch [8/50], Class Loss: 0.7290, Discrepancy Loss: 0.0908\n",
      "Epoch [9/50], Class Loss: 0.7028, Discrepancy Loss: 0.0994\n",
      "Epoch [10/50], Class Loss: 0.6207, Discrepancy Loss: 0.0906\n",
      "Epoch [11/50], Class Loss: 0.5499, Discrepancy Loss: 0.1107\n",
      "Epoch [12/50], Class Loss: 0.5206, Discrepancy Loss: 0.0910\n",
      "Epoch [13/50], Class Loss: 0.5252, Discrepancy Loss: 0.0867\n",
      "Epoch [14/50], Class Loss: 0.4928, Discrepancy Loss: 0.0875\n",
      "Epoch [15/50], Class Loss: 0.4003, Discrepancy Loss: 0.0797\n",
      "Epoch [16/50], Class Loss: 0.3317, Discrepancy Loss: 0.0645\n",
      "Epoch [17/50], Class Loss: 0.2525, Discrepancy Loss: 0.0623\n",
      "Epoch [18/50], Class Loss: 0.2040, Discrepancy Loss: 0.0594\n",
      "Epoch [19/50], Class Loss: 0.1767, Discrepancy Loss: 0.0534\n",
      "Epoch [20/50], Class Loss: 0.1563, Discrepancy Loss: 0.0522\n",
      "Epoch [21/50], Class Loss: 0.1143, Discrepancy Loss: 0.0533\n",
      "Epoch [22/50], Class Loss: 0.1348, Discrepancy Loss: 0.0490\n",
      "Epoch [23/50], Class Loss: 0.1155, Discrepancy Loss: 0.0538\n",
      "Epoch [24/50], Class Loss: 0.0983, Discrepancy Loss: 0.0490\n",
      "Epoch [25/50], Class Loss: 0.0842, Discrepancy Loss: 0.0497\n",
      "Epoch [26/50], Class Loss: 0.0901, Discrepancy Loss: 0.0519\n",
      "Epoch [27/50], Class Loss: 0.0876, Discrepancy Loss: 0.0533\n",
      "Epoch [28/50], Class Loss: 0.0803, Discrepancy Loss: 0.0475\n",
      "Epoch [29/50], Class Loss: 0.0799, Discrepancy Loss: 0.0557\n",
      "Epoch [30/50], Class Loss: 0.0818, Discrepancy Loss: 0.0497\n",
      "Epoch [31/50], Class Loss: 0.0670, Discrepancy Loss: 0.0511\n",
      "Epoch [32/50], Class Loss: 0.0837, Discrepancy Loss: 0.0513\n",
      "Epoch [33/50], Class Loss: 0.0803, Discrepancy Loss: 0.0505\n",
      "Epoch [34/50], Class Loss: 0.0773, Discrepancy Loss: 0.0554\n",
      "Epoch [35/50], Class Loss: 0.0785, Discrepancy Loss: 0.0550\n",
      "Epoch [36/50], Class Loss: 0.0719, Discrepancy Loss: 0.0557\n",
      "Epoch [37/50], Class Loss: 0.0753, Discrepancy Loss: 0.0589\n",
      "Epoch [38/50], Class Loss: 0.0804, Discrepancy Loss: 0.0586\n",
      "Epoch [39/50], Class Loss: 0.0750, Discrepancy Loss: 0.0548\n",
      "Epoch [40/50], Class Loss: 0.0756, Discrepancy Loss: 0.0569\n",
      "Epoch [41/50], Class Loss: 0.0815, Discrepancy Loss: 0.0519\n",
      "Epoch [42/50], Class Loss: 0.0733, Discrepancy Loss: 0.0550\n",
      "Epoch [43/50], Class Loss: 0.0727, Discrepancy Loss: 0.0576\n",
      "Epoch [44/50], Class Loss: 0.0694, Discrepancy Loss: 0.0554\n",
      "Epoch [45/50], Class Loss: 0.0746, Discrepancy Loss: 0.0505\n",
      "Epoch [46/50], Class Loss: 0.0707, Discrepancy Loss: 0.0551\n",
      "Epoch [47/50], Class Loss: 0.0715, Discrepancy Loss: 0.0558\n",
      "Epoch [48/50], Class Loss: 0.0907, Discrepancy Loss: 0.0528\n",
      "Epoch [49/50], Class Loss: 0.0707, Discrepancy Loss: 0.0579\n",
      "Epoch [50/50], Class Loss: 0.0776, Discrepancy Loss: 0.0557\n",
      "Source Domain Performance - Accuracy: 89.15%, Precision: 90.64%, Recall: 88.62%, F1 Score: 88.43%\n",
      "Target Domain Performance - Accuracy: 66.31%, Precision: 71.16%, Recall: 67.02%, F1 Score: 66.29%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 2.8740, Discrepancy Loss: 0.0936\n",
      "Epoch [2/50], Class Loss: 0.9412, Discrepancy Loss: 0.1036\n",
      "Epoch [3/50], Class Loss: 0.8164, Discrepancy Loss: 0.0934\n",
      "Epoch [4/50], Class Loss: 0.7830, Discrepancy Loss: 0.1048\n",
      "Epoch [5/50], Class Loss: 0.7885, Discrepancy Loss: 0.1023\n",
      "Epoch [6/50], Class Loss: 0.7447, Discrepancy Loss: 0.0974\n",
      "Epoch [7/50], Class Loss: 0.7552, Discrepancy Loss: 0.0920\n",
      "Epoch [8/50], Class Loss: 0.6174, Discrepancy Loss: 0.1043\n",
      "Epoch [9/50], Class Loss: 0.6316, Discrepancy Loss: 0.0960\n",
      "Epoch [10/50], Class Loss: 0.5510, Discrepancy Loss: 0.0837\n",
      "Epoch [11/50], Class Loss: 0.4875, Discrepancy Loss: 0.0704\n",
      "Epoch [12/50], Class Loss: 0.4591, Discrepancy Loss: 0.0729\n",
      "Epoch [13/50], Class Loss: 0.3582, Discrepancy Loss: 0.0724\n",
      "Epoch [14/50], Class Loss: 0.2768, Discrepancy Loss: 0.0629\n",
      "Epoch [15/50], Class Loss: 0.2182, Discrepancy Loss: 0.0596\n",
      "Epoch [16/50], Class Loss: 0.1689, Discrepancy Loss: 0.0547\n",
      "Epoch [17/50], Class Loss: 0.1592, Discrepancy Loss: 0.0479\n",
      "Epoch [18/50], Class Loss: 0.1393, Discrepancy Loss: 0.0538\n",
      "Epoch [19/50], Class Loss: 0.1366, Discrepancy Loss: 0.0505\n",
      "Epoch [20/50], Class Loss: 0.1160, Discrepancy Loss: 0.0489\n",
      "Epoch [21/50], Class Loss: 0.0861, Discrepancy Loss: 0.0503\n",
      "Epoch [22/50], Class Loss: 0.0877, Discrepancy Loss: 0.0464\n",
      "Epoch [23/50], Class Loss: 0.0972, Discrepancy Loss: 0.0488\n",
      "Epoch [24/50], Class Loss: 0.0999, Discrepancy Loss: 0.0462\n",
      "Epoch [25/50], Class Loss: 0.0909, Discrepancy Loss: 0.0501\n",
      "Epoch [26/50], Class Loss: 0.0715, Discrepancy Loss: 0.0519\n",
      "Epoch [27/50], Class Loss: 0.0721, Discrepancy Loss: 0.0535\n",
      "Epoch [28/50], Class Loss: 0.0656, Discrepancy Loss: 0.0484\n",
      "Epoch [29/50], Class Loss: 0.0690, Discrepancy Loss: 0.0489\n",
      "Epoch [30/50], Class Loss: 0.0778, Discrepancy Loss: 0.0472\n",
      "Epoch [31/50], Class Loss: 0.0695, Discrepancy Loss: 0.0474\n",
      "Epoch [32/50], Class Loss: 0.0697, Discrepancy Loss: 0.0467\n",
      "Epoch [33/50], Class Loss: 0.0673, Discrepancy Loss: 0.0528\n",
      "Epoch [34/50], Class Loss: 0.0696, Discrepancy Loss: 0.0481\n",
      "Epoch [35/50], Class Loss: 0.0676, Discrepancy Loss: 0.0487\n",
      "Epoch [36/50], Class Loss: 0.0657, Discrepancy Loss: 0.0496\n",
      "Epoch [37/50], Class Loss: 0.0684, Discrepancy Loss: 0.0491\n",
      "Epoch [38/50], Class Loss: 0.0702, Discrepancy Loss: 0.0459\n",
      "Epoch [39/50], Class Loss: 0.0680, Discrepancy Loss: 0.0491\n",
      "Epoch [40/50], Class Loss: 0.0645, Discrepancy Loss: 0.0493\n",
      "Epoch [41/50], Class Loss: 0.0694, Discrepancy Loss: 0.0481\n",
      "Epoch [42/50], Class Loss: 0.0626, Discrepancy Loss: 0.0458\n",
      "Epoch [43/50], Class Loss: 0.0656, Discrepancy Loss: 0.0497\n",
      "Epoch [44/50], Class Loss: 0.0723, Discrepancy Loss: 0.0516\n",
      "Epoch [45/50], Class Loss: 0.0633, Discrepancy Loss: 0.0499\n",
      "Epoch [46/50], Class Loss: 0.0688, Discrepancy Loss: 0.0519\n",
      "Epoch [47/50], Class Loss: 0.0651, Discrepancy Loss: 0.0471\n",
      "Epoch [48/50], Class Loss: 0.0641, Discrepancy Loss: 0.0509\n",
      "Epoch [49/50], Class Loss: 0.0672, Discrepancy Loss: 0.0510\n",
      "Epoch [50/50], Class Loss: 0.0662, Discrepancy Loss: 0.0506\n",
      "Source Domain Performance - Accuracy: 89.51%, Precision: 90.31%, Recall: 89.10%, F1 Score: 88.97%\n",
      "Target Domain Performance - Accuracy: 71.76%, Precision: 75.60%, Recall: 72.13%, F1 Score: 72.33%\n",
      "\n",
      "Source performance: 90.65% 91.62% 90.22% 90.11%\n",
      "Target performance: 68.69% 72.94% 69.33% 68.65%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.38%\n",
      "qpsk: 45.95%\n",
      "16qam: 46.48%\n",
      "16apsk: 85.49%\n",
      "SNR level: 18\n",
      "SNR level: 18\n",
      "CORAL\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 0.9578, CORAL Loss: 0.0350\n",
      "Validation Loss: 0.6395\n",
      "Epoch [2/50], Class Loss: 0.5707, CORAL Loss: 0.0205\n",
      "Validation Loss: 0.6384\n",
      "Epoch [3/50], Class Loss: 0.5743, CORAL Loss: 0.0155\n",
      "Validation Loss: 0.5741\n",
      "Epoch [4/50], Class Loss: 0.5511, CORAL Loss: 0.0106\n",
      "Validation Loss: 0.6059\n",
      "Epoch [5/50], Class Loss: 0.5450, CORAL Loss: 0.0118\n",
      "Validation Loss: 0.7452\n",
      "Epoch [6/50], Class Loss: 0.5428, CORAL Loss: 0.0119\n",
      "Validation Loss: 0.6040\n",
      "Epoch [7/50], Class Loss: 0.5208, CORAL Loss: 0.0084\n",
      "Validation Loss: 0.6362\n",
      "Epoch [8/50], Class Loss: 0.6020, CORAL Loss: 0.0264\n",
      "Validation Loss: 0.6296\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 69.78%, Precision: 67.36%, Recall: 70.91%, F1 Score: 63.00%\n",
      "Target Domain Performance - Accuracy: 62.35%, Precision: 64.95%, Recall: 62.73%, F1 Score: 56.18%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 1.0510, CORAL Loss: 0.0337\n",
      "Validation Loss: 0.6729\n",
      "Epoch [2/50], Class Loss: 0.6192, CORAL Loss: 0.0225\n",
      "Validation Loss: 0.6174\n",
      "Epoch [3/50], Class Loss: 0.5754, CORAL Loss: 0.0148\n",
      "Validation Loss: 0.5497\n",
      "Epoch [4/50], Class Loss: 0.5574, CORAL Loss: 0.0126\n",
      "Validation Loss: 0.5537\n",
      "Epoch [5/50], Class Loss: 0.5441, CORAL Loss: 0.0096\n",
      "Validation Loss: 0.5814\n",
      "Epoch [6/50], Class Loss: 0.5534, CORAL Loss: 0.0151\n",
      "Validation Loss: 0.6021\n",
      "Epoch [7/50], Class Loss: 0.5148, CORAL Loss: 0.0096\n",
      "Validation Loss: 0.5953\n",
      "Epoch [8/50], Class Loss: 0.4972, CORAL Loss: 0.0110\n",
      "Validation Loss: 0.6342\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 70.20%, Precision: 68.69%, Recall: 70.47%, F1 Score: 67.59%\n",
      "Target Domain Performance - Accuracy: 58.51%, Precision: 60.96%, Recall: 58.64%, F1 Score: 52.67%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 1.0413, CORAL Loss: 0.0640\n",
      "Validation Loss: 0.7064\n",
      "Epoch [2/50], Class Loss: 0.6240, CORAL Loss: 0.0472\n",
      "Validation Loss: 0.6440\n",
      "Epoch [3/50], Class Loss: 0.5567, CORAL Loss: 0.0217\n",
      "Validation Loss: 0.5638\n",
      "Epoch [4/50], Class Loss: 0.5492, CORAL Loss: 0.0164\n",
      "Validation Loss: 0.5568\n",
      "Epoch [5/50], Class Loss: 0.5941, CORAL Loss: 0.0190\n",
      "Validation Loss: 0.6057\n",
      "Epoch [6/50], Class Loss: 0.5474, CORAL Loss: 0.0158\n",
      "Validation Loss: 0.5810\n",
      "Epoch [7/50], Class Loss: 0.5176, CORAL Loss: 0.0139\n",
      "Validation Loss: 0.5761\n",
      "Epoch [8/50], Class Loss: 0.4859, CORAL Loss: 0.0137\n",
      "Validation Loss: 0.5978\n",
      "Epoch [9/50], Class Loss: 0.4641, CORAL Loss: 0.0176\n",
      "Validation Loss: 0.6491\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 67.75%, Precision: 66.90%, Recall: 67.00%, F1 Score: 65.12%\n",
      "Target Domain Performance - Accuracy: 58.21%, Precision: 59.29%, Recall: 58.14%, F1 Score: 51.21%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 0.9393, CORAL Loss: 0.0470\n",
      "Validation Loss: 0.8678\n",
      "Epoch [2/50], Class Loss: 0.6201, CORAL Loss: 0.0331\n",
      "Validation Loss: 0.5592\n",
      "Epoch [3/50], Class Loss: 0.5587, CORAL Loss: 0.0165\n",
      "Validation Loss: 0.5499\n",
      "Epoch [4/50], Class Loss: 0.5556, CORAL Loss: 0.0124\n",
      "Validation Loss: 0.8193\n",
      "Epoch [5/50], Class Loss: 0.5919, CORAL Loss: 0.0235\n",
      "Validation Loss: 0.6235\n",
      "Epoch [6/50], Class Loss: 0.5305, CORAL Loss: 0.0110\n",
      "Validation Loss: 0.5623\n",
      "Epoch [7/50], Class Loss: 0.5220, CORAL Loss: 0.0133\n",
      "Validation Loss: 0.5981\n",
      "Epoch [8/50], Class Loss: 0.4868, CORAL Loss: 0.0123\n",
      "Validation Loss: 0.6137\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 70.80%, Precision: 70.68%, Recall: 70.27%, F1 Score: 69.61%\n",
      "Target Domain Performance - Accuracy: 61.33%, Precision: 60.06%, Recall: 61.08%, F1 Score: 55.08%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 0.9662, CORAL Loss: 0.0527\n",
      "Validation Loss: 0.7597\n",
      "Epoch [2/50], Class Loss: 0.6002, CORAL Loss: 0.0348\n",
      "Validation Loss: 0.6780\n",
      "Epoch [3/50], Class Loss: 0.5586, CORAL Loss: 0.0179\n",
      "Validation Loss: 0.5558\n",
      "Epoch [4/50], Class Loss: 0.5488, CORAL Loss: 0.0132\n",
      "Validation Loss: 0.5747\n",
      "Epoch [5/50], Class Loss: 0.5623, CORAL Loss: 0.0146\n",
      "Validation Loss: 0.5806\n",
      "Epoch [6/50], Class Loss: 0.5693, CORAL Loss: 0.0137\n",
      "Validation Loss: 0.6654\n",
      "Epoch [7/50], Class Loss: 0.5153, CORAL Loss: 0.0137\n",
      "Validation Loss: 0.6081\n",
      "Epoch [8/50], Class Loss: 0.4923, CORAL Loss: 0.0107\n",
      "Validation Loss: 0.6127\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 69.72%, Precision: 69.46%, Recall: 70.27%, F1 Score: 69.51%\n",
      "Target Domain Performance - Accuracy: 64.99%, Precision: 64.28%, Recall: 64.80%, F1 Score: 61.96%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 0.9327, CORAL Loss: 0.0549\n",
      "Validation Loss: 0.8287\n",
      "Epoch [2/50], Class Loss: 0.6476, CORAL Loss: 0.0360\n",
      "Validation Loss: 0.5809\n",
      "Epoch [3/50], Class Loss: 0.5667, CORAL Loss: 0.0196\n",
      "Validation Loss: 0.5555\n",
      "Epoch [4/50], Class Loss: 0.5550, CORAL Loss: 0.0140\n",
      "Validation Loss: 0.5629\n",
      "Epoch [5/50], Class Loss: 0.5620, CORAL Loss: 0.0158\n",
      "Validation Loss: 0.5972\n",
      "Epoch [6/50], Class Loss: 0.5410, CORAL Loss: 0.0134\n",
      "Validation Loss: 0.5646\n",
      "Epoch [7/50], Class Loss: 0.5286, CORAL Loss: 0.0110\n",
      "Validation Loss: 0.5701\n",
      "Epoch [8/50], Class Loss: 0.5341, CORAL Loss: 0.0168\n",
      "Validation Loss: 0.5682\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 71.28%, Precision: 70.27%, Recall: 71.30%, F1 Score: 70.54%\n",
      "Target Domain Performance - Accuracy: 62.35%, Precision: 62.20%, Recall: 62.27%, F1 Score: 57.02%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 1.0335, CORAL Loss: 0.0375\n",
      "Validation Loss: 0.5850\n",
      "Epoch [2/50], Class Loss: 0.5863, CORAL Loss: 0.0257\n",
      "Validation Loss: 0.6076\n",
      "Epoch [3/50], Class Loss: 0.5556, CORAL Loss: 0.0157\n",
      "Validation Loss: 0.5756\n",
      "Epoch [4/50], Class Loss: 0.5721, CORAL Loss: 0.0167\n",
      "Validation Loss: 0.5947\n",
      "Epoch [5/50], Class Loss: 0.6497, CORAL Loss: 0.0403\n",
      "Validation Loss: 0.5683\n",
      "Epoch [6/50], Class Loss: 0.5359, CORAL Loss: 0.0090\n",
      "Validation Loss: 0.5891\n",
      "Epoch [7/50], Class Loss: 0.5314, CORAL Loss: 0.0078\n",
      "Validation Loss: 0.5692\n",
      "Epoch [8/50], Class Loss: 0.5075, CORAL Loss: 0.0078\n",
      "Validation Loss: 0.5799\n",
      "Epoch [9/50], Class Loss: 0.5239, CORAL Loss: 0.0184\n",
      "Validation Loss: 0.5966\n",
      "Epoch [10/50], Class Loss: 0.4731, CORAL Loss: 0.0096\n",
      "Validation Loss: 0.6251\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 69.96%, Precision: 68.63%, Recall: 70.60%, F1 Score: 68.25%\n",
      "Target Domain Performance - Accuracy: 63.61%, Precision: 63.76%, Recall: 63.63%, F1 Score: 60.12%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 0.9588, CORAL Loss: 0.0396\n",
      "Validation Loss: 0.5633\n",
      "Epoch [2/50], Class Loss: 0.5846, CORAL Loss: 0.0205\n",
      "Validation Loss: 0.5578\n",
      "Epoch [3/50], Class Loss: 0.5999, CORAL Loss: 0.0165\n",
      "Validation Loss: 0.5836\n",
      "Epoch [4/50], Class Loss: 0.5767, CORAL Loss: 0.0181\n",
      "Validation Loss: 0.6274\n",
      "Epoch [5/50], Class Loss: 0.5539, CORAL Loss: 0.0127\n",
      "Validation Loss: 0.6407\n",
      "Epoch [6/50], Class Loss: 0.5266, CORAL Loss: 0.0090\n",
      "Validation Loss: 0.5644\n",
      "Epoch [7/50], Class Loss: 0.5113, CORAL Loss: 0.0111\n",
      "Validation Loss: 0.6185\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 69.90%, Precision: 69.50%, Recall: 70.72%, F1 Score: 69.11%\n",
      "Target Domain Performance - Accuracy: 66.97%, Precision: 66.35%, Recall: 66.90%, F1 Score: 64.31%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.0180, CORAL Loss: 0.0381\n",
      "Validation Loss: 0.7714\n",
      "Epoch [2/50], Class Loss: 0.6085, CORAL Loss: 0.0359\n",
      "Validation Loss: 0.5586\n",
      "Epoch [3/50], Class Loss: 0.5585, CORAL Loss: 0.0200\n",
      "Validation Loss: 0.5665\n",
      "Epoch [4/50], Class Loss: 0.5676, CORAL Loss: 0.0162\n",
      "Validation Loss: 0.5849\n",
      "Epoch [5/50], Class Loss: 0.5770, CORAL Loss: 0.0149\n",
      "Validation Loss: 0.6085\n",
      "Epoch [6/50], Class Loss: 0.5356, CORAL Loss: 0.0123\n",
      "Validation Loss: 0.5794\n",
      "Epoch [7/50], Class Loss: 0.5483, CORAL Loss: 0.0153\n",
      "Validation Loss: 0.5710\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 70.74%, Precision: 70.59%, Recall: 71.06%, F1 Score: 70.75%\n",
      "Target Domain Performance - Accuracy: 65.89%, Precision: 66.75%, Recall: 65.65%, F1 Score: 61.21%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 0.9410, CORAL Loss: 0.0451\n",
      "Validation Loss: 0.6089\n",
      "Epoch [2/50], Class Loss: 0.5814, CORAL Loss: 0.0251\n",
      "Validation Loss: 0.5891\n",
      "Epoch [3/50], Class Loss: 0.5781, CORAL Loss: 0.0171\n",
      "Validation Loss: 0.5618\n",
      "Epoch [4/50], Class Loss: 0.5949, CORAL Loss: 0.0194\n",
      "Validation Loss: 0.6214\n",
      "Epoch [5/50], Class Loss: 0.5513, CORAL Loss: 0.0138\n",
      "Validation Loss: 0.6841\n",
      "Epoch [6/50], Class Loss: 0.5436, CORAL Loss: 0.0145\n",
      "Validation Loss: 0.5690\n",
      "Epoch [7/50], Class Loss: 0.5410, CORAL Loss: 0.0133\n",
      "Validation Loss: 0.6278\n",
      "Epoch [8/50], Class Loss: 0.5083, CORAL Loss: 0.0147\n",
      "Validation Loss: 0.6513\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 69.96%, Precision: 72.29%, Recall: 68.97%, F1 Score: 66.79%\n",
      "Target Domain Performance - Accuracy: 58.39%, Precision: 61.56%, Recall: 58.25%, F1 Score: 49.94%\n",
      "\n",
      "Source performance: 70.01% 69.44% 70.16% 68.03%\n",
      "Target performance: 62.26% 63.01% 62.21% 56.97%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 100.00%\n",
      "qpsk: 95.36%\n",
      "16qam: 32.78%\n",
      "16apsk: 20.69%\n",
      "SNR level: 18\n",
      "JAN\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 1.1045, JMMD Loss: 0.2720\n",
      "Validation Loss: 0.6590\n",
      "Epoch [2/50], Class Loss: 0.5742, JMMD Loss: 0.3247\n",
      "Validation Loss: 0.5459\n",
      "Epoch [3/50], Class Loss: 0.5532, JMMD Loss: 0.3197\n",
      "Validation Loss: 0.5645\n",
      "Epoch [4/50], Class Loss: 0.5609, JMMD Loss: 0.3118\n",
      "Validation Loss: 0.5487\n",
      "Epoch [5/50], Class Loss: 0.5305, JMMD Loss: 0.3072\n",
      "Validation Loss: 0.5609\n",
      "Epoch [6/50], Class Loss: 0.5410, JMMD Loss: 0.2918\n",
      "Validation Loss: 0.5741\n",
      "Epoch [7/50], Class Loss: 0.5019, JMMD Loss: 0.2776\n",
      "Validation Loss: 0.5668\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 71.16%, Precision: 69.83%, Recall: 71.41%, F1 Score: 70.00%\n",
      "Target Domain Performance - Accuracy: 62.65%, Precision: 62.75%, Recall: 62.59%, F1 Score: 58.39%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 0.9322, JMMD Loss: 0.2904\n",
      "Validation Loss: 0.5931\n",
      "Epoch [2/50], Class Loss: 0.5678, JMMD Loss: 0.3419\n",
      "Validation Loss: 0.5724\n",
      "Epoch [3/50], Class Loss: 0.5463, JMMD Loss: 0.3105\n",
      "Validation Loss: 0.5503\n",
      "Epoch [4/50], Class Loss: 0.5544, JMMD Loss: 0.3137\n",
      "Validation Loss: 0.5515\n",
      "Epoch [5/50], Class Loss: 0.5342, JMMD Loss: 0.2950\n",
      "Validation Loss: 0.5721\n",
      "Epoch [6/50], Class Loss: 0.5272, JMMD Loss: 0.2805\n",
      "Validation Loss: 0.5680\n",
      "Epoch [7/50], Class Loss: 0.5081, JMMD Loss: 0.2455\n",
      "Validation Loss: 0.6007\n",
      "Epoch [8/50], Class Loss: 0.4634, JMMD Loss: 0.1943\n",
      "Validation Loss: 0.5878\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 70.80%, Precision: 69.45%, Recall: 70.82%, F1 Score: 69.71%\n",
      "Target Domain Performance - Accuracy: 62.35%, Precision: 61.47%, Recall: 62.20%, F1 Score: 58.26%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 0.9749, JMMD Loss: 0.2929\n",
      "Validation Loss: 0.6409\n",
      "Epoch [2/50], Class Loss: 0.5908, JMMD Loss: 0.3289\n",
      "Validation Loss: 0.5666\n",
      "Epoch [3/50], Class Loss: 0.5589, JMMD Loss: 0.3269\n",
      "Validation Loss: 0.5544\n",
      "Epoch [4/50], Class Loss: 0.5636, JMMD Loss: 0.3030\n",
      "Validation Loss: 0.5856\n",
      "Epoch [5/50], Class Loss: 0.5371, JMMD Loss: 0.3018\n",
      "Validation Loss: 0.5736\n",
      "Epoch [6/50], Class Loss: 0.5385, JMMD Loss: 0.2709\n",
      "Validation Loss: 0.7784\n",
      "Epoch [7/50], Class Loss: 0.5188, JMMD Loss: 0.2677\n",
      "Validation Loss: 0.6534\n",
      "Epoch [8/50], Class Loss: 0.5313, JMMD Loss: 0.2480\n",
      "Validation Loss: 0.5733\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 70.56%, Precision: 68.90%, Recall: 70.83%, F1 Score: 68.97%\n",
      "Target Domain Performance - Accuracy: 61.33%, Precision: 61.02%, Recall: 61.35%, F1 Score: 57.07%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 0.9195, JMMD Loss: 0.2920\n",
      "Validation Loss: 0.5562\n",
      "Epoch [2/50], Class Loss: 0.5823, JMMD Loss: 0.3187\n",
      "Validation Loss: 0.6072\n",
      "Epoch [3/50], Class Loss: 0.5684, JMMD Loss: 0.3099\n",
      "Validation Loss: 0.5782\n",
      "Epoch [4/50], Class Loss: 0.5417, JMMD Loss: 0.3015\n",
      "Validation Loss: 0.5422\n",
      "Epoch [5/50], Class Loss: 0.5708, JMMD Loss: 0.3061\n",
      "Validation Loss: 0.5712\n",
      "Epoch [6/50], Class Loss: 0.5197, JMMD Loss: 0.2627\n",
      "Validation Loss: 0.5547\n",
      "Epoch [7/50], Class Loss: 0.5148, JMMD Loss: 0.2100\n",
      "Validation Loss: 1.1932\n",
      "Epoch [8/50], Class Loss: 0.5898, JMMD Loss: 0.2095\n",
      "Validation Loss: 0.5562\n",
      "Epoch [9/50], Class Loss: 0.4855, JMMD Loss: 0.1654\n",
      "Validation Loss: 0.5834\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 70.02%, Precision: 70.43%, Recall: 70.22%, F1 Score: 70.29%\n",
      "Target Domain Performance - Accuracy: 59.65%, Precision: 60.17%, Recall: 58.61%, F1 Score: 57.89%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 0.9351, JMMD Loss: 0.2911\n",
      "Validation Loss: 1.1222\n",
      "Epoch [2/50], Class Loss: 0.6191, JMMD Loss: 0.3134\n",
      "Validation Loss: 0.6479\n",
      "Epoch [3/50], Class Loss: 0.5503, JMMD Loss: 0.3077\n",
      "Validation Loss: 0.5757\n",
      "Epoch [4/50], Class Loss: 0.5553, JMMD Loss: 0.2963\n",
      "Validation Loss: 0.5536\n",
      "Epoch [5/50], Class Loss: 0.5431, JMMD Loss: 0.2825\n",
      "Validation Loss: 0.5884\n",
      "Epoch [6/50], Class Loss: 0.5356, JMMD Loss: 0.2831\n",
      "Validation Loss: 0.5911\n",
      "Epoch [7/50], Class Loss: 0.5144, JMMD Loss: 0.2458\n",
      "Validation Loss: 0.7891\n",
      "Epoch [8/50], Class Loss: 0.4904, JMMD Loss: 0.2390\n",
      "Validation Loss: 0.5868\n",
      "Epoch [9/50], Class Loss: 0.4377, JMMD Loss: 0.1854\n",
      "Validation Loss: 0.6247\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 70.02%, Precision: 68.70%, Recall: 69.93%, F1 Score: 69.03%\n",
      "Target Domain Performance - Accuracy: 61.27%, Precision: 59.82%, Recall: 60.96%, F1 Score: 57.15%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 1.0212, JMMD Loss: 0.2771\n",
      "Validation Loss: 0.7543\n",
      "Epoch [2/50], Class Loss: 0.5812, JMMD Loss: 0.3158\n",
      "Validation Loss: 0.5695\n",
      "Epoch [3/50], Class Loss: 0.5585, JMMD Loss: 0.3200\n",
      "Validation Loss: 0.5635\n",
      "Epoch [4/50], Class Loss: 0.5424, JMMD Loss: 0.2959\n",
      "Validation Loss: 0.5611\n",
      "Epoch [5/50], Class Loss: 0.5925, JMMD Loss: 0.2923\n",
      "Validation Loss: 0.6138\n",
      "Epoch [6/50], Class Loss: 0.5311, JMMD Loss: 0.2850\n",
      "Validation Loss: 0.5709\n",
      "Epoch [7/50], Class Loss: 0.5015, JMMD Loss: 0.2535\n",
      "Validation Loss: 0.5724\n",
      "Epoch [8/50], Class Loss: 0.4860, JMMD Loss: 0.2144\n",
      "Validation Loss: 0.5948\n",
      "Epoch [9/50], Class Loss: 0.4795, JMMD Loss: 0.1853\n",
      "Validation Loss: 1.3293\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 53.54%, Precision: 61.06%, Recall: 55.62%, F1 Score: 49.46%\n",
      "Target Domain Performance - Accuracy: 54.56%, Precision: 53.85%, Recall: 53.90%, F1 Score: 50.21%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 1.0666, JMMD Loss: 0.2684\n",
      "Validation Loss: 0.6148\n",
      "Epoch [2/50], Class Loss: 0.5854, JMMD Loss: 0.3049\n",
      "Validation Loss: 0.6210\n",
      "Epoch [3/50], Class Loss: 0.5631, JMMD Loss: 0.3228\n",
      "Validation Loss: 0.5655\n",
      "Epoch [4/50], Class Loss: 0.5342, JMMD Loss: 0.2977\n",
      "Validation Loss: 0.6051\n",
      "Epoch [5/50], Class Loss: 0.5785, JMMD Loss: 0.2879\n",
      "Validation Loss: 0.5566\n",
      "Epoch [6/50], Class Loss: 0.5126, JMMD Loss: 0.2505\n",
      "Validation Loss: 0.5754\n",
      "Epoch [7/50], Class Loss: 0.6281, JMMD Loss: 0.2156\n",
      "Validation Loss: 0.5760\n",
      "Epoch [8/50], Class Loss: 0.5172, JMMD Loss: 0.2260\n",
      "Validation Loss: 0.6063\n",
      "Epoch [9/50], Class Loss: 0.4719, JMMD Loss: 0.1623\n",
      "Validation Loss: 0.5816\n",
      "Epoch [10/50], Class Loss: 0.4371, JMMD Loss: 0.1523\n",
      "Validation Loss: 0.6881\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 69.24%, Precision: 67.68%, Recall: 68.99%, F1 Score: 67.21%\n",
      "Target Domain Performance - Accuracy: 56.95%, Precision: 55.71%, Recall: 56.58%, F1 Score: 53.45%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 0.9690, JMMD Loss: 0.2714\n",
      "Validation Loss: 0.5626\n",
      "Epoch [2/50], Class Loss: 0.5994, JMMD Loss: 0.3199\n",
      "Validation Loss: 0.5707\n",
      "Epoch [3/50], Class Loss: 0.5596, JMMD Loss: 0.3265\n",
      "Validation Loss: 0.5864\n",
      "Epoch [4/50], Class Loss: 0.5407, JMMD Loss: 0.3163\n",
      "Validation Loss: 0.5800\n",
      "Epoch [5/50], Class Loss: 0.5461, JMMD Loss: 0.2902\n",
      "Validation Loss: 0.5729\n",
      "Epoch [6/50], Class Loss: 0.5278, JMMD Loss: 0.2740\n",
      "Validation Loss: 0.5567\n",
      "Epoch [7/50], Class Loss: 0.5075, JMMD Loss: 0.2555\n",
      "Validation Loss: 0.5852\n",
      "Epoch [8/50], Class Loss: 0.4801, JMMD Loss: 0.2002\n",
      "Validation Loss: 0.6346\n",
      "Epoch [9/50], Class Loss: 0.4562, JMMD Loss: 0.1787\n",
      "Validation Loss: 0.5983\n",
      "Epoch [10/50], Class Loss: 0.4446, JMMD Loss: 0.1711\n",
      "Validation Loss: 0.6043\n",
      "Epoch [11/50], Class Loss: 0.3446, JMMD Loss: 0.1968\n",
      "Validation Loss: 0.6502\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 71.58%, Precision: 70.23%, Recall: 71.70%, F1 Score: 70.53%\n",
      "Target Domain Performance - Accuracy: 62.05%, Precision: 60.25%, Recall: 61.86%, F1 Score: 59.04%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 0.9518, JMMD Loss: 0.2919\n",
      "Validation Loss: 0.6034\n",
      "Epoch [2/50], Class Loss: 0.5806, JMMD Loss: 0.3191\n",
      "Validation Loss: 0.5645\n",
      "Epoch [3/50], Class Loss: 0.5594, JMMD Loss: 0.3167\n",
      "Validation Loss: 0.5587\n",
      "Epoch [4/50], Class Loss: 0.5622, JMMD Loss: 0.3171\n",
      "Validation Loss: 0.5692\n",
      "Epoch [5/50], Class Loss: 0.5440, JMMD Loss: 0.3136\n",
      "Validation Loss: 0.6134\n",
      "Epoch [6/50], Class Loss: 0.5451, JMMD Loss: 0.2980\n",
      "Validation Loss: 0.5717\n",
      "Epoch [7/50], Class Loss: 0.5620, JMMD Loss: 0.2849\n",
      "Validation Loss: 0.5643\n",
      "Epoch [8/50], Class Loss: 0.5050, JMMD Loss: 0.2570\n",
      "Validation Loss: 0.6071\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 69.66%, Precision: 68.84%, Recall: 70.41%, F1 Score: 68.63%\n",
      "Target Domain Performance - Accuracy: 64.87%, Precision: 63.51%, Recall: 64.74%, F1 Score: 62.41%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 1.0937, JMMD Loss: 0.2768\n",
      "Validation Loss: 0.7444\n",
      "Epoch [2/50], Class Loss: 0.5740, JMMD Loss: 0.3192\n",
      "Validation Loss: 0.5538\n",
      "Epoch [3/50], Class Loss: 0.6206, JMMD Loss: 0.3151\n",
      "Validation Loss: 0.5856\n",
      "Epoch [4/50], Class Loss: 0.5458, JMMD Loss: 0.3153\n",
      "Validation Loss: 0.5826\n",
      "Epoch [5/50], Class Loss: 0.5268, JMMD Loss: 0.3029\n",
      "Validation Loss: 0.5996\n",
      "Epoch [6/50], Class Loss: 0.5227, JMMD Loss: 0.2718\n",
      "Validation Loss: 0.5656\n",
      "Epoch [7/50], Class Loss: 0.5163, JMMD Loss: 0.2524\n",
      "Validation Loss: 0.5806\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 72.06%, Precision: 71.06%, Recall: 72.00%, F1 Score: 71.23%\n",
      "Target Domain Performance - Accuracy: 62.05%, Precision: 62.23%, Recall: 61.90%, F1 Score: 56.83%\n",
      "\n",
      "Source performance: 68.87% 68.62% 69.19% 67.50%\n",
      "Target performance: 60.77% 60.08% 60.47% 57.07%\n",
      "\n",
      "Per-Class Accuracy on Target Domain (Mean over runs):\n",
      "  Class 0: 99.49%\n",
      "  Class 1: 79.51%\n",
      "  Class 2: 33.46%\n",
      "  Class 3: 29.43%\n",
      "SNR level: 18\n",
      "BASE\n",
      "\n",
      "Run 1/10\n",
      "Epoch 1/50, Train Loss: 0.8885, Train Acc: 0.6192, Val Loss: 0.5762, Val Acc: 0.6978\n",
      "Epoch 2/50, Train Loss: 0.5853, Train Acc: 0.7040, Val Loss: 0.5593, Val Acc: 0.7218\n",
      "Epoch 3/50, Train Loss: 0.5715, Train Acc: 0.7143, Val Loss: 0.6205, Val Acc: 0.6936\n",
      "Epoch 4/50, Train Loss: 0.5425, Train Acc: 0.7271, Val Loss: 0.5779, Val Acc: 0.7110\n",
      "Epoch 5/50, Train Loss: 0.5374, Train Acc: 0.7359, Val Loss: 0.5952, Val Acc: 0.7008\n",
      "Epoch 6/50, Train Loss: 0.5285, Train Acc: 0.7461, Val Loss: 0.6209, Val Acc: 0.7062\n",
      "Epoch 7/50, Train Loss: 0.4705, Train Acc: 0.7833, Val Loss: 0.5413, Val Acc: 0.7710\n",
      "Epoch 8/50, Train Loss: 0.3662, Train Acc: 0.8595, Val Loss: 0.3562, Val Acc: 0.8567\n",
      "Epoch 9/50, Train Loss: 0.2302, Train Acc: 0.9126, Val Loss: 0.2668, Val Acc: 0.8999\n",
      "Epoch 10/50, Train Loss: 0.1685, Train Acc: 0.9378, Val Loss: 0.2716, Val Acc: 0.8999\n",
      "Epoch 11/50, Train Loss: 0.0661, Train Acc: 0.9784, Val Loss: 0.2070, Val Acc: 0.9263\n",
      "Epoch 12/50, Train Loss: 0.0515, Train Acc: 0.9826, Val Loss: 0.2472, Val Acc: 0.9233\n",
      "Epoch 13/50, Train Loss: 0.0419, Train Acc: 0.9885, Val Loss: 0.2461, Val Acc: 0.9263\n",
      "Epoch 14/50, Train Loss: 0.0349, Train Acc: 0.9882, Val Loss: 0.2343, Val Acc: 0.9287\n",
      "Epoch 15/50, Train Loss: 0.0311, Train Acc: 0.9910, Val Loss: 0.2436, Val Acc: 0.9281\n",
      "Epoch 16/50, Train Loss: 0.0297, Train Acc: 0.9906, Val Loss: 0.2394, Val Acc: 0.9329\n",
      "Early stopping!\n",
      "\n",
      "Run 2/10\n",
      "Epoch 1/50, Train Loss: 0.9497, Train Acc: 0.6254, Val Loss: 0.7516, Val Acc: 0.6421\n",
      "Epoch 2/50, Train Loss: 0.6051, Train Acc: 0.7037, Val Loss: 0.5713, Val Acc: 0.7092\n",
      "Epoch 3/50, Train Loss: 0.5896, Train Acc: 0.7094, Val Loss: 0.5600, Val Acc: 0.7140\n",
      "Epoch 4/50, Train Loss: 0.5680, Train Acc: 0.7205, Val Loss: 0.5733, Val Acc: 0.7140\n",
      "Epoch 5/50, Train Loss: 0.5341, Train Acc: 0.7368, Val Loss: 0.6436, Val Acc: 0.6936\n",
      "Epoch 6/50, Train Loss: 0.5239, Train Acc: 0.7460, Val Loss: 0.5957, Val Acc: 0.7146\n",
      "Epoch 7/50, Train Loss: 0.5011, Train Acc: 0.7701, Val Loss: 0.5793, Val Acc: 0.7146\n",
      "Epoch 8/50, Train Loss: 0.4633, Train Acc: 0.7818, Val Loss: 0.6306, Val Acc: 0.7128\n",
      "Early stopping!\n",
      "\n",
      "Run 3/10\n",
      "Epoch 1/50, Train Loss: 0.8602, Train Acc: 0.6162, Val Loss: 0.5681, Val Acc: 0.7092\n",
      "Epoch 2/50, Train Loss: 0.5919, Train Acc: 0.7074, Val Loss: 0.6297, Val Acc: 0.7026\n",
      "Epoch 3/50, Train Loss: 0.5723, Train Acc: 0.7098, Val Loss: 0.5972, Val Acc: 0.7062\n",
      "Epoch 4/50, Train Loss: 0.5517, Train Acc: 0.7208, Val Loss: 0.5820, Val Acc: 0.7062\n",
      "Epoch 5/50, Train Loss: 0.5329, Train Acc: 0.7376, Val Loss: 0.5820, Val Acc: 0.6990\n",
      "Epoch 6/50, Train Loss: 0.5075, Train Acc: 0.7618, Val Loss: 0.6453, Val Acc: 0.7080\n",
      "Early stopping!\n",
      "\n",
      "Run 4/10\n",
      "Epoch 1/50, Train Loss: 0.9567, Train Acc: 0.5928, Val Loss: 0.6347, Val Acc: 0.6996\n",
      "Epoch 2/50, Train Loss: 0.5817, Train Acc: 0.7019, Val Loss: 0.5805, Val Acc: 0.7212\n",
      "Epoch 3/50, Train Loss: 0.5551, Train Acc: 0.7245, Val Loss: 0.5704, Val Acc: 0.7140\n",
      "Epoch 4/50, Train Loss: 0.5633, Train Acc: 0.7290, Val Loss: 0.5698, Val Acc: 0.7098\n",
      "Epoch 5/50, Train Loss: 0.5296, Train Acc: 0.7443, Val Loss: 0.5790, Val Acc: 0.7158\n",
      "Epoch 6/50, Train Loss: 0.5068, Train Acc: 0.7579, Val Loss: 0.6208, Val Acc: 0.6966\n",
      "Epoch 7/50, Train Loss: 0.4710, Train Acc: 0.7840, Val Loss: 0.6069, Val Acc: 0.7092\n",
      "Epoch 8/50, Train Loss: 0.4226, Train Acc: 0.8106, Val Loss: 0.6642, Val Acc: 0.6972\n",
      "Epoch 9/50, Train Loss: 0.3552, Train Acc: 0.8424, Val Loss: 0.7070, Val Acc: 0.7014\n",
      "Early stopping!\n",
      "\n",
      "Run 5/10\n",
      "Epoch 1/50, Train Loss: 0.8302, Train Acc: 0.6242, Val Loss: 0.5649, Val Acc: 0.7074\n",
      "Epoch 2/50, Train Loss: 0.5903, Train Acc: 0.7056, Val Loss: 0.5590, Val Acc: 0.7308\n",
      "Epoch 3/50, Train Loss: 0.5710, Train Acc: 0.7148, Val Loss: 0.5718, Val Acc: 0.7236\n",
      "Epoch 4/50, Train Loss: 0.5513, Train Acc: 0.7257, Val Loss: 0.5634, Val Acc: 0.7170\n",
      "Epoch 5/50, Train Loss: 0.5355, Train Acc: 0.7394, Val Loss: 0.5748, Val Acc: 0.7152\n",
      "Epoch 6/50, Train Loss: 0.4964, Train Acc: 0.7603, Val Loss: 0.6009, Val Acc: 0.7194\n",
      "Epoch 7/50, Train Loss: 0.3984, Train Acc: 0.8263, Val Loss: 0.6855, Val Acc: 0.7368\n",
      "Early stopping!\n",
      "\n",
      "Run 6/10\n",
      "Epoch 1/50, Train Loss: 0.8928, Train Acc: 0.5937, Val Loss: 0.5563, Val Acc: 0.7110\n",
      "Epoch 2/50, Train Loss: 0.5748, Train Acc: 0.7089, Val Loss: 0.5860, Val Acc: 0.6972\n",
      "Epoch 3/50, Train Loss: 0.5533, Train Acc: 0.7179, Val Loss: 0.5629, Val Acc: 0.7122\n",
      "Epoch 4/50, Train Loss: 0.5521, Train Acc: 0.7247, Val Loss: 0.5613, Val Acc: 0.7200\n",
      "Epoch 5/50, Train Loss: 0.5306, Train Acc: 0.7415, Val Loss: 0.5784, Val Acc: 0.7080\n",
      "Epoch 6/50, Train Loss: 0.5221, Train Acc: 0.7528, Val Loss: 0.5617, Val Acc: 0.7170\n",
      "Early stopping!\n",
      "\n",
      "Run 7/10\n",
      "Epoch 1/50, Train Loss: 0.8650, Train Acc: 0.6099, Val Loss: 0.5891, Val Acc: 0.7134\n",
      "Epoch 2/50, Train Loss: 0.5676, Train Acc: 0.7191, Val Loss: 0.6355, Val Acc: 0.7080\n",
      "Epoch 3/50, Train Loss: 0.5834, Train Acc: 0.7139, Val Loss: 0.6675, Val Acc: 0.6853\n",
      "Epoch 4/50, Train Loss: 0.5534, Train Acc: 0.7308, Val Loss: 0.5666, Val Acc: 0.7176\n",
      "Epoch 5/50, Train Loss: 0.5269, Train Acc: 0.7374, Val Loss: 0.6528, Val Acc: 0.6906\n",
      "Epoch 6/50, Train Loss: 0.5111, Train Acc: 0.7473, Val Loss: 0.6014, Val Acc: 0.7092\n",
      "Epoch 7/50, Train Loss: 0.4801, Train Acc: 0.7680, Val Loss: 0.6025, Val Acc: 0.7134\n",
      "Epoch 8/50, Train Loss: 0.4082, Train Acc: 0.8197, Val Loss: 0.5376, Val Acc: 0.7806\n",
      "Epoch 9/50, Train Loss: 0.2630, Train Acc: 0.8955, Val Loss: 0.4526, Val Acc: 0.8459\n",
      "Epoch 10/50, Train Loss: 0.2107, Train Acc: 0.9189, Val Loss: 0.4764, Val Acc: 0.8345\n",
      "Epoch 11/50, Train Loss: 0.0654, Train Acc: 0.9792, Val Loss: 0.4127, Val Acc: 0.8813\n",
      "Epoch 12/50, Train Loss: 0.0460, Train Acc: 0.9856, Val Loss: 0.4473, Val Acc: 0.8699\n",
      "Epoch 13/50, Train Loss: 0.0373, Train Acc: 0.9880, Val Loss: 0.3647, Val Acc: 0.9035\n",
      "Epoch 14/50, Train Loss: 0.0324, Train Acc: 0.9885, Val Loss: 0.4179, Val Acc: 0.8927\n",
      "Epoch 15/50, Train Loss: 0.0273, Train Acc: 0.9921, Val Loss: 0.3778, Val Acc: 0.9005\n",
      "Epoch 16/50, Train Loss: 0.0224, Train Acc: 0.9934, Val Loss: 0.4114, Val Acc: 0.8981\n",
      "Epoch 17/50, Train Loss: 0.0149, Train Acc: 0.9958, Val Loss: 0.3964, Val Acc: 0.9077\n",
      "Epoch 18/50, Train Loss: 0.0105, Train Acc: 0.9978, Val Loss: 0.4056, Val Acc: 0.9071\n",
      "Early stopping!\n",
      "\n",
      "Run 8/10\n",
      "Epoch 1/50, Train Loss: 1.2932, Train Acc: 0.5625, Val Loss: 0.6208, Val Acc: 0.6781\n",
      "Epoch 2/50, Train Loss: 0.6018, Train Acc: 0.6975, Val Loss: 0.7055, Val Acc: 0.6553\n",
      "Epoch 3/50, Train Loss: 0.5614, Train Acc: 0.7232, Val Loss: 0.6021, Val Acc: 0.7062\n",
      "Epoch 4/50, Train Loss: 0.5447, Train Acc: 0.7266, Val Loss: 0.6267, Val Acc: 0.6727\n",
      "Epoch 5/50, Train Loss: 0.5449, Train Acc: 0.7208, Val Loss: 0.5727, Val Acc: 0.7182\n",
      "Epoch 6/50, Train Loss: 0.5196, Train Acc: 0.7376, Val Loss: 0.5514, Val Acc: 0.7230\n",
      "Epoch 7/50, Train Loss: 0.4853, Train Acc: 0.7671, Val Loss: 0.6786, Val Acc: 0.6966\n",
      "Epoch 8/50, Train Loss: 0.4523, Train Acc: 0.7947, Val Loss: 0.5419, Val Acc: 0.7578\n",
      "Epoch 9/50, Train Loss: 0.3616, Train Acc: 0.8460, Val Loss: 0.4512, Val Acc: 0.8153\n",
      "Epoch 10/50, Train Loss: 0.2265, Train Acc: 0.9112, Val Loss: 0.3691, Val Acc: 0.8801\n",
      "Epoch 11/50, Train Loss: 0.0994, Train Acc: 0.9630, Val Loss: 0.2706, Val Acc: 0.9071\n",
      "Epoch 12/50, Train Loss: 0.0832, Train Acc: 0.9696, Val Loss: 0.3785, Val Acc: 0.8783\n",
      "Epoch 13/50, Train Loss: 0.0738, Train Acc: 0.9732, Val Loss: 0.2842, Val Acc: 0.9011\n",
      "Epoch 14/50, Train Loss: 0.0597, Train Acc: 0.9786, Val Loss: 0.2789, Val Acc: 0.9113\n",
      "Epoch 15/50, Train Loss: 0.0522, Train Acc: 0.9819, Val Loss: 0.2881, Val Acc: 0.9095\n",
      "Epoch 16/50, Train Loss: 0.0450, Train Acc: 0.9853, Val Loss: 0.2741, Val Acc: 0.9167\n",
      "Early stopping!\n",
      "\n",
      "Run 9/10\n",
      "Epoch 1/50, Train Loss: 0.8130, Train Acc: 0.6305, Val Loss: 0.5643, Val Acc: 0.7230\n",
      "Epoch 2/50, Train Loss: 0.5912, Train Acc: 0.7064, Val Loss: 0.6504, Val Acc: 0.6900\n",
      "Epoch 3/50, Train Loss: 0.5831, Train Acc: 0.7149, Val Loss: 0.5726, Val Acc: 0.7158\n",
      "Epoch 4/50, Train Loss: 0.5467, Train Acc: 0.7346, Val Loss: 0.5826, Val Acc: 0.7074\n",
      "Epoch 5/50, Train Loss: 0.5534, Train Acc: 0.7326, Val Loss: 0.5919, Val Acc: 0.7134\n",
      "Epoch 6/50, Train Loss: 0.5305, Train Acc: 0.7496, Val Loss: 0.5774, Val Acc: 0.7062\n",
      "Early stopping!\n",
      "\n",
      "Run 10/10\n",
      "Epoch 1/50, Train Loss: 0.7771, Train Acc: 0.6365, Val Loss: 0.5807, Val Acc: 0.7176\n",
      "Epoch 2/50, Train Loss: 0.5677, Train Acc: 0.7182, Val Loss: 0.5585, Val Acc: 0.7308\n",
      "Epoch 3/50, Train Loss: 0.5601, Train Acc: 0.7221, Val Loss: 0.5590, Val Acc: 0.7140\n",
      "Epoch 4/50, Train Loss: 0.5549, Train Acc: 0.7263, Val Loss: 0.5756, Val Acc: 0.7152\n",
      "Epoch 5/50, Train Loss: 0.5314, Train Acc: 0.7404, Val Loss: 0.5909, Val Acc: 0.7068\n",
      "Epoch 6/50, Train Loss: 0.5007, Train Acc: 0.7573, Val Loss: 0.5886, Val Acc: 0.7074\n",
      "Epoch 7/50, Train Loss: 0.4791, Train Acc: 0.7777, Val Loss: 0.6470, Val Acc: 0.6906\n",
      "Early stopping!\n",
      "\n",
      "Source performance: 77.30 78.16 77.41 75.63\n",
      "Target performance: 62.52 64.87 61.81 58.03\n",
      "\n",
      "bpsk: 100.00\n",
      "qpsk: 70.03\n",
      "16qam: 54.29\n",
      "16apsk: 22.91\n",
      "SNR level: 18\n",
      "DANN\n",
      "Epoch 1/50, Loss: 3.4659, Domain Loss: 1.9591, Class Loss: 1.5068\n",
      "Epoch 2/50, Loss: 1.9543, Domain Loss: 1.3360, Class Loss: 0.6183\n",
      "Epoch 3/50, Loss: 1.8441, Domain Loss: 1.2807, Class Loss: 0.5634\n",
      "Epoch 4/50, Loss: 1.8652, Domain Loss: 1.2747, Class Loss: 0.5905\n",
      "Epoch 5/50, Loss: 1.9477, Domain Loss: 1.2888, Class Loss: 0.6589\n",
      "Epoch 6/50, Loss: 1.8544, Domain Loss: 1.2562, Class Loss: 0.5982\n",
      "Epoch 7/50, Loss: 1.7968, Domain Loss: 1.2364, Class Loss: 0.5603\n",
      "Epoch 8/50, Loss: 1.8118, Domain Loss: 1.2381, Class Loss: 0.5737\n",
      "Epoch 9/50, Loss: 1.8207, Domain Loss: 1.2435, Class Loss: 0.5772\n",
      "Epoch 10/50, Loss: 1.8023, Domain Loss: 1.2327, Class Loss: 0.5696\n",
      "Epoch 11/50, Loss: 1.8911, Domain Loss: 1.2604, Class Loss: 0.6308\n",
      "Epoch 12/50, Loss: 1.8345, Domain Loss: 1.2425, Class Loss: 0.5921\n",
      "Epoch 13/50, Loss: 1.7440, Domain Loss: 1.2248, Class Loss: 0.5192\n",
      "Epoch 14/50, Loss: 1.7822, Domain Loss: 1.2285, Class Loss: 0.5537\n",
      "Epoch 15/50, Loss: 1.8765, Domain Loss: 1.3196, Class Loss: 0.5569\n",
      "Epoch 16/50, Loss: 3.0611, Domain Loss: 2.2595, Class Loss: 0.8016\n",
      "Epoch 17/50, Loss: 2.6269, Domain Loss: 1.8715, Class Loss: 0.7555\n",
      "Epoch 18/50, Loss: 2.1898, Domain Loss: 1.3864, Class Loss: 0.8035\n",
      "Epoch 19/50, Loss: 1.9329, Domain Loss: 1.3863, Class Loss: 0.5466\n",
      "Epoch 20/50, Loss: 1.9393, Domain Loss: 1.3863, Class Loss: 0.5530\n",
      "Epoch 21/50, Loss: 1.9158, Domain Loss: 1.3863, Class Loss: 0.5295\n",
      "Epoch 22/50, Loss: 1.9265, Domain Loss: 1.3863, Class Loss: 0.5402\n",
      "Epoch 23/50, Loss: 1.9187, Domain Loss: 1.3863, Class Loss: 0.5324\n",
      "Epoch 24/50, Loss: 1.9120, Domain Loss: 1.3863, Class Loss: 0.5257\n",
      "Epoch 25/50, Loss: 1.8921, Domain Loss: 1.3863, Class Loss: 0.5058\n",
      "Epoch 26/50, Loss: 1.9108, Domain Loss: 1.3863, Class Loss: 0.5245\n",
      "Epoch 27/50, Loss: 1.9342, Domain Loss: 1.3863, Class Loss: 0.5479\n",
      "Epoch 28/50, Loss: 1.9124, Domain Loss: 1.3863, Class Loss: 0.5261\n",
      "Epoch 29/50, Loss: 1.9014, Domain Loss: 1.3863, Class Loss: 0.5151\n",
      "Epoch 30/50, Loss: 1.9099, Domain Loss: 1.3863, Class Loss: 0.5236\n",
      "Epoch 31/50, Loss: 1.8917, Domain Loss: 1.3863, Class Loss: 0.5054\n",
      "Epoch 32/50, Loss: 1.8823, Domain Loss: 1.3863, Class Loss: 0.4960\n",
      "Epoch 33/50, Loss: 1.8858, Domain Loss: 1.3863, Class Loss: 0.4995\n",
      "Epoch 34/50, Loss: 1.8878, Domain Loss: 1.3863, Class Loss: 0.5015\n",
      "Epoch 35/50, Loss: 1.8818, Domain Loss: 1.3863, Class Loss: 0.4955\n",
      "Epoch 36/50, Loss: 1.9028, Domain Loss: 1.3863, Class Loss: 0.5165\n",
      "Epoch 37/50, Loss: 1.8666, Domain Loss: 1.3863, Class Loss: 0.4803\n",
      "Epoch 38/50, Loss: 1.8811, Domain Loss: 1.3863, Class Loss: 0.4948\n",
      "Epoch 39/50, Loss: 1.8514, Domain Loss: 1.3863, Class Loss: 0.4651\n",
      "Epoch 40/50, Loss: 1.8716, Domain Loss: 1.3863, Class Loss: 0.4853\n",
      "Epoch 41/50, Loss: 1.8466, Domain Loss: 1.3863, Class Loss: 0.4603\n",
      "Epoch 42/50, Loss: 1.8549, Domain Loss: 1.3863, Class Loss: 0.4686\n",
      "Epoch 43/50, Loss: 1.8217, Domain Loss: 1.3863, Class Loss: 0.4354\n",
      "Epoch 44/50, Loss: 1.8533, Domain Loss: 1.3863, Class Loss: 0.4670\n",
      "Epoch 45/50, Loss: 1.8315, Domain Loss: 1.3863, Class Loss: 0.4452\n",
      "Epoch 46/50, Loss: 1.8146, Domain Loss: 1.3862, Class Loss: 0.4285\n",
      "Epoch 47/50, Loss: 1.8029, Domain Loss: 1.3859, Class Loss: 0.4170\n",
      "Epoch 48/50, Loss: 1.7795, Domain Loss: 1.3858, Class Loss: 0.3937\n",
      "Epoch 49/50, Loss: 1.7715, Domain Loss: 1.3762, Class Loss: 0.3953\n",
      "Epoch 50/50, Loss: 1.6751, Domain Loss: 1.3047, Class Loss: 0.3704\n",
      "60.79\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8680, Domain Loss: 1.8447, Class Loss: 2.0233\n",
      "Epoch 2/50, Loss: 2.2438, Domain Loss: 1.3583, Class Loss: 0.8854\n",
      "Epoch 3/50, Loss: 1.8959, Domain Loss: 1.3034, Class Loss: 0.5924\n",
      "Epoch 4/50, Loss: 1.8730, Domain Loss: 1.2772, Class Loss: 0.5958\n",
      "Epoch 5/50, Loss: 1.8127, Domain Loss: 1.2655, Class Loss: 0.5472\n",
      "Epoch 6/50, Loss: 1.8260, Domain Loss: 1.2551, Class Loss: 0.5709\n",
      "Epoch 7/50, Loss: 1.7916, Domain Loss: 1.2616, Class Loss: 0.5301\n",
      "Epoch 8/50, Loss: 1.7809, Domain Loss: 1.2537, Class Loss: 0.5272\n",
      "Epoch 9/50, Loss: 1.7896, Domain Loss: 1.2419, Class Loss: 0.5477\n",
      "Epoch 10/50, Loss: 1.8016, Domain Loss: 1.2512, Class Loss: 0.5504\n",
      "Epoch 11/50, Loss: 1.7853, Domain Loss: 1.2503, Class Loss: 0.5350\n",
      "Epoch 12/50, Loss: 1.8416, Domain Loss: 1.2621, Class Loss: 0.5795\n",
      "Epoch 13/50, Loss: 1.7972, Domain Loss: 1.2576, Class Loss: 0.5396\n",
      "Epoch 14/50, Loss: 1.9056, Domain Loss: 1.2837, Class Loss: 0.6219\n",
      "Epoch 15/50, Loss: 1.8237, Domain Loss: 1.2638, Class Loss: 0.5599\n",
      "Epoch 16/50, Loss: 1.8003, Domain Loss: 1.2601, Class Loss: 0.5402\n",
      "Epoch 17/50, Loss: 1.8758, Domain Loss: 1.2679, Class Loss: 0.6080\n",
      "Epoch 18/50, Loss: 1.8547, Domain Loss: 1.2914, Class Loss: 0.5634\n",
      "Epoch 19/50, Loss: 1.8222, Domain Loss: 1.2555, Class Loss: 0.5667\n",
      "Epoch 20/50, Loss: 1.7786, Domain Loss: 1.2426, Class Loss: 0.5360\n",
      "Epoch 21/50, Loss: 1.7801, Domain Loss: 1.2356, Class Loss: 0.5445\n",
      "Epoch 22/50, Loss: 1.8254, Domain Loss: 1.2445, Class Loss: 0.5809\n",
      "Epoch 23/50, Loss: 1.7509, Domain Loss: 1.2050, Class Loss: 0.5459\n",
      "Epoch 24/50, Loss: 1.7829, Domain Loss: 1.2579, Class Loss: 0.5250\n",
      "Epoch 25/50, Loss: 1.7235, Domain Loss: 1.1989, Class Loss: 0.5245\n",
      "Epoch 26/50, Loss: 1.7218, Domain Loss: 1.1730, Class Loss: 0.5488\n",
      "Epoch 27/50, Loss: 1.7593, Domain Loss: 1.2099, Class Loss: 0.5495\n",
      "Epoch 28/50, Loss: 1.7219, Domain Loss: 1.1814, Class Loss: 0.5406\n",
      "Epoch 29/50, Loss: 1.8252, Domain Loss: 1.2665, Class Loss: 0.5586\n",
      "Epoch 30/50, Loss: 1.7943, Domain Loss: 1.2592, Class Loss: 0.5351\n",
      "Epoch 31/50, Loss: 1.6975, Domain Loss: 1.1713, Class Loss: 0.5262\n",
      "Epoch 32/50, Loss: 1.7788, Domain Loss: 1.1752, Class Loss: 0.6036\n",
      "Epoch 33/50, Loss: 2.0740, Domain Loss: 1.2192, Class Loss: 0.8548\n",
      "Epoch 34/50, Loss: 1.6386, Domain Loss: 1.1023, Class Loss: 0.5363\n",
      "Epoch 35/50, Loss: 1.6983, Domain Loss: 1.1354, Class Loss: 0.5629\n",
      "Epoch 36/50, Loss: 1.6114, Domain Loss: 1.0997, Class Loss: 0.5117\n",
      "Epoch 37/50, Loss: 1.5990, Domain Loss: 1.1091, Class Loss: 0.4899\n",
      "Epoch 38/50, Loss: 1.5798, Domain Loss: 1.1319, Class Loss: 0.4478\n",
      "Epoch 39/50, Loss: 1.8303, Domain Loss: 1.2852, Class Loss: 0.5451\n",
      "Epoch 40/50, Loss: 1.7853, Domain Loss: 1.2903, Class Loss: 0.4950\n",
      "Epoch 41/50, Loss: 1.9036, Domain Loss: 1.3488, Class Loss: 0.5547\n",
      "Epoch 42/50, Loss: 1.8373, Domain Loss: 1.2964, Class Loss: 0.5409\n",
      "Epoch 43/50, Loss: 1.8664, Domain Loss: 1.3698, Class Loss: 0.4966\n",
      "Epoch 44/50, Loss: 1.8410, Domain Loss: 1.3910, Class Loss: 0.4500\n",
      "Epoch 45/50, Loss: 1.8292, Domain Loss: 1.3888, Class Loss: 0.4403\n",
      "Epoch 46/50, Loss: 1.8184, Domain Loss: 1.3876, Class Loss: 0.4307\n",
      "Epoch 47/50, Loss: 1.7916, Domain Loss: 1.3867, Class Loss: 0.4049\n",
      "Epoch 48/50, Loss: 1.7951, Domain Loss: 1.3867, Class Loss: 0.4083\n",
      "Epoch 49/50, Loss: 1.8041, Domain Loss: 1.3864, Class Loss: 0.4176\n",
      "Epoch 50/50, Loss: 1.7682, Domain Loss: 1.3855, Class Loss: 0.3827\n",
      "62.41\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.8144, Domain Loss: 2.0058, Class Loss: 1.8086\n",
      "Epoch 2/50, Loss: 2.0862, Domain Loss: 1.3776, Class Loss: 0.7086\n",
      "Epoch 3/50, Loss: 2.0293, Domain Loss: 1.3920, Class Loss: 0.6373\n",
      "Epoch 4/50, Loss: 1.9135, Domain Loss: 1.3234, Class Loss: 0.5901\n",
      "Epoch 5/50, Loss: 1.8640, Domain Loss: 1.2991, Class Loss: 0.5649\n",
      "Epoch 6/50, Loss: 1.8463, Domain Loss: 1.2743, Class Loss: 0.5720\n",
      "Epoch 7/50, Loss: 2.0177, Domain Loss: 1.4332, Class Loss: 0.5845\n",
      "Epoch 8/50, Loss: 2.0733, Domain Loss: 1.4016, Class Loss: 0.6717\n",
      "Epoch 9/50, Loss: 1.8824, Domain Loss: 1.2995, Class Loss: 0.5829\n",
      "Epoch 10/50, Loss: 1.9435, Domain Loss: 1.3204, Class Loss: 0.6231\n",
      "Epoch 11/50, Loss: 2.0738, Domain Loss: 1.3712, Class Loss: 0.7026\n",
      "Epoch 12/50, Loss: 2.0649, Domain Loss: 1.3790, Class Loss: 0.6859\n",
      "Epoch 13/50, Loss: 1.9417, Domain Loss: 1.3542, Class Loss: 0.5875\n",
      "Epoch 14/50, Loss: 1.8828, Domain Loss: 1.3084, Class Loss: 0.5744\n",
      "Epoch 15/50, Loss: 1.8186, Domain Loss: 1.2711, Class Loss: 0.5476\n",
      "Epoch 16/50, Loss: 1.7966, Domain Loss: 1.2633, Class Loss: 0.5333\n",
      "Epoch 17/50, Loss: 1.8471, Domain Loss: 1.3017, Class Loss: 0.5454\n",
      "Epoch 18/50, Loss: 1.8203, Domain Loss: 1.2705, Class Loss: 0.5499\n",
      "Epoch 19/50, Loss: 1.8422, Domain Loss: 1.3068, Class Loss: 0.5355\n",
      "Epoch 20/50, Loss: 1.8599, Domain Loss: 1.3271, Class Loss: 0.5328\n",
      "Epoch 21/50, Loss: 1.9554, Domain Loss: 1.3588, Class Loss: 0.5965\n",
      "Epoch 22/50, Loss: 1.9913, Domain Loss: 1.3543, Class Loss: 0.6370\n",
      "Epoch 23/50, Loss: 1.9531, Domain Loss: 1.3625, Class Loss: 0.5905\n",
      "Epoch 24/50, Loss: 1.8928, Domain Loss: 1.3470, Class Loss: 0.5458\n",
      "Epoch 25/50, Loss: 1.7996, Domain Loss: 1.3017, Class Loss: 0.4979\n",
      "Epoch 26/50, Loss: 1.8607, Domain Loss: 1.2912, Class Loss: 0.5694\n",
      "Epoch 27/50, Loss: 1.8144, Domain Loss: 1.2775, Class Loss: 0.5368\n",
      "Epoch 28/50, Loss: 1.7908, Domain Loss: 1.2731, Class Loss: 0.5177\n",
      "Epoch 29/50, Loss: 1.8564, Domain Loss: 1.3073, Class Loss: 0.5491\n",
      "Epoch 30/50, Loss: 1.7533, Domain Loss: 1.2580, Class Loss: 0.4952\n",
      "Epoch 31/50, Loss: 1.8711, Domain Loss: 1.2874, Class Loss: 0.5838\n",
      "Epoch 32/50, Loss: 1.8356, Domain Loss: 1.2891, Class Loss: 0.5465\n",
      "Epoch 33/50, Loss: 1.8276, Domain Loss: 1.3155, Class Loss: 0.5121\n",
      "Epoch 34/50, Loss: 1.8371, Domain Loss: 1.3020, Class Loss: 0.5351\n",
      "Epoch 35/50, Loss: 1.8080, Domain Loss: 1.2898, Class Loss: 0.5182\n",
      "Epoch 36/50, Loss: 1.7620, Domain Loss: 1.2691, Class Loss: 0.4928\n",
      "Epoch 37/50, Loss: 1.7734, Domain Loss: 1.2749, Class Loss: 0.4985\n",
      "Epoch 38/50, Loss: 1.7756, Domain Loss: 1.2639, Class Loss: 0.5117\n",
      "Epoch 39/50, Loss: 1.8000, Domain Loss: 1.2852, Class Loss: 0.5147\n",
      "Epoch 40/50, Loss: 1.7980, Domain Loss: 1.2966, Class Loss: 0.5015\n",
      "Epoch 41/50, Loss: 1.7589, Domain Loss: 1.2873, Class Loss: 0.4716\n",
      "Epoch 42/50, Loss: 1.7306, Domain Loss: 1.2680, Class Loss: 0.4627\n",
      "Epoch 43/50, Loss: 1.7120, Domain Loss: 1.2707, Class Loss: 0.4413\n",
      "Epoch 44/50, Loss: 1.6997, Domain Loss: 1.2660, Class Loss: 0.4337\n",
      "Epoch 45/50, Loss: 1.6403, Domain Loss: 1.2335, Class Loss: 0.4069\n",
      "Epoch 46/50, Loss: 1.7759, Domain Loss: 1.3059, Class Loss: 0.4700\n",
      "Epoch 47/50, Loss: 1.8288, Domain Loss: 1.3220, Class Loss: 0.5068\n",
      "Epoch 48/50, Loss: 1.8137, Domain Loss: 1.3698, Class Loss: 0.4439\n",
      "Epoch 49/50, Loss: 1.7816, Domain Loss: 1.3423, Class Loss: 0.4393\n",
      "Epoch 50/50, Loss: 1.7519, Domain Loss: 1.3322, Class Loss: 0.4197\n",
      "62.65\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.7235, Domain Loss: 2.0397, Class Loss: 1.6838\n",
      "Epoch 2/50, Loss: 2.0290, Domain Loss: 1.3872, Class Loss: 0.6418\n",
      "Epoch 3/50, Loss: 1.8888, Domain Loss: 1.3449, Class Loss: 0.5438\n",
      "Epoch 4/50, Loss: 1.9510, Domain Loss: 1.3210, Class Loss: 0.6301\n",
      "Epoch 5/50, Loss: 1.8473, Domain Loss: 1.2834, Class Loss: 0.5639\n",
      "Epoch 6/50, Loss: 1.8495, Domain Loss: 1.2579, Class Loss: 0.5916\n",
      "Epoch 7/50, Loss: 1.8299, Domain Loss: 1.2683, Class Loss: 0.5616\n",
      "Epoch 8/50, Loss: 1.8326, Domain Loss: 1.2723, Class Loss: 0.5603\n",
      "Epoch 9/50, Loss: 1.8764, Domain Loss: 1.2600, Class Loss: 0.6164\n",
      "Epoch 10/50, Loss: 1.8143, Domain Loss: 1.2661, Class Loss: 0.5482\n",
      "Epoch 11/50, Loss: 1.8203, Domain Loss: 1.2673, Class Loss: 0.5530\n",
      "Epoch 12/50, Loss: 1.7948, Domain Loss: 1.2468, Class Loss: 0.5480\n",
      "Epoch 13/50, Loss: 1.7940, Domain Loss: 1.2458, Class Loss: 0.5482\n",
      "Epoch 14/50, Loss: 1.8465, Domain Loss: 1.2467, Class Loss: 0.5998\n",
      "Epoch 15/50, Loss: 1.8975, Domain Loss: 1.3295, Class Loss: 0.5680\n",
      "Epoch 16/50, Loss: 1.8593, Domain Loss: 1.2825, Class Loss: 0.5768\n",
      "Epoch 17/50, Loss: 1.8172, Domain Loss: 1.2811, Class Loss: 0.5362\n",
      "Epoch 18/50, Loss: 1.7763, Domain Loss: 1.2632, Class Loss: 0.5130\n",
      "Epoch 19/50, Loss: 1.8059, Domain Loss: 1.2800, Class Loss: 0.5258\n",
      "Epoch 20/50, Loss: 1.9614, Domain Loss: 1.3984, Class Loss: 0.5631\n",
      "Epoch 21/50, Loss: 1.9856, Domain Loss: 1.4156, Class Loss: 0.5700\n",
      "Epoch 22/50, Loss: 1.9134, Domain Loss: 1.3415, Class Loss: 0.5719\n",
      "Epoch 23/50, Loss: 1.8839, Domain Loss: 1.3065, Class Loss: 0.5773\n",
      "Epoch 24/50, Loss: 1.9321, Domain Loss: 1.3273, Class Loss: 0.6048\n",
      "Epoch 25/50, Loss: 1.8383, Domain Loss: 1.3092, Class Loss: 0.5291\n",
      "Epoch 26/50, Loss: 1.8701, Domain Loss: 1.3133, Class Loss: 0.5568\n",
      "Epoch 27/50, Loss: 2.1817, Domain Loss: 1.3447, Class Loss: 0.8370\n",
      "Epoch 28/50, Loss: 1.8917, Domain Loss: 1.2728, Class Loss: 0.6189\n",
      "Epoch 29/50, Loss: 1.8971, Domain Loss: 1.3457, Class Loss: 0.5514\n",
      "Epoch 30/50, Loss: 1.9616, Domain Loss: 1.4275, Class Loss: 0.5342\n",
      "Epoch 31/50, Loss: 1.7930, Domain Loss: 1.2781, Class Loss: 0.5149\n",
      "Epoch 32/50, Loss: 1.8455, Domain Loss: 1.3307, Class Loss: 0.5148\n",
      "Epoch 33/50, Loss: 1.7925, Domain Loss: 1.2861, Class Loss: 0.5064\n",
      "Epoch 34/50, Loss: 1.7830, Domain Loss: 1.2647, Class Loss: 0.5183\n",
      "Epoch 35/50, Loss: 1.8356, Domain Loss: 1.3030, Class Loss: 0.5326\n",
      "Epoch 36/50, Loss: 1.7941, Domain Loss: 1.2857, Class Loss: 0.5084\n",
      "Epoch 37/50, Loss: 1.7902, Domain Loss: 1.2552, Class Loss: 0.5350\n",
      "Epoch 38/50, Loss: 1.8293, Domain Loss: 1.3275, Class Loss: 0.5018\n",
      "Epoch 39/50, Loss: 1.8387, Domain Loss: 1.2914, Class Loss: 0.5473\n",
      "Epoch 40/50, Loss: 1.8394, Domain Loss: 1.3135, Class Loss: 0.5259\n",
      "Epoch 41/50, Loss: 1.8317, Domain Loss: 1.3430, Class Loss: 0.4888\n",
      "Epoch 42/50, Loss: 4.7784, Domain Loss: 4.0405, Class Loss: 0.7379\n",
      "Epoch 43/50, Loss: 2.4871, Domain Loss: 1.9289, Class Loss: 0.5582\n",
      "Epoch 44/50, Loss: 1.8904, Domain Loss: 1.3537, Class Loss: 0.5367\n",
      "Epoch 45/50, Loss: 1.8413, Domain Loss: 1.3283, Class Loss: 0.5130\n",
      "Epoch 46/50, Loss: 1.8535, Domain Loss: 1.3411, Class Loss: 0.5124\n",
      "Epoch 47/50, Loss: 1.8418, Domain Loss: 1.3349, Class Loss: 0.5070\n",
      "Epoch 48/50, Loss: 1.8042, Domain Loss: 1.3211, Class Loss: 0.4830\n",
      "Epoch 49/50, Loss: 1.7877, Domain Loss: 1.3312, Class Loss: 0.4565\n",
      "Epoch 50/50, Loss: 1.7834, Domain Loss: 1.3284, Class Loss: 0.4550\n",
      "61.57\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 4.1596, Domain Loss: 2.1213, Class Loss: 2.0383\n",
      "Epoch 2/50, Loss: 2.3653, Domain Loss: 1.4308, Class Loss: 0.9345\n",
      "Epoch 3/50, Loss: 1.9522, Domain Loss: 1.3515, Class Loss: 0.6008\n",
      "Epoch 4/50, Loss: 1.9121, Domain Loss: 1.3028, Class Loss: 0.6094\n",
      "Epoch 5/50, Loss: 1.8840, Domain Loss: 1.3079, Class Loss: 0.5760\n",
      "Epoch 6/50, Loss: 1.9037, Domain Loss: 1.2965, Class Loss: 0.6072\n",
      "Epoch 7/50, Loss: 1.9911, Domain Loss: 1.3418, Class Loss: 0.6493\n",
      "Epoch 8/50, Loss: 2.1186, Domain Loss: 1.4622, Class Loss: 0.6563\n",
      "Epoch 9/50, Loss: 2.4641, Domain Loss: 1.6971, Class Loss: 0.7670\n",
      "Epoch 10/50, Loss: 1.9443, Domain Loss: 1.3712, Class Loss: 0.5732\n",
      "Epoch 11/50, Loss: 1.9512, Domain Loss: 1.3358, Class Loss: 0.6154\n",
      "Epoch 12/50, Loss: 1.9240, Domain Loss: 1.3441, Class Loss: 0.5799\n",
      "Epoch 13/50, Loss: 1.9183, Domain Loss: 1.3561, Class Loss: 0.5622\n",
      "Epoch 14/50, Loss: 1.8716, Domain Loss: 1.3261, Class Loss: 0.5455\n",
      "Epoch 15/50, Loss: 1.8710, Domain Loss: 1.2964, Class Loss: 0.5746\n",
      "Epoch 16/50, Loss: 1.9071, Domain Loss: 1.3031, Class Loss: 0.6040\n",
      "Epoch 17/50, Loss: 1.8850, Domain Loss: 1.3022, Class Loss: 0.5828\n",
      "Epoch 18/50, Loss: 1.8434, Domain Loss: 1.3031, Class Loss: 0.5403\n",
      "Epoch 19/50, Loss: 1.8843, Domain Loss: 1.3049, Class Loss: 0.5794\n",
      "Epoch 20/50, Loss: 1.8116, Domain Loss: 1.2918, Class Loss: 0.5197\n",
      "Epoch 21/50, Loss: 1.8551, Domain Loss: 1.2980, Class Loss: 0.5571\n",
      "Epoch 22/50, Loss: 1.8289, Domain Loss: 1.2952, Class Loss: 0.5337\n",
      "Epoch 23/50, Loss: 1.8864, Domain Loss: 1.3303, Class Loss: 0.5561\n",
      "Epoch 24/50, Loss: 1.8662, Domain Loss: 1.3137, Class Loss: 0.5525\n",
      "Epoch 25/50, Loss: 1.8318, Domain Loss: 1.3026, Class Loss: 0.5291\n",
      "Epoch 26/50, Loss: 1.8043, Domain Loss: 1.2790, Class Loss: 0.5253\n",
      "Epoch 27/50, Loss: 1.8119, Domain Loss: 1.2785, Class Loss: 0.5334\n",
      "Epoch 28/50, Loss: 1.8045, Domain Loss: 1.2740, Class Loss: 0.5304\n",
      "Epoch 29/50, Loss: 1.8828, Domain Loss: 1.2923, Class Loss: 0.5905\n",
      "Epoch 30/50, Loss: 1.7623, Domain Loss: 1.2627, Class Loss: 0.4997\n",
      "Epoch 31/50, Loss: 1.7410, Domain Loss: 1.2655, Class Loss: 0.4755\n",
      "Epoch 32/50, Loss: 1.8217, Domain Loss: 1.2854, Class Loss: 0.5363\n",
      "Epoch 33/50, Loss: 1.8147, Domain Loss: 1.3099, Class Loss: 0.5047\n",
      "Epoch 34/50, Loss: 1.7404, Domain Loss: 1.2652, Class Loss: 0.4752\n",
      "Epoch 35/50, Loss: 1.7759, Domain Loss: 1.2644, Class Loss: 0.5115\n",
      "Epoch 36/50, Loss: 1.7830, Domain Loss: 1.2980, Class Loss: 0.4850\n",
      "Epoch 37/50, Loss: 1.7274, Domain Loss: 1.2704, Class Loss: 0.4570\n",
      "Epoch 38/50, Loss: 1.8914, Domain Loss: 1.3385, Class Loss: 0.5530\n",
      "Epoch 39/50, Loss: 1.7484, Domain Loss: 1.2848, Class Loss: 0.4636\n",
      "Epoch 40/50, Loss: 1.7246, Domain Loss: 1.2738, Class Loss: 0.4508\n",
      "Epoch 41/50, Loss: 1.7186, Domain Loss: 1.2840, Class Loss: 0.4346\n",
      "Epoch 42/50, Loss: 1.7081, Domain Loss: 1.2841, Class Loss: 0.4239\n",
      "Epoch 43/50, Loss: 1.6413, Domain Loss: 1.2484, Class Loss: 0.3929\n",
      "Epoch 44/50, Loss: 1.6110, Domain Loss: 1.2356, Class Loss: 0.3754\n",
      "Epoch 45/50, Loss: 1.6515, Domain Loss: 1.2404, Class Loss: 0.4111\n",
      "Epoch 46/50, Loss: 1.6492, Domain Loss: 1.2428, Class Loss: 0.4064\n",
      "Epoch 47/50, Loss: 1.7476, Domain Loss: 1.2588, Class Loss: 0.4888\n",
      "Epoch 48/50, Loss: 1.8645, Domain Loss: 1.4364, Class Loss: 0.4281\n",
      "Epoch 49/50, Loss: 1.6366, Domain Loss: 1.2772, Class Loss: 0.3594\n",
      "Epoch 50/50, Loss: 1.6583, Domain Loss: 1.3129, Class Loss: 0.3454\n",
      "59.23\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.2840, Domain Loss: 1.7774, Class Loss: 1.5066\n",
      "Epoch 2/50, Loss: 2.0970, Domain Loss: 1.4379, Class Loss: 0.6592\n",
      "Epoch 3/50, Loss: 1.9950, Domain Loss: 1.4112, Class Loss: 0.5838\n",
      "Epoch 4/50, Loss: 1.8425, Domain Loss: 1.2785, Class Loss: 0.5640\n",
      "Epoch 5/50, Loss: 1.8358, Domain Loss: 1.2596, Class Loss: 0.5762\n",
      "Epoch 6/50, Loss: 1.9164, Domain Loss: 1.3150, Class Loss: 0.6013\n",
      "Epoch 7/50, Loss: 1.8978, Domain Loss: 1.3144, Class Loss: 0.5834\n",
      "Epoch 8/50, Loss: 1.9859, Domain Loss: 1.3620, Class Loss: 0.6239\n",
      "Epoch 9/50, Loss: 1.8902, Domain Loss: 1.2627, Class Loss: 0.6275\n",
      "Epoch 10/50, Loss: 1.7913, Domain Loss: 1.2477, Class Loss: 0.5435\n",
      "Epoch 11/50, Loss: 2.1969, Domain Loss: 1.5847, Class Loss: 0.6122\n",
      "Epoch 12/50, Loss: 2.0013, Domain Loss: 1.4129, Class Loss: 0.5884\n",
      "Epoch 13/50, Loss: 2.4904, Domain Loss: 1.8174, Class Loss: 0.6730\n",
      "Epoch 14/50, Loss: 2.0303, Domain Loss: 1.4681, Class Loss: 0.5623\n",
      "Epoch 15/50, Loss: 2.2998, Domain Loss: 1.5394, Class Loss: 0.7605\n",
      "Epoch 16/50, Loss: 1.9227, Domain Loss: 1.3516, Class Loss: 0.5711\n",
      "Epoch 17/50, Loss: 1.8809, Domain Loss: 1.3284, Class Loss: 0.5525\n",
      "Epoch 18/50, Loss: 1.8732, Domain Loss: 1.2904, Class Loss: 0.5828\n",
      "Epoch 19/50, Loss: 1.8972, Domain Loss: 1.3470, Class Loss: 0.5502\n",
      "Epoch 20/50, Loss: 1.8591, Domain Loss: 1.3292, Class Loss: 0.5299\n",
      "Epoch 21/50, Loss: 1.8066, Domain Loss: 1.2952, Class Loss: 0.5115\n",
      "Epoch 22/50, Loss: 1.8926, Domain Loss: 1.3023, Class Loss: 0.5903\n",
      "Epoch 23/50, Loss: 1.8327, Domain Loss: 1.3105, Class Loss: 0.5222\n",
      "Epoch 24/50, Loss: 1.8531, Domain Loss: 1.3161, Class Loss: 0.5370\n",
      "Epoch 25/50, Loss: 1.8938, Domain Loss: 1.3613, Class Loss: 0.5325\n",
      "Epoch 26/50, Loss: 1.9043, Domain Loss: 1.3285, Class Loss: 0.5757\n",
      "Epoch 27/50, Loss: 1.9237, Domain Loss: 1.3296, Class Loss: 0.5942\n",
      "Epoch 28/50, Loss: 1.8155, Domain Loss: 1.2805, Class Loss: 0.5350\n",
      "Epoch 29/50, Loss: 1.8214, Domain Loss: 1.2969, Class Loss: 0.5244\n",
      "Epoch 30/50, Loss: 1.8219, Domain Loss: 1.3083, Class Loss: 0.5136\n",
      "Epoch 31/50, Loss: 1.7884, Domain Loss: 1.2857, Class Loss: 0.5027\n",
      "Epoch 32/50, Loss: 2.0936, Domain Loss: 1.5740, Class Loss: 0.5196\n",
      "Epoch 33/50, Loss: 1.9217, Domain Loss: 1.3656, Class Loss: 0.5561\n",
      "Epoch 34/50, Loss: 1.8274, Domain Loss: 1.3050, Class Loss: 0.5224\n",
      "Epoch 35/50, Loss: 1.7790, Domain Loss: 1.2911, Class Loss: 0.4878\n",
      "Epoch 36/50, Loss: 1.7856, Domain Loss: 1.2867, Class Loss: 0.4989\n",
      "Epoch 37/50, Loss: 1.8134, Domain Loss: 1.3279, Class Loss: 0.4856\n",
      "Epoch 38/50, Loss: 1.8134, Domain Loss: 1.2918, Class Loss: 0.5216\n",
      "Epoch 39/50, Loss: 1.8928, Domain Loss: 1.3339, Class Loss: 0.5588\n",
      "Epoch 40/50, Loss: 1.7788, Domain Loss: 1.2780, Class Loss: 0.5007\n",
      "Epoch 41/50, Loss: 2.1091, Domain Loss: 1.3372, Class Loss: 0.7719\n",
      "Epoch 42/50, Loss: 1.9831, Domain Loss: 1.4431, Class Loss: 0.5400\n",
      "Epoch 43/50, Loss: 1.7775, Domain Loss: 1.2877, Class Loss: 0.4898\n",
      "Epoch 44/50, Loss: 1.7861, Domain Loss: 1.3089, Class Loss: 0.4772\n",
      "Epoch 45/50, Loss: 1.8265, Domain Loss: 1.3525, Class Loss: 0.4740\n",
      "Epoch 46/50, Loss: 1.7566, Domain Loss: 1.3038, Class Loss: 0.4528\n",
      "Epoch 47/50, Loss: 1.7138, Domain Loss: 1.2895, Class Loss: 0.4243\n",
      "Epoch 48/50, Loss: 1.7617, Domain Loss: 1.3000, Class Loss: 0.4617\n",
      "Epoch 49/50, Loss: 1.7548, Domain Loss: 1.2873, Class Loss: 0.4675\n",
      "Epoch 50/50, Loss: 1.7174, Domain Loss: 1.2763, Class Loss: 0.4411\n",
      "58.75\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.9607, Domain Loss: 2.0916, Class Loss: 1.8692\n",
      "Epoch 2/50, Loss: 2.2798, Domain Loss: 1.4673, Class Loss: 0.8125\n",
      "Epoch 3/50, Loss: 1.9847, Domain Loss: 1.3812, Class Loss: 0.6035\n",
      "Epoch 4/50, Loss: 1.8631, Domain Loss: 1.3011, Class Loss: 0.5620\n",
      "Epoch 5/50, Loss: 1.8614, Domain Loss: 1.2800, Class Loss: 0.5814\n",
      "Epoch 6/50, Loss: 1.8231, Domain Loss: 1.2511, Class Loss: 0.5720\n",
      "Epoch 7/50, Loss: 1.8169, Domain Loss: 1.2530, Class Loss: 0.5639\n",
      "Epoch 8/50, Loss: 1.8667, Domain Loss: 1.2734, Class Loss: 0.5933\n",
      "Epoch 9/50, Loss: 1.9645, Domain Loss: 1.3410, Class Loss: 0.6236\n",
      "Epoch 10/50, Loss: 1.8753, Domain Loss: 1.2957, Class Loss: 0.5796\n",
      "Epoch 11/50, Loss: 1.7470, Domain Loss: 1.2508, Class Loss: 0.4962\n",
      "Epoch 12/50, Loss: 1.8519, Domain Loss: 1.2881, Class Loss: 0.5638\n",
      "Epoch 13/50, Loss: 1.7696, Domain Loss: 1.2391, Class Loss: 0.5305\n",
      "Epoch 14/50, Loss: 2.7130, Domain Loss: 1.8361, Class Loss: 0.8769\n",
      "Epoch 15/50, Loss: 2.0338, Domain Loss: 1.3392, Class Loss: 0.6946\n",
      "Epoch 16/50, Loss: 1.8689, Domain Loss: 1.3215, Class Loss: 0.5474\n",
      "Epoch 17/50, Loss: 1.8848, Domain Loss: 1.3056, Class Loss: 0.5792\n",
      "Epoch 18/50, Loss: 1.8425, Domain Loss: 1.2828, Class Loss: 0.5597\n",
      "Epoch 19/50, Loss: 1.8272, Domain Loss: 1.2799, Class Loss: 0.5473\n",
      "Epoch 20/50, Loss: 1.8226, Domain Loss: 1.2947, Class Loss: 0.5279\n",
      "Epoch 21/50, Loss: 1.8622, Domain Loss: 1.3009, Class Loss: 0.5613\n",
      "Epoch 22/50, Loss: 1.8741, Domain Loss: 1.3168, Class Loss: 0.5574\n",
      "Epoch 23/50, Loss: 1.8657, Domain Loss: 1.2899, Class Loss: 0.5759\n",
      "Epoch 24/50, Loss: 1.8081, Domain Loss: 1.2932, Class Loss: 0.5149\n",
      "Epoch 25/50, Loss: 1.7976, Domain Loss: 1.2633, Class Loss: 0.5342\n",
      "Epoch 26/50, Loss: 1.7666, Domain Loss: 1.2636, Class Loss: 0.5030\n",
      "Epoch 27/50, Loss: 1.8130, Domain Loss: 1.2736, Class Loss: 0.5394\n",
      "Epoch 28/50, Loss: 1.8512, Domain Loss: 1.2996, Class Loss: 0.5516\n",
      "Epoch 29/50, Loss: 1.8070, Domain Loss: 1.2902, Class Loss: 0.5168\n",
      "Epoch 30/50, Loss: 1.7744, Domain Loss: 1.2695, Class Loss: 0.5049\n",
      "Epoch 31/50, Loss: 1.7536, Domain Loss: 1.2615, Class Loss: 0.4922\n",
      "Epoch 32/50, Loss: 1.8595, Domain Loss: 1.3096, Class Loss: 0.5500\n",
      "Epoch 33/50, Loss: 1.7889, Domain Loss: 1.2896, Class Loss: 0.4993\n",
      "Epoch 34/50, Loss: 1.8027, Domain Loss: 1.2905, Class Loss: 0.5123\n",
      "Epoch 35/50, Loss: 1.7834, Domain Loss: 1.2941, Class Loss: 0.4893\n",
      "Epoch 36/50, Loss: 1.7461, Domain Loss: 1.2683, Class Loss: 0.4778\n",
      "Epoch 37/50, Loss: 1.7144, Domain Loss: 1.2556, Class Loss: 0.4588\n",
      "Epoch 38/50, Loss: 1.7496, Domain Loss: 1.2607, Class Loss: 0.4889\n",
      "Epoch 39/50, Loss: 1.7216, Domain Loss: 1.2612, Class Loss: 0.4604\n",
      "Epoch 40/50, Loss: 1.7374, Domain Loss: 1.2725, Class Loss: 0.4649\n",
      "Epoch 41/50, Loss: 1.8016, Domain Loss: 1.2880, Class Loss: 0.5136\n",
      "Epoch 42/50, Loss: 1.7835, Domain Loss: 1.3032, Class Loss: 0.4803\n",
      "Epoch 43/50, Loss: 1.8006, Domain Loss: 1.3069, Class Loss: 0.4937\n",
      "Epoch 44/50, Loss: 1.7476, Domain Loss: 1.2737, Class Loss: 0.4739\n",
      "Epoch 45/50, Loss: 1.7812, Domain Loss: 1.2838, Class Loss: 0.4974\n",
      "Epoch 46/50, Loss: 1.8036, Domain Loss: 1.3464, Class Loss: 0.4571\n",
      "Epoch 47/50, Loss: 1.6937, Domain Loss: 1.2716, Class Loss: 0.4221\n",
      "Epoch 48/50, Loss: 1.6462, Domain Loss: 1.2604, Class Loss: 0.3857\n",
      "Epoch 49/50, Loss: 1.6894, Domain Loss: 1.2692, Class Loss: 0.4202\n",
      "Epoch 50/50, Loss: 1.6754, Domain Loss: 1.2953, Class Loss: 0.3800\n",
      "59.11\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.0466, Domain Loss: 1.5873, Class Loss: 1.4593\n",
      "Epoch 2/50, Loss: 2.0262, Domain Loss: 1.3427, Class Loss: 0.6835\n",
      "Epoch 3/50, Loss: 2.0290, Domain Loss: 1.3786, Class Loss: 0.6504\n",
      "Epoch 4/50, Loss: 1.8841, Domain Loss: 1.2936, Class Loss: 0.5905\n",
      "Epoch 5/50, Loss: 1.7697, Domain Loss: 1.2356, Class Loss: 0.5341\n",
      "Epoch 6/50, Loss: 1.8300, Domain Loss: 1.2550, Class Loss: 0.5751\n",
      "Epoch 7/50, Loss: 1.8372, Domain Loss: 1.2765, Class Loss: 0.5606\n",
      "Epoch 8/50, Loss: 1.8237, Domain Loss: 1.2676, Class Loss: 0.5561\n",
      "Epoch 9/50, Loss: 1.7902, Domain Loss: 1.2467, Class Loss: 0.5435\n",
      "Epoch 10/50, Loss: 1.7975, Domain Loss: 1.2528, Class Loss: 0.5447\n",
      "Epoch 11/50, Loss: 1.7815, Domain Loss: 1.2377, Class Loss: 0.5438\n",
      "Epoch 12/50, Loss: 1.7689, Domain Loss: 1.2569, Class Loss: 0.5120\n",
      "Epoch 13/50, Loss: 1.8934, Domain Loss: 1.2815, Class Loss: 0.6119\n",
      "Epoch 14/50, Loss: 1.8173, Domain Loss: 1.2535, Class Loss: 0.5638\n",
      "Epoch 15/50, Loss: 1.7467, Domain Loss: 1.2319, Class Loss: 0.5148\n",
      "Epoch 16/50, Loss: 1.7949, Domain Loss: 1.2839, Class Loss: 0.5110\n",
      "Epoch 17/50, Loss: 1.8033, Domain Loss: 1.2779, Class Loss: 0.5254\n",
      "Epoch 18/50, Loss: 1.7777, Domain Loss: 1.2596, Class Loss: 0.5181\n",
      "Epoch 19/50, Loss: 1.8236, Domain Loss: 1.2848, Class Loss: 0.5389\n",
      "Epoch 20/50, Loss: 2.0422, Domain Loss: 1.3447, Class Loss: 0.6975\n",
      "Epoch 21/50, Loss: 1.8605, Domain Loss: 1.2959, Class Loss: 0.5646\n",
      "Epoch 22/50, Loss: 1.7839, Domain Loss: 1.2374, Class Loss: 0.5465\n",
      "Epoch 23/50, Loss: 1.7619, Domain Loss: 1.2678, Class Loss: 0.4941\n",
      "Epoch 24/50, Loss: 1.8606, Domain Loss: 1.3429, Class Loss: 0.5177\n",
      "Epoch 25/50, Loss: 1.8659, Domain Loss: 1.3067, Class Loss: 0.5592\n",
      "Epoch 26/50, Loss: 1.7710, Domain Loss: 1.2728, Class Loss: 0.4982\n",
      "Epoch 27/50, Loss: 1.7225, Domain Loss: 1.2583, Class Loss: 0.4641\n",
      "Epoch 28/50, Loss: 1.9161, Domain Loss: 1.2618, Class Loss: 0.6543\n",
      "Epoch 29/50, Loss: 1.8054, Domain Loss: 1.2720, Class Loss: 0.5334\n",
      "Epoch 30/50, Loss: 1.7196, Domain Loss: 1.2405, Class Loss: 0.4792\n",
      "Epoch 31/50, Loss: 1.7465, Domain Loss: 1.2636, Class Loss: 0.4829\n",
      "Epoch 32/50, Loss: 1.7180, Domain Loss: 1.2362, Class Loss: 0.4818\n",
      "Epoch 33/50, Loss: 1.7275, Domain Loss: 1.2396, Class Loss: 0.4879\n",
      "Epoch 34/50, Loss: 1.7662, Domain Loss: 1.2835, Class Loss: 0.4828\n",
      "Epoch 35/50, Loss: 1.6989, Domain Loss: 1.2415, Class Loss: 0.4574\n",
      "Epoch 36/50, Loss: 1.7549, Domain Loss: 1.2783, Class Loss: 0.4767\n",
      "Epoch 37/50, Loss: 1.8102, Domain Loss: 1.3354, Class Loss: 0.4748\n",
      "Epoch 38/50, Loss: 2.2765, Domain Loss: 1.8026, Class Loss: 0.4739\n",
      "Epoch 39/50, Loss: 2.2033, Domain Loss: 1.4669, Class Loss: 0.7364\n",
      "Epoch 40/50, Loss: 1.8524, Domain Loss: 1.3864, Class Loss: 0.4660\n",
      "Epoch 41/50, Loss: 1.8217, Domain Loss: 1.3864, Class Loss: 0.4353\n",
      "Epoch 42/50, Loss: 1.7821, Domain Loss: 1.3864, Class Loss: 0.3957\n",
      "Epoch 43/50, Loss: 1.8078, Domain Loss: 1.3864, Class Loss: 0.4215\n",
      "Epoch 44/50, Loss: 1.7568, Domain Loss: 1.3863, Class Loss: 0.3705\n",
      "Epoch 45/50, Loss: 1.7723, Domain Loss: 1.3863, Class Loss: 0.3859\n",
      "Epoch 46/50, Loss: 1.7738, Domain Loss: 1.3863, Class Loss: 0.3875\n",
      "Epoch 47/50, Loss: 1.7284, Domain Loss: 1.3863, Class Loss: 0.3421\n",
      "Epoch 48/50, Loss: 1.7174, Domain Loss: 1.3863, Class Loss: 0.3310\n",
      "Epoch 49/50, Loss: 1.7411, Domain Loss: 1.3863, Class Loss: 0.3548\n",
      "Epoch 50/50, Loss: 1.6895, Domain Loss: 1.3863, Class Loss: 0.3032\n",
      "57.61\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.3504, Domain Loss: 1.7871, Class Loss: 1.5633\n",
      "Epoch 2/50, Loss: 2.1399, Domain Loss: 1.4327, Class Loss: 0.7072\n",
      "Epoch 3/50, Loss: 1.9056, Domain Loss: 1.3318, Class Loss: 0.5738\n",
      "Epoch 4/50, Loss: 1.8582, Domain Loss: 1.2878, Class Loss: 0.5704\n",
      "Epoch 5/50, Loss: 1.9397, Domain Loss: 1.3974, Class Loss: 0.5423\n",
      "Epoch 6/50, Loss: 3.5205, Domain Loss: 2.6902, Class Loss: 0.8303\n",
      "Epoch 7/50, Loss: 3.7386, Domain Loss: 2.9178, Class Loss: 0.8207\n",
      "Epoch 8/50, Loss: 2.2826, Domain Loss: 1.5747, Class Loss: 0.7079\n",
      "Epoch 9/50, Loss: 1.8901, Domain Loss: 1.3119, Class Loss: 0.5782\n",
      "Epoch 10/50, Loss: 1.8872, Domain Loss: 1.3069, Class Loss: 0.5803\n",
      "Epoch 11/50, Loss: 1.9959, Domain Loss: 1.3781, Class Loss: 0.6178\n",
      "Epoch 12/50, Loss: 1.9099, Domain Loss: 1.3231, Class Loss: 0.5868\n",
      "Epoch 13/50, Loss: 2.0066, Domain Loss: 1.4064, Class Loss: 0.6002\n",
      "Epoch 14/50, Loss: 1.9093, Domain Loss: 1.3073, Class Loss: 0.6020\n",
      "Epoch 15/50, Loss: 1.8269, Domain Loss: 1.2945, Class Loss: 0.5324\n",
      "Epoch 16/50, Loss: 1.9842, Domain Loss: 1.4156, Class Loss: 0.5686\n",
      "Epoch 17/50, Loss: 2.2254, Domain Loss: 1.3792, Class Loss: 0.8462\n",
      "Epoch 18/50, Loss: 2.8688, Domain Loss: 2.1487, Class Loss: 0.7201\n",
      "Epoch 19/50, Loss: 1.9273, Domain Loss: 1.3742, Class Loss: 0.5531\n",
      "Epoch 20/50, Loss: 1.8981, Domain Loss: 1.3071, Class Loss: 0.5909\n",
      "Epoch 21/50, Loss: 1.8740, Domain Loss: 1.2974, Class Loss: 0.5765\n",
      "Epoch 22/50, Loss: 1.8266, Domain Loss: 1.2737, Class Loss: 0.5528\n",
      "Epoch 23/50, Loss: 1.8537, Domain Loss: 1.2854, Class Loss: 0.5683\n",
      "Epoch 24/50, Loss: 1.8468, Domain Loss: 1.2948, Class Loss: 0.5520\n",
      "Epoch 25/50, Loss: 1.8306, Domain Loss: 1.2939, Class Loss: 0.5366\n",
      "Epoch 26/50, Loss: 1.8211, Domain Loss: 1.2883, Class Loss: 0.5328\n",
      "Epoch 27/50, Loss: 1.8101, Domain Loss: 1.3000, Class Loss: 0.5101\n",
      "Epoch 28/50, Loss: 1.8260, Domain Loss: 1.2881, Class Loss: 0.5379\n",
      "Epoch 29/50, Loss: 1.8400, Domain Loss: 1.2979, Class Loss: 0.5421\n",
      "Epoch 30/50, Loss: 1.8515, Domain Loss: 1.2909, Class Loss: 0.5606\n",
      "Epoch 31/50, Loss: 1.8184, Domain Loss: 1.2892, Class Loss: 0.5292\n",
      "Epoch 32/50, Loss: 1.9239, Domain Loss: 1.3107, Class Loss: 0.6132\n",
      "Epoch 33/50, Loss: 2.1300, Domain Loss: 1.3776, Class Loss: 0.7524\n",
      "Epoch 34/50, Loss: 1.8301, Domain Loss: 1.2768, Class Loss: 0.5533\n",
      "Epoch 35/50, Loss: 1.8205, Domain Loss: 1.2626, Class Loss: 0.5579\n",
      "Epoch 36/50, Loss: 1.7878, Domain Loss: 1.2519, Class Loss: 0.5359\n",
      "Epoch 37/50, Loss: 1.8024, Domain Loss: 1.2808, Class Loss: 0.5216\n",
      "Epoch 38/50, Loss: 1.7810, Domain Loss: 1.2527, Class Loss: 0.5282\n",
      "Epoch 39/50, Loss: 1.8065, Domain Loss: 1.2665, Class Loss: 0.5401\n",
      "Epoch 40/50, Loss: 1.8158, Domain Loss: 1.2879, Class Loss: 0.5279\n",
      "Epoch 41/50, Loss: 1.7729, Domain Loss: 1.2829, Class Loss: 0.4900\n",
      "Epoch 42/50, Loss: 1.7623, Domain Loss: 1.2754, Class Loss: 0.4869\n",
      "Epoch 43/50, Loss: 1.8189, Domain Loss: 1.2768, Class Loss: 0.5421\n",
      "Epoch 44/50, Loss: 1.8133, Domain Loss: 1.2882, Class Loss: 0.5251\n",
      "Epoch 45/50, Loss: 1.8045, Domain Loss: 1.3007, Class Loss: 0.5038\n",
      "Epoch 46/50, Loss: 1.7970, Domain Loss: 1.2799, Class Loss: 0.5171\n",
      "Epoch 47/50, Loss: 1.7929, Domain Loss: 1.2924, Class Loss: 0.5005\n",
      "Epoch 48/50, Loss: 1.7671, Domain Loss: 1.2797, Class Loss: 0.4874\n",
      "Epoch 49/50, Loss: 1.8193, Domain Loss: 1.2762, Class Loss: 0.5431\n",
      "Epoch 50/50, Loss: 1.7747, Domain Loss: 1.2641, Class Loss: 0.5106\n",
      "63.07\n",
      "\n",
      "\n",
      "Epoch 1/50, Loss: 3.9347, Domain Loss: 2.0940, Class Loss: 1.8407\n",
      "Epoch 2/50, Loss: 2.4446, Domain Loss: 1.4213, Class Loss: 1.0233\n",
      "Epoch 3/50, Loss: 2.0085, Domain Loss: 1.4002, Class Loss: 0.6084\n",
      "Epoch 4/50, Loss: 1.9185, Domain Loss: 1.3214, Class Loss: 0.5970\n",
      "Epoch 5/50, Loss: 1.8778, Domain Loss: 1.2594, Class Loss: 0.6184\n",
      "Epoch 6/50, Loss: 1.7912, Domain Loss: 1.2533, Class Loss: 0.5378\n",
      "Epoch 7/50, Loss: 1.8120, Domain Loss: 1.2533, Class Loss: 0.5587\n",
      "Epoch 8/50, Loss: 1.8388, Domain Loss: 1.2483, Class Loss: 0.5905\n",
      "Epoch 9/50, Loss: 1.7936, Domain Loss: 1.2414, Class Loss: 0.5522\n",
      "Epoch 10/50, Loss: 1.7989, Domain Loss: 1.2504, Class Loss: 0.5485\n",
      "Epoch 11/50, Loss: 1.8205, Domain Loss: 1.2474, Class Loss: 0.5731\n",
      "Epoch 12/50, Loss: 1.7550, Domain Loss: 1.2139, Class Loss: 0.5411\n",
      "Epoch 13/50, Loss: 1.8069, Domain Loss: 1.2395, Class Loss: 0.5673\n",
      "Epoch 14/50, Loss: 1.8333, Domain Loss: 1.2671, Class Loss: 0.5662\n",
      "Epoch 15/50, Loss: 1.8012, Domain Loss: 1.2579, Class Loss: 0.5433\n",
      "Epoch 16/50, Loss: 1.9708, Domain Loss: 1.3530, Class Loss: 0.6178\n",
      "Epoch 17/50, Loss: 1.9979, Domain Loss: 1.3631, Class Loss: 0.6347\n",
      "Epoch 18/50, Loss: 1.7935, Domain Loss: 1.2639, Class Loss: 0.5297\n",
      "Epoch 19/50, Loss: 1.8998, Domain Loss: 1.3342, Class Loss: 0.5656\n",
      "Epoch 20/50, Loss: 2.0628, Domain Loss: 1.5048, Class Loss: 0.5580\n",
      "Epoch 21/50, Loss: 1.9941, Domain Loss: 1.3955, Class Loss: 0.5985\n",
      "Epoch 22/50, Loss: 1.9321, Domain Loss: 1.3851, Class Loss: 0.5470\n",
      "Epoch 23/50, Loss: 1.8693, Domain Loss: 1.3313, Class Loss: 0.5381\n",
      "Epoch 24/50, Loss: 1.8052, Domain Loss: 1.2772, Class Loss: 0.5280\n",
      "Epoch 25/50, Loss: 1.7898, Domain Loss: 1.2933, Class Loss: 0.4965\n",
      "Epoch 26/50, Loss: 1.8925, Domain Loss: 1.3604, Class Loss: 0.5322\n",
      "Epoch 27/50, Loss: 2.0939, Domain Loss: 1.3960, Class Loss: 0.6979\n",
      "Epoch 28/50, Loss: 1.8109, Domain Loss: 1.3196, Class Loss: 0.4913\n",
      "Epoch 29/50, Loss: 1.8176, Domain Loss: 1.3244, Class Loss: 0.4932\n",
      "Epoch 30/50, Loss: 1.8186, Domain Loss: 1.3032, Class Loss: 0.5153\n",
      "Epoch 31/50, Loss: 1.7825, Domain Loss: 1.2701, Class Loss: 0.5124\n",
      "Epoch 32/50, Loss: 1.7526, Domain Loss: 1.2518, Class Loss: 0.5008\n",
      "Epoch 33/50, Loss: 1.8204, Domain Loss: 1.2896, Class Loss: 0.5308\n",
      "Epoch 34/50, Loss: 1.8141, Domain Loss: 1.3132, Class Loss: 0.5008\n",
      "Epoch 35/50, Loss: 1.7766, Domain Loss: 1.2730, Class Loss: 0.5036\n",
      "Epoch 36/50, Loss: 1.7547, Domain Loss: 1.2746, Class Loss: 0.4802\n",
      "Epoch 37/50, Loss: 1.7463, Domain Loss: 1.2729, Class Loss: 0.4733\n",
      "Epoch 38/50, Loss: 1.7395, Domain Loss: 1.2548, Class Loss: 0.4847\n",
      "Epoch 39/50, Loss: 1.7614, Domain Loss: 1.2652, Class Loss: 0.4962\n",
      "Epoch 40/50, Loss: 1.7462, Domain Loss: 1.2615, Class Loss: 0.4847\n",
      "Epoch 41/50, Loss: 1.7130, Domain Loss: 1.2637, Class Loss: 0.4493\n",
      "Epoch 42/50, Loss: 1.7704, Domain Loss: 1.2785, Class Loss: 0.4919\n",
      "Epoch 43/50, Loss: 1.7228, Domain Loss: 1.3154, Class Loss: 0.4074\n",
      "Epoch 44/50, Loss: 1.6916, Domain Loss: 1.2980, Class Loss: 0.3936\n",
      "Epoch 45/50, Loss: 1.6812, Domain Loss: 1.2626, Class Loss: 0.4186\n",
      "Epoch 46/50, Loss: 1.7063, Domain Loss: 1.2567, Class Loss: 0.4496\n",
      "Epoch 47/50, Loss: 1.7788, Domain Loss: 1.2740, Class Loss: 0.5048\n",
      "Epoch 48/50, Loss: 1.8633, Domain Loss: 1.3661, Class Loss: 0.4972\n",
      "Epoch 49/50, Loss: 1.6388, Domain Loss: 1.2435, Class Loss: 0.3954\n",
      "Epoch 50/50, Loss: 1.6364, Domain Loss: 1.2414, Class Loss: 0.3950\n",
      "60.01\n",
      "\n",
      "\n",
      "Source performance:\n",
      "70.99 69.88 71.06 69.92 \n",
      "Target performance:\n",
      "60.52 59.76 59.95 57.52 \n",
      "\n",
      "Per-class target performance: 100.00 72.21 43.34 24.24 \n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 2.0139, Discrepancy Loss: 0.0798\n",
      "Validation Loss: 1.4171\n",
      "Epoch [2/50], Class Loss: 1.2177, Discrepancy Loss: 0.0455\n",
      "Validation Loss: 1.3231\n",
      "Epoch [3/50], Class Loss: 1.1576, Discrepancy Loss: 0.0299\n",
      "Validation Loss: 1.1716\n",
      "Epoch [4/50], Class Loss: 1.1193, Discrepancy Loss: 0.0240\n",
      "Validation Loss: 1.1899\n",
      "Epoch [5/50], Class Loss: 1.1308, Discrepancy Loss: 0.0336\n",
      "Validation Loss: 1.1702\n",
      "Epoch [6/50], Class Loss: 1.0877, Discrepancy Loss: 0.0391\n",
      "Validation Loss: 1.1609\n",
      "Epoch [7/50], Class Loss: 1.0863, Discrepancy Loss: 0.0489\n",
      "Validation Loss: 1.4861\n",
      "Epoch [8/50], Class Loss: 1.0040, Discrepancy Loss: 0.0340\n",
      "Validation Loss: 3.7252\n",
      "Epoch [9/50], Class Loss: 0.9544, Discrepancy Loss: 0.0445\n",
      "Validation Loss: 1.6036\n",
      "Epoch [10/50], Class Loss: 0.7401, Discrepancy Loss: 0.0431\n",
      "Validation Loss: 0.9566\n",
      "Epoch [11/50], Class Loss: 0.2601, Discrepancy Loss: 0.0330\n",
      "Validation Loss: 0.6345\n",
      "Epoch [12/50], Class Loss: 0.1778, Discrepancy Loss: 0.0242\n",
      "Validation Loss: 0.6007\n",
      "Epoch [13/50], Class Loss: 0.1530, Discrepancy Loss: 0.0239\n",
      "Validation Loss: 0.5983\n",
      "Epoch [14/50], Class Loss: 0.1236, Discrepancy Loss: 0.0202\n",
      "Validation Loss: 0.6803\n",
      "Epoch [15/50], Class Loss: 0.0986, Discrepancy Loss: 0.0173\n",
      "Validation Loss: 0.5613\n",
      "Epoch [16/50], Class Loss: 0.0750, Discrepancy Loss: 0.0173\n",
      "Validation Loss: 0.7842\n",
      "Epoch [17/50], Class Loss: 0.0528, Discrepancy Loss: 0.0188\n",
      "Validation Loss: 0.7225\n",
      "Epoch [18/50], Class Loss: 0.0643, Discrepancy Loss: 0.0193\n",
      "Validation Loss: 0.6738\n",
      "Epoch [19/50], Class Loss: 0.0676, Discrepancy Loss: 0.0210\n",
      "Validation Loss: 0.6515\n",
      "Epoch [20/50], Class Loss: 0.0419, Discrepancy Loss: 0.0196\n",
      "Validation Loss: 0.7275\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 90.89%, Precision: 90.72%, Recall: 90.75%, F1 Score: 90.73%\n",
      "Target Domain Performance - Accuracy: 62.35%, Precision: 70.18%, Recall: 60.77%, F1 Score: 57.25%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 2.0946, Discrepancy Loss: 0.0893\n",
      "Validation Loss: 1.2426\n",
      "Epoch [2/50], Class Loss: 1.1971, Discrepancy Loss: 0.0348\n",
      "Validation Loss: 1.1495\n",
      "Epoch [3/50], Class Loss: 1.1792, Discrepancy Loss: 0.0331\n",
      "Validation Loss: 1.2905\n",
      "Epoch [4/50], Class Loss: 1.1107, Discrepancy Loss: 0.0323\n",
      "Validation Loss: 1.1417\n",
      "Epoch [5/50], Class Loss: 1.1306, Discrepancy Loss: 0.0288\n",
      "Validation Loss: 1.2658\n",
      "Epoch [6/50], Class Loss: 1.1010, Discrepancy Loss: 0.0550\n",
      "Validation Loss: 1.2410\n",
      "Epoch [7/50], Class Loss: 1.0435, Discrepancy Loss: 0.0441\n",
      "Validation Loss: 1.0027\n",
      "Epoch [8/50], Class Loss: 1.0728, Discrepancy Loss: 0.0422\n",
      "Validation Loss: 0.8029\n",
      "Epoch [9/50], Class Loss: 0.6041, Discrepancy Loss: 0.0372\n",
      "Validation Loss: 0.6364\n",
      "Epoch [10/50], Class Loss: 0.6336, Discrepancy Loss: 0.0401\n",
      "Validation Loss: 0.6630\n",
      "Epoch [11/50], Class Loss: 0.2450, Discrepancy Loss: 0.0318\n",
      "Validation Loss: 0.5270\n",
      "Epoch [12/50], Class Loss: 0.1643, Discrepancy Loss: 0.0220\n",
      "Validation Loss: 0.4279\n",
      "Epoch [13/50], Class Loss: 0.1371, Discrepancy Loss: 0.0214\n",
      "Validation Loss: 0.4548\n",
      "Epoch [14/50], Class Loss: 0.1237, Discrepancy Loss: 0.0221\n",
      "Validation Loss: 0.5137\n",
      "Epoch [15/50], Class Loss: 0.1304, Discrepancy Loss: 0.0216\n",
      "Validation Loss: 0.6158\n",
      "Epoch [16/50], Class Loss: 0.0820, Discrepancy Loss: 0.0153\n",
      "Validation Loss: 0.4961\n",
      "Epoch [17/50], Class Loss: 0.0742, Discrepancy Loss: 0.0167\n",
      "Validation Loss: 0.6910\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 90.23%, Precision: 90.78%, Recall: 90.34%, F1 Score: 90.05%\n",
      "Target Domain Performance - Accuracy: 71.16%, Precision: 74.47%, Recall: 70.10%, F1 Score: 67.69%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 1.7979, Discrepancy Loss: 0.0578\n",
      "Validation Loss: 1.1896\n",
      "Epoch [2/50], Class Loss: 1.2394, Discrepancy Loss: 0.0419\n",
      "Validation Loss: 1.8813\n",
      "Epoch [3/50], Class Loss: 1.1878, Discrepancy Loss: 0.0382\n",
      "Validation Loss: 1.4383\n",
      "Epoch [4/50], Class Loss: 1.1263, Discrepancy Loss: 0.0304\n",
      "Validation Loss: 1.1462\n",
      "Epoch [5/50], Class Loss: 1.1050, Discrepancy Loss: 0.0377\n",
      "Validation Loss: 1.1102\n",
      "Epoch [6/50], Class Loss: 1.0365, Discrepancy Loss: 0.0471\n",
      "Validation Loss: 1.0226\n",
      "Epoch [7/50], Class Loss: 0.8969, Discrepancy Loss: 0.0522\n",
      "Validation Loss: 0.8151\n",
      "Epoch [8/50], Class Loss: 0.6238, Discrepancy Loss: 0.0430\n",
      "Validation Loss: 0.5484\n",
      "Epoch [9/50], Class Loss: 0.4962, Discrepancy Loss: 0.0342\n",
      "Validation Loss: 0.4704\n",
      "Epoch [10/50], Class Loss: 0.4041, Discrepancy Loss: 0.0282\n",
      "Validation Loss: 0.6726\n",
      "Epoch [11/50], Class Loss: 0.1879, Discrepancy Loss: 0.0247\n",
      "Validation Loss: 0.4372\n",
      "Epoch [12/50], Class Loss: 0.1095, Discrepancy Loss: 0.0203\n",
      "Validation Loss: 0.6515\n",
      "Epoch [13/50], Class Loss: 0.1029, Discrepancy Loss: 0.0167\n",
      "Validation Loss: 0.4500\n",
      "Epoch [14/50], Class Loss: 0.0828, Discrepancy Loss: 0.0162\n",
      "Validation Loss: 0.6635\n",
      "Epoch [15/50], Class Loss: 0.0743, Discrepancy Loss: 0.0153\n",
      "Validation Loss: 0.4795\n",
      "Epoch [16/50], Class Loss: 0.0554, Discrepancy Loss: 0.0135\n",
      "Validation Loss: 0.5241\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 92.75%, Precision: 92.64%, Recall: 92.67%, F1 Score: 92.62%\n",
      "Target Domain Performance - Accuracy: 64.81%, Precision: 71.98%, Recall: 63.41%, F1 Score: 59.52%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 1.8767, Discrepancy Loss: 0.0808\n",
      "Validation Loss: 1.2597\n",
      "Epoch [2/50], Class Loss: 1.2543, Discrepancy Loss: 0.0363\n",
      "Validation Loss: 1.3782\n",
      "Epoch [3/50], Class Loss: 1.1336, Discrepancy Loss: 0.0315\n",
      "Validation Loss: 1.1977\n",
      "Epoch [4/50], Class Loss: 1.1435, Discrepancy Loss: 0.0298\n",
      "Validation Loss: 1.2325\n",
      "Epoch [5/50], Class Loss: 1.1343, Discrepancy Loss: 0.0276\n",
      "Validation Loss: 1.2923\n",
      "Epoch [6/50], Class Loss: 1.1032, Discrepancy Loss: 0.0401\n",
      "Validation Loss: 1.2168\n",
      "Epoch [7/50], Class Loss: 1.0709, Discrepancy Loss: 0.0355\n",
      "Validation Loss: 1.1782\n",
      "Epoch [8/50], Class Loss: 0.8951, Discrepancy Loss: 0.0355\n",
      "Validation Loss: 0.8991\n",
      "Epoch [9/50], Class Loss: 0.7846, Discrepancy Loss: 0.0356\n",
      "Validation Loss: 0.5918\n",
      "Epoch [10/50], Class Loss: 0.5850, Discrepancy Loss: 0.0371\n",
      "Validation Loss: 1.0148\n",
      "Epoch [11/50], Class Loss: 0.2369, Discrepancy Loss: 0.0261\n",
      "Validation Loss: 0.4885\n",
      "Epoch [12/50], Class Loss: 0.1620, Discrepancy Loss: 0.0194\n",
      "Validation Loss: 0.5489\n",
      "Epoch [13/50], Class Loss: 0.1326, Discrepancy Loss: 0.0178\n",
      "Validation Loss: 0.5145\n",
      "Epoch [14/50], Class Loss: 0.1129, Discrepancy Loss: 0.0161\n",
      "Validation Loss: 0.5481\n",
      "Epoch [15/50], Class Loss: 0.0877, Discrepancy Loss: 0.0146\n",
      "Validation Loss: 0.6298\n",
      "Epoch [16/50], Class Loss: 0.0819, Discrepancy Loss: 0.0150\n",
      "Validation Loss: 0.5220\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 91.67%, Precision: 91.53%, Recall: 91.55%, F1 Score: 91.52%\n",
      "Target Domain Performance - Accuracy: 64.63%, Precision: 69.09%, Recall: 63.28%, F1 Score: 58.33%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 2.0750, Discrepancy Loss: 0.0936\n",
      "Validation Loss: 1.2849\n",
      "Epoch [2/50], Class Loss: 1.2372, Discrepancy Loss: 0.0379\n",
      "Validation Loss: 1.3829\n",
      "Epoch [3/50], Class Loss: 1.1704, Discrepancy Loss: 0.0444\n",
      "Validation Loss: 1.2191\n",
      "Epoch [4/50], Class Loss: 1.1421, Discrepancy Loss: 0.0346\n",
      "Validation Loss: 1.2206\n",
      "Epoch [5/50], Class Loss: 1.1083, Discrepancy Loss: 0.0345\n",
      "Validation Loss: 1.1676\n",
      "Epoch [6/50], Class Loss: 1.0599, Discrepancy Loss: 0.0315\n",
      "Validation Loss: 1.1521\n",
      "Epoch [7/50], Class Loss: 1.0603, Discrepancy Loss: 0.0550\n",
      "Validation Loss: 1.1761\n",
      "Epoch [8/50], Class Loss: 1.5548, Discrepancy Loss: 0.0589\n",
      "Validation Loss: 1.1876\n",
      "Epoch [9/50], Class Loss: 0.6835, Discrepancy Loss: 0.0391\n",
      "Validation Loss: 1.2870\n",
      "Epoch [10/50], Class Loss: 0.4950, Discrepancy Loss: 0.0302\n",
      "Validation Loss: 1.6376\n",
      "Epoch [11/50], Class Loss: 0.2294, Discrepancy Loss: 0.0279\n",
      "Validation Loss: 0.4231\n",
      "Epoch [12/50], Class Loss: 0.1466, Discrepancy Loss: 0.0208\n",
      "Validation Loss: 0.4433\n",
      "Epoch [13/50], Class Loss: 0.1163, Discrepancy Loss: 0.0182\n",
      "Validation Loss: 0.5116\n",
      "Epoch [14/50], Class Loss: 0.0882, Discrepancy Loss: 0.0171\n",
      "Validation Loss: 0.5833\n",
      "Epoch [15/50], Class Loss: 0.0713, Discrepancy Loss: 0.0162\n",
      "Validation Loss: 0.5071\n",
      "Epoch [16/50], Class Loss: 0.0589, Discrepancy Loss: 0.0149\n",
      "Validation Loss: 0.5519\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 92.15%, Precision: 92.11%, Recall: 92.07%, F1 Score: 91.99%\n",
      "Target Domain Performance - Accuracy: 67.39%, Precision: 72.90%, Recall: 66.15%, F1 Score: 62.09%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 1.7707, Discrepancy Loss: 0.0458\n",
      "Validation Loss: 2.1833\n",
      "Epoch [2/50], Class Loss: 1.1673, Discrepancy Loss: 0.0151\n",
      "Validation Loss: 1.1786\n",
      "Epoch [3/50], Class Loss: 1.1723, Discrepancy Loss: 0.0252\n",
      "Validation Loss: 1.1458\n",
      "Epoch [4/50], Class Loss: 1.0900, Discrepancy Loss: 0.0229\n",
      "Validation Loss: 1.1175\n",
      "Epoch [5/50], Class Loss: 1.0947, Discrepancy Loss: 0.0484\n",
      "Validation Loss: 1.1793\n",
      "Epoch [6/50], Class Loss: 1.0547, Discrepancy Loss: 0.0448\n",
      "Validation Loss: 1.1420\n",
      "Epoch [7/50], Class Loss: 0.8790, Discrepancy Loss: 0.0371\n",
      "Validation Loss: 0.8794\n",
      "Epoch [8/50], Class Loss: 0.7123, Discrepancy Loss: 0.0337\n",
      "Validation Loss: 0.8261\n",
      "Epoch [9/50], Class Loss: 0.6424, Discrepancy Loss: 0.0442\n",
      "Validation Loss: 0.5406\n",
      "Epoch [10/50], Class Loss: 0.4691, Discrepancy Loss: 0.0267\n",
      "Validation Loss: 0.5626\n",
      "Epoch [11/50], Class Loss: 0.1757, Discrepancy Loss: 0.0180\n",
      "Validation Loss: 0.4097\n",
      "Epoch [12/50], Class Loss: 0.1335, Discrepancy Loss: 0.0148\n",
      "Validation Loss: 0.3832\n",
      "Epoch [13/50], Class Loss: 0.1144, Discrepancy Loss: 0.0134\n",
      "Validation Loss: 0.4226\n",
      "Epoch [14/50], Class Loss: 0.0953, Discrepancy Loss: 0.0130\n",
      "Validation Loss: 0.4954\n",
      "Epoch [15/50], Class Loss: 0.0762, Discrepancy Loss: 0.0116\n",
      "Validation Loss: 0.4798\n",
      "Epoch [16/50], Class Loss: 0.0762, Discrepancy Loss: 0.0111\n",
      "Validation Loss: 0.5565\n",
      "Epoch [17/50], Class Loss: 0.0576, Discrepancy Loss: 0.0123\n",
      "Validation Loss: 0.4878\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 92.09%, Precision: 92.20%, Recall: 92.11%, F1 Score: 91.96%\n",
      "Target Domain Performance - Accuracy: 67.51%, Precision: 71.72%, Recall: 66.11%, F1 Score: 63.41%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 2.0180, Discrepancy Loss: 0.0865\n",
      "Validation Loss: 1.1318\n",
      "Epoch [2/50], Class Loss: 1.2737, Discrepancy Loss: 0.0364\n",
      "Validation Loss: 1.1494\n",
      "Epoch [3/50], Class Loss: 1.1766, Discrepancy Loss: 0.0515\n",
      "Validation Loss: 1.3279\n",
      "Epoch [4/50], Class Loss: 1.1401, Discrepancy Loss: 0.0532\n",
      "Validation Loss: 1.1075\n",
      "Epoch [5/50], Class Loss: 1.1613, Discrepancy Loss: 0.0419\n",
      "Validation Loss: 1.4563\n",
      "Epoch [6/50], Class Loss: 1.1457, Discrepancy Loss: 0.0458\n",
      "Validation Loss: 1.1293\n",
      "Epoch [7/50], Class Loss: 1.1048, Discrepancy Loss: 0.0424\n",
      "Validation Loss: 1.3313\n",
      "Epoch [8/50], Class Loss: 1.0450, Discrepancy Loss: 0.0491\n",
      "Validation Loss: 1.0468\n",
      "Epoch [9/50], Class Loss: 1.0114, Discrepancy Loss: 0.0573\n",
      "Validation Loss: 1.1283\n",
      "Epoch [10/50], Class Loss: 1.0461, Discrepancy Loss: 0.0692\n",
      "Validation Loss: 1.8070\n",
      "Epoch [11/50], Class Loss: 0.4134, Discrepancy Loss: 0.0377\n",
      "Validation Loss: 0.4867\n",
      "Epoch [12/50], Class Loss: 0.2607, Discrepancy Loss: 0.0272\n",
      "Validation Loss: 0.4860\n",
      "Epoch [13/50], Class Loss: 0.2103, Discrepancy Loss: 0.0187\n",
      "Validation Loss: 0.4333\n",
      "Epoch [14/50], Class Loss: 0.1727, Discrepancy Loss: 0.0162\n",
      "Validation Loss: 0.4609\n",
      "Epoch [15/50], Class Loss: 0.1533, Discrepancy Loss: 0.0167\n",
      "Validation Loss: 0.5894\n",
      "Epoch [16/50], Class Loss: 0.1233, Discrepancy Loss: 0.0142\n",
      "Validation Loss: 0.5044\n",
      "Epoch [17/50], Class Loss: 0.1099, Discrepancy Loss: 0.0130\n",
      "Validation Loss: 0.6780\n",
      "Epoch [18/50], Class Loss: 0.1014, Discrepancy Loss: 0.0124\n",
      "Validation Loss: 0.5203\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 92.63%, Precision: 92.63%, Recall: 92.62%, F1 Score: 92.50%\n",
      "Target Domain Performance - Accuracy: 63.13%, Precision: 69.00%, Recall: 61.61%, F1 Score: 56.60%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 1.7572, Discrepancy Loss: 0.0549\n",
      "Validation Loss: 1.1151\n",
      "Epoch [2/50], Class Loss: 1.1986, Discrepancy Loss: 0.0237\n",
      "Validation Loss: 1.1681\n",
      "Epoch [3/50], Class Loss: 1.1351, Discrepancy Loss: 0.0284\n",
      "Validation Loss: 1.1654\n",
      "Epoch [4/50], Class Loss: 1.1279, Discrepancy Loss: 0.0309\n",
      "Validation Loss: 1.0986\n",
      "Epoch [5/50], Class Loss: 1.1025, Discrepancy Loss: 0.0358\n",
      "Validation Loss: 1.1516\n",
      "Epoch [6/50], Class Loss: 1.0635, Discrepancy Loss: 0.0404\n",
      "Validation Loss: 1.0955\n",
      "Epoch [7/50], Class Loss: 1.0038, Discrepancy Loss: 0.0581\n",
      "Validation Loss: 1.2150\n",
      "Epoch [8/50], Class Loss: 0.8150, Discrepancy Loss: 0.0465\n",
      "Validation Loss: 0.7760\n",
      "Epoch [9/50], Class Loss: 0.7010, Discrepancy Loss: 0.0350\n",
      "Validation Loss: 0.6047\n",
      "Epoch [10/50], Class Loss: 0.5707, Discrepancy Loss: 0.0321\n",
      "Validation Loss: 0.4754\n",
      "Epoch [11/50], Class Loss: 0.1667, Discrepancy Loss: 0.0244\n",
      "Validation Loss: 0.4326\n",
      "Epoch [12/50], Class Loss: 0.1299, Discrepancy Loss: 0.0188\n",
      "Validation Loss: 0.4850\n",
      "Epoch [13/50], Class Loss: 0.1252, Discrepancy Loss: 0.0163\n",
      "Validation Loss: 0.5649\n",
      "Epoch [14/50], Class Loss: 0.0870, Discrepancy Loss: 0.0152\n",
      "Validation Loss: 0.6387\n",
      "Epoch [15/50], Class Loss: 0.0818, Discrepancy Loss: 0.0152\n",
      "Validation Loss: 0.4570\n",
      "Epoch [16/50], Class Loss: 0.0653, Discrepancy Loss: 0.0154\n",
      "Validation Loss: 0.5019\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 92.27%, Precision: 92.16%, Recall: 92.20%, F1 Score: 92.12%\n",
      "Target Domain Performance - Accuracy: 68.05%, Precision: 72.58%, Recall: 66.68%, F1 Score: 63.99%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.9861, Discrepancy Loss: 0.0710\n",
      "Validation Loss: 1.1176\n",
      "Epoch [2/50], Class Loss: 1.1744, Discrepancy Loss: 0.0312\n",
      "Validation Loss: 1.1903\n",
      "Epoch [3/50], Class Loss: 1.1250, Discrepancy Loss: 0.0229\n",
      "Validation Loss: 1.1431\n",
      "Epoch [4/50], Class Loss: 1.0979, Discrepancy Loss: 0.0266\n",
      "Validation Loss: 1.1499\n",
      "Epoch [5/50], Class Loss: 1.0554, Discrepancy Loss: 0.0299\n",
      "Validation Loss: 1.6977\n",
      "Epoch [6/50], Class Loss: 1.0124, Discrepancy Loss: 0.0368\n",
      "Validation Loss: 1.1361\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 72.72%, Precision: 71.50%, Recall: 72.21%, F1 Score: 71.18%\n",
      "Target Domain Performance - Accuracy: 58.99%, Precision: 58.65%, Recall: 57.95%, F1 Score: 54.40%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 1.7837, Discrepancy Loss: 0.0505\n",
      "Validation Loss: 1.2774\n",
      "Epoch [2/50], Class Loss: 1.1867, Discrepancy Loss: 0.0280\n",
      "Validation Loss: 1.2810\n",
      "Epoch [3/50], Class Loss: 1.1310, Discrepancy Loss: 0.0268\n",
      "Validation Loss: 1.1458\n",
      "Epoch [4/50], Class Loss: 1.1107, Discrepancy Loss: 0.0320\n",
      "Validation Loss: 1.2478\n",
      "Epoch [5/50], Class Loss: 1.1267, Discrepancy Loss: 0.0353\n",
      "Validation Loss: 1.2945\n",
      "Epoch [6/50], Class Loss: 1.0526, Discrepancy Loss: 0.0389\n",
      "Validation Loss: 1.2086\n",
      "Epoch [7/50], Class Loss: 1.0704, Discrepancy Loss: 0.0547\n",
      "Validation Loss: 1.2605\n",
      "Epoch [8/50], Class Loss: 1.0487, Discrepancy Loss: 0.0531\n",
      "Validation Loss: 1.2030\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 77.10%, Precision: 77.50%, Recall: 77.52%, F1 Score: 77.06%\n",
      "Target Domain Performance - Accuracy: 62.95%, Precision: 61.56%, Recall: 61.94%, F1 Score: 57.76%\n",
      "\n",
      "Source performance: 88.45% 88.38% 88.40% 88.17%\n",
      "Target performance: 65.10% 69.21% 63.80% 60.11%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 100.00%\n",
      "qpsk: 57.71%\n",
      "16qam: 85.52%\n",
      "16apsk: 11.97%\n",
      "SNR level: 18\n",
      "STAR\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 2.4241, Discrepancy Loss: 0.1058\n",
      "Epoch [2/50], Class Loss: 0.9961, Discrepancy Loss: 0.1257\n",
      "Epoch [3/50], Class Loss: 0.9425, Discrepancy Loss: 0.1267\n",
      "Epoch [4/50], Class Loss: 0.9077, Discrepancy Loss: 0.1340\n",
      "Epoch [5/50], Class Loss: 1.0112, Discrepancy Loss: 0.1171\n",
      "Epoch [6/50], Class Loss: 0.8598, Discrepancy Loss: 0.1233\n",
      "Epoch [7/50], Class Loss: 0.9019, Discrepancy Loss: 0.1220\n",
      "Epoch [8/50], Class Loss: 0.9285, Discrepancy Loss: 0.1219\n",
      "Epoch [9/50], Class Loss: 0.8456, Discrepancy Loss: 0.1212\n",
      "Epoch [10/50], Class Loss: 0.7546, Discrepancy Loss: 0.1245\n",
      "Epoch [11/50], Class Loss: 0.7546, Discrepancy Loss: 0.1070\n",
      "Epoch [12/50], Class Loss: 0.6983, Discrepancy Loss: 0.1096\n",
      "Epoch [13/50], Class Loss: 0.7052, Discrepancy Loss: 0.1071\n",
      "Epoch [14/50], Class Loss: 0.7114, Discrepancy Loss: 0.1140\n",
      "Epoch [15/50], Class Loss: 0.6678, Discrepancy Loss: 0.1180\n",
      "Epoch [16/50], Class Loss: 0.6801, Discrepancy Loss: 0.1101\n",
      "Epoch [17/50], Class Loss: 0.6674, Discrepancy Loss: 0.1056\n",
      "Epoch [18/50], Class Loss: 0.6360, Discrepancy Loss: 0.1027\n",
      "Epoch [19/50], Class Loss: 0.6329, Discrepancy Loss: 0.1058\n",
      "Epoch [20/50], Class Loss: 0.6248, Discrepancy Loss: 0.1216\n",
      "Epoch [21/50], Class Loss: 0.6003, Discrepancy Loss: 0.1090\n",
      "Epoch [22/50], Class Loss: 0.5733, Discrepancy Loss: 0.1060\n",
      "Epoch [23/50], Class Loss: 0.5809, Discrepancy Loss: 0.1048\n",
      "Epoch [24/50], Class Loss: 0.5689, Discrepancy Loss: 0.1016\n",
      "Epoch [25/50], Class Loss: 0.5709, Discrepancy Loss: 0.0952\n",
      "Epoch [26/50], Class Loss: 0.5487, Discrepancy Loss: 0.1128\n",
      "Epoch [27/50], Class Loss: 0.5574, Discrepancy Loss: 0.1010\n",
      "Epoch [28/50], Class Loss: 0.5504, Discrepancy Loss: 0.0962\n",
      "Epoch [29/50], Class Loss: 0.5937, Discrepancy Loss: 0.0967\n",
      "Epoch [30/50], Class Loss: 0.5412, Discrepancy Loss: 0.0937\n",
      "Epoch [31/50], Class Loss: 0.5304, Discrepancy Loss: 0.0967\n",
      "Epoch [32/50], Class Loss: 0.5160, Discrepancy Loss: 0.0917\n",
      "Epoch [33/50], Class Loss: 0.5167, Discrepancy Loss: 0.0891\n",
      "Epoch [34/50], Class Loss: 0.5103, Discrepancy Loss: 0.0889\n",
      "Epoch [35/50], Class Loss: 0.5167, Discrepancy Loss: 0.0864\n",
      "Epoch [36/50], Class Loss: 0.5321, Discrepancy Loss: 0.0921\n",
      "Epoch [37/50], Class Loss: 0.5170, Discrepancy Loss: 0.0886\n",
      "Epoch [38/50], Class Loss: 0.5116, Discrepancy Loss: 0.0881\n",
      "Epoch [39/50], Class Loss: 0.5170, Discrepancy Loss: 0.0876\n",
      "Epoch [40/50], Class Loss: 0.5155, Discrepancy Loss: 0.0944\n",
      "Epoch [41/50], Class Loss: 0.5334, Discrepancy Loss: 0.0916\n",
      "Epoch [42/50], Class Loss: 0.5216, Discrepancy Loss: 0.0915\n",
      "Epoch [43/50], Class Loss: 0.5116, Discrepancy Loss: 0.0866\n",
      "Epoch [44/50], Class Loss: 0.5230, Discrepancy Loss: 0.0836\n",
      "Epoch [45/50], Class Loss: 0.5161, Discrepancy Loss: 0.0859\n",
      "Epoch [46/50], Class Loss: 0.5239, Discrepancy Loss: 0.0903\n",
      "Epoch [47/50], Class Loss: 0.5465, Discrepancy Loss: 0.0892\n",
      "Epoch [48/50], Class Loss: 0.5222, Discrepancy Loss: 0.0872\n",
      "Epoch [49/50], Class Loss: 0.5217, Discrepancy Loss: 0.0887\n",
      "Epoch [50/50], Class Loss: 0.5171, Discrepancy Loss: 0.0878\n",
      "Source Domain Performance - Accuracy: 67.75%, Precision: 70.04%, Recall: 69.17%, F1 Score: 65.68%\n",
      "Target Domain Performance - Accuracy: 59.29%, Precision: 59.47%, Recall: 58.41%, F1 Score: 58.79%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 2.4609, Discrepancy Loss: 0.1031\n",
      "Epoch [2/50], Class Loss: 0.9715, Discrepancy Loss: 0.1338\n",
      "Epoch [3/50], Class Loss: 0.9225, Discrepancy Loss: 0.1218\n",
      "Epoch [4/50], Class Loss: 0.8737, Discrepancy Loss: 0.1246\n",
      "Epoch [5/50], Class Loss: 0.8975, Discrepancy Loss: 0.1119\n",
      "Epoch [6/50], Class Loss: 0.8321, Discrepancy Loss: 0.1294\n",
      "Epoch [7/50], Class Loss: 0.8285, Discrepancy Loss: 0.1228\n",
      "Epoch [8/50], Class Loss: 0.7917, Discrepancy Loss: 0.1145\n",
      "Epoch [9/50], Class Loss: 0.7542, Discrepancy Loss: 0.1311\n",
      "Epoch [10/50], Class Loss: 0.7813, Discrepancy Loss: 0.1071\n",
      "Epoch [11/50], Class Loss: 0.6595, Discrepancy Loss: 0.1192\n",
      "Epoch [12/50], Class Loss: 0.6731, Discrepancy Loss: 0.1082\n",
      "Epoch [13/50], Class Loss: 0.6293, Discrepancy Loss: 0.1031\n",
      "Epoch [14/50], Class Loss: 0.6013, Discrepancy Loss: 0.1018\n",
      "Epoch [15/50], Class Loss: 0.5799, Discrepancy Loss: 0.1048\n",
      "Epoch [16/50], Class Loss: 0.4988, Discrepancy Loss: 0.1043\n",
      "Epoch [17/50], Class Loss: 0.4062, Discrepancy Loss: 0.0858\n",
      "Epoch [18/50], Class Loss: 0.3054, Discrepancy Loss: 0.0751\n",
      "Epoch [19/50], Class Loss: 0.2515, Discrepancy Loss: 0.0722\n",
      "Epoch [20/50], Class Loss: 0.2335, Discrepancy Loss: 0.0669\n",
      "Epoch [21/50], Class Loss: 0.1709, Discrepancy Loss: 0.0640\n",
      "Epoch [22/50], Class Loss: 0.1735, Discrepancy Loss: 0.0654\n",
      "Epoch [23/50], Class Loss: 0.1607, Discrepancy Loss: 0.0603\n",
      "Epoch [24/50], Class Loss: 0.1508, Discrepancy Loss: 0.0587\n",
      "Epoch [25/50], Class Loss: 0.1601, Discrepancy Loss: 0.0635\n",
      "Epoch [26/50], Class Loss: 0.1955, Discrepancy Loss: 0.0628\n",
      "Epoch [27/50], Class Loss: 0.1560, Discrepancy Loss: 0.0611\n",
      "Epoch [28/50], Class Loss: 0.1514, Discrepancy Loss: 0.0644\n",
      "Epoch [29/50], Class Loss: 0.1523, Discrepancy Loss: 0.0588\n",
      "Epoch [30/50], Class Loss: 0.1455, Discrepancy Loss: 0.0635\n",
      "Epoch [31/50], Class Loss: 0.1340, Discrepancy Loss: 0.0614\n",
      "Epoch [32/50], Class Loss: 0.1268, Discrepancy Loss: 0.0618\n",
      "Epoch [33/50], Class Loss: 0.1280, Discrepancy Loss: 0.0633\n",
      "Epoch [34/50], Class Loss: 0.1423, Discrepancy Loss: 0.0673\n",
      "Epoch [35/50], Class Loss: 0.1461, Discrepancy Loss: 0.0613\n",
      "Epoch [36/50], Class Loss: 0.1241, Discrepancy Loss: 0.0561\n",
      "Epoch [37/50], Class Loss: 0.1347, Discrepancy Loss: 0.0604\n",
      "Epoch [38/50], Class Loss: 0.1499, Discrepancy Loss: 0.0653\n",
      "Epoch [39/50], Class Loss: 0.1305, Discrepancy Loss: 0.0628\n",
      "Epoch [40/50], Class Loss: 0.1317, Discrepancy Loss: 0.0625\n",
      "Epoch [41/50], Class Loss: 0.1328, Discrepancy Loss: 0.0656\n",
      "Epoch [42/50], Class Loss: 0.1259, Discrepancy Loss: 0.0596\n",
      "Epoch [43/50], Class Loss: 0.1398, Discrepancy Loss: 0.0624\n",
      "Epoch [44/50], Class Loss: 0.1283, Discrepancy Loss: 0.0611\n",
      "Epoch [45/50], Class Loss: 0.1231, Discrepancy Loss: 0.0632\n",
      "Epoch [46/50], Class Loss: 0.1295, Discrepancy Loss: 0.0579\n",
      "Epoch [47/50], Class Loss: 0.1315, Discrepancy Loss: 0.0633\n",
      "Epoch [48/50], Class Loss: 0.1267, Discrepancy Loss: 0.0628\n",
      "Epoch [49/50], Class Loss: 0.1351, Discrepancy Loss: 0.0646\n",
      "Epoch [50/50], Class Loss: 0.1240, Discrepancy Loss: 0.0617\n",
      "Source Domain Performance - Accuracy: 83.75%, Precision: 87.76%, Recall: 84.37%, F1 Score: 83.55%\n",
      "Target Domain Performance - Accuracy: 71.22%, Precision: 70.52%, Recall: 70.50%, F1 Score: 70.11%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 2.8051, Discrepancy Loss: 0.1043\n",
      "Epoch [2/50], Class Loss: 1.2134, Discrepancy Loss: 0.1263\n",
      "Epoch [3/50], Class Loss: 1.0358, Discrepancy Loss: 0.1416\n",
      "Epoch [4/50], Class Loss: 1.0176, Discrepancy Loss: 0.1208\n",
      "Epoch [5/50], Class Loss: 0.9767, Discrepancy Loss: 0.1227\n",
      "Epoch [6/50], Class Loss: 0.9178, Discrepancy Loss: 0.1392\n",
      "Epoch [7/50], Class Loss: 0.8766, Discrepancy Loss: 0.1215\n",
      "Epoch [8/50], Class Loss: 0.8161, Discrepancy Loss: 0.1203\n",
      "Epoch [9/50], Class Loss: 0.8531, Discrepancy Loss: 0.1159\n",
      "Epoch [10/50], Class Loss: 0.7380, Discrepancy Loss: 0.1188\n",
      "Epoch [11/50], Class Loss: 0.7072, Discrepancy Loss: 0.1155\n",
      "Epoch [12/50], Class Loss: 0.6798, Discrepancy Loss: 0.1137\n",
      "Epoch [13/50], Class Loss: 0.6595, Discrepancy Loss: 0.1117\n",
      "Epoch [14/50], Class Loss: 0.6519, Discrepancy Loss: 0.1114\n",
      "Epoch [15/50], Class Loss: 0.6276, Discrepancy Loss: 0.1016\n",
      "Epoch [16/50], Class Loss: 0.5231, Discrepancy Loss: 0.0933\n",
      "Epoch [17/50], Class Loss: 0.4132, Discrepancy Loss: 0.0914\n",
      "Epoch [18/50], Class Loss: 0.3555, Discrepancy Loss: 0.0775\n",
      "Epoch [19/50], Class Loss: 0.2847, Discrepancy Loss: 0.0636\n",
      "Epoch [20/50], Class Loss: 0.2546, Discrepancy Loss: 0.0608\n",
      "Epoch [21/50], Class Loss: 0.1925, Discrepancy Loss: 0.0621\n",
      "Epoch [22/50], Class Loss: 0.1817, Discrepancy Loss: 0.0639\n",
      "Epoch [23/50], Class Loss: 0.1713, Discrepancy Loss: 0.0571\n",
      "Epoch [24/50], Class Loss: 0.1683, Discrepancy Loss: 0.0567\n",
      "Epoch [25/50], Class Loss: 0.1664, Discrepancy Loss: 0.0604\n",
      "Epoch [26/50], Class Loss: 0.1623, Discrepancy Loss: 0.0570\n",
      "Epoch [27/50], Class Loss: 0.1449, Discrepancy Loss: 0.0563\n",
      "Epoch [28/50], Class Loss: 0.1622, Discrepancy Loss: 0.0590\n",
      "Epoch [29/50], Class Loss: 0.1417, Discrepancy Loss: 0.0539\n",
      "Epoch [30/50], Class Loss: 0.1438, Discrepancy Loss: 0.0607\n",
      "Epoch [31/50], Class Loss: 0.1218, Discrepancy Loss: 0.0559\n",
      "Epoch [32/50], Class Loss: 0.1265, Discrepancy Loss: 0.0539\n",
      "Epoch [33/50], Class Loss: 0.1267, Discrepancy Loss: 0.0547\n",
      "Epoch [34/50], Class Loss: 0.1278, Discrepancy Loss: 0.0552\n",
      "Epoch [35/50], Class Loss: 0.1283, Discrepancy Loss: 0.0543\n",
      "Epoch [36/50], Class Loss: 0.1388, Discrepancy Loss: 0.0579\n",
      "Epoch [37/50], Class Loss: 0.1342, Discrepancy Loss: 0.0594\n",
      "Epoch [38/50], Class Loss: 0.1297, Discrepancy Loss: 0.0570\n",
      "Epoch [39/50], Class Loss: 0.1369, Discrepancy Loss: 0.0622\n",
      "Epoch [40/50], Class Loss: 0.1375, Discrepancy Loss: 0.0574\n",
      "Epoch [41/50], Class Loss: 0.1194, Discrepancy Loss: 0.0567\n",
      "Epoch [42/50], Class Loss: 0.1293, Discrepancy Loss: 0.0580\n",
      "Epoch [43/50], Class Loss: 0.1241, Discrepancy Loss: 0.0555\n",
      "Epoch [44/50], Class Loss: 0.1188, Discrepancy Loss: 0.0560\n",
      "Epoch [45/50], Class Loss: 0.1292, Discrepancy Loss: 0.0553\n",
      "Epoch [46/50], Class Loss: 0.1255, Discrepancy Loss: 0.0540\n",
      "Epoch [47/50], Class Loss: 0.1200, Discrepancy Loss: 0.0529\n",
      "Epoch [48/50], Class Loss: 0.1196, Discrepancy Loss: 0.0562\n",
      "Epoch [49/50], Class Loss: 0.1244, Discrepancy Loss: 0.0544\n",
      "Epoch [50/50], Class Loss: 0.1205, Discrepancy Loss: 0.0557\n",
      "Source Domain Performance - Accuracy: 81.77%, Precision: 86.35%, Recall: 82.37%, F1 Score: 80.86%\n",
      "Target Domain Performance - Accuracy: 67.81%, Precision: 68.44%, Recall: 66.71%, F1 Score: 65.98%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 2.4315, Discrepancy Loss: 0.1150\n",
      "Epoch [2/50], Class Loss: 1.1543, Discrepancy Loss: 0.1163\n",
      "Epoch [3/50], Class Loss: 1.0797, Discrepancy Loss: 0.1296\n",
      "Epoch [4/50], Class Loss: 0.9222, Discrepancy Loss: 0.1250\n",
      "Epoch [5/50], Class Loss: 0.9134, Discrepancy Loss: 0.1222\n",
      "Epoch [6/50], Class Loss: 0.8675, Discrepancy Loss: 0.1130\n",
      "Epoch [7/50], Class Loss: 0.9055, Discrepancy Loss: 0.1218\n",
      "Epoch [8/50], Class Loss: 0.8127, Discrepancy Loss: 0.1253\n",
      "Epoch [9/50], Class Loss: 0.8167, Discrepancy Loss: 0.1236\n",
      "Epoch [10/50], Class Loss: 0.7615, Discrepancy Loss: 0.1039\n",
      "Epoch [11/50], Class Loss: 0.6937, Discrepancy Loss: 0.1196\n",
      "Epoch [12/50], Class Loss: 0.7226, Discrepancy Loss: 0.1109\n",
      "Epoch [13/50], Class Loss: 0.7016, Discrepancy Loss: 0.1080\n",
      "Epoch [14/50], Class Loss: 0.6526, Discrepancy Loss: 0.1142\n",
      "Epoch [15/50], Class Loss: 0.6687, Discrepancy Loss: 0.1085\n",
      "Epoch [16/50], Class Loss: 0.6486, Discrepancy Loss: 0.1008\n",
      "Epoch [17/50], Class Loss: 0.6221, Discrepancy Loss: 0.1039\n",
      "Epoch [18/50], Class Loss: 0.6080, Discrepancy Loss: 0.0939\n",
      "Epoch [19/50], Class Loss: 0.5574, Discrepancy Loss: 0.1046\n",
      "Epoch [20/50], Class Loss: 0.4929, Discrepancy Loss: 0.0914\n",
      "Epoch [21/50], Class Loss: 0.3742, Discrepancy Loss: 0.0857\n",
      "Epoch [22/50], Class Loss: 0.3356, Discrepancy Loss: 0.0914\n",
      "Epoch [23/50], Class Loss: 0.3401, Discrepancy Loss: 0.0846\n",
      "Epoch [24/50], Class Loss: 0.3282, Discrepancy Loss: 0.0870\n",
      "Epoch [25/50], Class Loss: 0.3971, Discrepancy Loss: 0.0918\n",
      "Epoch [26/50], Class Loss: 0.3057, Discrepancy Loss: 0.0844\n",
      "Epoch [27/50], Class Loss: 0.2978, Discrepancy Loss: 0.0931\n",
      "Epoch [28/50], Class Loss: 0.2948, Discrepancy Loss: 0.0831\n",
      "Epoch [29/50], Class Loss: 0.2752, Discrepancy Loss: 0.0827\n",
      "Epoch [30/50], Class Loss: 0.2753, Discrepancy Loss: 0.0846\n",
      "Epoch [31/50], Class Loss: 0.2467, Discrepancy Loss: 0.0877\n",
      "Epoch [32/50], Class Loss: 0.2688, Discrepancy Loss: 0.0859\n",
      "Epoch [33/50], Class Loss: 0.2644, Discrepancy Loss: 0.0854\n",
      "Epoch [34/50], Class Loss: 0.2632, Discrepancy Loss: 0.0847\n",
      "Epoch [35/50], Class Loss: 0.2756, Discrepancy Loss: 0.0890\n",
      "Epoch [36/50], Class Loss: 0.2571, Discrepancy Loss: 0.0893\n",
      "Epoch [37/50], Class Loss: 0.2567, Discrepancy Loss: 0.0853\n",
      "Epoch [38/50], Class Loss: 0.2592, Discrepancy Loss: 0.0815\n",
      "Epoch [39/50], Class Loss: 0.2549, Discrepancy Loss: 0.0818\n",
      "Epoch [40/50], Class Loss: 0.2619, Discrepancy Loss: 0.0921\n",
      "Epoch [41/50], Class Loss: 0.2463, Discrepancy Loss: 0.0857\n",
      "Epoch [42/50], Class Loss: 0.2608, Discrepancy Loss: 0.0817\n",
      "Epoch [43/50], Class Loss: 0.3201, Discrepancy Loss: 0.0882\n",
      "Epoch [44/50], Class Loss: 0.2755, Discrepancy Loss: 0.0842\n",
      "Epoch [45/50], Class Loss: 0.2457, Discrepancy Loss: 0.0850\n",
      "Epoch [46/50], Class Loss: 0.2568, Discrepancy Loss: 0.0900\n",
      "Epoch [47/50], Class Loss: 0.2611, Discrepancy Loss: 0.0852\n",
      "Epoch [48/50], Class Loss: 0.2577, Discrepancy Loss: 0.0845\n",
      "Epoch [49/50], Class Loss: 0.2449, Discrepancy Loss: 0.0840\n",
      "Epoch [50/50], Class Loss: 0.2624, Discrepancy Loss: 0.0869\n",
      "Source Domain Performance - Accuracy: 83.15%, Precision: 86.43%, Recall: 83.72%, F1 Score: 83.32%\n",
      "Target Domain Performance - Accuracy: 71.04%, Precision: 70.67%, Recall: 70.15%, F1 Score: 70.11%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 2.2074, Discrepancy Loss: 0.1089\n",
      "Epoch [2/50], Class Loss: 1.2143, Discrepancy Loss: 0.1304\n",
      "Epoch [3/50], Class Loss: 1.0167, Discrepancy Loss: 0.1345\n",
      "Epoch [4/50], Class Loss: 1.0089, Discrepancy Loss: 0.1386\n",
      "Epoch [5/50], Class Loss: 0.9219, Discrepancy Loss: 0.1230\n",
      "Epoch [6/50], Class Loss: 0.9096, Discrepancy Loss: 0.1333\n",
      "Epoch [7/50], Class Loss: 0.8832, Discrepancy Loss: 0.1317\n",
      "Epoch [8/50], Class Loss: 0.8151, Discrepancy Loss: 0.1279\n",
      "Epoch [9/50], Class Loss: 0.8207, Discrepancy Loss: 0.1300\n",
      "Epoch [10/50], Class Loss: 0.8026, Discrepancy Loss: 0.1257\n",
      "Epoch [11/50], Class Loss: 0.6932, Discrepancy Loss: 0.1073\n",
      "Epoch [12/50], Class Loss: 0.6278, Discrepancy Loss: 0.1022\n",
      "Epoch [13/50], Class Loss: 0.5279, Discrepancy Loss: 0.0971\n",
      "Epoch [14/50], Class Loss: 0.4693, Discrepancy Loss: 0.0801\n",
      "Epoch [15/50], Class Loss: 0.3524, Discrepancy Loss: 0.0733\n",
      "Epoch [16/50], Class Loss: 0.3199, Discrepancy Loss: 0.0742\n",
      "Epoch [17/50], Class Loss: 0.3013, Discrepancy Loss: 0.0698\n",
      "Epoch [18/50], Class Loss: 0.2776, Discrepancy Loss: 0.0719\n",
      "Epoch [19/50], Class Loss: 0.2188, Discrepancy Loss: 0.0738\n",
      "Epoch [20/50], Class Loss: 0.2056, Discrepancy Loss: 0.0643\n",
      "Epoch [21/50], Class Loss: 0.1652, Discrepancy Loss: 0.0661\n",
      "Epoch [22/50], Class Loss: 0.1874, Discrepancy Loss: 0.0678\n",
      "Epoch [23/50], Class Loss: 0.1512, Discrepancy Loss: 0.0638\n",
      "Epoch [24/50], Class Loss: 0.1619, Discrepancy Loss: 0.0638\n",
      "Epoch [25/50], Class Loss: 0.1517, Discrepancy Loss: 0.0695\n",
      "Epoch [26/50], Class Loss: 0.1480, Discrepancy Loss: 0.0617\n",
      "Epoch [27/50], Class Loss: 0.1446, Discrepancy Loss: 0.0658\n",
      "Epoch [28/50], Class Loss: 0.1728, Discrepancy Loss: 0.0643\n",
      "Epoch [29/50], Class Loss: 0.1454, Discrepancy Loss: 0.0664\n",
      "Epoch [30/50], Class Loss: 0.1498, Discrepancy Loss: 0.0586\n",
      "Epoch [31/50], Class Loss: 0.1558, Discrepancy Loss: 0.0571\n",
      "Epoch [32/50], Class Loss: 0.1406, Discrepancy Loss: 0.0685\n",
      "Epoch [33/50], Class Loss: 0.1295, Discrepancy Loss: 0.0669\n",
      "Epoch [34/50], Class Loss: 0.1544, Discrepancy Loss: 0.0644\n",
      "Epoch [35/50], Class Loss: 0.1362, Discrepancy Loss: 0.0664\n",
      "Epoch [36/50], Class Loss: 0.1413, Discrepancy Loss: 0.0646\n",
      "Epoch [37/50], Class Loss: 0.1251, Discrepancy Loss: 0.0631\n",
      "Epoch [38/50], Class Loss: 0.1383, Discrepancy Loss: 0.0678\n",
      "Epoch [39/50], Class Loss: 0.1268, Discrepancy Loss: 0.0625\n",
      "Epoch [40/50], Class Loss: 0.1215, Discrepancy Loss: 0.0610\n",
      "Epoch [41/50], Class Loss: 0.1252, Discrepancy Loss: 0.0637\n",
      "Epoch [42/50], Class Loss: 0.1375, Discrepancy Loss: 0.0634\n",
      "Epoch [43/50], Class Loss: 0.1489, Discrepancy Loss: 0.0673\n",
      "Epoch [44/50], Class Loss: 0.1576, Discrepancy Loss: 0.0648\n",
      "Epoch [45/50], Class Loss: 0.1376, Discrepancy Loss: 0.0698\n",
      "Epoch [46/50], Class Loss: 0.1244, Discrepancy Loss: 0.0662\n",
      "Epoch [47/50], Class Loss: 0.1373, Discrepancy Loss: 0.0660\n",
      "Epoch [48/50], Class Loss: 0.1255, Discrepancy Loss: 0.0636\n",
      "Epoch [49/50], Class Loss: 0.1412, Discrepancy Loss: 0.0671\n",
      "Epoch [50/50], Class Loss: 0.1411, Discrepancy Loss: 0.0667\n",
      "Source Domain Performance - Accuracy: 87.71%, Precision: 89.89%, Recall: 88.11%, F1 Score: 87.56%\n",
      "Target Domain Performance - Accuracy: 76.26%, Precision: 75.36%, Recall: 75.82%, F1 Score: 75.34%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 2.6838, Discrepancy Loss: 0.1084\n",
      "Epoch [2/50], Class Loss: 1.1630, Discrepancy Loss: 0.1364\n",
      "Epoch [3/50], Class Loss: 1.0435, Discrepancy Loss: 0.1445\n",
      "Epoch [4/50], Class Loss: 1.1105, Discrepancy Loss: 0.1206\n",
      "Epoch [5/50], Class Loss: 1.0622, Discrepancy Loss: 0.1255\n",
      "Epoch [6/50], Class Loss: 1.0592, Discrepancy Loss: 0.1303\n",
      "Epoch [7/50], Class Loss: 0.9255, Discrepancy Loss: 0.1269\n",
      "Epoch [8/50], Class Loss: 0.9989, Discrepancy Loss: 0.1234\n",
      "Epoch [9/50], Class Loss: 0.9056, Discrepancy Loss: 0.1267\n",
      "Epoch [10/50], Class Loss: 0.8515, Discrepancy Loss: 0.1214\n",
      "Epoch [11/50], Class Loss: 0.6947, Discrepancy Loss: 0.1119\n",
      "Epoch [12/50], Class Loss: 0.6753, Discrepancy Loss: 0.1132\n",
      "Epoch [13/50], Class Loss: 0.6142, Discrepancy Loss: 0.0971\n",
      "Epoch [14/50], Class Loss: 0.5408, Discrepancy Loss: 0.0921\n",
      "Epoch [15/50], Class Loss: 0.4731, Discrepancy Loss: 0.0855\n",
      "Epoch [16/50], Class Loss: 0.3929, Discrepancy Loss: 0.0799\n",
      "Epoch [17/50], Class Loss: 0.3613, Discrepancy Loss: 0.0705\n",
      "Epoch [18/50], Class Loss: 0.3011, Discrepancy Loss: 0.0673\n",
      "Epoch [19/50], Class Loss: 0.2648, Discrepancy Loss: 0.0596\n",
      "Epoch [20/50], Class Loss: 0.2495, Discrepancy Loss: 0.0595\n",
      "Epoch [21/50], Class Loss: 0.2075, Discrepancy Loss: 0.0597\n",
      "Epoch [22/50], Class Loss: 0.1652, Discrepancy Loss: 0.0623\n",
      "Epoch [23/50], Class Loss: 0.1827, Discrepancy Loss: 0.0573\n",
      "Epoch [24/50], Class Loss: 0.1749, Discrepancy Loss: 0.0556\n",
      "Epoch [25/50], Class Loss: 0.1794, Discrepancy Loss: 0.0584\n",
      "Epoch [26/50], Class Loss: 0.1649, Discrepancy Loss: 0.0555\n",
      "Epoch [27/50], Class Loss: 0.1639, Discrepancy Loss: 0.0607\n",
      "Epoch [28/50], Class Loss: 0.1581, Discrepancy Loss: 0.0586\n",
      "Epoch [29/50], Class Loss: 0.1719, Discrepancy Loss: 0.0554\n",
      "Epoch [30/50], Class Loss: 0.1452, Discrepancy Loss: 0.0496\n",
      "Epoch [31/50], Class Loss: 0.1718, Discrepancy Loss: 0.0568\n",
      "Epoch [32/50], Class Loss: 0.1394, Discrepancy Loss: 0.0583\n",
      "Epoch [33/50], Class Loss: 0.1591, Discrepancy Loss: 0.0629\n",
      "Epoch [34/50], Class Loss: 0.1548, Discrepancy Loss: 0.0512\n",
      "Epoch [35/50], Class Loss: 0.1593, Discrepancy Loss: 0.0579\n",
      "Epoch [36/50], Class Loss: 0.1575, Discrepancy Loss: 0.0555\n",
      "Epoch [37/50], Class Loss: 0.1509, Discrepancy Loss: 0.0556\n",
      "Epoch [38/50], Class Loss: 0.1508, Discrepancy Loss: 0.0639\n",
      "Epoch [39/50], Class Loss: 0.1379, Discrepancy Loss: 0.0575\n",
      "Epoch [40/50], Class Loss: 0.1512, Discrepancy Loss: 0.0545\n",
      "Epoch [41/50], Class Loss: 0.1438, Discrepancy Loss: 0.0561\n",
      "Epoch [42/50], Class Loss: 0.1626, Discrepancy Loss: 0.0603\n",
      "Epoch [43/50], Class Loss: 0.1323, Discrepancy Loss: 0.0585\n",
      "Epoch [44/50], Class Loss: 0.1486, Discrepancy Loss: 0.0586\n",
      "Epoch [45/50], Class Loss: 0.1399, Discrepancy Loss: 0.0592\n",
      "Epoch [46/50], Class Loss: 0.1479, Discrepancy Loss: 0.0561\n",
      "Epoch [47/50], Class Loss: 0.1485, Discrepancy Loss: 0.0596\n",
      "Epoch [48/50], Class Loss: 0.1584, Discrepancy Loss: 0.0607\n",
      "Epoch [49/50], Class Loss: 0.1434, Discrepancy Loss: 0.0614\n",
      "Epoch [50/50], Class Loss: 0.1336, Discrepancy Loss: 0.0622\n",
      "Source Domain Performance - Accuracy: 83.21%, Precision: 87.25%, Recall: 83.78%, F1 Score: 82.42%\n",
      "Target Domain Performance - Accuracy: 70.26%, Precision: 70.41%, Recall: 69.24%, F1 Score: 68.80%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 2.5172, Discrepancy Loss: 0.1219\n",
      "Epoch [2/50], Class Loss: 1.1106, Discrepancy Loss: 0.1383\n",
      "Epoch [3/50], Class Loss: 0.9589, Discrepancy Loss: 0.1464\n",
      "Epoch [4/50], Class Loss: 1.0684, Discrepancy Loss: 0.1250\n",
      "Epoch [5/50], Class Loss: 1.0452, Discrepancy Loss: 0.1145\n",
      "Epoch [6/50], Class Loss: 0.9507, Discrepancy Loss: 0.1296\n",
      "Epoch [7/50], Class Loss: 0.9208, Discrepancy Loss: 0.1257\n",
      "Epoch [8/50], Class Loss: 1.0050, Discrepancy Loss: 0.1329\n",
      "Epoch [9/50], Class Loss: 0.7957, Discrepancy Loss: 0.1183\n",
      "Epoch [10/50], Class Loss: 0.7744, Discrepancy Loss: 0.1245\n",
      "Epoch [11/50], Class Loss: 0.7401, Discrepancy Loss: 0.1136\n",
      "Epoch [12/50], Class Loss: 0.6988, Discrepancy Loss: 0.1156\n",
      "Epoch [13/50], Class Loss: 0.7003, Discrepancy Loss: 0.1200\n",
      "Epoch [14/50], Class Loss: 0.6868, Discrepancy Loss: 0.1260\n",
      "Epoch [15/50], Class Loss: 0.6680, Discrepancy Loss: 0.1262\n",
      "Epoch [16/50], Class Loss: 0.6737, Discrepancy Loss: 0.1154\n",
      "Epoch [17/50], Class Loss: 0.5972, Discrepancy Loss: 0.1193\n",
      "Epoch [18/50], Class Loss: 0.4942, Discrepancy Loss: 0.1026\n",
      "Epoch [19/50], Class Loss: 0.3698, Discrepancy Loss: 0.0870\n",
      "Epoch [20/50], Class Loss: 0.3197, Discrepancy Loss: 0.0830\n",
      "Epoch [21/50], Class Loss: 0.2285, Discrepancy Loss: 0.0798\n",
      "Epoch [22/50], Class Loss: 0.2295, Discrepancy Loss: 0.0798\n",
      "Epoch [23/50], Class Loss: 0.2153, Discrepancy Loss: 0.0718\n",
      "Epoch [24/50], Class Loss: 0.2194, Discrepancy Loss: 0.0710\n",
      "Epoch [25/50], Class Loss: 0.2182, Discrepancy Loss: 0.0795\n",
      "Epoch [26/50], Class Loss: 0.2124, Discrepancy Loss: 0.0682\n",
      "Epoch [27/50], Class Loss: 0.2158, Discrepancy Loss: 0.0695\n",
      "Epoch [28/50], Class Loss: 0.2003, Discrepancy Loss: 0.0731\n",
      "Epoch [29/50], Class Loss: 0.1997, Discrepancy Loss: 0.0690\n",
      "Epoch [30/50], Class Loss: 0.2016, Discrepancy Loss: 0.0655\n",
      "Epoch [31/50], Class Loss: 0.1813, Discrepancy Loss: 0.0679\n",
      "Epoch [32/50], Class Loss: 0.1756, Discrepancy Loss: 0.0676\n",
      "Epoch [33/50], Class Loss: 0.1797, Discrepancy Loss: 0.0687\n",
      "Epoch [34/50], Class Loss: 0.1854, Discrepancy Loss: 0.0644\n",
      "Epoch [35/50], Class Loss: 0.1849, Discrepancy Loss: 0.0684\n",
      "Epoch [36/50], Class Loss: 0.1975, Discrepancy Loss: 0.0714\n",
      "Epoch [37/50], Class Loss: 0.1865, Discrepancy Loss: 0.0720\n",
      "Epoch [38/50], Class Loss: 0.1833, Discrepancy Loss: 0.0715\n",
      "Epoch [39/50], Class Loss: 0.1922, Discrepancy Loss: 0.0704\n",
      "Epoch [40/50], Class Loss: 0.1837, Discrepancy Loss: 0.0658\n",
      "Epoch [41/50], Class Loss: 0.1811, Discrepancy Loss: 0.0638\n",
      "Epoch [42/50], Class Loss: 0.1810, Discrepancy Loss: 0.0625\n",
      "Epoch [43/50], Class Loss: 0.1719, Discrepancy Loss: 0.0689\n",
      "Epoch [44/50], Class Loss: 0.1963, Discrepancy Loss: 0.0683\n",
      "Epoch [45/50], Class Loss: 0.1849, Discrepancy Loss: 0.0656\n",
      "Epoch [46/50], Class Loss: 0.1743, Discrepancy Loss: 0.0687\n",
      "Epoch [47/50], Class Loss: 0.1936, Discrepancy Loss: 0.0691\n",
      "Epoch [48/50], Class Loss: 0.1766, Discrepancy Loss: 0.0675\n",
      "Epoch [49/50], Class Loss: 0.1738, Discrepancy Loss: 0.0682\n",
      "Epoch [50/50], Class Loss: 0.1723, Discrepancy Loss: 0.0636\n",
      "Source Domain Performance - Accuracy: 82.37%, Precision: 86.42%, Recall: 82.96%, F1 Score: 81.40%\n",
      "Target Domain Performance - Accuracy: 70.26%, Precision: 71.03%, Recall: 69.39%, F1 Score: 68.53%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 2.4371, Discrepancy Loss: 0.1223\n",
      "Epoch [2/50], Class Loss: 1.2677, Discrepancy Loss: 0.1398\n",
      "Epoch [3/50], Class Loss: 1.1002, Discrepancy Loss: 0.1425\n",
      "Epoch [4/50], Class Loss: 1.1591, Discrepancy Loss: 0.1312\n",
      "Epoch [5/50], Class Loss: 1.0383, Discrepancy Loss: 0.1463\n",
      "Epoch [6/50], Class Loss: 0.9573, Discrepancy Loss: 0.1287\n",
      "Epoch [7/50], Class Loss: 0.8748, Discrepancy Loss: 0.1459\n",
      "Epoch [8/50], Class Loss: 0.8681, Discrepancy Loss: 0.1318\n",
      "Epoch [9/50], Class Loss: 0.8441, Discrepancy Loss: 0.1342\n",
      "Epoch [10/50], Class Loss: 0.7000, Discrepancy Loss: 0.1096\n",
      "Epoch [11/50], Class Loss: 0.3746, Discrepancy Loss: 0.0898\n",
      "Epoch [12/50], Class Loss: 0.3357, Discrepancy Loss: 0.0913\n",
      "Epoch [13/50], Class Loss: 0.3065, Discrepancy Loss: 0.0783\n",
      "Epoch [14/50], Class Loss: 0.3006, Discrepancy Loss: 0.0793\n",
      "Epoch [15/50], Class Loss: 0.2528, Discrepancy Loss: 0.0773\n",
      "Epoch [16/50], Class Loss: 0.2496, Discrepancy Loss: 0.0774\n",
      "Epoch [17/50], Class Loss: 0.2202, Discrepancy Loss: 0.0691\n",
      "Epoch [18/50], Class Loss: 0.2104, Discrepancy Loss: 0.0591\n",
      "Epoch [19/50], Class Loss: 0.2810, Discrepancy Loss: 0.0655\n",
      "Epoch [20/50], Class Loss: 0.1977, Discrepancy Loss: 0.0616\n",
      "Epoch [21/50], Class Loss: 0.1660, Discrepancy Loss: 0.0625\n",
      "Epoch [22/50], Class Loss: 0.1660, Discrepancy Loss: 0.0602\n",
      "Epoch [23/50], Class Loss: 0.1609, Discrepancy Loss: 0.0545\n",
      "Epoch [24/50], Class Loss: 0.1503, Discrepancy Loss: 0.0547\n",
      "Epoch [25/50], Class Loss: 0.1432, Discrepancy Loss: 0.0593\n",
      "Epoch [26/50], Class Loss: 0.1393, Discrepancy Loss: 0.0594\n",
      "Epoch [27/50], Class Loss: 0.1556, Discrepancy Loss: 0.0622\n",
      "Epoch [28/50], Class Loss: 0.1289, Discrepancy Loss: 0.0574\n",
      "Epoch [29/50], Class Loss: 0.1348, Discrepancy Loss: 0.0536\n",
      "Epoch [30/50], Class Loss: 0.1519, Discrepancy Loss: 0.0611\n",
      "Epoch [31/50], Class Loss: 0.1300, Discrepancy Loss: 0.0553\n",
      "Epoch [32/50], Class Loss: 0.1553, Discrepancy Loss: 0.0556\n",
      "Epoch [33/50], Class Loss: 0.1333, Discrepancy Loss: 0.0569\n",
      "Epoch [34/50], Class Loss: 0.1355, Discrepancy Loss: 0.0541\n",
      "Epoch [35/50], Class Loss: 0.1222, Discrepancy Loss: 0.0586\n",
      "Epoch [36/50], Class Loss: 0.1342, Discrepancy Loss: 0.0506\n",
      "Epoch [37/50], Class Loss: 0.1310, Discrepancy Loss: 0.0574\n",
      "Epoch [38/50], Class Loss: 0.1349, Discrepancy Loss: 0.0596\n",
      "Epoch [39/50], Class Loss: 0.1336, Discrepancy Loss: 0.0534\n",
      "Epoch [40/50], Class Loss: 0.1238, Discrepancy Loss: 0.0577\n",
      "Epoch [41/50], Class Loss: 0.1399, Discrepancy Loss: 0.0551\n",
      "Epoch [42/50], Class Loss: 0.1443, Discrepancy Loss: 0.0557\n",
      "Epoch [43/50], Class Loss: 0.1309, Discrepancy Loss: 0.0636\n",
      "Epoch [44/50], Class Loss: 0.1259, Discrepancy Loss: 0.0570\n",
      "Epoch [45/50], Class Loss: 0.1289, Discrepancy Loss: 0.0527\n",
      "Epoch [46/50], Class Loss: 0.1362, Discrepancy Loss: 0.0518\n",
      "Epoch [47/50], Class Loss: 0.1250, Discrepancy Loss: 0.0559\n",
      "Epoch [48/50], Class Loss: 0.1234, Discrepancy Loss: 0.0565\n",
      "Epoch [49/50], Class Loss: 0.1417, Discrepancy Loss: 0.0532\n",
      "Epoch [50/50], Class Loss: 0.1323, Discrepancy Loss: 0.0552\n",
      "Source Domain Performance - Accuracy: 87.41%, Precision: 89.82%, Recall: 87.83%, F1 Score: 87.23%\n",
      "Target Domain Performance - Accuracy: 76.62%, Precision: 75.58%, Recall: 76.44%, F1 Score: 75.66%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 2.3487, Discrepancy Loss: 0.1191\n",
      "Epoch [2/50], Class Loss: 1.1822, Discrepancy Loss: 0.1274\n",
      "Epoch [3/50], Class Loss: 1.0090, Discrepancy Loss: 0.1427\n",
      "Epoch [4/50], Class Loss: 1.0662, Discrepancy Loss: 0.1193\n",
      "Epoch [5/50], Class Loss: 0.9346, Discrepancy Loss: 0.1355\n",
      "Epoch [6/50], Class Loss: 0.9236, Discrepancy Loss: 0.1338\n",
      "Epoch [7/50], Class Loss: 0.9740, Discrepancy Loss: 0.1194\n",
      "Epoch [8/50], Class Loss: 0.8377, Discrepancy Loss: 0.1244\n",
      "Epoch [9/50], Class Loss: 0.8390, Discrepancy Loss: 0.1251\n",
      "Epoch [10/50], Class Loss: 0.8105, Discrepancy Loss: 0.1183\n",
      "Epoch [11/50], Class Loss: 0.7505, Discrepancy Loss: 0.1254\n",
      "Epoch [12/50], Class Loss: 0.7454, Discrepancy Loss: 0.1243\n",
      "Epoch [13/50], Class Loss: 0.7587, Discrepancy Loss: 0.1287\n",
      "Epoch [14/50], Class Loss: 0.7321, Discrepancy Loss: 0.1162\n",
      "Epoch [15/50], Class Loss: 0.7106, Discrepancy Loss: 0.1314\n",
      "Epoch [16/50], Class Loss: 0.7409, Discrepancy Loss: 0.1313\n",
      "Epoch [17/50], Class Loss: 0.6909, Discrepancy Loss: 0.1248\n",
      "Epoch [18/50], Class Loss: 0.7162, Discrepancy Loss: 0.1162\n",
      "Epoch [19/50], Class Loss: 0.6663, Discrepancy Loss: 0.1239\n",
      "Epoch [20/50], Class Loss: 0.7390, Discrepancy Loss: 0.1181\n",
      "Epoch [21/50], Class Loss: 0.6838, Discrepancy Loss: 0.1117\n",
      "Epoch [22/50], Class Loss: 0.6566, Discrepancy Loss: 0.1116\n",
      "Epoch [23/50], Class Loss: 0.6591, Discrepancy Loss: 0.1106\n",
      "Epoch [24/50], Class Loss: 0.6495, Discrepancy Loss: 0.1100\n",
      "Epoch [25/50], Class Loss: 0.6585, Discrepancy Loss: 0.1030\n",
      "Epoch [26/50], Class Loss: 0.6441, Discrepancy Loss: 0.1150\n",
      "Epoch [27/50], Class Loss: 0.6037, Discrepancy Loss: 0.1069\n",
      "Epoch [28/50], Class Loss: 0.6223, Discrepancy Loss: 0.0991\n",
      "Epoch [29/50], Class Loss: 0.6337, Discrepancy Loss: 0.1042\n",
      "Epoch [30/50], Class Loss: 0.6161, Discrepancy Loss: 0.0968\n",
      "Epoch [31/50], Class Loss: 0.6303, Discrepancy Loss: 0.0949\n",
      "Epoch [32/50], Class Loss: 0.6242, Discrepancy Loss: 0.0929\n",
      "Epoch [33/50], Class Loss: 0.5917, Discrepancy Loss: 0.0954\n",
      "Epoch [34/50], Class Loss: 0.6058, Discrepancy Loss: 0.0917\n",
      "Epoch [35/50], Class Loss: 0.5931, Discrepancy Loss: 0.0895\n",
      "Epoch [36/50], Class Loss: 0.5957, Discrepancy Loss: 0.0931\n",
      "Epoch [37/50], Class Loss: 0.6254, Discrepancy Loss: 0.0895\n",
      "Epoch [38/50], Class Loss: 0.6051, Discrepancy Loss: 0.0941\n",
      "Epoch [39/50], Class Loss: 0.6186, Discrepancy Loss: 0.0865\n",
      "Epoch [40/50], Class Loss: 0.6060, Discrepancy Loss: 0.0895\n",
      "Epoch [41/50], Class Loss: 0.5961, Discrepancy Loss: 0.0944\n",
      "Epoch [42/50], Class Loss: 0.5990, Discrepancy Loss: 0.0909\n",
      "Epoch [43/50], Class Loss: 0.6083, Discrepancy Loss: 0.0879\n",
      "Epoch [44/50], Class Loss: 0.5983, Discrepancy Loss: 0.0852\n",
      "Epoch [45/50], Class Loss: 0.6235, Discrepancy Loss: 0.0966\n",
      "Epoch [46/50], Class Loss: 0.5882, Discrepancy Loss: 0.0928\n",
      "Epoch [47/50], Class Loss: 0.6013, Discrepancy Loss: 0.0906\n",
      "Epoch [48/50], Class Loss: 0.5971, Discrepancy Loss: 0.0905\n",
      "Epoch [49/50], Class Loss: 0.5942, Discrepancy Loss: 0.0936\n",
      "Epoch [50/50], Class Loss: 0.6019, Discrepancy Loss: 0.0955\n",
      "Source Domain Performance - Accuracy: 71.64%, Precision: 71.35%, Recall: 72.57%, F1 Score: 69.47%\n",
      "Target Domain Performance - Accuracy: 65.71%, Precision: 64.77%, Recall: 65.52%, F1 Score: 63.45%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 2.5748, Discrepancy Loss: 0.1068\n",
      "Epoch [2/50], Class Loss: 1.2122, Discrepancy Loss: 0.1178\n",
      "Epoch [3/50], Class Loss: 1.0529, Discrepancy Loss: 0.1285\n",
      "Epoch [4/50], Class Loss: 0.9354, Discrepancy Loss: 0.1160\n",
      "Epoch [5/50], Class Loss: 0.9209, Discrepancy Loss: 0.1320\n",
      "Epoch [6/50], Class Loss: 0.9351, Discrepancy Loss: 0.1241\n",
      "Epoch [7/50], Class Loss: 0.9164, Discrepancy Loss: 0.1258\n",
      "Epoch [8/50], Class Loss: 0.8997, Discrepancy Loss: 0.1230\n",
      "Epoch [9/50], Class Loss: 0.7964, Discrepancy Loss: 0.1153\n",
      "Epoch [10/50], Class Loss: 0.7598, Discrepancy Loss: 0.1089\n",
      "Epoch [11/50], Class Loss: 0.6814, Discrepancy Loss: 0.1155\n",
      "Epoch [12/50], Class Loss: 0.6393, Discrepancy Loss: 0.1086\n",
      "Epoch [13/50], Class Loss: 0.5975, Discrepancy Loss: 0.0972\n",
      "Epoch [14/50], Class Loss: 0.5266, Discrepancy Loss: 0.0877\n",
      "Epoch [15/50], Class Loss: 0.4191, Discrepancy Loss: 0.0752\n",
      "Epoch [16/50], Class Loss: 0.3558, Discrepancy Loss: 0.0744\n",
      "Epoch [17/50], Class Loss: 0.2942, Discrepancy Loss: 0.0721\n",
      "Epoch [18/50], Class Loss: 0.2956, Discrepancy Loss: 0.0669\n",
      "Epoch [19/50], Class Loss: 0.2497, Discrepancy Loss: 0.0602\n",
      "Epoch [20/50], Class Loss: 0.2279, Discrepancy Loss: 0.0648\n",
      "Epoch [21/50], Class Loss: 0.1921, Discrepancy Loss: 0.0652\n",
      "Epoch [22/50], Class Loss: 0.1727, Discrepancy Loss: 0.0583\n",
      "Epoch [23/50], Class Loss: 0.1615, Discrepancy Loss: 0.0619\n",
      "Epoch [24/50], Class Loss: 0.1747, Discrepancy Loss: 0.0617\n",
      "Epoch [25/50], Class Loss: 0.1720, Discrepancy Loss: 0.0642\n",
      "Epoch [26/50], Class Loss: 0.1600, Discrepancy Loss: 0.0605\n",
      "Epoch [27/50], Class Loss: 0.1666, Discrepancy Loss: 0.0616\n",
      "Epoch [28/50], Class Loss: 0.1451, Discrepancy Loss: 0.0602\n",
      "Epoch [29/50], Class Loss: 0.1318, Discrepancy Loss: 0.0601\n",
      "Epoch [30/50], Class Loss: 0.1629, Discrepancy Loss: 0.0620\n",
      "Epoch [31/50], Class Loss: 0.1476, Discrepancy Loss: 0.0560\n",
      "Epoch [32/50], Class Loss: 0.1265, Discrepancy Loss: 0.0630\n",
      "Epoch [33/50], Class Loss: 0.1332, Discrepancy Loss: 0.0655\n",
      "Epoch [34/50], Class Loss: 0.1313, Discrepancy Loss: 0.0582\n",
      "Epoch [35/50], Class Loss: 0.1386, Discrepancy Loss: 0.0613\n",
      "Epoch [36/50], Class Loss: 0.1362, Discrepancy Loss: 0.0595\n",
      "Epoch [37/50], Class Loss: 0.1419, Discrepancy Loss: 0.0624\n",
      "Epoch [38/50], Class Loss: 0.1538, Discrepancy Loss: 0.0558\n",
      "Epoch [39/50], Class Loss: 0.1404, Discrepancy Loss: 0.0585\n",
      "Epoch [40/50], Class Loss: 0.1458, Discrepancy Loss: 0.0628\n",
      "Epoch [41/50], Class Loss: 0.1328, Discrepancy Loss: 0.0570\n",
      "Epoch [42/50], Class Loss: 0.1274, Discrepancy Loss: 0.0620\n",
      "Epoch [43/50], Class Loss: 0.1480, Discrepancy Loss: 0.0606\n",
      "Epoch [44/50], Class Loss: 0.1442, Discrepancy Loss: 0.0604\n",
      "Epoch [45/50], Class Loss: 0.1899, Discrepancy Loss: 0.0603\n",
      "Epoch [46/50], Class Loss: 0.1367, Discrepancy Loss: 0.0599\n",
      "Epoch [47/50], Class Loss: 0.1530, Discrepancy Loss: 0.0595\n",
      "Epoch [48/50], Class Loss: 0.1202, Discrepancy Loss: 0.0575\n",
      "Epoch [49/50], Class Loss: 0.1378, Discrepancy Loss: 0.0607\n",
      "Epoch [50/50], Class Loss: 0.1374, Discrepancy Loss: 0.0620\n",
      "Source Domain Performance - Accuracy: 83.75%, Precision: 87.70%, Recall: 84.37%, F1 Score: 83.55%\n",
      "Target Domain Performance - Accuracy: 68.35%, Precision: 68.77%, Recall: 67.26%, F1 Score: 67.06%\n",
      "\n",
      "Source performance: 81.25% 84.30% 81.93% 80.50%\n",
      "Target performance: 69.68% 69.50% 68.94% 68.38%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 100.00%\n",
      "qpsk: 67.50%\n",
      "16qam: 66.10%\n",
      "16apsk: 42.17%\n",
      "SNR level: 22\n",
      "SNR level: 22\n",
      "CORAL\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 1.1750, CORAL Loss: 0.0237\n",
      "Validation Loss: 0.8721\n",
      "Epoch [2/50], Class Loss: 0.8318, CORAL Loss: 0.0103\n",
      "Validation Loss: 0.9061\n",
      "Epoch [3/50], Class Loss: 0.8384, CORAL Loss: 0.0063\n",
      "Validation Loss: 0.8465\n",
      "Epoch [4/50], Class Loss: 0.8252, CORAL Loss: 0.0048\n",
      "Validation Loss: 0.8458\n",
      "Epoch [5/50], Class Loss: 0.8135, CORAL Loss: 0.0052\n",
      "Validation Loss: 0.8474\n",
      "Epoch [6/50], Class Loss: 0.8613, CORAL Loss: 0.0346\n",
      "Validation Loss: 1.0306\n",
      "Epoch [7/50], Class Loss: 0.8105, CORAL Loss: 0.0092\n",
      "Validation Loss: 0.8702\n",
      "Epoch [8/50], Class Loss: 0.7584, CORAL Loss: 0.0080\n",
      "Validation Loss: 0.8232\n",
      "Epoch [9/50], Class Loss: 0.6390, CORAL Loss: 0.0261\n",
      "Validation Loss: 0.6404\n",
      "Epoch [10/50], Class Loss: 0.4612, CORAL Loss: 0.0409\n",
      "Validation Loss: 0.6297\n",
      "Epoch [11/50], Class Loss: 0.3201, CORAL Loss: 0.0315\n",
      "Validation Loss: 0.5639\n",
      "Epoch [12/50], Class Loss: 0.2867, CORAL Loss: 0.0328\n",
      "Validation Loss: 0.5714\n",
      "Epoch [13/50], Class Loss: 0.2706, CORAL Loss: 0.0332\n",
      "Validation Loss: 0.5734\n",
      "Epoch [14/50], Class Loss: 0.2524, CORAL Loss: 0.0314\n",
      "Validation Loss: 0.5743\n",
      "Epoch [15/50], Class Loss: 0.2405, CORAL Loss: 0.0298\n",
      "Validation Loss: 0.5781\n",
      "Epoch [16/50], Class Loss: 0.2221, CORAL Loss: 0.0299\n",
      "Validation Loss: 0.5823\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 72.42%, Precision: 73.15%, Recall: 73.21%, F1 Score: 73.14%\n",
      "Target Domain Performance - Accuracy: 47.06%, Precision: 53.37%, Recall: 47.49%, F1 Score: 42.13%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 1.0006, CORAL Loss: 0.0200\n",
      "Validation Loss: 0.8482\n",
      "Epoch [2/50], Class Loss: 0.8302, CORAL Loss: 0.0074\n",
      "Validation Loss: 0.8462\n",
      "Epoch [3/50], Class Loss: 0.8362, CORAL Loss: 0.0075\n",
      "Validation Loss: 0.8357\n",
      "Epoch [4/50], Class Loss: 0.8093, CORAL Loss: 0.0032\n",
      "Validation Loss: 0.8304\n",
      "Epoch [5/50], Class Loss: 0.7909, CORAL Loss: 0.0061\n",
      "Validation Loss: 0.8153\n",
      "Epoch [6/50], Class Loss: 0.8460, CORAL Loss: 0.0948\n",
      "Validation Loss: 0.8318\n",
      "Epoch [7/50], Class Loss: 0.6373, CORAL Loss: 0.0280\n",
      "Validation Loss: 1.1261\n",
      "Epoch [8/50], Class Loss: 0.4889, CORAL Loss: 0.0354\n",
      "Validation Loss: 0.5541\n",
      "Epoch [9/50], Class Loss: 0.3463, CORAL Loss: 0.0316\n",
      "Validation Loss: 0.4985\n",
      "Epoch [10/50], Class Loss: 0.2781, CORAL Loss: 0.0204\n",
      "Validation Loss: 0.4757\n",
      "Epoch [11/50], Class Loss: 0.2104, CORAL Loss: 0.0133\n",
      "Validation Loss: 0.4373\n",
      "Epoch [12/50], Class Loss: 0.1977, CORAL Loss: 0.0127\n",
      "Validation Loss: 0.4592\n",
      "Epoch [13/50], Class Loss: 0.1855, CORAL Loss: 0.0126\n",
      "Validation Loss: 0.4747\n",
      "Epoch [14/50], Class Loss: 0.1772, CORAL Loss: 0.0122\n",
      "Validation Loss: 0.4839\n",
      "Epoch [15/50], Class Loss: 0.1676, CORAL Loss: 0.0135\n",
      "Validation Loss: 0.4930\n",
      "Epoch [16/50], Class Loss: 0.1586, CORAL Loss: 0.0140\n",
      "Validation Loss: 0.5171\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 76.86%, Precision: 77.46%, Recall: 77.68%, F1 Score: 77.40%\n",
      "Target Domain Performance - Accuracy: 52.22%, Precision: 60.94%, Recall: 52.67%, F1 Score: 50.13%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 1.1374, CORAL Loss: 0.0230\n",
      "Validation Loss: 0.8743\n",
      "Epoch [2/50], Class Loss: 0.8228, CORAL Loss: 0.0085\n",
      "Validation Loss: 0.8671\n",
      "Epoch [3/50], Class Loss: 0.8265, CORAL Loss: 0.0072\n",
      "Validation Loss: 0.8640\n",
      "Epoch [4/50], Class Loss: 0.8136, CORAL Loss: 0.0044\n",
      "Validation Loss: 0.8520\n",
      "Epoch [5/50], Class Loss: 0.8590, CORAL Loss: 0.0351\n",
      "Validation Loss: 0.8504\n",
      "Epoch [6/50], Class Loss: 0.7461, CORAL Loss: 0.0085\n",
      "Validation Loss: 0.7394\n",
      "Epoch [7/50], Class Loss: 0.5431, CORAL Loss: 0.0437\n",
      "Validation Loss: 0.5298\n",
      "Epoch [8/50], Class Loss: 0.3767, CORAL Loss: 0.0386\n",
      "Validation Loss: 1.1207\n",
      "Epoch [9/50], Class Loss: 0.3553, CORAL Loss: 0.0370\n",
      "Validation Loss: 0.4776\n",
      "Epoch [10/50], Class Loss: 0.2741, CORAL Loss: 0.0309\n",
      "Validation Loss: 0.5208\n",
      "Epoch [11/50], Class Loss: 0.1796, CORAL Loss: 0.0211\n",
      "Validation Loss: 0.5119\n",
      "Epoch [12/50], Class Loss: 0.1600, CORAL Loss: 0.0227\n",
      "Validation Loss: 0.5521\n",
      "Epoch [13/50], Class Loss: 0.1460, CORAL Loss: 0.0225\n",
      "Validation Loss: 0.5682\n",
      "Epoch [14/50], Class Loss: 0.1372, CORAL Loss: 0.0220\n",
      "Validation Loss: 0.5878\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 76.02%, Precision: 76.31%, Recall: 76.74%, F1 Score: 76.47%\n",
      "Target Domain Performance - Accuracy: 52.28%, Precision: 57.54%, Recall: 52.74%, F1 Score: 50.98%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 1.1111, CORAL Loss: 0.0189\n",
      "Validation Loss: 0.8445\n",
      "Epoch [2/50], Class Loss: 0.8296, CORAL Loss: 0.0069\n",
      "Validation Loss: 0.8429\n",
      "Epoch [3/50], Class Loss: 0.8320, CORAL Loss: 0.0070\n",
      "Validation Loss: 0.8485\n",
      "Epoch [4/50], Class Loss: 0.8107, CORAL Loss: 0.0051\n",
      "Validation Loss: 0.8666\n",
      "Epoch [5/50], Class Loss: 0.7914, CORAL Loss: 0.0105\n",
      "Validation Loss: 0.8116\n",
      "Epoch [6/50], Class Loss: 0.6364, CORAL Loss: 0.0326\n",
      "Validation Loss: 0.6130\n",
      "Epoch [7/50], Class Loss: 0.3790, CORAL Loss: 0.0333\n",
      "Validation Loss: 0.3812\n",
      "Epoch [8/50], Class Loss: 0.2816, CORAL Loss: 0.0210\n",
      "Validation Loss: 0.3894\n",
      "Epoch [9/50], Class Loss: 0.2381, CORAL Loss: 0.0340\n",
      "Validation Loss: 0.4040\n",
      "Epoch [10/50], Class Loss: 0.1825, CORAL Loss: 0.0228\n",
      "Validation Loss: 0.4838\n",
      "Epoch [11/50], Class Loss: 0.1158, CORAL Loss: 0.0252\n",
      "Validation Loss: 0.4037\n",
      "Epoch [12/50], Class Loss: 0.0846, CORAL Loss: 0.0211\n",
      "Validation Loss: 0.4116\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 82.97%, Precision: 83.54%, Recall: 83.48%, F1 Score: 83.48%\n",
      "Target Domain Performance - Accuracy: 58.21%, Precision: 67.40%, Recall: 58.66%, F1 Score: 59.12%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 1.1684, CORAL Loss: 0.0364\n",
      "Validation Loss: 0.8589\n",
      "Epoch [2/50], Class Loss: 0.8392, CORAL Loss: 0.0127\n",
      "Validation Loss: 0.8488\n",
      "Epoch [3/50], Class Loss: 0.8803, CORAL Loss: 0.0318\n",
      "Validation Loss: 0.8863\n",
      "Epoch [4/50], Class Loss: 0.8229, CORAL Loss: 0.0080\n",
      "Validation Loss: 0.8387\n",
      "Epoch [5/50], Class Loss: 0.8077, CORAL Loss: 0.0039\n",
      "Validation Loss: 0.8363\n",
      "Epoch [6/50], Class Loss: 0.7800, CORAL Loss: 0.0070\n",
      "Validation Loss: 0.7329\n",
      "Epoch [7/50], Class Loss: 0.6237, CORAL Loss: 0.0475\n",
      "Validation Loss: 0.6456\n",
      "Epoch [8/50], Class Loss: 0.4122, CORAL Loss: 0.0383\n",
      "Validation Loss: 0.3798\n",
      "Epoch [9/50], Class Loss: 0.3452, CORAL Loss: 0.0260\n",
      "Validation Loss: 0.3528\n",
      "Epoch [10/50], Class Loss: 0.2780, CORAL Loss: 0.0206\n",
      "Validation Loss: 0.4066\n",
      "Epoch [11/50], Class Loss: 0.2121, CORAL Loss: 0.0191\n",
      "Validation Loss: 0.2936\n",
      "Epoch [12/50], Class Loss: 0.1771, CORAL Loss: 0.0209\n",
      "Validation Loss: 0.2930\n",
      "Epoch [13/50], Class Loss: 0.1641, CORAL Loss: 0.0236\n",
      "Validation Loss: 0.2698\n",
      "Epoch [14/50], Class Loss: 0.1527, CORAL Loss: 0.0204\n",
      "Validation Loss: 0.2607\n",
      "Epoch [15/50], Class Loss: 0.1410, CORAL Loss: 0.0189\n",
      "Validation Loss: 0.2530\n",
      "Epoch [16/50], Class Loss: 0.1328, CORAL Loss: 0.0191\n",
      "Validation Loss: 0.2437\n",
      "Epoch [17/50], Class Loss: 0.1177, CORAL Loss: 0.0211\n",
      "Validation Loss: 0.2365\n",
      "Epoch [18/50], Class Loss: 0.1092, CORAL Loss: 0.0204\n",
      "Validation Loss: 0.2440\n",
      "Epoch [19/50], Class Loss: 0.1037, CORAL Loss: 0.0171\n",
      "Validation Loss: 0.2254\n",
      "Epoch [20/50], Class Loss: 0.0921, CORAL Loss: 0.0201\n",
      "Validation Loss: 0.2598\n",
      "Epoch [21/50], Class Loss: 0.0792, CORAL Loss: 0.0186\n",
      "Validation Loss: 0.2308\n",
      "Epoch [22/50], Class Loss: 0.0786, CORAL Loss: 0.0187\n",
      "Validation Loss: 0.2224\n",
      "Epoch [23/50], Class Loss: 0.0776, CORAL Loss: 0.0177\n",
      "Validation Loss: 0.2422\n",
      "Epoch [24/50], Class Loss: 0.0772, CORAL Loss: 0.0161\n",
      "Validation Loss: 0.2301\n",
      "Epoch [25/50], Class Loss: 0.0741, CORAL Loss: 0.0156\n",
      "Validation Loss: 0.2249\n",
      "Epoch [26/50], Class Loss: 0.0732, CORAL Loss: 0.0155\n",
      "Validation Loss: 0.2306\n",
      "Epoch [27/50], Class Loss: 0.0730, CORAL Loss: 0.0149\n",
      "Validation Loss: 0.2366\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 90.05%, Precision: 90.89%, Recall: 90.26%, F1 Score: 90.25%\n",
      "Target Domain Performance - Accuracy: 52.58%, Precision: 59.14%, Recall: 53.05%, F1 Score: 49.50%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 1.1420, CORAL Loss: 0.0231\n",
      "Validation Loss: 0.8706\n",
      "Epoch [2/50], Class Loss: 0.8388, CORAL Loss: 0.0151\n",
      "Validation Loss: 0.8572\n",
      "Epoch [3/50], Class Loss: 0.8369, CORAL Loss: 0.0067\n",
      "Validation Loss: 0.8414\n",
      "Epoch [4/50], Class Loss: 0.8175, CORAL Loss: 0.0032\n",
      "Validation Loss: 0.8349\n",
      "Epoch [5/50], Class Loss: 0.8196, CORAL Loss: 0.0050\n",
      "Validation Loss: 0.8770\n",
      "Epoch [6/50], Class Loss: 0.8228, CORAL Loss: 0.0149\n",
      "Validation Loss: 0.8405\n",
      "Epoch [7/50], Class Loss: 0.7875, CORAL Loss: 0.0043\n",
      "Validation Loss: 0.8389\n",
      "Epoch [8/50], Class Loss: 0.7090, CORAL Loss: 0.0183\n",
      "Validation Loss: 0.8989\n",
      "Epoch [9/50], Class Loss: 0.5143, CORAL Loss: 0.0426\n",
      "Validation Loss: 0.5281\n",
      "Epoch [10/50], Class Loss: 0.4432, CORAL Loss: 0.0696\n",
      "Validation Loss: 0.7195\n",
      "Epoch [11/50], Class Loss: 0.3682, CORAL Loss: 0.0241\n",
      "Validation Loss: 0.5457\n",
      "Epoch [12/50], Class Loss: 0.3096, CORAL Loss: 0.0328\n",
      "Validation Loss: 0.5174\n",
      "Epoch [13/50], Class Loss: 0.2721, CORAL Loss: 0.0337\n",
      "Validation Loss: 0.5109\n",
      "Epoch [14/50], Class Loss: 0.2551, CORAL Loss: 0.0301\n",
      "Validation Loss: 0.5116\n",
      "Epoch [15/50], Class Loss: 0.2418, CORAL Loss: 0.0285\n",
      "Validation Loss: 0.5071\n",
      "Epoch [16/50], Class Loss: 0.2285, CORAL Loss: 0.0256\n",
      "Validation Loss: 0.5157\n",
      "Epoch [17/50], Class Loss: 0.2134, CORAL Loss: 0.0248\n",
      "Validation Loss: 0.5203\n",
      "Epoch [18/50], Class Loss: 0.2029, CORAL Loss: 0.0240\n",
      "Validation Loss: 0.5321\n",
      "Epoch [19/50], Class Loss: 0.1936, CORAL Loss: 0.0223\n",
      "Validation Loss: 0.5366\n",
      "Epoch [20/50], Class Loss: 0.1860, CORAL Loss: 0.0220\n",
      "Validation Loss: 0.5438\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 75.42%, Precision: 76.55%, Recall: 76.21%, F1 Score: 76.35%\n",
      "Target Domain Performance - Accuracy: 49.22%, Precision: 55.15%, Recall: 49.63%, F1 Score: 44.88%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 1.0591, CORAL Loss: 0.0243\n",
      "Validation Loss: 0.8934\n",
      "Epoch [2/50], Class Loss: 0.8472, CORAL Loss: 0.0079\n",
      "Validation Loss: 0.9462\n",
      "Epoch [3/50], Class Loss: 0.8181, CORAL Loss: 0.0053\n",
      "Validation Loss: 0.8484\n",
      "Epoch [4/50], Class Loss: 0.8107, CORAL Loss: 0.0057\n",
      "Validation Loss: 0.8231\n",
      "Epoch [5/50], Class Loss: 0.7849, CORAL Loss: 0.0042\n",
      "Validation Loss: 0.8393\n",
      "Epoch [6/50], Class Loss: 0.8807, CORAL Loss: 0.1136\n",
      "Validation Loss: 0.8299\n",
      "Epoch [7/50], Class Loss: 0.7380, CORAL Loss: 0.0067\n",
      "Validation Loss: 0.8399\n",
      "Epoch [8/50], Class Loss: 0.6533, CORAL Loss: 0.0151\n",
      "Validation Loss: 0.7825\n",
      "Epoch [9/50], Class Loss: 0.5560, CORAL Loss: 0.0289\n",
      "Validation Loss: 0.6225\n",
      "Epoch [10/50], Class Loss: 0.4056, CORAL Loss: 0.0409\n",
      "Validation Loss: 0.5938\n",
      "Epoch [11/50], Class Loss: 0.2558, CORAL Loss: 0.0409\n",
      "Validation Loss: 0.5078\n",
      "Epoch [12/50], Class Loss: 0.2368, CORAL Loss: 0.0380\n",
      "Validation Loss: 0.5109\n",
      "Epoch [13/50], Class Loss: 0.2162, CORAL Loss: 0.0368\n",
      "Validation Loss: 0.5053\n",
      "Epoch [14/50], Class Loss: 0.1991, CORAL Loss: 0.0347\n",
      "Validation Loss: 0.5023\n",
      "Epoch [15/50], Class Loss: 0.1912, CORAL Loss: 0.0337\n",
      "Validation Loss: 0.4909\n",
      "Epoch [16/50], Class Loss: 0.1757, CORAL Loss: 0.0301\n",
      "Validation Loss: 0.4804\n",
      "Epoch [17/50], Class Loss: 0.1679, CORAL Loss: 0.0307\n",
      "Validation Loss: 0.4618\n",
      "Epoch [18/50], Class Loss: 0.1604, CORAL Loss: 0.0292\n",
      "Validation Loss: 0.4613\n",
      "Epoch [19/50], Class Loss: 0.1410, CORAL Loss: 0.0282\n",
      "Validation Loss: 0.4606\n",
      "Epoch [20/50], Class Loss: 0.1230, CORAL Loss: 0.0268\n",
      "Validation Loss: 0.4741\n",
      "Epoch [21/50], Class Loss: 0.1043, CORAL Loss: 0.0264\n",
      "Validation Loss: 0.4248\n",
      "Epoch [22/50], Class Loss: 0.1017, CORAL Loss: 0.0260\n",
      "Validation Loss: 0.4222\n",
      "Epoch [23/50], Class Loss: 0.1046, CORAL Loss: 0.0251\n",
      "Validation Loss: 0.4290\n",
      "Epoch [24/50], Class Loss: 0.1016, CORAL Loss: 0.0250\n",
      "Validation Loss: 0.4386\n",
      "Epoch [25/50], Class Loss: 0.1030, CORAL Loss: 0.0253\n",
      "Validation Loss: 0.4159\n",
      "Epoch [26/50], Class Loss: 0.0983, CORAL Loss: 0.0247\n",
      "Validation Loss: 0.4189\n",
      "Epoch [27/50], Class Loss: 0.0952, CORAL Loss: 0.0254\n",
      "Validation Loss: 0.4177\n",
      "Epoch [28/50], Class Loss: 0.0964, CORAL Loss: 0.0244\n",
      "Validation Loss: 0.4113\n",
      "Epoch [29/50], Class Loss: 0.0935, CORAL Loss: 0.0235\n",
      "Validation Loss: 0.4104\n",
      "Epoch [30/50], Class Loss: 0.0971, CORAL Loss: 0.0250\n",
      "Validation Loss: 0.4185\n",
      "Epoch [31/50], Class Loss: 0.0921, CORAL Loss: 0.0241\n",
      "Validation Loss: 0.4092\n",
      "Epoch [32/50], Class Loss: 0.0900, CORAL Loss: 0.0246\n",
      "Validation Loss: 0.4112\n",
      "Epoch [33/50], Class Loss: 0.0933, CORAL Loss: 0.0239\n",
      "Validation Loss: 0.4090\n",
      "Epoch [34/50], Class Loss: 0.0897, CORAL Loss: 0.0240\n",
      "Validation Loss: 0.4098\n",
      "Epoch [35/50], Class Loss: 0.0876, CORAL Loss: 0.0245\n",
      "Validation Loss: 0.4086\n",
      "Epoch [36/50], Class Loss: 0.0942, CORAL Loss: 0.0246\n",
      "Validation Loss: 0.4073\n",
      "Epoch [37/50], Class Loss: 0.0905, CORAL Loss: 0.0245\n",
      "Validation Loss: 0.4082\n",
      "Epoch [38/50], Class Loss: 0.0896, CORAL Loss: 0.0239\n",
      "Validation Loss: 0.4093\n",
      "Epoch [39/50], Class Loss: 0.0872, CORAL Loss: 0.0244\n",
      "Validation Loss: 0.4071\n",
      "Epoch [40/50], Class Loss: 0.0897, CORAL Loss: 0.0244\n",
      "Validation Loss: 0.4079\n",
      "Epoch [41/50], Class Loss: 0.0874, CORAL Loss: 0.0238\n",
      "Validation Loss: 0.4077\n",
      "Epoch [42/50], Class Loss: 0.0906, CORAL Loss: 0.0250\n",
      "Validation Loss: 0.4079\n",
      "Epoch [43/50], Class Loss: 0.0888, CORAL Loss: 0.0236\n",
      "Validation Loss: 0.4079\n",
      "Epoch [44/50], Class Loss: 0.0893, CORAL Loss: 0.0247\n",
      "Validation Loss: 0.4079\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 83.87%, Precision: 84.60%, Recall: 84.39%, F1 Score: 84.40%\n",
      "Target Domain Performance - Accuracy: 54.44%, Precision: 58.53%, Recall: 54.57%, F1 Score: 47.32%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 1.0622, CORAL Loss: 0.0218\n",
      "Validation Loss: 0.9626\n",
      "Epoch [2/50], Class Loss: 0.8518, CORAL Loss: 0.0101\n",
      "Validation Loss: 0.9072\n",
      "Epoch [3/50], Class Loss: 0.8234, CORAL Loss: 0.0045\n",
      "Validation Loss: 0.8424\n",
      "Epoch [4/50], Class Loss: 0.8041, CORAL Loss: 0.0039\n",
      "Validation Loss: 0.8346\n",
      "Epoch [5/50], Class Loss: 0.7813, CORAL Loss: 0.0067\n",
      "Validation Loss: 0.8265\n",
      "Epoch [6/50], Class Loss: 0.7302, CORAL Loss: 0.0135\n",
      "Validation Loss: 0.7624\n",
      "Epoch [7/50], Class Loss: 0.8059, CORAL Loss: 0.0760\n",
      "Validation Loss: 0.9410\n",
      "Epoch [8/50], Class Loss: 0.5788, CORAL Loss: 0.0294\n",
      "Validation Loss: 0.7324\n",
      "Epoch [9/50], Class Loss: 0.4077, CORAL Loss: 0.0398\n",
      "Validation Loss: 0.5512\n",
      "Epoch [10/50], Class Loss: 0.3001, CORAL Loss: 0.0303\n",
      "Validation Loss: 0.4926\n",
      "Epoch [11/50], Class Loss: 0.2061, CORAL Loss: 0.0218\n",
      "Validation Loss: 0.5180\n",
      "Epoch [12/50], Class Loss: 0.1923, CORAL Loss: 0.0231\n",
      "Validation Loss: 0.5334\n",
      "Epoch [13/50], Class Loss: 0.1726, CORAL Loss: 0.0219\n",
      "Validation Loss: 0.5602\n",
      "Epoch [14/50], Class Loss: 0.1628, CORAL Loss: 0.0201\n",
      "Validation Loss: 0.5646\n",
      "Epoch [15/50], Class Loss: 0.1574, CORAL Loss: 0.0196\n",
      "Validation Loss: 0.5732\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 74.40%, Precision: 75.13%, Recall: 75.18%, F1 Score: 75.15%\n",
      "Target Domain Performance - Accuracy: 47.66%, Precision: 50.25%, Recall: 48.08%, F1 Score: 42.78%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.0528, CORAL Loss: 0.0260\n",
      "Validation Loss: 0.8519\n",
      "Epoch [2/50], Class Loss: 0.8298, CORAL Loss: 0.0130\n",
      "Validation Loss: 0.8612\n",
      "Epoch [3/50], Class Loss: 0.8309, CORAL Loss: 0.0047\n",
      "Validation Loss: 0.8662\n",
      "Epoch [4/50], Class Loss: 0.8132, CORAL Loss: 0.0044\n",
      "Validation Loss: 0.8256\n",
      "Epoch [5/50], Class Loss: 0.7829, CORAL Loss: 0.0089\n",
      "Validation Loss: 0.8092\n",
      "Epoch [6/50], Class Loss: 0.6828, CORAL Loss: 0.0250\n",
      "Validation Loss: 0.6444\n",
      "Epoch [7/50], Class Loss: 0.4667, CORAL Loss: 0.0458\n",
      "Validation Loss: 0.4256\n",
      "Epoch [8/50], Class Loss: 0.3207, CORAL Loss: 0.0217\n",
      "Validation Loss: 0.4374\n",
      "Epoch [9/50], Class Loss: 0.2760, CORAL Loss: 0.0197\n",
      "Validation Loss: 0.3993\n",
      "Epoch [10/50], Class Loss: 0.2301, CORAL Loss: 0.0171\n",
      "Validation Loss: 0.4076\n",
      "Epoch [11/50], Class Loss: 0.1591, CORAL Loss: 0.0159\n",
      "Validation Loss: 0.4426\n",
      "Epoch [12/50], Class Loss: 0.1369, CORAL Loss: 0.0133\n",
      "Validation Loss: 0.4576\n",
      "Epoch [13/50], Class Loss: 0.1283, CORAL Loss: 0.0138\n",
      "Validation Loss: 0.4668\n",
      "Epoch [14/50], Class Loss: 0.1154, CORAL Loss: 0.0142\n",
      "Validation Loss: 0.4733\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 80.76%, Precision: 81.37%, Recall: 81.35%, F1 Score: 81.35%\n",
      "Target Domain Performance - Accuracy: 53.90%, Precision: 63.73%, Recall: 54.35%, F1 Score: 54.16%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 1.1973, CORAL Loss: 0.0190\n",
      "Validation Loss: 0.8492\n",
      "Epoch [2/50], Class Loss: 0.8313, CORAL Loss: 0.0099\n",
      "Validation Loss: 0.8374\n",
      "Epoch [3/50], Class Loss: 0.8199, CORAL Loss: 0.0052\n",
      "Validation Loss: 0.8379\n",
      "Epoch [4/50], Class Loss: 0.8137, CORAL Loss: 0.0048\n",
      "Validation Loss: 0.8697\n",
      "Epoch [5/50], Class Loss: 0.8156, CORAL Loss: 0.0066\n",
      "Validation Loss: 0.8404\n",
      "Epoch [6/50], Class Loss: 0.7744, CORAL Loss: 0.0115\n",
      "Validation Loss: 0.8607\n",
      "Epoch [7/50], Class Loss: 0.7222, CORAL Loss: 0.0214\n",
      "Validation Loss: 0.6129\n",
      "Epoch [8/50], Class Loss: 0.4613, CORAL Loss: 0.0444\n",
      "Validation Loss: 0.4265\n",
      "Epoch [9/50], Class Loss: 0.3044, CORAL Loss: 0.0286\n",
      "Validation Loss: 0.4119\n",
      "Epoch [10/50], Class Loss: 0.2627, CORAL Loss: 0.0217\n",
      "Validation Loss: 0.3967\n",
      "Epoch [11/50], Class Loss: 0.1779, CORAL Loss: 0.0163\n",
      "Validation Loss: 0.4045\n",
      "Epoch [12/50], Class Loss: 0.1503, CORAL Loss: 0.0185\n",
      "Validation Loss: 0.3984\n",
      "Epoch [13/50], Class Loss: 0.1304, CORAL Loss: 0.0206\n",
      "Validation Loss: 0.3981\n",
      "Epoch [14/50], Class Loss: 0.1219, CORAL Loss: 0.0201\n",
      "Validation Loss: 0.4110\n",
      "Epoch [15/50], Class Loss: 0.1082, CORAL Loss: 0.0219\n",
      "Validation Loss: 0.4117\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 83.27%, Precision: 83.79%, Recall: 83.81%, F1 Score: 83.80%\n",
      "Target Domain Performance - Accuracy: 51.74%, Precision: 59.02%, Recall: 52.32%, F1 Score: 50.42%\n",
      "\n",
      "Source performance: 79.60% 80.28% 80.23% 80.18%\n",
      "Target performance: 51.93% 58.51% 52.36% 49.14%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 100.00%\n",
      "qpsk: 12.11%\n",
      "16qam: 51.01%\n",
      "16apsk: 46.30%\n",
      "SNR level: 22\n",
      "JAN\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 1.5633, JMMD Loss: 0.3417\n",
      "Validation Loss: 1.2517\n",
      "Epoch [2/50], Class Loss: 0.9083, JMMD Loss: 1.1903\n",
      "Validation Loss: 0.8609\n",
      "Epoch [3/50], Class Loss: 0.8400, JMMD Loss: 0.7323\n",
      "Validation Loss: 0.8520\n",
      "Epoch [4/50], Class Loss: 0.8214, JMMD Loss: 0.2790\n",
      "Validation Loss: 0.8378\n",
      "Epoch [5/50], Class Loss: 0.7831, JMMD Loss: 0.1417\n",
      "Validation Loss: 0.8429\n",
      "Epoch [6/50], Class Loss: 0.7528, JMMD Loss: 0.1757\n",
      "Validation Loss: 0.8521\n",
      "Epoch [7/50], Class Loss: 0.5970, JMMD Loss: 0.2682\n",
      "Validation Loss: 0.5342\n",
      "Epoch [8/50], Class Loss: 0.4186, JMMD Loss: 0.2971\n",
      "Validation Loss: 0.5273\n",
      "Epoch [9/50], Class Loss: 0.2948, JMMD Loss: 0.2543\n",
      "Validation Loss: 0.4253\n",
      "Epoch [10/50], Class Loss: 0.2154, JMMD Loss: 0.2107\n",
      "Validation Loss: 0.4690\n",
      "Epoch [11/50], Class Loss: 0.1158, JMMD Loss: 0.1710\n",
      "Validation Loss: 0.5230\n",
      "Epoch [12/50], Class Loss: 0.0962, JMMD Loss: 0.1571\n",
      "Validation Loss: 0.5428\n",
      "Epoch [13/50], Class Loss: 0.0790, JMMD Loss: 0.1544\n",
      "Validation Loss: 0.5839\n",
      "Epoch [14/50], Class Loss: 0.0664, JMMD Loss: 0.1635\n",
      "Validation Loss: 0.6118\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 76.98%, Precision: 77.69%, Recall: 77.77%, F1 Score: 77.67%\n",
      "Target Domain Performance - Accuracy: 63.43%, Precision: 65.94%, Recall: 64.09%, F1 Score: 64.32%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 1.3193, JMMD Loss: 0.8822\n",
      "Validation Loss: 0.8892\n",
      "Epoch [2/50], Class Loss: 0.8547, JMMD Loss: 1.0541\n",
      "Validation Loss: 0.8994\n",
      "Epoch [3/50], Class Loss: 0.8375, JMMD Loss: 0.6204\n",
      "Validation Loss: 0.8549\n",
      "Epoch [4/50], Class Loss: 0.8127, JMMD Loss: 0.3843\n",
      "Validation Loss: 0.8471\n",
      "Epoch [5/50], Class Loss: 0.7857, JMMD Loss: 0.2137\n",
      "Validation Loss: 0.8965\n",
      "Epoch [6/50], Class Loss: 0.6949, JMMD Loss: 0.2090\n",
      "Validation Loss: 0.6065\n",
      "Epoch [7/50], Class Loss: 0.4534, JMMD Loss: 0.2728\n",
      "Validation Loss: 0.4326\n",
      "Epoch [8/50], Class Loss: 0.3488, JMMD Loss: 0.2503\n",
      "Validation Loss: 0.5064\n",
      "Epoch [9/50], Class Loss: 0.2752, JMMD Loss: 0.2338\n",
      "Validation Loss: 0.4500\n",
      "Epoch [10/50], Class Loss: 0.1974, JMMD Loss: 0.1635\n",
      "Validation Loss: 0.5003\n",
      "Epoch [11/50], Class Loss: 0.1037, JMMD Loss: 0.1286\n",
      "Validation Loss: 0.5049\n",
      "Epoch [12/50], Class Loss: 0.0744, JMMD Loss: 0.1168\n",
      "Validation Loss: 0.5280\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 79.38%, Precision: 79.98%, Recall: 80.02%, F1 Score: 79.99%\n",
      "Target Domain Performance - Accuracy: 63.67%, Precision: 64.83%, Recall: 64.48%, F1 Score: 64.45%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 1.4576, JMMD Loss: 0.2302\n",
      "Validation Loss: 1.3774\n",
      "Epoch [2/50], Class Loss: 0.9757, JMMD Loss: 1.0256\n",
      "Validation Loss: 0.9747\n",
      "Epoch [3/50], Class Loss: 0.8373, JMMD Loss: 0.6147\n",
      "Validation Loss: 0.8546\n",
      "Epoch [4/50], Class Loss: 0.8423, JMMD Loss: 0.2331\n",
      "Validation Loss: 0.8431\n",
      "Epoch [5/50], Class Loss: 0.8192, JMMD Loss: 0.0942\n",
      "Validation Loss: 0.8484\n",
      "Epoch [6/50], Class Loss: 0.8100, JMMD Loss: 0.0901\n",
      "Validation Loss: 0.8471\n",
      "Epoch [7/50], Class Loss: 0.7955, JMMD Loss: 0.1077\n",
      "Validation Loss: 0.8219\n",
      "Epoch [8/50], Class Loss: 0.7823, JMMD Loss: 0.1820\n",
      "Validation Loss: 0.8159\n",
      "Epoch [9/50], Class Loss: 0.6001, JMMD Loss: 0.2964\n",
      "Validation Loss: 0.5302\n",
      "Epoch [10/50], Class Loss: 0.3909, JMMD Loss: 0.3316\n",
      "Validation Loss: 0.4112\n",
      "Epoch [11/50], Class Loss: 0.2772, JMMD Loss: 0.2491\n",
      "Validation Loss: 0.4131\n",
      "Epoch [12/50], Class Loss: 0.2502, JMMD Loss: 0.2344\n",
      "Validation Loss: 0.4273\n",
      "Epoch [13/50], Class Loss: 0.2355, JMMD Loss: 0.2047\n",
      "Validation Loss: 0.4295\n",
      "Epoch [14/50], Class Loss: 0.2222, JMMD Loss: 0.1980\n",
      "Validation Loss: 0.4342\n",
      "Epoch [15/50], Class Loss: 0.2033, JMMD Loss: 0.1851\n",
      "Validation Loss: 0.4455\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 78.78%, Precision: 79.48%, Recall: 79.53%, F1 Score: 79.36%\n",
      "Target Domain Performance - Accuracy: 51.20%, Precision: 62.00%, Recall: 51.66%, F1 Score: 46.89%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 1.1926, JMMD Loss: 0.9935\n",
      "Validation Loss: 0.8778\n",
      "Epoch [2/50], Class Loss: 0.8386, JMMD Loss: 0.8466\n",
      "Validation Loss: 0.8481\n",
      "Epoch [3/50], Class Loss: 0.8726, JMMD Loss: 0.7003\n",
      "Validation Loss: 0.8739\n",
      "Epoch [4/50], Class Loss: 0.8044, JMMD Loss: 0.2578\n",
      "Validation Loss: 0.8609\n",
      "Epoch [5/50], Class Loss: 0.7550, JMMD Loss: 0.1571\n",
      "Validation Loss: 0.9200\n",
      "Epoch [6/50], Class Loss: 0.6260, JMMD Loss: 0.2893\n",
      "Validation Loss: 0.6600\n",
      "Epoch [7/50], Class Loss: 0.4277, JMMD Loss: 0.3885\n",
      "Validation Loss: 0.4779\n",
      "Epoch [8/50], Class Loss: 0.3122, JMMD Loss: 0.2870\n",
      "Validation Loss: 0.4145\n",
      "Epoch [9/50], Class Loss: 0.2991, JMMD Loss: 0.2462\n",
      "Validation Loss: 0.5178\n",
      "Epoch [10/50], Class Loss: 0.3191, JMMD Loss: 0.1799\n",
      "Validation Loss: 0.4139\n",
      "Epoch [11/50], Class Loss: 0.1741, JMMD Loss: 0.1676\n",
      "Validation Loss: 0.4809\n",
      "Epoch [12/50], Class Loss: 0.1513, JMMD Loss: 0.1639\n",
      "Validation Loss: 0.5198\n",
      "Epoch [13/50], Class Loss: 0.1392, JMMD Loss: 0.1700\n",
      "Validation Loss: 0.5215\n",
      "Epoch [14/50], Class Loss: 0.1221, JMMD Loss: 0.1819\n",
      "Validation Loss: 0.5403\n",
      "Epoch [15/50], Class Loss: 0.1120, JMMD Loss: 0.1824\n",
      "Validation Loss: 0.5575\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 77.94%, Precision: 78.59%, Recall: 78.64%, F1 Score: 78.62%\n",
      "Target Domain Performance - Accuracy: 61.39%, Precision: 65.45%, Recall: 62.03%, F1 Score: 62.75%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 1.4870, JMMD Loss: 0.3244\n",
      "Validation Loss: 1.1905\n",
      "Epoch [2/50], Class Loss: 0.8784, JMMD Loss: 0.9545\n",
      "Validation Loss: 0.8407\n",
      "Epoch [3/50], Class Loss: 0.8448, JMMD Loss: 0.1697\n",
      "Validation Loss: 0.8481\n",
      "Epoch [4/50], Class Loss: 0.8299, JMMD Loss: 0.1275\n",
      "Validation Loss: 0.8510\n",
      "Epoch [5/50], Class Loss: 0.8227, JMMD Loss: 0.0999\n",
      "Validation Loss: 0.8398\n",
      "Epoch [6/50], Class Loss: 0.8144, JMMD Loss: 0.0938\n",
      "Validation Loss: 0.8353\n",
      "Epoch [7/50], Class Loss: 0.7894, JMMD Loss: 0.1007\n",
      "Validation Loss: 0.7064\n",
      "Epoch [8/50], Class Loss: 0.4711, JMMD Loss: 0.4404\n",
      "Validation Loss: 0.3663\n",
      "Epoch [9/50], Class Loss: 0.3369, JMMD Loss: 0.2780\n",
      "Validation Loss: 0.3393\n",
      "Epoch [10/50], Class Loss: 0.2542, JMMD Loss: 0.2258\n",
      "Validation Loss: 0.7070\n",
      "Epoch [11/50], Class Loss: 0.1738, JMMD Loss: 0.1455\n",
      "Validation Loss: 0.1911\n",
      "Epoch [12/50], Class Loss: 0.1382, JMMD Loss: 0.1646\n",
      "Validation Loss: 0.1856\n",
      "Epoch [13/50], Class Loss: 0.1335, JMMD Loss: 0.1813\n",
      "Validation Loss: 0.1789\n",
      "Epoch [14/50], Class Loss: 0.1193, JMMD Loss: 0.1726\n",
      "Validation Loss: 0.1816\n",
      "Epoch [15/50], Class Loss: 0.1195, JMMD Loss: 0.1636\n",
      "Validation Loss: 0.1829\n",
      "Epoch [16/50], Class Loss: 0.1122, JMMD Loss: 0.1620\n",
      "Validation Loss: 0.1780\n",
      "Epoch [17/50], Class Loss: 0.1000, JMMD Loss: 0.1670\n",
      "Validation Loss: 0.1781\n",
      "Epoch [18/50], Class Loss: 0.0962, JMMD Loss: 0.1623\n",
      "Validation Loss: 0.2006\n",
      "Epoch [19/50], Class Loss: 0.0900, JMMD Loss: 0.1608\n",
      "Validation Loss: 0.1817\n",
      "Epoch [20/50], Class Loss: 0.0796, JMMD Loss: 0.1565\n",
      "Validation Loss: 0.1909\n",
      "Epoch [21/50], Class Loss: 0.0695, JMMD Loss: 0.1518\n",
      "Validation Loss: 0.1862\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 92.51%, Precision: 92.75%, Recall: 92.74%, F1 Score: 92.75%\n",
      "Target Domain Performance - Accuracy: 64.75%, Precision: 68.12%, Recall: 65.33%, F1 Score: 65.24%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 1.1184, JMMD Loss: 1.1188\n",
      "Validation Loss: 0.8821\n",
      "Epoch [2/50], Class Loss: 0.8915, JMMD Loss: 0.9012\n",
      "Validation Loss: 0.8685\n",
      "Epoch [3/50], Class Loss: 0.8395, JMMD Loss: 0.4302\n",
      "Validation Loss: 0.8422\n",
      "Epoch [4/50], Class Loss: 0.7985, JMMD Loss: 0.1229\n",
      "Validation Loss: 0.8065\n",
      "Epoch [5/50], Class Loss: 0.7201, JMMD Loss: 0.2799\n",
      "Validation Loss: 0.7946\n",
      "Epoch [6/50], Class Loss: 0.6573, JMMD Loss: 0.4085\n",
      "Validation Loss: 0.7069\n",
      "Epoch [7/50], Class Loss: 0.3613, JMMD Loss: 0.3179\n",
      "Validation Loss: 0.3917\n",
      "Epoch [8/50], Class Loss: 0.3051, JMMD Loss: 0.2372\n",
      "Validation Loss: 0.4819\n",
      "Epoch [9/50], Class Loss: 0.2734, JMMD Loss: 0.2055\n",
      "Validation Loss: 0.3722\n",
      "Epoch [10/50], Class Loss: 0.2345, JMMD Loss: 0.1986\n",
      "Validation Loss: 0.3324\n",
      "Epoch [11/50], Class Loss: 0.1451, JMMD Loss: 0.1664\n",
      "Validation Loss: 0.3393\n",
      "Epoch [12/50], Class Loss: 0.1327, JMMD Loss: 0.1383\n",
      "Validation Loss: 0.3513\n",
      "Epoch [13/50], Class Loss: 0.1146, JMMD Loss: 0.1336\n",
      "Validation Loss: 0.3268\n",
      "Epoch [14/50], Class Loss: 0.1020, JMMD Loss: 0.1304\n",
      "Validation Loss: 0.3237\n",
      "Epoch [15/50], Class Loss: 0.0914, JMMD Loss: 0.1264\n",
      "Validation Loss: 0.3345\n",
      "Epoch [16/50], Class Loss: 0.0812, JMMD Loss: 0.1166\n",
      "Validation Loss: 0.3425\n",
      "Epoch [17/50], Class Loss: 0.0733, JMMD Loss: 0.1301\n",
      "Validation Loss: 0.3188\n",
      "Epoch [18/50], Class Loss: 0.0625, JMMD Loss: 0.1256\n",
      "Validation Loss: 0.3376\n",
      "Epoch [19/50], Class Loss: 0.0568, JMMD Loss: 0.1155\n",
      "Validation Loss: 0.3211\n",
      "Epoch [20/50], Class Loss: 0.0523, JMMD Loss: 0.1082\n",
      "Validation Loss: 0.3158\n",
      "Epoch [21/50], Class Loss: 0.0371, JMMD Loss: 0.1155\n",
      "Validation Loss: 0.3229\n",
      "Epoch [22/50], Class Loss: 0.0379, JMMD Loss: 0.1137\n",
      "Validation Loss: 0.3189\n",
      "Epoch [23/50], Class Loss: 0.0330, JMMD Loss: 0.1097\n",
      "Validation Loss: 0.3233\n",
      "Epoch [24/50], Class Loss: 0.0360, JMMD Loss: 0.1150\n",
      "Validation Loss: 0.3223\n",
      "Epoch [25/50], Class Loss: 0.0332, JMMD Loss: 0.1077\n",
      "Validation Loss: 0.3234\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 88.01%, Precision: 88.35%, Recall: 88.40%, F1 Score: 88.37%\n",
      "Target Domain Performance - Accuracy: 71.82%, Precision: 72.47%, Recall: 72.48%, F1 Score: 72.15%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 1.3665, JMMD Loss: 0.6852\n",
      "Validation Loss: 0.8722\n",
      "Epoch [2/50], Class Loss: 0.8633, JMMD Loss: 1.0090\n",
      "Validation Loss: 0.8540\n",
      "Epoch [3/50], Class Loss: 0.8182, JMMD Loss: 0.3545\n",
      "Validation Loss: 0.8658\n",
      "Epoch [4/50], Class Loss: 0.7976, JMMD Loss: 0.1836\n",
      "Validation Loss: 0.8322\n",
      "Epoch [5/50], Class Loss: 0.7633, JMMD Loss: 0.2045\n",
      "Validation Loss: 0.7948\n",
      "Epoch [6/50], Class Loss: 0.6037, JMMD Loss: 0.3016\n",
      "Validation Loss: 0.6188\n",
      "Epoch [7/50], Class Loss: 0.4461, JMMD Loss: 0.3661\n",
      "Validation Loss: 0.4159\n",
      "Epoch [8/50], Class Loss: 0.3054, JMMD Loss: 0.3069\n",
      "Validation Loss: 0.4348\n",
      "Epoch [9/50], Class Loss: 0.2630, JMMD Loss: 0.2437\n",
      "Validation Loss: 0.3944\n",
      "Epoch [10/50], Class Loss: 0.2149, JMMD Loss: 0.2238\n",
      "Validation Loss: 0.4295\n",
      "Epoch [11/50], Class Loss: 0.1347, JMMD Loss: 0.1894\n",
      "Validation Loss: 0.4822\n",
      "Epoch [12/50], Class Loss: 0.1124, JMMD Loss: 0.1814\n",
      "Validation Loss: 0.5005\n",
      "Epoch [13/50], Class Loss: 0.0983, JMMD Loss: 0.1626\n",
      "Validation Loss: 0.5102\n",
      "Epoch [14/50], Class Loss: 0.0856, JMMD Loss: 0.1778\n",
      "Validation Loss: 0.5370\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 79.86%, Precision: 80.43%, Recall: 80.48%, F1 Score: 80.44%\n",
      "Target Domain Performance - Accuracy: 60.43%, Precision: 63.44%, Recall: 60.97%, F1 Score: 61.33%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 1.1381, JMMD Loss: 1.0102\n",
      "Validation Loss: 0.8575\n",
      "Epoch [2/50], Class Loss: 0.8469, JMMD Loss: 0.7609\n",
      "Validation Loss: 0.8537\n",
      "Epoch [3/50], Class Loss: 0.8519, JMMD Loss: 0.3161\n",
      "Validation Loss: 2.1666\n",
      "Epoch [4/50], Class Loss: 0.9991, JMMD Loss: 0.3474\n",
      "Validation Loss: 0.8168\n",
      "Epoch [5/50], Class Loss: 0.8113, JMMD Loss: 0.1537\n",
      "Validation Loss: 0.8512\n",
      "Epoch [6/50], Class Loss: 0.8084, JMMD Loss: 0.0930\n",
      "Validation Loss: 0.8334\n",
      "Epoch [7/50], Class Loss: 0.7912, JMMD Loss: 0.1647\n",
      "Validation Loss: 0.8229\n",
      "Epoch [8/50], Class Loss: 0.7058, JMMD Loss: 0.1921\n",
      "Validation Loss: 0.5363\n",
      "Epoch [9/50], Class Loss: 0.5355, JMMD Loss: 0.2797\n",
      "Validation Loss: 0.4697\n",
      "Epoch [10/50], Class Loss: 0.4778, JMMD Loss: 0.2799\n",
      "Validation Loss: 0.4296\n",
      "Epoch [11/50], Class Loss: 0.3657, JMMD Loss: 0.3452\n",
      "Validation Loss: 0.4064\n",
      "Epoch [12/50], Class Loss: 0.3530, JMMD Loss: 0.3349\n",
      "Validation Loss: 0.4010\n",
      "Epoch [13/50], Class Loss: 0.3452, JMMD Loss: 0.3222\n",
      "Validation Loss: 0.4016\n",
      "Epoch [14/50], Class Loss: 0.3379, JMMD Loss: 0.2968\n",
      "Validation Loss: 0.3962\n",
      "Epoch [15/50], Class Loss: 0.3317, JMMD Loss: 0.3053\n",
      "Validation Loss: 0.3968\n",
      "Epoch [16/50], Class Loss: 0.3271, JMMD Loss: 0.2703\n",
      "Validation Loss: 0.4040\n",
      "Epoch [17/50], Class Loss: 0.3212, JMMD Loss: 0.2345\n",
      "Validation Loss: 0.3985\n",
      "Epoch [18/50], Class Loss: 0.3127, JMMD Loss: 0.2391\n",
      "Validation Loss: 0.4013\n",
      "Epoch [19/50], Class Loss: 0.3043, JMMD Loss: 0.2070\n",
      "Validation Loss: 0.4121\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 75.72%, Precision: 75.87%, Recall: 76.56%, F1 Score: 76.06%\n",
      "Target Domain Performance - Accuracy: 52.64%, Precision: 58.21%, Recall: 52.93%, F1 Score: 48.27%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.2361, JMMD Loss: 1.0114\n",
      "Validation Loss: 0.8888\n",
      "Epoch [2/50], Class Loss: 0.8465, JMMD Loss: 0.8645\n",
      "Validation Loss: 0.8726\n",
      "Epoch [3/50], Class Loss: 0.8560, JMMD Loss: 0.3559\n",
      "Validation Loss: 1.3841\n",
      "Epoch [4/50], Class Loss: 0.8356, JMMD Loss: 0.2766\n",
      "Validation Loss: 0.8492\n",
      "Epoch [5/50], Class Loss: 0.7931, JMMD Loss: 0.1298\n",
      "Validation Loss: 0.8535\n",
      "Epoch [6/50], Class Loss: 0.7552, JMMD Loss: 0.1245\n",
      "Validation Loss: 0.8260\n",
      "Epoch [7/50], Class Loss: 0.8055, JMMD Loss: 0.2076\n",
      "Validation Loss: 0.9127\n",
      "Epoch [8/50], Class Loss: 0.5857, JMMD Loss: 0.1845\n",
      "Validation Loss: 0.6054\n",
      "Epoch [9/50], Class Loss: 0.4338, JMMD Loss: 0.3295\n",
      "Validation Loss: 0.4743\n",
      "Epoch [10/50], Class Loss: 0.3535, JMMD Loss: 0.4136\n",
      "Validation Loss: 0.4918\n",
      "Epoch [11/50], Class Loss: 0.2563, JMMD Loss: 0.4441\n",
      "Validation Loss: 0.4566\n",
      "Epoch [12/50], Class Loss: 0.2433, JMMD Loss: 0.4459\n",
      "Validation Loss: 0.4597\n",
      "Epoch [13/50], Class Loss: 0.2343, JMMD Loss: 0.3831\n",
      "Validation Loss: 0.4669\n",
      "Epoch [14/50], Class Loss: 0.2286, JMMD Loss: 0.3054\n",
      "Validation Loss: 0.4734\n",
      "Epoch [15/50], Class Loss: 0.2191, JMMD Loss: 0.2575\n",
      "Validation Loss: 0.4793\n",
      "Epoch [16/50], Class Loss: 0.2113, JMMD Loss: 0.2580\n",
      "Validation Loss: 0.5074\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 74.88%, Precision: 74.97%, Recall: 75.61%, F1 Score: 75.12%\n",
      "Target Domain Performance - Accuracy: 55.40%, Precision: 63.74%, Recall: 55.80%, F1 Score: 55.16%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 1.3103, JMMD Loss: 0.8659\n",
      "Validation Loss: 0.8653\n",
      "Epoch [2/50], Class Loss: 0.8554, JMMD Loss: 1.0433\n",
      "Validation Loss: 0.8542\n",
      "Epoch [3/50], Class Loss: 0.8275, JMMD Loss: 0.5333\n",
      "Validation Loss: 0.8523\n",
      "Epoch [4/50], Class Loss: 0.8064, JMMD Loss: 0.1755\n",
      "Validation Loss: 0.8582\n",
      "Epoch [5/50], Class Loss: 0.7953, JMMD Loss: 0.1860\n",
      "Validation Loss: 0.8380\n",
      "Epoch [6/50], Class Loss: 0.7475, JMMD Loss: 0.1667\n",
      "Validation Loss: 0.8595\n",
      "Epoch [7/50], Class Loss: 0.5964, JMMD Loss: 0.3152\n",
      "Validation Loss: 0.6639\n",
      "Epoch [8/50], Class Loss: 0.5744, JMMD Loss: 0.3367\n",
      "Validation Loss: 0.5527\n",
      "Epoch [9/50], Class Loss: 0.3766, JMMD Loss: 0.2176\n",
      "Validation Loss: 0.4311\n",
      "Epoch [10/50], Class Loss: 0.2881, JMMD Loss: 0.1848\n",
      "Validation Loss: 0.4012\n",
      "Epoch [11/50], Class Loss: 0.2243, JMMD Loss: 0.1682\n",
      "Validation Loss: 0.4457\n",
      "Epoch [12/50], Class Loss: 0.2153, JMMD Loss: 0.1714\n",
      "Validation Loss: 0.4620\n",
      "Epoch [13/50], Class Loss: 0.2088, JMMD Loss: 0.1518\n",
      "Validation Loss: 0.4894\n",
      "Epoch [14/50], Class Loss: 0.1961, JMMD Loss: 0.1554\n",
      "Validation Loss: 0.4884\n",
      "Epoch [15/50], Class Loss: 0.1851, JMMD Loss: 0.1529\n",
      "Validation Loss: 0.4990\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 76.80%, Precision: 77.30%, Recall: 77.45%, F1 Score: 77.21%\n",
      "Target Domain Performance - Accuracy: 66.97%, Precision: 65.71%, Recall: 67.60%, F1 Score: 66.33%\n",
      "\n",
      "Source performance: 80.08% 80.54% 80.72% 80.56%\n",
      "Target performance: 61.17% 64.99% 61.74% 60.69%\n",
      "\n",
      "Per-Class Accuracy on Target Domain (Mean over runs):\n",
      "  Class 0: 100.00%\n",
      "  Class 1: 51.02%\n",
      "  Class 2: 54.03%\n",
      "  Class 3: 41.90%\n",
      "SNR level: 22\n",
      "BASE\n",
      "\n",
      "Run 1/10\n",
      "Epoch 1/50, Train Loss: 1.0093, Train Acc: 0.4861, Val Loss: 0.8806, Val Acc: 0.4898\n",
      "Epoch 2/50, Train Loss: 0.8275, Train Acc: 0.5393, Val Loss: 0.8166, Val Acc: 0.5552\n",
      "Epoch 3/50, Train Loss: 0.5122, Train Acc: 0.7513, Val Loss: 0.2844, Val Acc: 0.8723\n",
      "Epoch 4/50, Train Loss: 0.2677, Train Acc: 0.8896, Val Loss: 0.2348, Val Acc: 0.8921\n",
      "Epoch 5/50, Train Loss: 0.2141, Train Acc: 0.9151, Val Loss: 0.4127, Val Acc: 0.8411\n",
      "Epoch 6/50, Train Loss: 0.1829, Train Acc: 0.9285, Val Loss: 0.3590, Val Acc: 0.8609\n",
      "Epoch 7/50, Train Loss: 0.1283, Train Acc: 0.9525, Val Loss: 0.1770, Val Acc: 0.9400\n",
      "Epoch 8/50, Train Loss: 0.1327, Train Acc: 0.9523, Val Loss: 0.2889, Val Acc: 0.8957\n",
      "Epoch 9/50, Train Loss: 0.1040, Train Acc: 0.9633, Val Loss: 0.2591, Val Acc: 0.9281\n",
      "Epoch 10/50, Train Loss: 0.1177, Train Acc: 0.9565, Val Loss: 0.2007, Val Acc: 0.9341\n",
      "Epoch 11/50, Train Loss: 0.0263, Train Acc: 0.9912, Val Loss: 0.1555, Val Acc: 0.9460\n",
      "Epoch 12/50, Train Loss: 0.0144, Train Acc: 0.9952, Val Loss: 0.1487, Val Acc: 0.9544\n",
      "Epoch 13/50, Train Loss: 0.0113, Train Acc: 0.9966, Val Loss: 0.1517, Val Acc: 0.9556\n",
      "Epoch 14/50, Train Loss: 0.0076, Train Acc: 0.9987, Val Loss: 0.1499, Val Acc: 0.9532\n",
      "Epoch 15/50, Train Loss: 0.0068, Train Acc: 0.9984, Val Loss: 0.1556, Val Acc: 0.9538\n",
      "Epoch 16/50, Train Loss: 0.0053, Train Acc: 0.9985, Val Loss: 0.1615, Val Acc: 0.9568\n",
      "Epoch 17/50, Train Loss: 0.0040, Train Acc: 0.9993, Val Loss: 0.1583, Val Acc: 0.9562\n",
      "Early stopping!\n",
      "\n",
      "Run 2/10\n",
      "Epoch 1/50, Train Loss: 0.9385, Train Acc: 0.4849, Val Loss: 0.8338, Val Acc: 0.5282\n",
      "Epoch 2/50, Train Loss: 0.8216, Train Acc: 0.5426, Val Loss: 0.8271, Val Acc: 0.5612\n",
      "Epoch 3/50, Train Loss: 0.5263, Train Acc: 0.7440, Val Loss: 0.4677, Val Acc: 0.7752\n",
      "Epoch 4/50, Train Loss: 0.3222, Train Acc: 0.8559, Val Loss: 0.6638, Val Acc: 0.7836\n",
      "Epoch 5/50, Train Loss: 0.2551, Train Acc: 0.8935, Val Loss: 0.2205, Val Acc: 0.9059\n",
      "Epoch 6/50, Train Loss: 0.1830, Train Acc: 0.9279, Val Loss: 0.1738, Val Acc: 0.9269\n",
      "Epoch 7/50, Train Loss: 0.1652, Train Acc: 0.9351, Val Loss: 0.3273, Val Acc: 0.8813\n",
      "Epoch 8/50, Train Loss: 0.1322, Train Acc: 0.9505, Val Loss: 0.1946, Val Acc: 0.9263\n",
      "Epoch 9/50, Train Loss: 0.1285, Train Acc: 0.9519, Val Loss: 0.1846, Val Acc: 0.9353\n",
      "Epoch 10/50, Train Loss: 0.1230, Train Acc: 0.9583, Val Loss: 0.4179, Val Acc: 0.8549\n",
      "Epoch 11/50, Train Loss: 0.0346, Train Acc: 0.9868, Val Loss: 0.1350, Val Acc: 0.9568\n",
      "Epoch 12/50, Train Loss: 0.0197, Train Acc: 0.9940, Val Loss: 0.1583, Val Acc: 0.9508\n",
      "Epoch 13/50, Train Loss: 0.0151, Train Acc: 0.9949, Val Loss: 0.1499, Val Acc: 0.9526\n",
      "Epoch 14/50, Train Loss: 0.0116, Train Acc: 0.9963, Val Loss: 0.1457, Val Acc: 0.9586\n",
      "Epoch 15/50, Train Loss: 0.0109, Train Acc: 0.9967, Val Loss: 0.1468, Val Acc: 0.9580\n",
      "Epoch 16/50, Train Loss: 0.0066, Train Acc: 0.9985, Val Loss: 0.1504, Val Acc: 0.9574\n",
      "Early stopping!\n",
      "\n",
      "Run 3/10\n",
      "Epoch 1/50, Train Loss: 1.1289, Train Acc: 0.4670, Val Loss: 0.8408, Val Acc: 0.5186\n",
      "Epoch 2/50, Train Loss: 0.8154, Train Acc: 0.5541, Val Loss: 0.8133, Val Acc: 0.5468\n",
      "Epoch 3/50, Train Loss: 0.6530, Train Acc: 0.6975, Val Loss: 0.5720, Val Acc: 0.7536\n",
      "Epoch 4/50, Train Loss: 0.3059, Train Acc: 0.8740, Val Loss: 0.1898, Val Acc: 0.9179\n",
      "Epoch 5/50, Train Loss: 0.2134, Train Acc: 0.9144, Val Loss: 0.5931, Val Acc: 0.8064\n",
      "Epoch 6/50, Train Loss: 0.2010, Train Acc: 0.9199, Val Loss: 0.3353, Val Acc: 0.8813\n",
      "Epoch 7/50, Train Loss: 0.1892, Train Acc: 0.9247, Val Loss: 0.1440, Val Acc: 0.9442\n",
      "Epoch 8/50, Train Loss: 0.1297, Train Acc: 0.9519, Val Loss: 0.2210, Val Acc: 0.9287\n",
      "Epoch 9/50, Train Loss: 0.1167, Train Acc: 0.9600, Val Loss: 0.3420, Val Acc: 0.8999\n",
      "Epoch 10/50, Train Loss: 0.1427, Train Acc: 0.9505, Val Loss: 0.2245, Val Acc: 0.9173\n",
      "Epoch 11/50, Train Loss: 0.0279, Train Acc: 0.9910, Val Loss: 0.1538, Val Acc: 0.9508\n",
      "Epoch 12/50, Train Loss: 0.0177, Train Acc: 0.9945, Val Loss: 0.1640, Val Acc: 0.9520\n",
      "Early stopping!\n",
      "\n",
      "Run 4/10\n",
      "Epoch 1/50, Train Loss: 1.0267, Train Acc: 0.4741, Val Loss: 0.8603, Val Acc: 0.4982\n",
      "Epoch 2/50, Train Loss: 0.8216, Train Acc: 0.5384, Val Loss: 0.8746, Val Acc: 0.4964\n",
      "Epoch 3/50, Train Loss: 0.7184, Train Acc: 0.6372, Val Loss: 0.4503, Val Acc: 0.7872\n",
      "Epoch 4/50, Train Loss: 0.3545, Train Acc: 0.8407, Val Loss: 0.3245, Val Acc: 0.8363\n",
      "Epoch 5/50, Train Loss: 0.2333, Train Acc: 0.9010, Val Loss: 0.1819, Val Acc: 0.9227\n",
      "Epoch 6/50, Train Loss: 0.1628, Train Acc: 0.9298, Val Loss: 0.2683, Val Acc: 0.8951\n",
      "Epoch 7/50, Train Loss: 0.1510, Train Acc: 0.9388, Val Loss: 0.4218, Val Acc: 0.8639\n",
      "Epoch 8/50, Train Loss: 0.1095, Train Acc: 0.9589, Val Loss: 0.1870, Val Acc: 0.9335\n",
      "Epoch 9/50, Train Loss: 0.1408, Train Acc: 0.9499, Val Loss: 0.2829, Val Acc: 0.9101\n",
      "Epoch 10/50, Train Loss: 0.1012, Train Acc: 0.9631, Val Loss: 0.2769, Val Acc: 0.9041\n",
      "Early stopping!\n",
      "\n",
      "Run 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 1.0127, Train Acc: 0.4820, Val Loss: 0.9238, Val Acc: 0.4964\n",
      "Epoch 2/50, Train Loss: 0.8296, Train Acc: 0.5319, Val Loss: 0.8599, Val Acc: 0.5054\n",
      "Epoch 3/50, Train Loss: 0.8006, Train Acc: 0.5801, Val Loss: 0.6540, Val Acc: 0.6996\n",
      "Epoch 4/50, Train Loss: 0.4221, Train Acc: 0.8103, Val Loss: 0.3491, Val Acc: 0.8297\n",
      "Epoch 5/50, Train Loss: 0.3008, Train Acc: 0.8739, Val Loss: 0.2972, Val Acc: 0.8555\n",
      "Epoch 6/50, Train Loss: 0.2170, Train Acc: 0.9085, Val Loss: 0.2021, Val Acc: 0.9155\n",
      "Epoch 7/50, Train Loss: 0.1763, Train Acc: 0.9330, Val Loss: 0.5172, Val Acc: 0.8453\n",
      "Epoch 8/50, Train Loss: 0.1977, Train Acc: 0.9321, Val Loss: 0.1498, Val Acc: 0.9400\n",
      "Epoch 9/50, Train Loss: 0.1282, Train Acc: 0.9520, Val Loss: 0.2657, Val Acc: 0.9173\n",
      "Epoch 10/50, Train Loss: 0.2083, Train Acc: 0.9411, Val Loss: 0.1210, Val Acc: 0.9520\n",
      "Epoch 11/50, Train Loss: 0.0370, Train Acc: 0.9871, Val Loss: 0.1351, Val Acc: 0.9478\n",
      "Epoch 12/50, Train Loss: 0.0320, Train Acc: 0.9889, Val Loss: 0.1148, Val Acc: 0.9586\n",
      "Epoch 13/50, Train Loss: 0.0290, Train Acc: 0.9895, Val Loss: 0.1495, Val Acc: 0.9514\n",
      "Epoch 14/50, Train Loss: 0.0234, Train Acc: 0.9912, Val Loss: 0.1230, Val Acc: 0.9586\n",
      "Epoch 15/50, Train Loss: 0.0212, Train Acc: 0.9936, Val Loss: 0.1241, Val Acc: 0.9586\n",
      "Epoch 16/50, Train Loss: 0.0156, Train Acc: 0.9951, Val Loss: 0.1318, Val Acc: 0.9580\n",
      "Epoch 17/50, Train Loss: 0.0169, Train Acc: 0.9936, Val Loss: 0.1763, Val Acc: 0.9514\n",
      "Early stopping!\n",
      "\n",
      "Run 6/10\n",
      "Epoch 1/50, Train Loss: 0.9554, Train Acc: 0.4852, Val Loss: 0.8516, Val Acc: 0.4832\n",
      "Epoch 2/50, Train Loss: 0.8238, Train Acc: 0.5307, Val Loss: 0.8132, Val Acc: 0.5492\n",
      "Epoch 3/50, Train Loss: 0.6469, Train Acc: 0.6750, Val Loss: 0.3393, Val Acc: 0.8094\n",
      "Epoch 4/50, Train Loss: 0.3786, Train Acc: 0.8284, Val Loss: 0.4801, Val Acc: 0.7866\n",
      "Epoch 5/50, Train Loss: 0.2412, Train Acc: 0.8986, Val Loss: 0.4595, Val Acc: 0.8094\n",
      "Epoch 6/50, Train Loss: 0.3079, Train Acc: 0.8772, Val Loss: 0.3221, Val Acc: 0.8783\n",
      "Epoch 7/50, Train Loss: 0.1873, Train Acc: 0.9195, Val Loss: 0.1490, Val Acc: 0.9353\n",
      "Epoch 8/50, Train Loss: 0.1525, Train Acc: 0.9448, Val Loss: 0.1646, Val Acc: 0.9299\n",
      "Epoch 9/50, Train Loss: 0.1679, Train Acc: 0.9376, Val Loss: 0.3747, Val Acc: 0.8789\n",
      "Epoch 10/50, Train Loss: 0.1088, Train Acc: 0.9628, Val Loss: 0.2484, Val Acc: 0.9215\n",
      "Epoch 11/50, Train Loss: 0.0365, Train Acc: 0.9862, Val Loss: 0.1368, Val Acc: 0.9478\n",
      "Epoch 12/50, Train Loss: 0.0268, Train Acc: 0.9903, Val Loss: 0.1216, Val Acc: 0.9544\n",
      "Epoch 13/50, Train Loss: 0.0203, Train Acc: 0.9922, Val Loss: 0.1228, Val Acc: 0.9550\n",
      "Epoch 14/50, Train Loss: 0.0197, Train Acc: 0.9925, Val Loss: 0.1514, Val Acc: 0.9514\n",
      "Epoch 15/50, Train Loss: 0.0141, Train Acc: 0.9954, Val Loss: 0.1494, Val Acc: 0.9538\n",
      "Epoch 16/50, Train Loss: 0.0147, Train Acc: 0.9963, Val Loss: 0.1322, Val Acc: 0.9574\n",
      "Epoch 17/50, Train Loss: 0.0094, Train Acc: 0.9967, Val Loss: 0.1588, Val Acc: 0.9484\n",
      "Early stopping!\n",
      "\n",
      "Run 7/10\n",
      "Epoch 1/50, Train Loss: 0.9701, Train Acc: 0.4834, Val Loss: 0.8472, Val Acc: 0.5162\n",
      "Epoch 2/50, Train Loss: 0.8333, Train Acc: 0.5357, Val Loss: 0.8544, Val Acc: 0.5216\n",
      "Epoch 3/50, Train Loss: 0.6622, Train Acc: 0.6876, Val Loss: 0.4106, Val Acc: 0.8004\n",
      "Epoch 4/50, Train Loss: 0.3331, Train Acc: 0.8599, Val Loss: 0.4547, Val Acc: 0.7896\n",
      "Epoch 5/50, Train Loss: 0.2528, Train Acc: 0.8913, Val Loss: 0.2000, Val Acc: 0.9083\n",
      "Epoch 6/50, Train Loss: 0.2536, Train Acc: 0.9196, Val Loss: 0.2133, Val Acc: 0.9083\n",
      "Epoch 7/50, Train Loss: 0.1546, Train Acc: 0.9414, Val Loss: 0.2840, Val Acc: 0.8951\n",
      "Epoch 8/50, Train Loss: 0.1592, Train Acc: 0.9439, Val Loss: 0.2701, Val Acc: 0.8867\n",
      "Epoch 9/50, Train Loss: 0.1194, Train Acc: 0.9564, Val Loss: 0.1899, Val Acc: 0.9335\n",
      "Epoch 10/50, Train Loss: 0.1351, Train Acc: 0.9471, Val Loss: 0.2455, Val Acc: 0.9005\n",
      "Epoch 11/50, Train Loss: 0.0357, Train Acc: 0.9877, Val Loss: 0.1479, Val Acc: 0.9448\n",
      "Epoch 12/50, Train Loss: 0.0335, Train Acc: 0.9913, Val Loss: 0.1493, Val Acc: 0.9490\n",
      "Epoch 13/50, Train Loss: 0.0182, Train Acc: 0.9936, Val Loss: 0.1529, Val Acc: 0.9460\n",
      "Epoch 14/50, Train Loss: 0.0180, Train Acc: 0.9933, Val Loss: 0.1477, Val Acc: 0.9490\n",
      "Epoch 15/50, Train Loss: 0.0145, Train Acc: 0.9960, Val Loss: 0.1537, Val Acc: 0.9508\n",
      "Epoch 16/50, Train Loss: 0.0099, Train Acc: 0.9969, Val Loss: 0.1664, Val Acc: 0.9490\n",
      "Epoch 17/50, Train Loss: 0.0139, Train Acc: 0.9981, Val Loss: 0.1664, Val Acc: 0.9484\n",
      "Epoch 18/50, Train Loss: 0.0062, Train Acc: 0.9984, Val Loss: 0.1733, Val Acc: 0.9502\n",
      "Epoch 19/50, Train Loss: 0.0053, Train Acc: 0.9984, Val Loss: 0.1833, Val Acc: 0.9484\n",
      "Early stopping!\n",
      "\n",
      "Run 8/10\n",
      "Epoch 1/50, Train Loss: 0.9608, Train Acc: 0.4819, Val Loss: 0.8425, Val Acc: 0.5012\n",
      "Epoch 2/50, Train Loss: 0.8243, Train Acc: 0.5474, Val Loss: 0.8832, Val Acc: 0.5108\n",
      "Epoch 3/50, Train Loss: 0.6093, Train Acc: 0.7154, Val Loss: 0.4725, Val Acc: 0.7806\n",
      "Epoch 4/50, Train Loss: 0.2871, Train Acc: 0.8749, Val Loss: 0.2204, Val Acc: 0.9035\n",
      "Epoch 5/50, Train Loss: 0.2367, Train Acc: 0.9058, Val Loss: 0.1686, Val Acc: 0.9287\n",
      "Epoch 6/50, Train Loss: 0.2506, Train Acc: 0.8955, Val Loss: 0.2416, Val Acc: 0.8963\n",
      "Epoch 7/50, Train Loss: 0.1415, Train Acc: 0.9436, Val Loss: 0.1591, Val Acc: 0.9347\n",
      "Epoch 8/50, Train Loss: 0.1488, Train Acc: 0.9469, Val Loss: 0.4493, Val Acc: 0.8543\n",
      "Epoch 9/50, Train Loss: 0.1544, Train Acc: 0.9528, Val Loss: 0.1881, Val Acc: 0.9376\n",
      "Epoch 10/50, Train Loss: 0.1303, Train Acc: 0.9663, Val Loss: 0.3779, Val Acc: 0.8963\n",
      "Epoch 11/50, Train Loss: 0.0419, Train Acc: 0.9859, Val Loss: 0.1891, Val Acc: 0.9323\n",
      "Epoch 12/50, Train Loss: 0.0206, Train Acc: 0.9934, Val Loss: 0.1834, Val Acc: 0.9448\n",
      "Early stopping!\n",
      "\n",
      "Run 9/10\n",
      "Epoch 1/50, Train Loss: 1.0252, Train Acc: 0.4591, Val Loss: 0.8832, Val Acc: 0.4850\n",
      "Epoch 2/50, Train Loss: 0.8222, Train Acc: 0.5400, Val Loss: 0.8201, Val Acc: 0.5540\n",
      "Epoch 3/50, Train Loss: 0.6432, Train Acc: 0.6831, Val Loss: 0.5038, Val Acc: 0.7578\n",
      "Epoch 4/50, Train Loss: 0.2924, Train Acc: 0.8718, Val Loss: 0.1815, Val Acc: 0.9269\n",
      "Epoch 5/50, Train Loss: 0.2350, Train Acc: 0.9003, Val Loss: 0.2527, Val Acc: 0.8903\n",
      "Epoch 6/50, Train Loss: 0.1873, Train Acc: 0.9205, Val Loss: 0.5062, Val Acc: 0.8100\n",
      "Epoch 7/50, Train Loss: 0.1913, Train Acc: 0.9241, Val Loss: 0.2048, Val Acc: 0.9095\n",
      "Epoch 8/50, Train Loss: 0.1735, Train Acc: 0.9486, Val Loss: 0.5357, Val Acc: 0.8495\n",
      "Epoch 9/50, Train Loss: 0.1423, Train Acc: 0.9507, Val Loss: 0.1406, Val Acc: 0.9442\n",
      "Epoch 10/50, Train Loss: 0.1070, Train Acc: 0.9648, Val Loss: 0.2480, Val Acc: 0.9173\n",
      "Epoch 11/50, Train Loss: 0.0341, Train Acc: 0.9879, Val Loss: 0.1763, Val Acc: 0.9448\n",
      "Epoch 12/50, Train Loss: 0.0238, Train Acc: 0.9915, Val Loss: 0.1410, Val Acc: 0.9472\n",
      "Epoch 13/50, Train Loss: 0.0186, Train Acc: 0.9934, Val Loss: 0.1358, Val Acc: 0.9550\n",
      "Epoch 14/50, Train Loss: 0.0150, Train Acc: 0.9951, Val Loss: 0.1396, Val Acc: 0.9568\n",
      "Epoch 15/50, Train Loss: 0.0225, Train Acc: 0.9942, Val Loss: 0.1402, Val Acc: 0.9568\n",
      "Epoch 16/50, Train Loss: 0.0126, Train Acc: 0.9967, Val Loss: 0.1462, Val Acc: 0.9574\n",
      "Epoch 17/50, Train Loss: 0.0081, Train Acc: 0.9982, Val Loss: 0.1500, Val Acc: 0.9550\n",
      "Epoch 18/50, Train Loss: 0.0085, Train Acc: 0.9976, Val Loss: 0.1530, Val Acc: 0.9574\n",
      "Early stopping!\n",
      "\n",
      "Run 10/10\n",
      "Epoch 1/50, Train Loss: 0.9698, Train Acc: 0.4843, Val Loss: 0.8407, Val Acc: 0.4982\n",
      "Epoch 2/50, Train Loss: 0.8236, Train Acc: 0.5411, Val Loss: 0.8532, Val Acc: 0.5246\n",
      "Epoch 3/50, Train Loss: 0.6085, Train Acc: 0.7100, Val Loss: 0.4727, Val Acc: 0.7992\n",
      "Epoch 4/50, Train Loss: 0.3120, Train Acc: 0.8662, Val Loss: 0.3352, Val Acc: 0.8489\n",
      "Epoch 5/50, Train Loss: 0.2002, Train Acc: 0.9208, Val Loss: 0.1930, Val Acc: 0.9251\n",
      "Epoch 6/50, Train Loss: 0.1457, Train Acc: 0.9420, Val Loss: 0.1839, Val Acc: 0.9269\n",
      "Epoch 7/50, Train Loss: 0.1392, Train Acc: 0.9429, Val Loss: 0.1296, Val Acc: 0.9532\n",
      "Epoch 8/50, Train Loss: 0.1110, Train Acc: 0.9574, Val Loss: 0.2796, Val Acc: 0.8951\n",
      "Epoch 9/50, Train Loss: 0.1484, Train Acc: 0.9454, Val Loss: 0.2954, Val Acc: 0.9059\n",
      "Epoch 10/50, Train Loss: 0.1131, Train Acc: 0.9589, Val Loss: 0.1702, Val Acc: 0.9347\n",
      "Epoch 11/50, Train Loss: 0.0217, Train Acc: 0.9931, Val Loss: 0.1317, Val Acc: 0.9538\n",
      "Epoch 12/50, Train Loss: 0.0155, Train Acc: 0.9948, Val Loss: 0.1435, Val Acc: 0.9526\n",
      "Early stopping!\n",
      "\n",
      "Source performance: 94.73 95.09 94.92 94.88\n",
      "Target performance: 48.48 51.40 49.10 39.60\n",
      "\n",
      "bpsk: 100.00\n",
      "qpsk: 5.12\n",
      "16qam: 83.66\n",
      "16apsk: 7.62\n",
      "SNR level: 22\n",
      "DANN\n",
      "Epoch 1/50, Loss: 4.2793, Domain Loss: 2.3095, Class Loss: 1.9698\n",
      "Epoch 2/50, Loss: 2.2872, Domain Loss: 1.4176, Class Loss: 0.8696\n",
      "Epoch 3/50, Loss: 1.9422, Domain Loss: 1.0764, Class Loss: 0.8658\n",
      "Epoch 4/50, Loss: 2.5634, Domain Loss: 1.6450, Class Loss: 0.9183\n",
      "Epoch 5/50, Loss: 3.7181, Domain Loss: 2.5778, Class Loss: 1.1403\n",
      "Epoch 6/50, Loss: 6.2735, Domain Loss: 4.4898, Class Loss: 1.7837\n",
      "Epoch 7/50, Loss: 2.6429, Domain Loss: 1.7682, Class Loss: 0.8747\n",
      "Epoch 8/50, Loss: 2.9063, Domain Loss: 2.0671, Class Loss: 0.8391\n",
      "Epoch 9/50, Loss: 9.1745, Domain Loss: 7.2583, Class Loss: 1.9162\n",
      "Epoch 10/50, Loss: 7.1237, Domain Loss: 6.2169, Class Loss: 0.9068\n",
      "Epoch 11/50, Loss: 11.6039, Domain Loss: 10.5467, Class Loss: 1.0572\n",
      "Epoch 12/50, Loss: 6.8472, Domain Loss: 5.7435, Class Loss: 1.1037\n",
      "Epoch 13/50, Loss: 4.6348, Domain Loss: 3.6359, Class Loss: 0.9990\n",
      "Epoch 14/50, Loss: 2.8376, Domain Loss: 1.8004, Class Loss: 1.0372\n",
      "Epoch 15/50, Loss: 2.9670, Domain Loss: 1.9068, Class Loss: 1.0602\n",
      "Epoch 16/50, Loss: 3.2187, Domain Loss: 2.0698, Class Loss: 1.1489\n",
      "Epoch 17/50, Loss: 3.7785, Domain Loss: 2.8060, Class Loss: 0.9725\n",
      "Epoch 18/50, Loss: 2.5387, Domain Loss: 1.5228, Class Loss: 1.0158\n",
      "Epoch 19/50, Loss: 2.7794, Domain Loss: 1.7636, Class Loss: 1.0158\n",
      "Epoch 20/50, Loss: 2.6059, Domain Loss: 1.7081, Class Loss: 0.8979\n",
      "Epoch 21/50, Loss: 2.7240, Domain Loss: 1.8637, Class Loss: 0.8602\n",
      "Epoch 22/50, Loss: 2.1956, Domain Loss: 1.3592, Class Loss: 0.8363\n",
      "Epoch 23/50, Loss: 1.9234, Domain Loss: 1.0959, Class Loss: 0.8275\n",
      "Epoch 24/50, Loss: 2.0790, Domain Loss: 1.2492, Class Loss: 0.8299\n",
      "Epoch 25/50, Loss: 2.4207, Domain Loss: 1.5604, Class Loss: 0.8603\n",
      "Epoch 26/50, Loss: 3.5357, Domain Loss: 2.5673, Class Loss: 0.9684\n",
      "Epoch 27/50, Loss: 2.5263, Domain Loss: 1.6000, Class Loss: 0.9263\n",
      "Epoch 28/50, Loss: 2.1743, Domain Loss: 1.3569, Class Loss: 0.8174\n",
      "Epoch 29/50, Loss: 2.0790, Domain Loss: 1.2634, Class Loss: 0.8157\n",
      "Epoch 30/50, Loss: 2.0078, Domain Loss: 1.1786, Class Loss: 0.8292\n",
      "Epoch 31/50, Loss: 1.9782, Domain Loss: 1.1306, Class Loss: 0.8477\n",
      "Epoch 32/50, Loss: 1.9129, Domain Loss: 1.0989, Class Loss: 0.8139\n",
      "Epoch 33/50, Loss: 1.9855, Domain Loss: 1.1672, Class Loss: 0.8183\n",
      "Epoch 34/50, Loss: 2.2239, Domain Loss: 1.2702, Class Loss: 0.9537\n",
      "Epoch 35/50, Loss: 2.3846, Domain Loss: 1.5306, Class Loss: 0.8540\n",
      "Epoch 36/50, Loss: 2.2515, Domain Loss: 1.3928, Class Loss: 0.8587\n",
      "Epoch 37/50, Loss: 2.1429, Domain Loss: 1.3181, Class Loss: 0.8248\n",
      "Epoch 38/50, Loss: 2.1928, Domain Loss: 1.3475, Class Loss: 0.8453\n",
      "Epoch 39/50, Loss: 2.1648, Domain Loss: 1.3532, Class Loss: 0.8117\n",
      "Epoch 40/50, Loss: 2.1627, Domain Loss: 1.3359, Class Loss: 0.8267\n",
      "Epoch 41/50, Loss: 2.1686, Domain Loss: 1.3303, Class Loss: 0.8382\n",
      "Epoch 42/50, Loss: 2.1614, Domain Loss: 1.3381, Class Loss: 0.8233\n",
      "Epoch 43/50, Loss: 2.1757, Domain Loss: 1.3540, Class Loss: 0.8216\n",
      "Epoch 44/50, Loss: 2.1968, Domain Loss: 1.3658, Class Loss: 0.8310\n",
      "Epoch 45/50, Loss: 2.1973, Domain Loss: 1.3513, Class Loss: 0.8461\n",
      "Epoch 46/50, Loss: 2.1361, Domain Loss: 1.3206, Class Loss: 0.8154\n",
      "Epoch 47/50, Loss: 2.1322, Domain Loss: 1.2955, Class Loss: 0.8367\n",
      "Epoch 48/50, Loss: 2.1330, Domain Loss: 1.3092, Class Loss: 0.8237\n",
      "Epoch 49/50, Loss: 2.1623, Domain Loss: 1.3378, Class Loss: 0.8245\n",
      "Epoch 50/50, Loss: 2.1881, Domain Loss: 1.3602, Class Loss: 0.8280\n",
      "48.56\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 4.4646, Domain Loss: 2.5574, Class Loss: 1.9072\n",
      "Epoch 2/50, Loss: 2.2521, Domain Loss: 1.3838, Class Loss: 0.8684\n",
      "Epoch 3/50, Loss: 2.1115, Domain Loss: 1.2733, Class Loss: 0.8381\n",
      "Epoch 4/50, Loss: 2.0164, Domain Loss: 1.1856, Class Loss: 0.8309\n",
      "Epoch 5/50, Loss: 2.1967, Domain Loss: 1.2913, Class Loss: 0.9055\n",
      "Epoch 6/50, Loss: 2.0624, Domain Loss: 1.1946, Class Loss: 0.8678\n",
      "Epoch 7/50, Loss: 1.9789, Domain Loss: 1.1108, Class Loss: 0.8680\n",
      "Epoch 8/50, Loss: 2.8616, Domain Loss: 2.0089, Class Loss: 0.8527\n",
      "Epoch 9/50, Loss: 3.9212, Domain Loss: 2.9143, Class Loss: 1.0069\n",
      "Epoch 10/50, Loss: 2.5572, Domain Loss: 1.7035, Class Loss: 0.8537\n",
      "Epoch 11/50, Loss: 2.2961, Domain Loss: 1.3765, Class Loss: 0.9196\n",
      "Epoch 12/50, Loss: 2.0990, Domain Loss: 1.2653, Class Loss: 0.8337\n",
      "Epoch 13/50, Loss: 2.0817, Domain Loss: 1.2747, Class Loss: 0.8069\n",
      "Epoch 14/50, Loss: 2.0693, Domain Loss: 1.2413, Class Loss: 0.8279\n",
      "Epoch 15/50, Loss: 2.1352, Domain Loss: 1.2692, Class Loss: 0.8661\n",
      "Epoch 16/50, Loss: 2.3288, Domain Loss: 1.3179, Class Loss: 1.0109\n",
      "Epoch 17/50, Loss: 2.4446, Domain Loss: 1.5754, Class Loss: 0.8692\n",
      "Epoch 18/50, Loss: 2.2735, Domain Loss: 1.4305, Class Loss: 0.8431\n",
      "Epoch 19/50, Loss: 2.2119, Domain Loss: 1.3876, Class Loss: 0.8243\n",
      "Epoch 20/50, Loss: 2.2237, Domain Loss: 1.3796, Class Loss: 0.8441\n",
      "Epoch 21/50, Loss: 2.2170, Domain Loss: 1.4020, Class Loss: 0.8150\n",
      "Epoch 22/50, Loss: 2.2034, Domain Loss: 1.3928, Class Loss: 0.8106\n",
      "Epoch 23/50, Loss: 2.2140, Domain Loss: 1.3918, Class Loss: 0.8223\n",
      "Epoch 24/50, Loss: 2.2269, Domain Loss: 1.3843, Class Loss: 0.8426\n",
      "Epoch 25/50, Loss: 2.2059, Domain Loss: 1.3925, Class Loss: 0.8135\n",
      "Epoch 26/50, Loss: 2.2162, Domain Loss: 1.3898, Class Loss: 0.8263\n",
      "Epoch 27/50, Loss: 2.2072, Domain Loss: 1.3965, Class Loss: 0.8107\n",
      "Epoch 28/50, Loss: 2.2130, Domain Loss: 1.3944, Class Loss: 0.8186\n",
      "Epoch 29/50, Loss: 2.2319, Domain Loss: 1.4089, Class Loss: 0.8230\n",
      "Epoch 30/50, Loss: 2.2124, Domain Loss: 1.4011, Class Loss: 0.8113\n",
      "Epoch 31/50, Loss: 2.2179, Domain Loss: 1.3926, Class Loss: 0.8252\n",
      "Epoch 32/50, Loss: 2.2059, Domain Loss: 1.3941, Class Loss: 0.8118\n",
      "Epoch 33/50, Loss: 2.2346, Domain Loss: 1.4216, Class Loss: 0.8131\n",
      "Epoch 34/50, Loss: 2.2285, Domain Loss: 1.4131, Class Loss: 0.8154\n",
      "Epoch 35/50, Loss: 2.2144, Domain Loss: 1.3936, Class Loss: 0.8208\n",
      "Epoch 36/50, Loss: 2.2072, Domain Loss: 1.4116, Class Loss: 0.7956\n",
      "Epoch 37/50, Loss: 2.1950, Domain Loss: 1.3803, Class Loss: 0.8147\n",
      "Epoch 38/50, Loss: 2.2016, Domain Loss: 1.3884, Class Loss: 0.8132\n",
      "Epoch 39/50, Loss: 2.1833, Domain Loss: 1.3708, Class Loss: 0.8125\n",
      "Epoch 40/50, Loss: 2.3410, Domain Loss: 1.4650, Class Loss: 0.8760\n",
      "Epoch 41/50, Loss: 7.0867, Domain Loss: 5.6610, Class Loss: 1.4256\n",
      "Epoch 42/50, Loss: 3.5494, Domain Loss: 2.5897, Class Loss: 0.9598\n",
      "Epoch 43/50, Loss: 2.4873, Domain Loss: 1.6420, Class Loss: 0.8453\n",
      "Epoch 44/50, Loss: 2.3769, Domain Loss: 1.5706, Class Loss: 0.8063\n",
      "Epoch 45/50, Loss: 2.2038, Domain Loss: 1.3816, Class Loss: 0.8223\n",
      "Epoch 46/50, Loss: 2.1842, Domain Loss: 1.3793, Class Loss: 0.8049\n",
      "Epoch 47/50, Loss: 2.1961, Domain Loss: 1.3791, Class Loss: 0.8170\n",
      "Epoch 48/50, Loss: 2.2156, Domain Loss: 1.3808, Class Loss: 0.8347\n",
      "Epoch 49/50, Loss: 2.2061, Domain Loss: 1.3879, Class Loss: 0.8181\n",
      "Epoch 50/50, Loss: 2.2032, Domain Loss: 1.3884, Class Loss: 0.8148\n",
      "48.98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 3.9807, Domain Loss: 2.4688, Class Loss: 1.5119\n",
      "Epoch 2/50, Loss: 2.1475, Domain Loss: 1.3239, Class Loss: 0.8236\n",
      "Epoch 3/50, Loss: 4.0644, Domain Loss: 2.9408, Class Loss: 1.1236\n",
      "Epoch 4/50, Loss: 3.1084, Domain Loss: 2.0805, Class Loss: 1.0279\n",
      "Epoch 5/50, Loss: 12.0608, Domain Loss: 9.3302, Class Loss: 2.7306\n",
      "Epoch 6/50, Loss: 7.1329, Domain Loss: 5.6299, Class Loss: 1.5030\n",
      "Epoch 7/50, Loss: 4.7564, Domain Loss: 3.3817, Class Loss: 1.3747\n",
      "Epoch 8/50, Loss: 4.2264, Domain Loss: 2.8900, Class Loss: 1.3364\n",
      "Epoch 9/50, Loss: 2.6566, Domain Loss: 1.6344, Class Loss: 1.0222\n",
      "Epoch 10/50, Loss: 8.5869, Domain Loss: 7.1548, Class Loss: 1.4321\n",
      "Epoch 11/50, Loss: 10.8768, Domain Loss: 9.5048, Class Loss: 1.3720\n",
      "Epoch 12/50, Loss: 8.1168, Domain Loss: 7.0861, Class Loss: 1.0308\n",
      "Epoch 13/50, Loss: 3.2723, Domain Loss: 2.4056, Class Loss: 0.8668\n",
      "Epoch 14/50, Loss: 2.2093, Domain Loss: 1.3677, Class Loss: 0.8416\n",
      "Epoch 15/50, Loss: 2.1739, Domain Loss: 1.3111, Class Loss: 0.8628\n",
      "Epoch 16/50, Loss: 2.0966, Domain Loss: 1.2403, Class Loss: 0.8563\n",
      "Epoch 17/50, Loss: 1.9533, Domain Loss: 1.1152, Class Loss: 0.8382\n",
      "Epoch 18/50, Loss: 1.9845, Domain Loss: 1.1460, Class Loss: 0.8385\n",
      "Epoch 19/50, Loss: 2.1225, Domain Loss: 1.2831, Class Loss: 0.8394\n",
      "Epoch 20/50, Loss: 2.0378, Domain Loss: 1.2123, Class Loss: 0.8254\n",
      "Epoch 21/50, Loss: 1.9651, Domain Loss: 1.1294, Class Loss: 0.8357\n",
      "Epoch 22/50, Loss: 2.1177, Domain Loss: 1.1848, Class Loss: 0.9329\n",
      "Epoch 23/50, Loss: 2.4056, Domain Loss: 1.4309, Class Loss: 0.9746\n",
      "Epoch 24/50, Loss: 2.4866, Domain Loss: 1.6460, Class Loss: 0.8407\n",
      "Epoch 25/50, Loss: 5.3221, Domain Loss: 4.4919, Class Loss: 0.8303\n",
      "Epoch 26/50, Loss: 3.0422, Domain Loss: 2.2102, Class Loss: 0.8320\n",
      "Epoch 27/50, Loss: 2.1384, Domain Loss: 1.3024, Class Loss: 0.8360\n",
      "Epoch 28/50, Loss: 2.1550, Domain Loss: 1.3354, Class Loss: 0.8196\n",
      "Epoch 29/50, Loss: 2.1449, Domain Loss: 1.3360, Class Loss: 0.8089\n",
      "Epoch 30/50, Loss: 2.1519, Domain Loss: 1.3151, Class Loss: 0.8367\n",
      "Epoch 31/50, Loss: 2.2180, Domain Loss: 1.3658, Class Loss: 0.8522\n",
      "Epoch 32/50, Loss: 2.1597, Domain Loss: 1.3128, Class Loss: 0.8469\n",
      "Epoch 33/50, Loss: 2.1894, Domain Loss: 1.3596, Class Loss: 0.8298\n",
      "Epoch 34/50, Loss: 2.1312, Domain Loss: 1.3052, Class Loss: 0.8259\n",
      "Epoch 35/50, Loss: 2.6042, Domain Loss: 1.7981, Class Loss: 0.8061\n",
      "Epoch 36/50, Loss: 3.7002, Domain Loss: 2.8812, Class Loss: 0.8190\n",
      "Epoch 37/50, Loss: 2.2986, Domain Loss: 1.4807, Class Loss: 0.8180\n",
      "Epoch 38/50, Loss: 2.1065, Domain Loss: 1.2944, Class Loss: 0.8120\n",
      "Epoch 39/50, Loss: 2.0829, Domain Loss: 1.2653, Class Loss: 0.8176\n",
      "Epoch 40/50, Loss: 2.0699, Domain Loss: 1.2696, Class Loss: 0.8003\n",
      "Epoch 41/50, Loss: 2.0981, Domain Loss: 1.2854, Class Loss: 0.8127\n",
      "Epoch 42/50, Loss: 2.1250, Domain Loss: 1.3270, Class Loss: 0.7980\n",
      "Epoch 43/50, Loss: 2.0215, Domain Loss: 1.2274, Class Loss: 0.7941\n",
      "Epoch 44/50, Loss: 2.1006, Domain Loss: 1.2683, Class Loss: 0.8323\n",
      "Epoch 45/50, Loss: 2.0865, Domain Loss: 1.2823, Class Loss: 0.8042\n",
      "Epoch 46/50, Loss: 5.4568, Domain Loss: 3.8620, Class Loss: 1.5948\n",
      "Epoch 47/50, Loss: 6.3135, Domain Loss: 4.7865, Class Loss: 1.5270\n",
      "Epoch 48/50, Loss: 2.1759, Domain Loss: 1.3229, Class Loss: 0.8531\n",
      "Epoch 49/50, Loss: 2.1762, Domain Loss: 1.3311, Class Loss: 0.8451\n",
      "Epoch 50/50, Loss: 2.2325, Domain Loss: 1.4168, Class Loss: 0.8156\n",
      "48.38\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.9976, Domain Loss: 1.4878, Class Loss: 1.5098\n",
      "Epoch 2/50, Loss: 1.8752, Domain Loss: 1.0162, Class Loss: 0.8590\n",
      "Epoch 3/50, Loss: 3.1185, Domain Loss: 2.0595, Class Loss: 1.0590\n",
      "Epoch 4/50, Loss: 2.9466, Domain Loss: 2.0138, Class Loss: 0.9328\n",
      "Epoch 5/50, Loss: 2.0926, Domain Loss: 1.2578, Class Loss: 0.8349\n",
      "Epoch 6/50, Loss: 1.9616, Domain Loss: 1.1593, Class Loss: 0.8023\n",
      "Epoch 7/50, Loss: 1.9677, Domain Loss: 1.1382, Class Loss: 0.8295\n",
      "Epoch 8/50, Loss: 2.0767, Domain Loss: 1.2528, Class Loss: 0.8240\n",
      "Epoch 9/50, Loss: 10.8153, Domain Loss: 9.1871, Class Loss: 1.6283\n",
      "Epoch 10/50, Loss: 6.1343, Domain Loss: 5.2609, Class Loss: 0.8734\n",
      "Epoch 11/50, Loss: 4.8980, Domain Loss: 4.0772, Class Loss: 0.8208\n",
      "Epoch 12/50, Loss: 3.6824, Domain Loss: 2.8506, Class Loss: 0.8318\n",
      "Epoch 13/50, Loss: 4.1982, Domain Loss: 3.3565, Class Loss: 0.8416\n",
      "Epoch 14/50, Loss: 3.0958, Domain Loss: 1.9356, Class Loss: 1.1603\n",
      "Epoch 15/50, Loss: 2.5982, Domain Loss: 1.7210, Class Loss: 0.8772\n",
      "Epoch 16/50, Loss: 2.5845, Domain Loss: 1.6534, Class Loss: 0.9311\n",
      "Epoch 17/50, Loss: 2.2313, Domain Loss: 1.3586, Class Loss: 0.8727\n",
      "Epoch 18/50, Loss: 15.4570, Domain Loss: 13.3567, Class Loss: 2.1003\n",
      "Epoch 19/50, Loss: 12.2436, Domain Loss: 10.8512, Class Loss: 1.3924\n",
      "Epoch 20/50, Loss: 7.0680, Domain Loss: 5.8974, Class Loss: 1.1706\n",
      "Epoch 21/50, Loss: 7.9301, Domain Loss: 7.0615, Class Loss: 0.8686\n",
      "Epoch 22/50, Loss: 3.2753, Domain Loss: 2.4362, Class Loss: 0.8391\n",
      "Epoch 23/50, Loss: 1.8732, Domain Loss: 1.0304, Class Loss: 0.8428\n",
      "Epoch 24/50, Loss: 1.8264, Domain Loss: 0.9977, Class Loss: 0.8287\n",
      "Epoch 25/50, Loss: 1.7875, Domain Loss: 0.9599, Class Loss: 0.8276\n",
      "Epoch 26/50, Loss: 1.7568, Domain Loss: 0.9538, Class Loss: 0.8030\n",
      "Epoch 27/50, Loss: 1.7892, Domain Loss: 0.9813, Class Loss: 0.8079\n",
      "Epoch 28/50, Loss: 1.7745, Domain Loss: 0.9600, Class Loss: 0.8145\n",
      "Epoch 29/50, Loss: 1.7937, Domain Loss: 0.9905, Class Loss: 0.8032\n",
      "Epoch 30/50, Loss: 1.8497, Domain Loss: 1.0378, Class Loss: 0.8119\n",
      "Epoch 31/50, Loss: 2.6843, Domain Loss: 1.0579, Class Loss: 1.6264\n",
      "Epoch 32/50, Loss: 2.9756, Domain Loss: 1.1064, Class Loss: 1.8692\n",
      "Epoch 33/50, Loss: 3.5576, Domain Loss: 2.1154, Class Loss: 1.4422\n",
      "Epoch 34/50, Loss: 3.3906, Domain Loss: 2.0445, Class Loss: 1.3461\n",
      "Epoch 35/50, Loss: 2.4240, Domain Loss: 1.1049, Class Loss: 1.3191\n",
      "Epoch 36/50, Loss: 2.5351, Domain Loss: 1.2655, Class Loss: 1.2696\n",
      "Epoch 37/50, Loss: 2.3687, Domain Loss: 1.0970, Class Loss: 1.2717\n",
      "Epoch 38/50, Loss: 2.1627, Domain Loss: 0.9833, Class Loss: 1.1794\n",
      "Epoch 39/50, Loss: 1.8478, Domain Loss: 1.0016, Class Loss: 0.8462\n",
      "Epoch 40/50, Loss: 1.8679, Domain Loss: 1.0426, Class Loss: 0.8253\n",
      "Epoch 41/50, Loss: 1.8713, Domain Loss: 1.0353, Class Loss: 0.8360\n",
      "Epoch 42/50, Loss: 1.8597, Domain Loss: 1.0507, Class Loss: 0.8090\n",
      "Epoch 43/50, Loss: 1.8856, Domain Loss: 1.0237, Class Loss: 0.8619\n",
      "Epoch 44/50, Loss: 2.9328, Domain Loss: 1.1227, Class Loss: 1.8102\n",
      "Epoch 45/50, Loss: 2.9110, Domain Loss: 1.2071, Class Loss: 1.7038\n",
      "Epoch 46/50, Loss: 2.8720, Domain Loss: 1.1882, Class Loss: 1.6837\n",
      "Epoch 47/50, Loss: 3.1110, Domain Loss: 1.4459, Class Loss: 1.6651\n",
      "Epoch 48/50, Loss: 3.2437, Domain Loss: 1.5938, Class Loss: 1.6498\n",
      "Epoch 49/50, Loss: 3.2039, Domain Loss: 1.5654, Class Loss: 1.6385\n",
      "Epoch 50/50, Loss: 3.0115, Domain Loss: 1.3828, Class Loss: 1.6286\n",
      "25.90\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 3.5566, Domain Loss: 1.8304, Class Loss: 1.7262\n",
      "Epoch 2/50, Loss: 2.1726, Domain Loss: 1.3271, Class Loss: 0.8456\n",
      "Epoch 3/50, Loss: 1.9962, Domain Loss: 1.1523, Class Loss: 0.8439\n",
      "Epoch 4/50, Loss: 2.3745, Domain Loss: 1.4450, Class Loss: 0.9294\n",
      "Epoch 5/50, Loss: 2.8973, Domain Loss: 1.8754, Class Loss: 1.0219\n",
      "Epoch 6/50, Loss: 2.1163, Domain Loss: 1.1412, Class Loss: 0.9750\n",
      "Epoch 7/50, Loss: 2.0581, Domain Loss: 1.0805, Class Loss: 0.9776\n",
      "Epoch 8/50, Loss: 2.3857, Domain Loss: 1.4568, Class Loss: 0.9289\n",
      "Epoch 9/50, Loss: 2.3445, Domain Loss: 1.4707, Class Loss: 0.8738\n",
      "Epoch 10/50, Loss: 2.2912, Domain Loss: 1.4539, Class Loss: 0.8373\n",
      "Epoch 11/50, Loss: 5.3857, Domain Loss: 3.6460, Class Loss: 1.7398\n",
      "Epoch 12/50, Loss: 4.8515, Domain Loss: 3.8935, Class Loss: 0.9580\n",
      "Epoch 13/50, Loss: 4.5899, Domain Loss: 3.7042, Class Loss: 0.8857\n",
      "Epoch 14/50, Loss: 4.2465, Domain Loss: 2.8788, Class Loss: 1.3677\n",
      "Epoch 15/50, Loss: 3.5084, Domain Loss: 2.6697, Class Loss: 0.8387\n",
      "Epoch 16/50, Loss: 3.3964, Domain Loss: 2.5183, Class Loss: 0.8781\n",
      "Epoch 17/50, Loss: 3.7338, Domain Loss: 2.4435, Class Loss: 1.2903\n",
      "Epoch 18/50, Loss: 2.8856, Domain Loss: 2.0503, Class Loss: 0.8353\n",
      "Epoch 19/50, Loss: 2.5281, Domain Loss: 1.6800, Class Loss: 0.8481\n",
      "Epoch 20/50, Loss: 1.8378, Domain Loss: 0.9974, Class Loss: 0.8403\n",
      "Epoch 21/50, Loss: 2.1474, Domain Loss: 1.3125, Class Loss: 0.8349\n",
      "Epoch 22/50, Loss: 1.7631, Domain Loss: 0.9422, Class Loss: 0.8209\n",
      "Epoch 23/50, Loss: 1.8022, Domain Loss: 0.9677, Class Loss: 0.8345\n",
      "Epoch 24/50, Loss: 1.8703, Domain Loss: 1.0470, Class Loss: 0.8232\n",
      "Epoch 25/50, Loss: 2.7358, Domain Loss: 1.7892, Class Loss: 0.9466\n",
      "Epoch 26/50, Loss: 1.8200, Domain Loss: 0.9982, Class Loss: 0.8218\n",
      "Epoch 27/50, Loss: 2.4740, Domain Loss: 1.4716, Class Loss: 1.0024\n",
      "Epoch 28/50, Loss: 2.8379, Domain Loss: 1.9309, Class Loss: 0.9070\n",
      "Epoch 29/50, Loss: 2.5574, Domain Loss: 1.6276, Class Loss: 0.9298\n",
      "Epoch 30/50, Loss: 2.9711, Domain Loss: 1.8500, Class Loss: 1.1212\n",
      "Epoch 31/50, Loss: 2.7466, Domain Loss: 1.5766, Class Loss: 1.1701\n",
      "Epoch 32/50, Loss: 2.4608, Domain Loss: 1.6005, Class Loss: 0.8603\n",
      "Epoch 33/50, Loss: 2.4041, Domain Loss: 1.5812, Class Loss: 0.8229\n",
      "Epoch 34/50, Loss: 3.2795, Domain Loss: 2.4404, Class Loss: 0.8391\n",
      "Epoch 35/50, Loss: 7.7059, Domain Loss: 6.8431, Class Loss: 0.8628\n",
      "Epoch 36/50, Loss: 68.0325, Domain Loss: 66.1802, Class Loss: 1.8523\n",
      "Epoch 37/50, Loss: 18.8658, Domain Loss: 17.0042, Class Loss: 1.8616\n",
      "Epoch 38/50, Loss: 3.6733, Domain Loss: 2.1203, Class Loss: 1.5530\n",
      "Epoch 39/50, Loss: 2.7986, Domain Loss: 1.3996, Class Loss: 1.3991\n",
      "Epoch 40/50, Loss: 2.7332, Domain Loss: 1.3573, Class Loss: 1.3759\n",
      "Epoch 41/50, Loss: 2.8990, Domain Loss: 1.3470, Class Loss: 1.5520\n",
      "Epoch 42/50, Loss: 2.7172, Domain Loss: 1.3451, Class Loss: 1.3721\n",
      "Epoch 43/50, Loss: 2.7055, Domain Loss: 1.3362, Class Loss: 1.3693\n",
      "Epoch 44/50, Loss: 2.6796, Domain Loss: 1.3309, Class Loss: 1.3486\n",
      "Epoch 45/50, Loss: 2.6875, Domain Loss: 1.3273, Class Loss: 1.3602\n",
      "Epoch 46/50, Loss: 2.6137, Domain Loss: 1.3173, Class Loss: 1.2964\n",
      "Epoch 47/50, Loss: 2.5615, Domain Loss: 1.3101, Class Loss: 1.2514\n",
      "Epoch 48/50, Loss: 2.5568, Domain Loss: 1.3018, Class Loss: 1.2550\n",
      "Epoch 49/50, Loss: 2.5050, Domain Loss: 1.2924, Class Loss: 1.2125\n",
      "Epoch 50/50, Loss: 2.4401, Domain Loss: 1.2979, Class Loss: 1.1422\n",
      "23.98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 3.8416, Domain Loss: 1.9341, Class Loss: 1.9076\n",
      "Epoch 2/50, Loss: 1.9445, Domain Loss: 1.0428, Class Loss: 0.9018\n",
      "Epoch 3/50, Loss: 2.0021, Domain Loss: 1.1429, Class Loss: 0.8592\n",
      "Epoch 4/50, Loss: 1.8982, Domain Loss: 1.0479, Class Loss: 0.8503\n",
      "Epoch 5/50, Loss: 2.0757, Domain Loss: 1.1909, Class Loss: 0.8848\n",
      "Epoch 6/50, Loss: 7.6014, Domain Loss: 6.2103, Class Loss: 1.3911\n",
      "Epoch 7/50, Loss: 13.1609, Domain Loss: 11.8140, Class Loss: 1.3469\n",
      "Epoch 8/50, Loss: 19.5405, Domain Loss: 18.3864, Class Loss: 1.1540\n",
      "Epoch 9/50, Loss: 12.9178, Domain Loss: 11.9842, Class Loss: 0.9336\n",
      "Epoch 10/50, Loss: 10.6525, Domain Loss: 9.7946, Class Loss: 0.8579\n",
      "Epoch 11/50, Loss: 11.7324, Domain Loss: 10.5985, Class Loss: 1.1339\n",
      "Epoch 12/50, Loss: 9.7445, Domain Loss: 8.7356, Class Loss: 1.0089\n",
      "Epoch 13/50, Loss: 7.2054, Domain Loss: 6.1550, Class Loss: 1.0504\n",
      "Epoch 14/50, Loss: 5.6902, Domain Loss: 4.8487, Class Loss: 0.8415\n",
      "Epoch 15/50, Loss: 5.2017, Domain Loss: 4.3445, Class Loss: 0.8573\n",
      "Epoch 16/50, Loss: 5.2879, Domain Loss: 4.4617, Class Loss: 0.8262\n",
      "Epoch 17/50, Loss: 3.2193, Domain Loss: 2.3316, Class Loss: 0.8877\n",
      "Epoch 18/50, Loss: 2.8764, Domain Loss: 2.0054, Class Loss: 0.8710\n",
      "Epoch 19/50, Loss: 2.9895, Domain Loss: 2.1485, Class Loss: 0.8410\n",
      "Epoch 20/50, Loss: 2.6070, Domain Loss: 1.7837, Class Loss: 0.8233\n",
      "Epoch 21/50, Loss: 2.4762, Domain Loss: 1.6543, Class Loss: 0.8219\n",
      "Epoch 22/50, Loss: 2.3571, Domain Loss: 1.5381, Class Loss: 0.8190\n",
      "Epoch 23/50, Loss: 2.1819, Domain Loss: 1.3617, Class Loss: 0.8202\n",
      "Epoch 24/50, Loss: 2.2242, Domain Loss: 1.2435, Class Loss: 0.9807\n",
      "Epoch 25/50, Loss: 2.3408, Domain Loss: 1.1406, Class Loss: 1.2002\n",
      "Epoch 26/50, Loss: 1.8700, Domain Loss: 1.0315, Class Loss: 0.8385\n",
      "Epoch 27/50, Loss: 2.3999, Domain Loss: 1.5509, Class Loss: 0.8490\n",
      "Epoch 28/50, Loss: 2.2444, Domain Loss: 1.4022, Class Loss: 0.8423\n",
      "Epoch 29/50, Loss: 2.0878, Domain Loss: 1.2671, Class Loss: 0.8207\n",
      "Epoch 30/50, Loss: 3.1898, Domain Loss: 2.0310, Class Loss: 1.1588\n",
      "Epoch 31/50, Loss: 2.7106, Domain Loss: 1.8988, Class Loss: 0.8118\n",
      "Epoch 32/50, Loss: 2.5381, Domain Loss: 1.6908, Class Loss: 0.8473\n",
      "Epoch 33/50, Loss: 2.5877, Domain Loss: 1.7658, Class Loss: 0.8219\n",
      "Epoch 34/50, Loss: 6.1010, Domain Loss: 5.2668, Class Loss: 0.8341\n",
      "Epoch 35/50, Loss: 3.3971, Domain Loss: 2.5619, Class Loss: 0.8352\n",
      "Epoch 36/50, Loss: 3.6282, Domain Loss: 2.8115, Class Loss: 0.8167\n",
      "Epoch 37/50, Loss: 6.4111, Domain Loss: 5.5243, Class Loss: 0.8869\n",
      "Epoch 38/50, Loss: 14.1707, Domain Loss: 13.2180, Class Loss: 0.9528\n",
      "Epoch 39/50, Loss: 16.7104, Domain Loss: 15.8706, Class Loss: 0.8398\n",
      "Epoch 40/50, Loss: 22.6350, Domain Loss: 21.7785, Class Loss: 0.8565\n",
      "Epoch 41/50, Loss: 13.2004, Domain Loss: 12.3801, Class Loss: 0.8203\n",
      "Epoch 42/50, Loss: 29.9428, Domain Loss: 29.1337, Class Loss: 0.8091\n",
      "Epoch 43/50, Loss: 16.5613, Domain Loss: 15.7414, Class Loss: 0.8199\n",
      "Epoch 44/50, Loss: 10.7531, Domain Loss: 9.9389, Class Loss: 0.8141\n",
      "Epoch 45/50, Loss: 9.0903, Domain Loss: 8.2532, Class Loss: 0.8371\n",
      "Epoch 46/50, Loss: 7.9244, Domain Loss: 6.8299, Class Loss: 1.0945\n",
      "Epoch 47/50, Loss: 5.3202, Domain Loss: 4.3324, Class Loss: 0.9878\n",
      "Epoch 48/50, Loss: 2.4531, Domain Loss: 1.6474, Class Loss: 0.8057\n",
      "Epoch 49/50, Loss: 2.3491, Domain Loss: 1.5211, Class Loss: 0.8280\n",
      "Epoch 50/50, Loss: 2.4255, Domain Loss: 1.5683, Class Loss: 0.8572\n",
      "48.38\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.7497, Domain Loss: 1.4217, Class Loss: 1.3280\n",
      "Epoch 2/50, Loss: 2.1662, Domain Loss: 1.2974, Class Loss: 0.8689\n",
      "Epoch 3/50, Loss: 2.9034, Domain Loss: 1.9612, Class Loss: 0.9423\n",
      "Epoch 4/50, Loss: 2.6499, Domain Loss: 1.5329, Class Loss: 1.1170\n",
      "Epoch 5/50, Loss: 2.0398, Domain Loss: 1.0048, Class Loss: 1.0350\n",
      "Epoch 6/50, Loss: 1.9487, Domain Loss: 1.0910, Class Loss: 0.8577\n",
      "Epoch 7/50, Loss: 3.9106, Domain Loss: 2.7774, Class Loss: 1.1332\n",
      "Epoch 8/50, Loss: 10.6703, Domain Loss: 9.5136, Class Loss: 1.1567\n",
      "Epoch 9/50, Loss: 13.1892, Domain Loss: 11.8679, Class Loss: 1.3213\n",
      "Epoch 10/50, Loss: 7.3039, Domain Loss: 6.3024, Class Loss: 1.0015\n",
      "Epoch 11/50, Loss: 7.4667, Domain Loss: 6.5923, Class Loss: 0.8744\n",
      "Epoch 12/50, Loss: 4.6116, Domain Loss: 3.7706, Class Loss: 0.8410\n",
      "Epoch 13/50, Loss: 7.6933, Domain Loss: 6.8574, Class Loss: 0.8359\n",
      "Epoch 14/50, Loss: 8.3799, Domain Loss: 7.5399, Class Loss: 0.8401\n",
      "Epoch 15/50, Loss: 8.0696, Domain Loss: 7.2391, Class Loss: 0.8305\n",
      "Epoch 16/50, Loss: 5.9604, Domain Loss: 4.5815, Class Loss: 1.3788\n",
      "Epoch 17/50, Loss: 5.0549, Domain Loss: 4.1342, Class Loss: 0.9207\n",
      "Epoch 18/50, Loss: 5.3159, Domain Loss: 4.4839, Class Loss: 0.8320\n",
      "Epoch 19/50, Loss: 3.5828, Domain Loss: 2.7357, Class Loss: 0.8470\n",
      "Epoch 20/50, Loss: 3.5778, Domain Loss: 2.7422, Class Loss: 0.8356\n",
      "Epoch 21/50, Loss: 2.9547, Domain Loss: 2.1404, Class Loss: 0.8143\n",
      "Epoch 22/50, Loss: 2.7387, Domain Loss: 1.9012, Class Loss: 0.8375\n",
      "Epoch 23/50, Loss: 2.4425, Domain Loss: 1.6237, Class Loss: 0.8189\n",
      "Epoch 24/50, Loss: 2.4799, Domain Loss: 1.6464, Class Loss: 0.8335\n",
      "Epoch 25/50, Loss: 2.6569, Domain Loss: 1.8391, Class Loss: 0.8178\n",
      "Epoch 26/50, Loss: 2.5714, Domain Loss: 1.7718, Class Loss: 0.7996\n",
      "Epoch 27/50, Loss: 2.2870, Domain Loss: 1.4848, Class Loss: 0.8022\n",
      "Epoch 28/50, Loss: 2.5247, Domain Loss: 1.7234, Class Loss: 0.8013\n",
      "Epoch 29/50, Loss: 2.4447, Domain Loss: 1.6314, Class Loss: 0.8133\n",
      "Epoch 30/50, Loss: 2.8342, Domain Loss: 2.0168, Class Loss: 0.8174\n",
      "Epoch 31/50, Loss: 2.9645, Domain Loss: 2.1774, Class Loss: 0.7871\n",
      "Epoch 32/50, Loss: 4.4311, Domain Loss: 3.6385, Class Loss: 0.7926\n",
      "Epoch 33/50, Loss: 4.0059, Domain Loss: 3.1972, Class Loss: 0.8087\n",
      "Epoch 34/50, Loss: 2.9216, Domain Loss: 2.0904, Class Loss: 0.8312\n",
      "Epoch 35/50, Loss: 5.8535, Domain Loss: 5.0457, Class Loss: 0.8078\n",
      "Epoch 36/50, Loss: 7.0838, Domain Loss: 6.2637, Class Loss: 0.8202\n",
      "Epoch 37/50, Loss: 3.3587, Domain Loss: 2.5866, Class Loss: 0.7721\n",
      "Epoch 38/50, Loss: 5.5116, Domain Loss: 4.6601, Class Loss: 0.8515\n",
      "Epoch 39/50, Loss: 4.2273, Domain Loss: 3.2879, Class Loss: 0.9394\n",
      "Epoch 40/50, Loss: 2.7006, Domain Loss: 1.5582, Class Loss: 1.1424\n",
      "Epoch 41/50, Loss: 1.9530, Domain Loss: 1.0947, Class Loss: 0.8583\n",
      "Epoch 42/50, Loss: 1.8918, Domain Loss: 1.0581, Class Loss: 0.8338\n",
      "Epoch 43/50, Loss: 1.7507, Domain Loss: 0.9266, Class Loss: 0.8241\n",
      "Epoch 44/50, Loss: 1.6857, Domain Loss: 0.8672, Class Loss: 0.8185\n",
      "Epoch 45/50, Loss: 2.3567, Domain Loss: 1.5301, Class Loss: 0.8266\n",
      "Epoch 46/50, Loss: 3.4548, Domain Loss: 2.6345, Class Loss: 0.8202\n",
      "Epoch 47/50, Loss: 2.0264, Domain Loss: 1.1973, Class Loss: 0.8290\n",
      "Epoch 48/50, Loss: 2.2748, Domain Loss: 1.4646, Class Loss: 0.8103\n",
      "Epoch 49/50, Loss: 2.1853, Domain Loss: 1.3618, Class Loss: 0.8235\n",
      "Epoch 50/50, Loss: 2.7135, Domain Loss: 1.8087, Class Loss: 0.9049\n",
      "36.57\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 3.6266, Domain Loss: 1.7956, Class Loss: 1.8310\n",
      "Epoch 2/50, Loss: 2.0273, Domain Loss: 1.1528, Class Loss: 0.8745\n",
      "Epoch 3/50, Loss: 2.0589, Domain Loss: 1.1744, Class Loss: 0.8846\n",
      "Epoch 4/50, Loss: 2.6187, Domain Loss: 1.6755, Class Loss: 0.9432\n",
      "Epoch 5/50, Loss: 2.1524, Domain Loss: 1.2647, Class Loss: 0.8878\n",
      "Epoch 6/50, Loss: 1.9932, Domain Loss: 1.1609, Class Loss: 0.8323\n",
      "Epoch 7/50, Loss: 1.8754, Domain Loss: 1.0401, Class Loss: 0.8353\n",
      "Epoch 8/50, Loss: 2.0377, Domain Loss: 1.1906, Class Loss: 0.8471\n",
      "Epoch 9/50, Loss: 3.2318, Domain Loss: 1.8961, Class Loss: 1.3357\n",
      "Epoch 10/50, Loss: 2.2903, Domain Loss: 1.4506, Class Loss: 0.8397\n",
      "Epoch 11/50, Loss: 2.7652, Domain Loss: 1.9434, Class Loss: 0.8218\n",
      "Epoch 12/50, Loss: 9.7714, Domain Loss: 7.9420, Class Loss: 1.8294\n",
      "Epoch 13/50, Loss: 13.9239, Domain Loss: 12.3146, Class Loss: 1.6093\n",
      "Epoch 14/50, Loss: 7.7272, Domain Loss: 6.3356, Class Loss: 1.3916\n",
      "Epoch 15/50, Loss: 8.2705, Domain Loss: 6.8846, Class Loss: 1.3859\n",
      "Epoch 16/50, Loss: 6.6815, Domain Loss: 5.2948, Class Loss: 1.3867\n",
      "Epoch 17/50, Loss: 2.6934, Domain Loss: 1.3463, Class Loss: 1.3470\n",
      "Epoch 18/50, Loss: 2.1482, Domain Loss: 1.0909, Class Loss: 1.0573\n",
      "Epoch 19/50, Loss: 1.9450, Domain Loss: 1.0170, Class Loss: 0.9280\n",
      "Epoch 20/50, Loss: 1.8041, Domain Loss: 0.9751, Class Loss: 0.8290\n",
      "Epoch 21/50, Loss: 1.7657, Domain Loss: 0.9288, Class Loss: 0.8370\n",
      "Epoch 22/50, Loss: 1.7552, Domain Loss: 0.9068, Class Loss: 0.8484\n",
      "Epoch 23/50, Loss: 1.7369, Domain Loss: 0.9133, Class Loss: 0.8236\n",
      "Epoch 24/50, Loss: 1.6897, Domain Loss: 0.8681, Class Loss: 0.8216\n",
      "Epoch 25/50, Loss: 1.6906, Domain Loss: 0.8493, Class Loss: 0.8412\n",
      "Epoch 26/50, Loss: 1.6905, Domain Loss: 0.8526, Class Loss: 0.8379\n",
      "Epoch 27/50, Loss: 1.6795, Domain Loss: 0.8603, Class Loss: 0.8193\n",
      "Epoch 28/50, Loss: 1.7065, Domain Loss: 0.8817, Class Loss: 0.8248\n",
      "Epoch 29/50, Loss: 1.6809, Domain Loss: 0.8560, Class Loss: 0.8250\n",
      "Epoch 30/50, Loss: 1.6737, Domain Loss: 0.8369, Class Loss: 0.8368\n",
      "Epoch 31/50, Loss: 1.7068, Domain Loss: 0.8684, Class Loss: 0.8383\n",
      "Epoch 32/50, Loss: 1.6900, Domain Loss: 0.8684, Class Loss: 0.8216\n",
      "Epoch 33/50, Loss: 1.7882, Domain Loss: 0.9673, Class Loss: 0.8210\n",
      "Epoch 34/50, Loss: 2.2009, Domain Loss: 0.8908, Class Loss: 1.3101\n",
      "Epoch 35/50, Loss: 2.4606, Domain Loss: 0.8851, Class Loss: 1.5755\n",
      "Epoch 36/50, Loss: 2.2414, Domain Loss: 0.8434, Class Loss: 1.3980\n",
      "Epoch 37/50, Loss: 2.2267, Domain Loss: 0.8300, Class Loss: 1.3967\n",
      "Epoch 38/50, Loss: 2.2722, Domain Loss: 0.8817, Class Loss: 1.3905\n",
      "Epoch 39/50, Loss: 2.2278, Domain Loss: 0.8370, Class Loss: 1.3908\n",
      "Epoch 40/50, Loss: 2.2668, Domain Loss: 0.8765, Class Loss: 1.3903\n",
      "Epoch 41/50, Loss: 2.2655, Domain Loss: 0.8772, Class Loss: 1.3882\n",
      "Epoch 42/50, Loss: 2.2697, Domain Loss: 0.8780, Class Loss: 1.3917\n",
      "Epoch 43/50, Loss: 2.2089, Domain Loss: 0.8211, Class Loss: 1.3878\n",
      "Epoch 44/50, Loss: 2.2669, Domain Loss: 0.8800, Class Loss: 1.3869\n",
      "Epoch 45/50, Loss: 2.2859, Domain Loss: 0.9057, Class Loss: 1.3802\n",
      "Epoch 46/50, Loss: 2.2293, Domain Loss: 0.8633, Class Loss: 1.3660\n",
      "Epoch 47/50, Loss: 2.2324, Domain Loss: 0.9016, Class Loss: 1.3308\n",
      "Epoch 48/50, Loss: 2.1456, Domain Loss: 0.8674, Class Loss: 1.2782\n",
      "Epoch 49/50, Loss: 2.1651, Domain Loss: 0.8671, Class Loss: 1.2981\n",
      "Epoch 50/50, Loss: 2.1470, Domain Loss: 0.9681, Class Loss: 1.1789\n",
      "24.04\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 3.4072, Domain Loss: 2.0622, Class Loss: 1.3449\n",
      "Epoch 2/50, Loss: 2.1250, Domain Loss: 1.2453, Class Loss: 0.8797\n",
      "Epoch 3/50, Loss: 2.0417, Domain Loss: 1.1884, Class Loss: 0.8534\n",
      "Epoch 4/50, Loss: 2.2449, Domain Loss: 1.3774, Class Loss: 0.8675\n",
      "Epoch 5/50, Loss: 2.7149, Domain Loss: 1.7772, Class Loss: 0.9377\n",
      "Epoch 6/50, Loss: 5.6393, Domain Loss: 4.2288, Class Loss: 1.4105\n",
      "Epoch 7/50, Loss: 2.6192, Domain Loss: 1.4530, Class Loss: 1.1663\n",
      "Epoch 8/50, Loss: 2.0867, Domain Loss: 1.2485, Class Loss: 0.8382\n",
      "Epoch 9/50, Loss: 2.2130, Domain Loss: 1.3120, Class Loss: 0.9010\n",
      "Epoch 10/50, Loss: 2.2079, Domain Loss: 1.3863, Class Loss: 0.8216\n",
      "Epoch 11/50, Loss: 2.2016, Domain Loss: 1.3863, Class Loss: 0.8153\n",
      "Epoch 12/50, Loss: 2.1927, Domain Loss: 1.3863, Class Loss: 0.8064\n",
      "Epoch 13/50, Loss: 2.1991, Domain Loss: 1.3863, Class Loss: 0.8128\n",
      "Epoch 14/50, Loss: 2.2168, Domain Loss: 1.3863, Class Loss: 0.8305\n",
      "Epoch 15/50, Loss: 2.2048, Domain Loss: 1.3863, Class Loss: 0.8185\n",
      "Epoch 16/50, Loss: 2.2052, Domain Loss: 1.3863, Class Loss: 0.8190\n",
      "Epoch 17/50, Loss: 2.1950, Domain Loss: 1.3863, Class Loss: 0.8087\n",
      "Epoch 18/50, Loss: 2.2311, Domain Loss: 1.3863, Class Loss: 0.8448\n",
      "Epoch 19/50, Loss: 2.1792, Domain Loss: 1.3863, Class Loss: 0.7929\n",
      "Epoch 20/50, Loss: 2.1887, Domain Loss: 1.3863, Class Loss: 0.8024\n",
      "Epoch 21/50, Loss: 2.2002, Domain Loss: 1.3863, Class Loss: 0.8139\n",
      "Epoch 22/50, Loss: 2.1800, Domain Loss: 1.3863, Class Loss: 0.7937\n",
      "Epoch 23/50, Loss: 2.2022, Domain Loss: 1.3863, Class Loss: 0.8159\n",
      "Epoch 24/50, Loss: 2.1766, Domain Loss: 1.3863, Class Loss: 0.7903\n",
      "Epoch 25/50, Loss: 2.1918, Domain Loss: 1.3863, Class Loss: 0.8055\n",
      "Epoch 26/50, Loss: 2.1805, Domain Loss: 1.3863, Class Loss: 0.7942\n",
      "Epoch 27/50, Loss: 2.1872, Domain Loss: 1.3863, Class Loss: 0.8009\n",
      "Epoch 28/50, Loss: 2.1798, Domain Loss: 1.3863, Class Loss: 0.7935\n",
      "Epoch 29/50, Loss: 2.1736, Domain Loss: 1.3863, Class Loss: 0.7873\n",
      "Epoch 30/50, Loss: 2.1756, Domain Loss: 1.3863, Class Loss: 0.7893\n",
      "Epoch 31/50, Loss: 2.1436, Domain Loss: 1.3863, Class Loss: 0.7574\n",
      "Epoch 32/50, Loss: 12.2134, Domain Loss: 7.0302, Class Loss: 5.1832\n",
      "Epoch 33/50, Loss: 21.1257, Domain Loss: 9.6169, Class Loss: 11.5089\n",
      "Epoch 34/50, Loss: 2.3224, Domain Loss: 1.3864, Class Loss: 0.9360\n",
      "Epoch 35/50, Loss: 2.2011, Domain Loss: 1.3864, Class Loss: 0.8147\n",
      "Epoch 36/50, Loss: 2.2490, Domain Loss: 1.3864, Class Loss: 0.8627\n",
      "Epoch 37/50, Loss: 2.2056, Domain Loss: 1.3863, Class Loss: 0.8193\n",
      "Epoch 38/50, Loss: 2.1939, Domain Loss: 1.3863, Class Loss: 0.8075\n",
      "Epoch 39/50, Loss: 2.2052, Domain Loss: 1.3863, Class Loss: 0.8189\n",
      "Epoch 40/50, Loss: 2.4955, Domain Loss: 1.7010, Class Loss: 0.7946\n",
      "Epoch 41/50, Loss: 2.1740, Domain Loss: 1.3864, Class Loss: 0.7876\n",
      "Epoch 42/50, Loss: 2.1649, Domain Loss: 1.3864, Class Loss: 0.7785\n",
      "Epoch 43/50, Loss: 2.1334, Domain Loss: 1.3863, Class Loss: 0.7470\n",
      "Epoch 44/50, Loss: 2.1120, Domain Loss: 1.3863, Class Loss: 0.7256\n",
      "Epoch 45/50, Loss: 2.0570, Domain Loss: 1.3863, Class Loss: 0.6706\n",
      "Epoch 46/50, Loss: 1.9873, Domain Loss: 1.3863, Class Loss: 0.6010\n",
      "Epoch 47/50, Loss: 1.9241, Domain Loss: 1.3863, Class Loss: 0.5378\n",
      "Epoch 48/50, Loss: 1.8467, Domain Loss: 1.3863, Class Loss: 0.4604\n",
      "Epoch 49/50, Loss: 1.8124, Domain Loss: 1.3863, Class Loss: 0.4261\n",
      "Epoch 50/50, Loss: 1.7682, Domain Loss: 1.3863, Class Loss: 0.3819\n",
      "48.02\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 4.7293, Domain Loss: 2.8681, Class Loss: 1.8612\n",
      "Epoch 2/50, Loss: 2.4593, Domain Loss: 1.5674, Class Loss: 0.8919\n",
      "Epoch 3/50, Loss: 2.3925, Domain Loss: 1.5525, Class Loss: 0.8400\n",
      "Epoch 4/50, Loss: 2.0718, Domain Loss: 1.2148, Class Loss: 0.8570\n",
      "Epoch 5/50, Loss: 2.0337, Domain Loss: 1.2002, Class Loss: 0.8335\n",
      "Epoch 6/50, Loss: 2.1492, Domain Loss: 1.3055, Class Loss: 0.8437\n",
      "Epoch 7/50, Loss: 3.3073, Domain Loss: 2.4797, Class Loss: 0.8277\n",
      "Epoch 8/50, Loss: 13.9963, Domain Loss: 12.1533, Class Loss: 1.8430\n",
      "Epoch 9/50, Loss: 2.8309, Domain Loss: 1.6976, Class Loss: 1.1333\n",
      "Epoch 10/50, Loss: 2.4676, Domain Loss: 1.5955, Class Loss: 0.8721\n",
      "Epoch 11/50, Loss: 2.1676, Domain Loss: 1.3452, Class Loss: 0.8224\n",
      "Epoch 12/50, Loss: 2.1821, Domain Loss: 1.3667, Class Loss: 0.8154\n",
      "Epoch 13/50, Loss: 2.1802, Domain Loss: 1.3576, Class Loss: 0.8226\n",
      "Epoch 14/50, Loss: 3.6095, Domain Loss: 2.7953, Class Loss: 0.8143\n",
      "Epoch 15/50, Loss: 2.7483, Domain Loss: 1.9021, Class Loss: 0.8462\n",
      "Epoch 16/50, Loss: 2.3117, Domain Loss: 1.4940, Class Loss: 0.8177\n",
      "Epoch 17/50, Loss: 2.5560, Domain Loss: 1.6522, Class Loss: 0.9038\n",
      "Epoch 18/50, Loss: 2.7323, Domain Loss: 1.3747, Class Loss: 1.3576\n",
      "Epoch 19/50, Loss: 2.1486, Domain Loss: 1.2930, Class Loss: 0.8556\n",
      "Epoch 20/50, Loss: 2.1368, Domain Loss: 1.2926, Class Loss: 0.8442\n",
      "Epoch 21/50, Loss: 2.1312, Domain Loss: 1.3150, Class Loss: 0.8162\n",
      "Epoch 22/50, Loss: 2.1090, Domain Loss: 1.2853, Class Loss: 0.8238\n",
      "Epoch 23/50, Loss: 2.1473, Domain Loss: 1.3185, Class Loss: 0.8288\n",
      "Epoch 24/50, Loss: 2.1593, Domain Loss: 1.3131, Class Loss: 0.8463\n",
      "Epoch 25/50, Loss: 2.1569, Domain Loss: 1.3283, Class Loss: 0.8286\n",
      "Epoch 26/50, Loss: 2.1286, Domain Loss: 1.3017, Class Loss: 0.8269\n",
      "Epoch 27/50, Loss: 2.1879, Domain Loss: 1.3530, Class Loss: 0.8349\n",
      "Epoch 28/50, Loss: 2.2699, Domain Loss: 1.4364, Class Loss: 0.8335\n",
      "Epoch 29/50, Loss: 2.3114, Domain Loss: 1.3908, Class Loss: 0.9206\n",
      "Epoch 30/50, Loss: 2.8393, Domain Loss: 2.0231, Class Loss: 0.8162\n",
      "Epoch 31/50, Loss: 2.7313, Domain Loss: 1.8967, Class Loss: 0.8346\n",
      "Epoch 32/50, Loss: 2.5140, Domain Loss: 1.6882, Class Loss: 0.8258\n",
      "Epoch 33/50, Loss: 2.2050, Domain Loss: 1.3998, Class Loss: 0.8052\n",
      "Epoch 34/50, Loss: 2.4468, Domain Loss: 1.4822, Class Loss: 0.9647\n",
      "Epoch 35/50, Loss: 2.5533, Domain Loss: 1.7084, Class Loss: 0.8449\n",
      "Epoch 36/50, Loss: 2.3283, Domain Loss: 1.4797, Class Loss: 0.8487\n",
      "Epoch 37/50, Loss: 2.2249, Domain Loss: 1.4101, Class Loss: 0.8148\n",
      "Epoch 38/50, Loss: 2.1281, Domain Loss: 1.2986, Class Loss: 0.8295\n",
      "Epoch 39/50, Loss: 2.2653, Domain Loss: 1.3978, Class Loss: 0.8675\n",
      "Epoch 40/50, Loss: 2.3309, Domain Loss: 1.4936, Class Loss: 0.8373\n",
      "Epoch 41/50, Loss: 2.2643, Domain Loss: 1.4564, Class Loss: 0.8079\n",
      "Epoch 42/50, Loss: 2.1299, Domain Loss: 1.3095, Class Loss: 0.8203\n",
      "Epoch 43/50, Loss: 1.9952, Domain Loss: 1.1777, Class Loss: 0.8175\n",
      "Epoch 44/50, Loss: 2.0207, Domain Loss: 1.1818, Class Loss: 0.8389\n",
      "Epoch 45/50, Loss: 2.0786, Domain Loss: 1.2365, Class Loss: 0.8421\n",
      "Epoch 46/50, Loss: 2.4751, Domain Loss: 1.6456, Class Loss: 0.8295\n",
      "Epoch 47/50, Loss: 2.6351, Domain Loss: 1.8140, Class Loss: 0.8211\n",
      "Epoch 48/50, Loss: 2.6251, Domain Loss: 1.8205, Class Loss: 0.8046\n",
      "Epoch 49/50, Loss: 3.8674, Domain Loss: 2.8573, Class Loss: 1.0101\n",
      "Epoch 50/50, Loss: 4.4625, Domain Loss: 3.5243, Class Loss: 0.9382\n",
      "49.88\n",
      "\n",
      "\n",
      "Source performance:\n",
      "47.42 34.60 48.19 37.35 \n",
      "Target performance:\n",
      "40.27 26.48 40.79 27.37 \n",
      "\n",
      "Per-class target performance: 90.00 10.68 28.04 34.44 \n",
      "Run 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ash/.conda/envs/torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Class Loss: 2.3631, Discrepancy Loss: 0.0956\n",
      "Validation Loss: 1.7665\n",
      "Epoch [2/50], Class Loss: 1.6925, Discrepancy Loss: 0.0731\n",
      "Validation Loss: 1.7470\n",
      "Epoch [3/50], Class Loss: 1.6842, Discrepancy Loss: 0.0623\n",
      "Validation Loss: 1.6167\n",
      "Epoch [4/50], Class Loss: 1.4092, Discrepancy Loss: 0.0593\n",
      "Validation Loss: 0.8178\n",
      "Epoch [5/50], Class Loss: 0.6693, Discrepancy Loss: 0.0569\n",
      "Validation Loss: 0.6534\n",
      "Epoch [6/50], Class Loss: 0.5146, Discrepancy Loss: 0.0389\n",
      "Validation Loss: 0.4367\n",
      "Epoch [7/50], Class Loss: 0.4565, Discrepancy Loss: 0.0408\n",
      "Validation Loss: 0.6493\n",
      "Epoch [8/50], Class Loss: 0.3378, Discrepancy Loss: 0.0402\n",
      "Validation Loss: 0.6280\n",
      "Epoch [9/50], Class Loss: 0.3018, Discrepancy Loss: 0.0484\n",
      "Validation Loss: 0.6990\n",
      "Epoch [10/50], Class Loss: 0.2768, Discrepancy Loss: 0.0406\n",
      "Validation Loss: 0.3116\n",
      "Epoch [11/50], Class Loss: 0.0772, Discrepancy Loss: 0.0420\n",
      "Validation Loss: 0.3568\n",
      "Epoch [12/50], Class Loss: 0.0617, Discrepancy Loss: 0.0293\n",
      "Validation Loss: 0.3409\n",
      "Epoch [13/50], Class Loss: 0.0377, Discrepancy Loss: 0.0242\n",
      "Validation Loss: 0.3465\n",
      "Epoch [14/50], Class Loss: 0.0349, Discrepancy Loss: 0.0195\n",
      "Validation Loss: 0.4454\n",
      "Epoch [15/50], Class Loss: 0.0345, Discrepancy Loss: 0.0267\n",
      "Validation Loss: 0.4269\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 94.60%, Precision: 94.79%, Recall: 94.76%, F1 Score: 94.75%\n",
      "Target Domain Performance - Accuracy: 50.84%, Precision: 56.40%, Recall: 51.44%, F1 Score: 46.11%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 2.1225, Discrepancy Loss: 0.0522\n",
      "Validation Loss: 1.7337\n",
      "Epoch [2/50], Class Loss: 1.6782, Discrepancy Loss: 0.0649\n",
      "Validation Loss: 1.6946\n",
      "Epoch [3/50], Class Loss: 1.4685, Discrepancy Loss: 0.0818\n",
      "Validation Loss: 0.6045\n",
      "Epoch [4/50], Class Loss: 0.5605, Discrepancy Loss: 0.0469\n",
      "Validation Loss: 0.5414\n",
      "Epoch [5/50], Class Loss: 0.5045, Discrepancy Loss: 0.0804\n",
      "Validation Loss: 0.4390\n",
      "Epoch [6/50], Class Loss: 0.4339, Discrepancy Loss: 0.0518\n",
      "Validation Loss: 0.4255\n",
      "Epoch [7/50], Class Loss: 0.3354, Discrepancy Loss: 0.0542\n",
      "Validation Loss: 0.4637\n",
      "Epoch [8/50], Class Loss: 0.3059, Discrepancy Loss: 0.0410\n",
      "Validation Loss: 0.4788\n",
      "Epoch [9/50], Class Loss: 0.3218, Discrepancy Loss: 0.0591\n",
      "Validation Loss: 0.6727\n",
      "Epoch [10/50], Class Loss: 0.2102, Discrepancy Loss: 0.0481\n",
      "Validation Loss: 1.1471\n",
      "Epoch [11/50], Class Loss: 0.0970, Discrepancy Loss: 0.0510\n",
      "Validation Loss: 0.5052\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 93.35%, Precision: 93.54%, Recall: 93.55%, F1 Score: 93.54%\n",
      "Target Domain Performance - Accuracy: 55.88%, Precision: 61.61%, Recall: 56.40%, F1 Score: 53.12%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 2.2902, Discrepancy Loss: 0.1228\n",
      "Validation Loss: 1.7949\n",
      "Epoch [2/50], Class Loss: 1.7484, Discrepancy Loss: 0.0966\n",
      "Validation Loss: 1.6587\n",
      "Epoch [3/50], Class Loss: 1.6308, Discrepancy Loss: 0.0840\n",
      "Validation Loss: 2.0649\n",
      "Epoch [4/50], Class Loss: 1.3749, Discrepancy Loss: 0.0932\n",
      "Validation Loss: 1.0397\n",
      "Epoch [5/50], Class Loss: 0.8537, Discrepancy Loss: 0.0571\n",
      "Validation Loss: 0.5432\n",
      "Epoch [6/50], Class Loss: 0.5979, Discrepancy Loss: 0.0412\n",
      "Validation Loss: 0.5742\n",
      "Epoch [7/50], Class Loss: 0.4228, Discrepancy Loss: 0.0426\n",
      "Validation Loss: 0.3972\n",
      "Epoch [8/50], Class Loss: 0.4441, Discrepancy Loss: 0.0415\n",
      "Validation Loss: 0.7515\n",
      "Epoch [9/50], Class Loss: 0.4576, Discrepancy Loss: 0.0442\n",
      "Validation Loss: 0.4194\n",
      "Epoch [10/50], Class Loss: 0.3261, Discrepancy Loss: 0.0563\n",
      "Validation Loss: 0.4720\n",
      "Epoch [11/50], Class Loss: 0.0928, Discrepancy Loss: 0.0403\n",
      "Validation Loss: 0.4252\n",
      "Epoch [12/50], Class Loss: 0.0632, Discrepancy Loss: 0.0321\n",
      "Validation Loss: 0.5505\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 91.49%, Precision: 92.51%, Recall: 91.64%, F1 Score: 91.62%\n",
      "Target Domain Performance - Accuracy: 60.37%, Precision: 66.61%, Recall: 60.92%, F1 Score: 58.37%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 2.0220, Discrepancy Loss: 0.0594\n",
      "Validation Loss: 1.7388\n",
      "Epoch [2/50], Class Loss: 1.6843, Discrepancy Loss: 0.0591\n",
      "Validation Loss: 1.7570\n",
      "Epoch [3/50], Class Loss: 1.5980, Discrepancy Loss: 0.0821\n",
      "Validation Loss: 1.3672\n",
      "Epoch [4/50], Class Loss: 0.9144, Discrepancy Loss: 0.0433\n",
      "Validation Loss: 0.4748\n",
      "Epoch [5/50], Class Loss: 0.7022, Discrepancy Loss: 0.0350\n",
      "Validation Loss: 1.0484\n",
      "Epoch [6/50], Class Loss: 0.6058, Discrepancy Loss: 0.0604\n",
      "Validation Loss: 0.5223\n",
      "Epoch [7/50], Class Loss: 0.4918, Discrepancy Loss: 0.0286\n",
      "Validation Loss: 0.5421\n",
      "Epoch [8/50], Class Loss: 0.5372, Discrepancy Loss: 0.0537\n",
      "Validation Loss: 0.9206\n",
      "Epoch [9/50], Class Loss: 0.7538, Discrepancy Loss: 0.0500\n",
      "Validation Loss: 0.6985\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 88.49%, Precision: 91.13%, Recall: 88.66%, F1 Score: 88.38%\n",
      "Target Domain Performance - Accuracy: 67.21%, Precision: 71.80%, Recall: 67.52%, F1 Score: 67.68%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 2.0929, Discrepancy Loss: 0.0821\n",
      "Validation Loss: 1.7762\n",
      "Epoch [2/50], Class Loss: 1.7326, Discrepancy Loss: 0.0784\n",
      "Validation Loss: 1.8314\n",
      "Epoch [3/50], Class Loss: 2.3219, Discrepancy Loss: 0.0899\n",
      "Validation Loss: 1.5706\n",
      "Epoch [4/50], Class Loss: 0.9396, Discrepancy Loss: 0.0627\n",
      "Validation Loss: 0.5507\n",
      "Epoch [5/50], Class Loss: 0.5069, Discrepancy Loss: 0.0329\n",
      "Validation Loss: 0.8736\n",
      "Epoch [6/50], Class Loss: 0.4971, Discrepancy Loss: 0.0327\n",
      "Validation Loss: 0.8135\n",
      "Epoch [7/50], Class Loss: 0.4145, Discrepancy Loss: 0.0443\n",
      "Validation Loss: 0.4027\n",
      "Epoch [8/50], Class Loss: 0.2956, Discrepancy Loss: 0.0345\n",
      "Validation Loss: 0.5505\n",
      "Epoch [9/50], Class Loss: 0.2648, Discrepancy Loss: 0.0312\n",
      "Validation Loss: 0.4637\n",
      "Epoch [10/50], Class Loss: 0.3146, Discrepancy Loss: 0.0199\n",
      "Validation Loss: 0.5151\n",
      "Epoch [11/50], Class Loss: 0.0741, Discrepancy Loss: 0.0143\n",
      "Validation Loss: 0.3303\n",
      "Epoch [12/50], Class Loss: 0.0380, Discrepancy Loss: 0.0115\n",
      "Validation Loss: 0.3351\n",
      "Epoch [13/50], Class Loss: 0.0312, Discrepancy Loss: 0.0111\n",
      "Validation Loss: 0.3653\n",
      "Epoch [14/50], Class Loss: 0.0303, Discrepancy Loss: 0.0129\n",
      "Validation Loss: 0.3773\n",
      "Epoch [15/50], Class Loss: 0.0323, Discrepancy Loss: 0.0160\n",
      "Validation Loss: 0.4362\n",
      "Epoch [16/50], Class Loss: 0.0455, Discrepancy Loss: 0.0213\n",
      "Validation Loss: 0.4887\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 94.18%, Precision: 94.41%, Recall: 94.41%, F1 Score: 94.35%\n",
      "Target Domain Performance - Accuracy: 53.00%, Precision: 64.67%, Recall: 53.45%, F1 Score: 50.70%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 2.1734, Discrepancy Loss: 0.1246\n",
      "Validation Loss: 1.8409\n",
      "Epoch [2/50], Class Loss: 1.6737, Discrepancy Loss: 0.0704\n",
      "Validation Loss: 1.7724\n",
      "Epoch [3/50], Class Loss: 1.4617, Discrepancy Loss: 0.0769\n",
      "Validation Loss: 0.9654\n",
      "Epoch [4/50], Class Loss: 0.6072, Discrepancy Loss: 0.0637\n",
      "Validation Loss: 0.4619\n",
      "Epoch [5/50], Class Loss: 0.6028, Discrepancy Loss: 0.0398\n",
      "Validation Loss: 0.9716\n",
      "Epoch [6/50], Class Loss: 0.3858, Discrepancy Loss: 0.0346\n",
      "Validation Loss: 1.5580\n",
      "Epoch [7/50], Class Loss: 0.3234, Discrepancy Loss: 0.0352\n",
      "Validation Loss: 0.3307\n",
      "Epoch [8/50], Class Loss: 0.2565, Discrepancy Loss: 0.0452\n",
      "Validation Loss: 0.4350\n",
      "Epoch [9/50], Class Loss: 0.2215, Discrepancy Loss: 0.0330\n",
      "Validation Loss: 0.6962\n",
      "Epoch [10/50], Class Loss: 0.1487, Discrepancy Loss: 0.0298\n",
      "Validation Loss: 0.5914\n",
      "Epoch [11/50], Class Loss: 0.0446, Discrepancy Loss: 0.0259\n",
      "Validation Loss: 0.3784\n",
      "Epoch [12/50], Class Loss: 0.0301, Discrepancy Loss: 0.0314\n",
      "Validation Loss: 0.4462\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 94.84%, Precision: 95.04%, Recall: 94.98%, F1 Score: 94.99%\n",
      "Target Domain Performance - Accuracy: 46.76%, Precision: 53.12%, Recall: 47.31%, F1 Score: 39.49%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 2.2839, Discrepancy Loss: 0.0730\n",
      "Validation Loss: 1.7340\n",
      "Epoch [2/50], Class Loss: 1.6458, Discrepancy Loss: 0.0769\n",
      "Validation Loss: 1.6300\n",
      "Epoch [3/50], Class Loss: 1.1116, Discrepancy Loss: 0.0537\n",
      "Validation Loss: 0.6829\n",
      "Epoch [4/50], Class Loss: 0.8965, Discrepancy Loss: 0.0363\n",
      "Validation Loss: 2.2097\n",
      "Epoch [5/50], Class Loss: 0.9892, Discrepancy Loss: 0.0434\n",
      "Validation Loss: 0.4568\n",
      "Epoch [6/50], Class Loss: 0.7297, Discrepancy Loss: 0.0702\n",
      "Validation Loss: 0.3433\n",
      "Epoch [7/50], Class Loss: 0.3965, Discrepancy Loss: 0.0374\n",
      "Validation Loss: 0.7014\n",
      "Epoch [8/50], Class Loss: 0.4085, Discrepancy Loss: 0.0459\n",
      "Validation Loss: 0.3652\n",
      "Epoch [9/50], Class Loss: 0.2861, Discrepancy Loss: 0.0412\n",
      "Validation Loss: 1.7837\n",
      "Epoch [10/50], Class Loss: 0.3581, Discrepancy Loss: 0.0348\n",
      "Validation Loss: 1.0722\n",
      "Epoch [11/50], Class Loss: 0.1170, Discrepancy Loss: 0.0348\n",
      "Validation Loss: 0.4527\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 92.93%, Precision: 93.44%, Recall: 93.08%, F1 Score: 93.10%\n",
      "Target Domain Performance - Accuracy: 54.02%, Precision: 63.85%, Recall: 54.52%, F1 Score: 49.33%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 2.1731, Discrepancy Loss: 0.0664\n",
      "Validation Loss: 1.7261\n",
      "Epoch [2/50], Class Loss: 1.6632, Discrepancy Loss: 0.0321\n",
      "Validation Loss: 1.6293\n",
      "Epoch [3/50], Class Loss: 1.2121, Discrepancy Loss: 0.0631\n",
      "Validation Loss: 1.0621\n",
      "Epoch [4/50], Class Loss: 0.7599, Discrepancy Loss: 0.0472\n",
      "Validation Loss: 0.4487\n",
      "Epoch [5/50], Class Loss: 1.0494, Discrepancy Loss: 0.0533\n",
      "Validation Loss: 0.4866\n",
      "Epoch [6/50], Class Loss: 0.4263, Discrepancy Loss: 0.0632\n",
      "Validation Loss: 0.4501\n",
      "Epoch [7/50], Class Loss: 0.5058, Discrepancy Loss: 0.0491\n",
      "Validation Loss: 0.4905\n",
      "Epoch [8/50], Class Loss: 0.3494, Discrepancy Loss: 0.0504\n",
      "Validation Loss: 0.3911\n",
      "Epoch [9/50], Class Loss: 0.3302, Discrepancy Loss: 0.0551\n",
      "Validation Loss: 0.4001\n",
      "Epoch [10/50], Class Loss: 0.1674, Discrepancy Loss: 0.0429\n",
      "Validation Loss: 0.5874\n",
      "Epoch [11/50], Class Loss: 0.0579, Discrepancy Loss: 0.0381\n",
      "Validation Loss: 0.4014\n",
      "Epoch [12/50], Class Loss: 0.0356, Discrepancy Loss: 0.0338\n",
      "Validation Loss: 0.4523\n",
      "Epoch [13/50], Class Loss: 0.0277, Discrepancy Loss: 0.0273\n",
      "Validation Loss: 0.4224\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 94.48%, Precision: 94.78%, Recall: 94.62%, F1 Score: 94.64%\n",
      "Target Domain Performance - Accuracy: 50.36%, Precision: 62.57%, Recall: 50.82%, F1 Score: 43.24%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 1.9755, Discrepancy Loss: 0.0761\n",
      "Validation Loss: 1.9337\n",
      "Epoch [2/50], Class Loss: 1.6884, Discrepancy Loss: 0.0979\n",
      "Validation Loss: 1.7974\n",
      "Epoch [3/50], Class Loss: 1.6563, Discrepancy Loss: 0.1210\n",
      "Validation Loss: 1.0227\n",
      "Epoch [4/50], Class Loss: 0.8753, Discrepancy Loss: 0.0682\n",
      "Validation Loss: 1.1002\n",
      "Epoch [5/50], Class Loss: 0.6188, Discrepancy Loss: 0.0487\n",
      "Validation Loss: 0.6153\n",
      "Epoch [6/50], Class Loss: 0.4873, Discrepancy Loss: 0.0720\n",
      "Validation Loss: 0.3389\n",
      "Epoch [7/50], Class Loss: 0.3909, Discrepancy Loss: 0.0447\n",
      "Validation Loss: 0.3415\n",
      "Epoch [8/50], Class Loss: 0.3321, Discrepancy Loss: 0.0373\n",
      "Validation Loss: 0.4789\n",
      "Epoch [9/50], Class Loss: 0.2648, Discrepancy Loss: 0.0477\n",
      "Validation Loss: 0.3888\n",
      "Epoch [10/50], Class Loss: 0.2327, Discrepancy Loss: 0.0301\n",
      "Validation Loss: 0.5345\n",
      "Epoch [11/50], Class Loss: 0.0609, Discrepancy Loss: 0.0219\n",
      "Validation Loss: 0.3797\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 93.29%, Precision: 93.47%, Recall: 93.52%, F1 Score: 93.49%\n",
      "Target Domain Performance - Accuracy: 52.76%, Precision: 61.27%, Recall: 53.35%, F1 Score: 47.01%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 2.0821, Discrepancy Loss: 0.0946\n",
      "Validation Loss: 2.2871\n",
      "Epoch [2/50], Class Loss: 1.7012, Discrepancy Loss: 0.0815\n",
      "Validation Loss: 1.6628\n",
      "Epoch [3/50], Class Loss: 1.4734, Discrepancy Loss: 0.0841\n",
      "Validation Loss: 0.8425\n",
      "Epoch [4/50], Class Loss: 0.6425, Discrepancy Loss: 0.0589\n",
      "Validation Loss: 0.4380\n",
      "Epoch [5/50], Class Loss: 0.4592, Discrepancy Loss: 0.0449\n",
      "Validation Loss: 0.3418\n",
      "Epoch [6/50], Class Loss: 1.9443, Discrepancy Loss: 0.0944\n",
      "Validation Loss: 0.9305\n",
      "Epoch [7/50], Class Loss: 0.3594, Discrepancy Loss: 0.0369\n",
      "Validation Loss: 0.4743\n",
      "Epoch [8/50], Class Loss: 0.5926, Discrepancy Loss: 0.0392\n",
      "Validation Loss: 0.5857\n",
      "Epoch [9/50], Class Loss: 0.3487, Discrepancy Loss: 0.0596\n",
      "Validation Loss: 0.4335\n",
      "Epoch [10/50], Class Loss: 0.2682, Discrepancy Loss: 0.0644\n",
      "Validation Loss: 0.5495\n",
      "Early stopping!\n",
      "Source Domain Performance - Accuracy: 90.41%, Precision: 91.21%, Recall: 90.63%, F1 Score: 90.57%\n",
      "Target Domain Performance - Accuracy: 56.35%, Precision: 66.68%, Recall: 56.93%, F1 Score: 51.52%\n",
      "\n",
      "Source performance: 92.81% 93.43% 92.99% 92.94%\n",
      "Target performance: 54.75% 62.86% 55.27% 50.66%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 100.00%\n",
      "qpsk: 17.74%\n",
      "16qam: 77.10%\n",
      "16apsk: 26.23%\n",
      "SNR level: 22\n",
      "STAR\n",
      "\n",
      "Run 1/10\n",
      "Epoch [1/50], Class Loss: 2.3555, Discrepancy Loss: 0.1666\n",
      "Epoch [2/50], Class Loss: 1.5675, Discrepancy Loss: 0.1534\n",
      "Epoch [3/50], Class Loss: 1.4347, Discrepancy Loss: 0.1658\n",
      "Epoch [4/50], Class Loss: 1.4180, Discrepancy Loss: 0.1569\n",
      "Epoch [5/50], Class Loss: 1.3277, Discrepancy Loss: 0.1441\n",
      "Epoch [6/50], Class Loss: 0.9107, Discrepancy Loss: 0.1300\n",
      "Epoch [7/50], Class Loss: 0.5116, Discrepancy Loss: 0.1183\n",
      "Epoch [8/50], Class Loss: 0.4250, Discrepancy Loss: 0.1149\n",
      "Epoch [9/50], Class Loss: 0.3550, Discrepancy Loss: 0.1158\n",
      "Epoch [10/50], Class Loss: 0.3544, Discrepancy Loss: 0.1117\n",
      "Epoch [11/50], Class Loss: 0.2531, Discrepancy Loss: 0.1057\n",
      "Epoch [12/50], Class Loss: 0.2260, Discrepancy Loss: 0.1211\n",
      "Epoch [13/50], Class Loss: 0.2156, Discrepancy Loss: 0.1177\n",
      "Epoch [14/50], Class Loss: 0.1942, Discrepancy Loss: 0.1243\n",
      "Epoch [15/50], Class Loss: 0.1746, Discrepancy Loss: 0.1210\n",
      "Epoch [16/50], Class Loss: 0.2186, Discrepancy Loss: 0.1113\n",
      "Epoch [17/50], Class Loss: 0.1891, Discrepancy Loss: 0.1047\n",
      "Epoch [18/50], Class Loss: 0.1852, Discrepancy Loss: 0.0782\n",
      "Epoch [19/50], Class Loss: 0.1740, Discrepancy Loss: 0.0741\n",
      "Epoch [20/50], Class Loss: 0.1823, Discrepancy Loss: 0.0787\n",
      "Epoch [21/50], Class Loss: 0.1510, Discrepancy Loss: 0.0915\n",
      "Epoch [22/50], Class Loss: 0.1514, Discrepancy Loss: 0.0787\n",
      "Epoch [23/50], Class Loss: 0.1449, Discrepancy Loss: 0.0778\n",
      "Epoch [24/50], Class Loss: 0.1701, Discrepancy Loss: 0.0865\n",
      "Epoch [25/50], Class Loss: 0.1486, Discrepancy Loss: 0.0913\n",
      "Epoch [26/50], Class Loss: 0.1619, Discrepancy Loss: 0.0875\n",
      "Epoch [27/50], Class Loss: 0.1547, Discrepancy Loss: 0.0949\n",
      "Epoch [28/50], Class Loss: 0.1533, Discrepancy Loss: 0.0853\n",
      "Epoch [29/50], Class Loss: 0.1351, Discrepancy Loss: 0.0995\n",
      "Epoch [30/50], Class Loss: 0.1300, Discrepancy Loss: 0.0955\n",
      "Epoch [31/50], Class Loss: 0.1314, Discrepancy Loss: 0.0937\n",
      "Epoch [32/50], Class Loss: 0.1289, Discrepancy Loss: 0.0889\n",
      "Epoch [33/50], Class Loss: 0.1398, Discrepancy Loss: 0.0943\n",
      "Epoch [34/50], Class Loss: 0.1388, Discrepancy Loss: 0.0952\n",
      "Epoch [35/50], Class Loss: 0.1270, Discrepancy Loss: 0.0901\n",
      "Epoch [36/50], Class Loss: 0.1262, Discrepancy Loss: 0.0942\n",
      "Epoch [37/50], Class Loss: 0.1303, Discrepancy Loss: 0.0898\n",
      "Epoch [38/50], Class Loss: 0.1399, Discrepancy Loss: 0.0998\n",
      "Epoch [39/50], Class Loss: 0.1387, Discrepancy Loss: 0.0952\n",
      "Epoch [40/50], Class Loss: 0.1540, Discrepancy Loss: 0.0878\n",
      "Epoch [41/50], Class Loss: 0.1279, Discrepancy Loss: 0.0979\n",
      "Epoch [42/50], Class Loss: 0.1288, Discrepancy Loss: 0.0971\n",
      "Epoch [43/50], Class Loss: 0.1331, Discrepancy Loss: 0.0925\n",
      "Epoch [44/50], Class Loss: 0.1287, Discrepancy Loss: 0.0997\n",
      "Epoch [45/50], Class Loss: 0.1322, Discrepancy Loss: 0.0935\n",
      "Epoch [46/50], Class Loss: 0.1352, Discrepancy Loss: 0.0887\n",
      "Epoch [47/50], Class Loss: 0.1267, Discrepancy Loss: 0.0967\n",
      "Epoch [48/50], Class Loss: 0.1310, Discrepancy Loss: 0.0918\n",
      "Epoch [49/50], Class Loss: 0.1310, Discrepancy Loss: 0.0927\n",
      "Epoch [50/50], Class Loss: 0.1323, Discrepancy Loss: 0.0971\n",
      "Source Domain Performance - Accuracy: 89.27%, Precision: 90.61%, Recall: 89.51%, F1 Score: 89.39%\n",
      "Target Domain Performance - Accuracy: 63.67%, Precision: 68.43%, Recall: 64.19%, F1 Score: 64.71%\n",
      "\n",
      "Run 2/10\n",
      "Epoch [1/50], Class Loss: 2.4235, Discrepancy Loss: 0.1456\n",
      "Epoch [2/50], Class Loss: 1.3788, Discrepancy Loss: 0.1760\n",
      "Epoch [3/50], Class Loss: 1.3618, Discrepancy Loss: 0.1749\n",
      "Epoch [4/50], Class Loss: 1.3202, Discrepancy Loss: 0.1569\n",
      "Epoch [5/50], Class Loss: 1.0897, Discrepancy Loss: 0.1310\n",
      "Epoch [6/50], Class Loss: 0.5395, Discrepancy Loss: 0.1182\n",
      "Epoch [7/50], Class Loss: 0.6698, Discrepancy Loss: 0.1149\n",
      "Epoch [8/50], Class Loss: 0.5214, Discrepancy Loss: 0.1059\n",
      "Epoch [9/50], Class Loss: 0.4129, Discrepancy Loss: 0.0782\n",
      "Epoch [10/50], Class Loss: 0.3645, Discrepancy Loss: 0.0679\n",
      "Epoch [11/50], Class Loss: 0.2300, Discrepancy Loss: 0.0569\n",
      "Epoch [12/50], Class Loss: 0.2244, Discrepancy Loss: 0.0482\n",
      "Epoch [13/50], Class Loss: 0.1914, Discrepancy Loss: 0.0534\n",
      "Epoch [14/50], Class Loss: 0.2007, Discrepancy Loss: 0.0578\n",
      "Epoch [15/50], Class Loss: 0.1718, Discrepancy Loss: 0.0557\n",
      "Epoch [16/50], Class Loss: 0.1567, Discrepancy Loss: 0.0531\n",
      "Epoch [17/50], Class Loss: 0.1439, Discrepancy Loss: 0.0566\n",
      "Epoch [18/50], Class Loss: 0.1370, Discrepancy Loss: 0.0599\n",
      "Epoch [19/50], Class Loss: 0.1269, Discrepancy Loss: 0.0635\n",
      "Epoch [20/50], Class Loss: 0.1319, Discrepancy Loss: 0.0762\n",
      "Epoch [21/50], Class Loss: 0.1129, Discrepancy Loss: 0.0981\n",
      "Epoch [22/50], Class Loss: 0.1094, Discrepancy Loss: 0.0985\n",
      "Epoch [23/50], Class Loss: 0.1090, Discrepancy Loss: 0.0949\n",
      "Epoch [24/50], Class Loss: 0.1212, Discrepancy Loss: 0.0995\n",
      "Epoch [25/50], Class Loss: 0.0902, Discrepancy Loss: 0.1121\n",
      "Epoch [26/50], Class Loss: 0.1021, Discrepancy Loss: 0.1154\n",
      "Epoch [27/50], Class Loss: 0.0988, Discrepancy Loss: 0.1209\n",
      "Epoch [28/50], Class Loss: 0.0960, Discrepancy Loss: 0.1352\n",
      "Epoch [29/50], Class Loss: 0.0978, Discrepancy Loss: 0.1302\n",
      "Epoch [30/50], Class Loss: 0.0892, Discrepancy Loss: 0.1352\n",
      "Epoch [31/50], Class Loss: 0.0902, Discrepancy Loss: 0.1325\n",
      "Epoch [32/50], Class Loss: 0.0863, Discrepancy Loss: 0.1334\n",
      "Epoch [33/50], Class Loss: 0.0855, Discrepancy Loss: 0.1313\n",
      "Epoch [34/50], Class Loss: 0.1316, Discrepancy Loss: 0.1358\n",
      "Epoch [35/50], Class Loss: 0.0914, Discrepancy Loss: 0.1284\n",
      "Epoch [36/50], Class Loss: 0.0909, Discrepancy Loss: 0.1365\n",
      "Epoch [37/50], Class Loss: 0.0853, Discrepancy Loss: 0.1406\n",
      "Epoch [38/50], Class Loss: 0.0882, Discrepancy Loss: 0.1410\n",
      "Epoch [39/50], Class Loss: 0.0926, Discrepancy Loss: 0.1485\n",
      "Epoch [40/50], Class Loss: 0.0861, Discrepancy Loss: 0.1369\n",
      "Epoch [41/50], Class Loss: 0.0983, Discrepancy Loss: 0.1389\n",
      "Epoch [42/50], Class Loss: 0.0871, Discrepancy Loss: 0.1367\n",
      "Epoch [43/50], Class Loss: 0.0851, Discrepancy Loss: 0.1493\n",
      "Epoch [44/50], Class Loss: 0.0899, Discrepancy Loss: 0.1407\n",
      "Epoch [45/50], Class Loss: 0.0947, Discrepancy Loss: 0.1434\n",
      "Epoch [46/50], Class Loss: 0.1107, Discrepancy Loss: 0.1356\n",
      "Epoch [47/50], Class Loss: 0.0910, Discrepancy Loss: 0.1442\n",
      "Epoch [48/50], Class Loss: 0.1000, Discrepancy Loss: 0.1448\n",
      "Epoch [49/50], Class Loss: 0.0849, Discrepancy Loss: 0.1390\n",
      "Epoch [50/50], Class Loss: 0.0919, Discrepancy Loss: 0.1503\n",
      "Source Domain Performance - Accuracy: 89.87%, Precision: 91.38%, Recall: 90.04%, F1 Score: 89.95%\n",
      "Target Domain Performance - Accuracy: 67.63%, Precision: 69.15%, Recall: 68.21%, F1 Score: 68.24%\n",
      "\n",
      "Run 3/10\n",
      "Epoch [1/50], Class Loss: 2.3668, Discrepancy Loss: 0.1501\n",
      "Epoch [2/50], Class Loss: 1.5513, Discrepancy Loss: 0.1625\n",
      "Epoch [3/50], Class Loss: 1.4486, Discrepancy Loss: 0.1615\n",
      "Epoch [4/50], Class Loss: 1.4069, Discrepancy Loss: 0.1756\n",
      "Epoch [5/50], Class Loss: 1.3093, Discrepancy Loss: 0.1583\n",
      "Epoch [6/50], Class Loss: 1.0972, Discrepancy Loss: 0.1370\n",
      "Epoch [7/50], Class Loss: 0.5992, Discrepancy Loss: 0.1294\n",
      "Epoch [8/50], Class Loss: 0.3958, Discrepancy Loss: 0.0816\n",
      "Epoch [9/50], Class Loss: 0.3475, Discrepancy Loss: 0.0732\n",
      "Epoch [10/50], Class Loss: 0.3167, Discrepancy Loss: 0.0615\n",
      "Epoch [11/50], Class Loss: 0.2128, Discrepancy Loss: 0.0684\n",
      "Epoch [12/50], Class Loss: 0.1848, Discrepancy Loss: 0.0582\n",
      "Epoch [13/50], Class Loss: 0.1563, Discrepancy Loss: 0.0548\n",
      "Epoch [14/50], Class Loss: 0.1596, Discrepancy Loss: 0.0490\n",
      "Epoch [15/50], Class Loss: 0.1509, Discrepancy Loss: 0.0554\n",
      "Epoch [16/50], Class Loss: 0.1316, Discrepancy Loss: 0.0541\n",
      "Epoch [17/50], Class Loss: 0.1310, Discrepancy Loss: 0.0601\n",
      "Epoch [18/50], Class Loss: 0.1231, Discrepancy Loss: 0.0641\n",
      "Epoch [19/50], Class Loss: 0.1291, Discrepancy Loss: 0.0613\n",
      "Epoch [20/50], Class Loss: 0.1294, Discrepancy Loss: 0.0709\n",
      "Epoch [21/50], Class Loss: 0.0874, Discrepancy Loss: 0.0790\n",
      "Epoch [22/50], Class Loss: 0.0900, Discrepancy Loss: 0.0788\n",
      "Epoch [23/50], Class Loss: 0.0972, Discrepancy Loss: 0.0783\n",
      "Epoch [24/50], Class Loss: 0.0860, Discrepancy Loss: 0.0776\n",
      "Epoch [25/50], Class Loss: 0.0851, Discrepancy Loss: 0.0887\n",
      "Epoch [26/50], Class Loss: 0.0955, Discrepancy Loss: 0.0871\n",
      "Epoch [27/50], Class Loss: 0.0874, Discrepancy Loss: 0.0882\n",
      "Epoch [28/50], Class Loss: 0.0930, Discrepancy Loss: 0.0860\n",
      "Epoch [29/50], Class Loss: 0.0979, Discrepancy Loss: 0.0983\n",
      "Epoch [30/50], Class Loss: 0.0883, Discrepancy Loss: 0.0974\n",
      "Epoch [31/50], Class Loss: 0.0805, Discrepancy Loss: 0.0988\n",
      "Epoch [32/50], Class Loss: 0.0900, Discrepancy Loss: 0.0965\n",
      "Epoch [33/50], Class Loss: 0.0827, Discrepancy Loss: 0.0957\n",
      "Epoch [34/50], Class Loss: 0.0809, Discrepancy Loss: 0.0928\n",
      "Epoch [35/50], Class Loss: 0.0944, Discrepancy Loss: 0.0980\n",
      "Epoch [36/50], Class Loss: 0.0701, Discrepancy Loss: 0.0992\n",
      "Epoch [37/50], Class Loss: 0.0801, Discrepancy Loss: 0.0930\n",
      "Epoch [38/50], Class Loss: 0.0898, Discrepancy Loss: 0.1009\n",
      "Epoch [39/50], Class Loss: 0.0949, Discrepancy Loss: 0.0981\n",
      "Epoch [40/50], Class Loss: 0.0908, Discrepancy Loss: 0.1001\n",
      "Epoch [41/50], Class Loss: 0.0905, Discrepancy Loss: 0.0993\n",
      "Epoch [42/50], Class Loss: 0.0740, Discrepancy Loss: 0.1011\n",
      "Epoch [43/50], Class Loss: 0.1232, Discrepancy Loss: 0.0974\n",
      "Epoch [44/50], Class Loss: 0.0853, Discrepancy Loss: 0.1007\n",
      "Epoch [45/50], Class Loss: 0.0764, Discrepancy Loss: 0.0975\n",
      "Epoch [46/50], Class Loss: 0.0842, Discrepancy Loss: 0.0970\n",
      "Epoch [47/50], Class Loss: 0.0832, Discrepancy Loss: 0.0951\n",
      "Epoch [48/50], Class Loss: 0.0817, Discrepancy Loss: 0.0975\n",
      "Epoch [49/50], Class Loss: 0.0792, Discrepancy Loss: 0.1005\n",
      "Epoch [50/50], Class Loss: 0.0817, Discrepancy Loss: 0.0992\n",
      "Source Domain Performance - Accuracy: 86.69%, Precision: 90.53%, Recall: 86.85%, F1 Score: 86.23%\n",
      "Target Domain Performance - Accuracy: 67.69%, Precision: 71.74%, Recall: 68.21%, F1 Score: 69.20%\n",
      "\n",
      "Run 4/10\n",
      "Epoch [1/50], Class Loss: 2.3276, Discrepancy Loss: 0.1495\n",
      "Epoch [2/50], Class Loss: 1.4495, Discrepancy Loss: 0.1774\n",
      "Epoch [3/50], Class Loss: 1.3776, Discrepancy Loss: 0.1680\n",
      "Epoch [4/50], Class Loss: 1.4714, Discrepancy Loss: 0.1510\n",
      "Epoch [5/50], Class Loss: 1.2460, Discrepancy Loss: 0.1614\n",
      "Epoch [6/50], Class Loss: 1.3187, Discrepancy Loss: 0.1540\n",
      "Epoch [7/50], Class Loss: 1.0894, Discrepancy Loss: 0.1359\n",
      "Epoch [8/50], Class Loss: 0.5750, Discrepancy Loss: 0.1148\n",
      "Epoch [9/50], Class Loss: 0.4676, Discrepancy Loss: 0.1153\n",
      "Epoch [10/50], Class Loss: 0.4501, Discrepancy Loss: 0.1076\n",
      "Epoch [11/50], Class Loss: 0.2879, Discrepancy Loss: 0.0975\n",
      "Epoch [12/50], Class Loss: 0.2447, Discrepancy Loss: 0.0930\n",
      "Epoch [13/50], Class Loss: 0.2396, Discrepancy Loss: 0.0638\n",
      "Epoch [14/50], Class Loss: 0.2283, Discrepancy Loss: 0.0639\n",
      "Epoch [15/50], Class Loss: 0.2331, Discrepancy Loss: 0.0667\n",
      "Epoch [16/50], Class Loss: 0.2360, Discrepancy Loss: 0.0725\n",
      "Epoch [17/50], Class Loss: 0.2251, Discrepancy Loss: 0.0708\n",
      "Epoch [18/50], Class Loss: 0.2024, Discrepancy Loss: 0.0723\n",
      "Epoch [19/50], Class Loss: 0.1727, Discrepancy Loss: 0.0743\n",
      "Epoch [20/50], Class Loss: 0.1621, Discrepancy Loss: 0.0720\n",
      "Epoch [21/50], Class Loss: 0.1310, Discrepancy Loss: 0.0714\n",
      "Epoch [22/50], Class Loss: 0.1392, Discrepancy Loss: 0.0734\n",
      "Epoch [23/50], Class Loss: 0.1456, Discrepancy Loss: 0.0798\n",
      "Epoch [24/50], Class Loss: 0.1325, Discrepancy Loss: 0.0727\n",
      "Epoch [25/50], Class Loss: 0.1262, Discrepancy Loss: 0.0758\n",
      "Epoch [26/50], Class Loss: 0.1187, Discrepancy Loss: 0.0742\n",
      "Epoch [27/50], Class Loss: 0.1203, Discrepancy Loss: 0.0725\n",
      "Epoch [28/50], Class Loss: 0.1252, Discrepancy Loss: 0.0760\n",
      "Epoch [29/50], Class Loss: 0.1208, Discrepancy Loss: 0.0740\n",
      "Epoch [30/50], Class Loss: 0.1295, Discrepancy Loss: 0.0826\n",
      "Epoch [31/50], Class Loss: 0.1250, Discrepancy Loss: 0.0713\n",
      "Epoch [32/50], Class Loss: 0.1205, Discrepancy Loss: 0.0753\n",
      "Epoch [33/50], Class Loss: 0.1172, Discrepancy Loss: 0.0792\n",
      "Epoch [34/50], Class Loss: 0.1137, Discrepancy Loss: 0.0734\n",
      "Epoch [35/50], Class Loss: 0.1223, Discrepancy Loss: 0.0739\n",
      "Epoch [36/50], Class Loss: 0.1172, Discrepancy Loss: 0.0775\n",
      "Epoch [37/50], Class Loss: 0.1090, Discrepancy Loss: 0.0723\n",
      "Epoch [38/50], Class Loss: 0.1129, Discrepancy Loss: 0.0745\n",
      "Epoch [39/50], Class Loss: 0.1120, Discrepancy Loss: 0.0777\n",
      "Epoch [40/50], Class Loss: 0.1073, Discrepancy Loss: 0.0753\n",
      "Epoch [41/50], Class Loss: 0.1064, Discrepancy Loss: 0.0782\n",
      "Epoch [42/50], Class Loss: 0.1088, Discrepancy Loss: 0.0765\n",
      "Epoch [43/50], Class Loss: 0.1181, Discrepancy Loss: 0.0753\n",
      "Epoch [44/50], Class Loss: 0.1100, Discrepancy Loss: 0.0755\n",
      "Epoch [45/50], Class Loss: 0.1193, Discrepancy Loss: 0.0762\n",
      "Epoch [46/50], Class Loss: 0.1114, Discrepancy Loss: 0.0728\n",
      "Epoch [47/50], Class Loss: 0.1109, Discrepancy Loss: 0.0760\n",
      "Epoch [48/50], Class Loss: 0.1131, Discrepancy Loss: 0.0809\n",
      "Epoch [49/50], Class Loss: 0.1143, Discrepancy Loss: 0.0745\n",
      "Epoch [50/50], Class Loss: 0.1163, Discrepancy Loss: 0.0832\n",
      "Source Domain Performance - Accuracy: 93.11%, Precision: 93.96%, Recall: 93.22%, F1 Score: 93.25%\n",
      "Target Domain Performance - Accuracy: 63.85%, Precision: 67.65%, Recall: 64.50%, F1 Score: 64.02%\n",
      "\n",
      "Run 5/10\n",
      "Epoch [1/50], Class Loss: 2.3285, Discrepancy Loss: 0.1469\n",
      "Epoch [2/50], Class Loss: 1.4141, Discrepancy Loss: 0.1666\n",
      "Epoch [3/50], Class Loss: 1.4770, Discrepancy Loss: 0.1570\n",
      "Epoch [4/50], Class Loss: 1.2689, Discrepancy Loss: 0.1536\n",
      "Epoch [5/50], Class Loss: 1.0439, Discrepancy Loss: 0.1291\n",
      "Epoch [6/50], Class Loss: 0.6618, Discrepancy Loss: 0.1148\n",
      "Epoch [7/50], Class Loss: 0.4657, Discrepancy Loss: 0.0837\n",
      "Epoch [8/50], Class Loss: 0.3869, Discrepancy Loss: 0.0807\n",
      "Epoch [9/50], Class Loss: 0.3534, Discrepancy Loss: 0.0666\n",
      "Epoch [10/50], Class Loss: 0.2839, Discrepancy Loss: 0.0652\n",
      "Epoch [11/50], Class Loss: 0.2402, Discrepancy Loss: 0.0601\n",
      "Epoch [12/50], Class Loss: 0.1888, Discrepancy Loss: 0.0589\n",
      "Epoch [13/50], Class Loss: 0.1772, Discrepancy Loss: 0.0591\n",
      "Epoch [14/50], Class Loss: 0.1619, Discrepancy Loss: 0.0622\n",
      "Epoch [15/50], Class Loss: 0.1490, Discrepancy Loss: 0.0674\n",
      "Epoch [16/50], Class Loss: 0.1419, Discrepancy Loss: 0.0650\n",
      "Epoch [17/50], Class Loss: 0.1352, Discrepancy Loss: 0.0635\n",
      "Epoch [18/50], Class Loss: 0.1327, Discrepancy Loss: 0.0660\n",
      "Epoch [19/50], Class Loss: 0.1043, Discrepancy Loss: 0.0693\n",
      "Epoch [20/50], Class Loss: 0.0941, Discrepancy Loss: 0.0608\n",
      "Epoch [21/50], Class Loss: 0.0702, Discrepancy Loss: 0.0673\n",
      "Epoch [22/50], Class Loss: 0.0696, Discrepancy Loss: 0.0695\n",
      "Epoch [23/50], Class Loss: 0.0737, Discrepancy Loss: 0.0694\n",
      "Epoch [24/50], Class Loss: 0.0687, Discrepancy Loss: 0.0727\n",
      "Epoch [25/50], Class Loss: 0.0747, Discrepancy Loss: 0.0750\n",
      "Epoch [26/50], Class Loss: 0.0622, Discrepancy Loss: 0.0742\n",
      "Epoch [27/50], Class Loss: 0.0674, Discrepancy Loss: 0.0778\n",
      "Epoch [28/50], Class Loss: 0.0647, Discrepancy Loss: 0.0745\n",
      "Epoch [29/50], Class Loss: 0.0676, Discrepancy Loss: 0.0805\n",
      "Epoch [30/50], Class Loss: 0.0602, Discrepancy Loss: 0.0814\n",
      "Epoch [31/50], Class Loss: 0.0683, Discrepancy Loss: 0.0842\n",
      "Epoch [32/50], Class Loss: 0.0630, Discrepancy Loss: 0.0827\n",
      "Epoch [33/50], Class Loss: 0.0620, Discrepancy Loss: 0.0795\n",
      "Epoch [34/50], Class Loss: 0.0572, Discrepancy Loss: 0.0782\n",
      "Epoch [35/50], Class Loss: 0.0695, Discrepancy Loss: 0.0743\n",
      "Epoch [36/50], Class Loss: 0.0627, Discrepancy Loss: 0.0836\n",
      "Epoch [37/50], Class Loss: 0.0595, Discrepancy Loss: 0.0778\n",
      "Epoch [38/50], Class Loss: 0.0592, Discrepancy Loss: 0.0830\n",
      "Epoch [39/50], Class Loss: 0.0623, Discrepancy Loss: 0.0814\n",
      "Epoch [40/50], Class Loss: 0.0682, Discrepancy Loss: 0.0768\n",
      "Epoch [41/50], Class Loss: 0.0648, Discrepancy Loss: 0.0801\n",
      "Epoch [42/50], Class Loss: 0.0656, Discrepancy Loss: 0.0847\n",
      "Epoch [43/50], Class Loss: 0.0583, Discrepancy Loss: 0.0798\n",
      "Epoch [44/50], Class Loss: 0.0562, Discrepancy Loss: 0.0797\n",
      "Epoch [45/50], Class Loss: 0.0661, Discrepancy Loss: 0.0850\n",
      "Epoch [46/50], Class Loss: 0.0558, Discrepancy Loss: 0.0858\n",
      "Epoch [47/50], Class Loss: 0.0616, Discrepancy Loss: 0.0845\n",
      "Epoch [48/50], Class Loss: 0.0646, Discrepancy Loss: 0.0808\n",
      "Epoch [49/50], Class Loss: 0.0642, Discrepancy Loss: 0.0861\n",
      "Epoch [50/50], Class Loss: 0.0616, Discrepancy Loss: 0.0786\n",
      "Source Domain Performance - Accuracy: 91.31%, Precision: 91.71%, Recall: 91.53%, F1 Score: 91.51%\n",
      "Target Domain Performance - Accuracy: 68.65%, Precision: 71.14%, Recall: 69.27%, F1 Score: 69.63%\n",
      "\n",
      "Run 6/10\n",
      "Epoch [1/50], Class Loss: 3.2025, Discrepancy Loss: 0.1325\n",
      "Epoch [2/50], Class Loss: 1.5827, Discrepancy Loss: 0.1622\n",
      "Epoch [3/50], Class Loss: 1.4418, Discrepancy Loss: 0.1616\n",
      "Epoch [4/50], Class Loss: 1.3807, Discrepancy Loss: 0.1733\n",
      "Epoch [5/50], Class Loss: 1.4276, Discrepancy Loss: 0.1543\n",
      "Epoch [6/50], Class Loss: 0.9768, Discrepancy Loss: 0.1389\n",
      "Epoch [7/50], Class Loss: 0.5058, Discrepancy Loss: 0.1155\n",
      "Epoch [8/50], Class Loss: 0.4389, Discrepancy Loss: 0.0891\n",
      "Epoch [9/50], Class Loss: 0.3997, Discrepancy Loss: 0.0912\n",
      "Epoch [10/50], Class Loss: 0.3697, Discrepancy Loss: 0.0931\n",
      "Epoch [11/50], Class Loss: 0.2819, Discrepancy Loss: 0.1035\n",
      "Epoch [12/50], Class Loss: 0.2497, Discrepancy Loss: 0.0619\n",
      "Epoch [13/50], Class Loss: 0.2299, Discrepancy Loss: 0.0672\n",
      "Epoch [14/50], Class Loss: 0.2390, Discrepancy Loss: 0.0619\n",
      "Epoch [15/50], Class Loss: 0.2321, Discrepancy Loss: 0.0625\n",
      "Epoch [16/50], Class Loss: 0.2386, Discrepancy Loss: 0.0636\n",
      "Epoch [17/50], Class Loss: 0.2285, Discrepancy Loss: 0.0610\n",
      "Epoch [18/50], Class Loss: 0.2076, Discrepancy Loss: 0.0578\n",
      "Epoch [19/50], Class Loss: 0.2146, Discrepancy Loss: 0.0642\n",
      "Epoch [20/50], Class Loss: 0.1852, Discrepancy Loss: 0.0644\n",
      "Epoch [21/50], Class Loss: 0.1420, Discrepancy Loss: 0.0590\n",
      "Epoch [22/50], Class Loss: 0.1531, Discrepancy Loss: 0.0610\n",
      "Epoch [23/50], Class Loss: 0.1588, Discrepancy Loss: 0.0621\n",
      "Epoch [24/50], Class Loss: 0.1513, Discrepancy Loss: 0.0620\n",
      "Epoch [25/50], Class Loss: 0.1652, Discrepancy Loss: 0.0610\n",
      "Epoch [26/50], Class Loss: 0.1363, Discrepancy Loss: 0.0566\n",
      "Epoch [27/50], Class Loss: 0.1426, Discrepancy Loss: 0.0662\n",
      "Epoch [28/50], Class Loss: 0.1339, Discrepancy Loss: 0.0688\n",
      "Epoch [29/50], Class Loss: 0.1456, Discrepancy Loss: 0.0698\n",
      "Epoch [30/50], Class Loss: 0.1431, Discrepancy Loss: 0.0676\n",
      "Epoch [31/50], Class Loss: 0.1380, Discrepancy Loss: 0.0686\n",
      "Epoch [32/50], Class Loss: 0.1486, Discrepancy Loss: 0.0684\n",
      "Epoch [33/50], Class Loss: 0.1252, Discrepancy Loss: 0.0748\n",
      "Epoch [34/50], Class Loss: 0.1289, Discrepancy Loss: 0.0699\n",
      "Epoch [35/50], Class Loss: 0.1323, Discrepancy Loss: 0.0771\n",
      "Epoch [36/50], Class Loss: 0.1272, Discrepancy Loss: 0.0767\n",
      "Epoch [37/50], Class Loss: 0.1381, Discrepancy Loss: 0.0773\n",
      "Epoch [38/50], Class Loss: 0.1405, Discrepancy Loss: 0.0752\n",
      "Epoch [39/50], Class Loss: 0.1468, Discrepancy Loss: 0.0764\n",
      "Epoch [40/50], Class Loss: 0.1365, Discrepancy Loss: 0.0726\n",
      "Epoch [41/50], Class Loss: 0.1303, Discrepancy Loss: 0.0738\n",
      "Epoch [42/50], Class Loss: 0.1395, Discrepancy Loss: 0.0764\n",
      "Epoch [43/50], Class Loss: 0.1267, Discrepancy Loss: 0.0729\n",
      "Epoch [44/50], Class Loss: 0.1357, Discrepancy Loss: 0.0679\n",
      "Epoch [45/50], Class Loss: 0.1540, Discrepancy Loss: 0.0755\n",
      "Epoch [46/50], Class Loss: 0.1311, Discrepancy Loss: 0.0756\n",
      "Epoch [47/50], Class Loss: 0.1352, Discrepancy Loss: 0.0760\n",
      "Epoch [48/50], Class Loss: 0.1445, Discrepancy Loss: 0.0739\n",
      "Epoch [49/50], Class Loss: 0.1294, Discrepancy Loss: 0.0768\n",
      "Epoch [50/50], Class Loss: 0.1370, Discrepancy Loss: 0.0665\n",
      "Source Domain Performance - Accuracy: 88.79%, Precision: 90.55%, Recall: 89.01%, F1 Score: 88.84%\n",
      "Target Domain Performance - Accuracy: 70.44%, Precision: 72.28%, Recall: 71.04%, F1 Score: 71.48%\n",
      "\n",
      "Run 7/10\n",
      "Epoch [1/50], Class Loss: 2.4633, Discrepancy Loss: 0.1411\n",
      "Epoch [2/50], Class Loss: 1.4598, Discrepancy Loss: 0.1697\n",
      "Epoch [3/50], Class Loss: 1.4326, Discrepancy Loss: 0.1498\n",
      "Epoch [4/50], Class Loss: 1.3493, Discrepancy Loss: 0.1595\n",
      "Epoch [5/50], Class Loss: 1.2020, Discrepancy Loss: 0.1360\n",
      "Epoch [6/50], Class Loss: 0.5735, Discrepancy Loss: 0.1157\n",
      "Epoch [7/50], Class Loss: 0.4272, Discrepancy Loss: 0.1134\n",
      "Epoch [8/50], Class Loss: 0.3817, Discrepancy Loss: 0.0796\n",
      "Epoch [9/50], Class Loss: 0.3292, Discrepancy Loss: 0.0621\n",
      "Epoch [10/50], Class Loss: 0.2749, Discrepancy Loss: 0.0675\n",
      "Epoch [11/50], Class Loss: 0.1697, Discrepancy Loss: 0.0584\n",
      "Epoch [12/50], Class Loss: 0.1888, Discrepancy Loss: 0.0555\n",
      "Epoch [13/50], Class Loss: 0.1449, Discrepancy Loss: 0.0542\n",
      "Epoch [14/50], Class Loss: 0.1233, Discrepancy Loss: 0.0505\n",
      "Epoch [15/50], Class Loss: 0.1169, Discrepancy Loss: 0.0568\n",
      "Epoch [16/50], Class Loss: 0.1073, Discrepancy Loss: 0.0496\n",
      "Epoch [17/50], Class Loss: 0.1102, Discrepancy Loss: 0.0539\n",
      "Epoch [18/50], Class Loss: 0.0979, Discrepancy Loss: 0.0679\n",
      "Epoch [19/50], Class Loss: 0.1002, Discrepancy Loss: 0.0760\n",
      "Epoch [20/50], Class Loss: 0.1026, Discrepancy Loss: 0.0790\n",
      "Epoch [21/50], Class Loss: 0.0740, Discrepancy Loss: 0.0814\n",
      "Epoch [22/50], Class Loss: 0.0717, Discrepancy Loss: 0.0762\n",
      "Epoch [23/50], Class Loss: 0.0677, Discrepancy Loss: 0.0858\n",
      "Epoch [24/50], Class Loss: 0.0645, Discrepancy Loss: 0.0835\n",
      "Epoch [25/50], Class Loss: 0.0607, Discrepancy Loss: 0.0807\n",
      "Epoch [26/50], Class Loss: 0.0586, Discrepancy Loss: 0.0792\n",
      "Epoch [27/50], Class Loss: 0.0632, Discrepancy Loss: 0.0866\n",
      "Epoch [28/50], Class Loss: 0.0545, Discrepancy Loss: 0.0853\n",
      "Epoch [29/50], Class Loss: 0.0565, Discrepancy Loss: 0.0862\n",
      "Epoch [30/50], Class Loss: 0.0595, Discrepancy Loss: 0.0861\n",
      "Epoch [31/50], Class Loss: 0.0543, Discrepancy Loss: 0.0860\n",
      "Epoch [32/50], Class Loss: 0.0617, Discrepancy Loss: 0.0894\n",
      "Epoch [33/50], Class Loss: 0.0525, Discrepancy Loss: 0.0921\n",
      "Epoch [34/50], Class Loss: 0.0479, Discrepancy Loss: 0.0853\n",
      "Epoch [35/50], Class Loss: 0.0507, Discrepancy Loss: 0.0828\n",
      "Epoch [36/50], Class Loss: 0.0612, Discrepancy Loss: 0.0885\n",
      "Epoch [37/50], Class Loss: 0.0536, Discrepancy Loss: 0.0848\n",
      "Epoch [38/50], Class Loss: 0.0615, Discrepancy Loss: 0.0838\n",
      "Epoch [39/50], Class Loss: 0.0577, Discrepancy Loss: 0.0904\n",
      "Epoch [40/50], Class Loss: 0.0489, Discrepancy Loss: 0.0900\n",
      "Epoch [41/50], Class Loss: 0.0589, Discrepancy Loss: 0.0864\n",
      "Epoch [42/50], Class Loss: 0.0511, Discrepancy Loss: 0.0873\n",
      "Epoch [43/50], Class Loss: 0.0576, Discrepancy Loss: 0.0877\n",
      "Epoch [44/50], Class Loss: 0.0489, Discrepancy Loss: 0.0863\n",
      "Epoch [45/50], Class Loss: 0.0554, Discrepancy Loss: 0.0833\n",
      "Epoch [46/50], Class Loss: 0.0484, Discrepancy Loss: 0.0872\n",
      "Epoch [47/50], Class Loss: 0.0513, Discrepancy Loss: 0.0854\n",
      "Epoch [48/50], Class Loss: 0.0586, Discrepancy Loss: 0.0874\n",
      "Epoch [49/50], Class Loss: 0.0559, Discrepancy Loss: 0.0860\n",
      "Epoch [50/50], Class Loss: 0.0591, Discrepancy Loss: 0.0907\n",
      "Source Domain Performance - Accuracy: 87.65%, Precision: 91.22%, Recall: 87.79%, F1 Score: 87.22%\n",
      "Target Domain Performance - Accuracy: 62.53%, Precision: 65.54%, Recall: 63.18%, F1 Score: 62.61%\n",
      "\n",
      "Run 8/10\n",
      "Epoch [1/50], Class Loss: 2.3046, Discrepancy Loss: 0.1677\n",
      "Epoch [2/50], Class Loss: 1.5421, Discrepancy Loss: 0.1809\n",
      "Epoch [3/50], Class Loss: 1.4972, Discrepancy Loss: 0.1760\n",
      "Epoch [4/50], Class Loss: 2.1879, Discrepancy Loss: 0.1260\n",
      "Epoch [5/50], Class Loss: 0.9873, Discrepancy Loss: 0.1011\n",
      "Epoch [6/50], Class Loss: 1.3761, Discrepancy Loss: 0.1378\n",
      "Epoch [7/50], Class Loss: 1.0211, Discrepancy Loss: 0.1242\n",
      "Epoch [8/50], Class Loss: 0.4907, Discrepancy Loss: 0.1059\n",
      "Epoch [9/50], Class Loss: 0.3755, Discrepancy Loss: 0.0802\n",
      "Epoch [10/50], Class Loss: 0.4186, Discrepancy Loss: 0.0665\n",
      "Epoch [11/50], Class Loss: 0.3900, Discrepancy Loss: 0.1145\n",
      "Epoch [12/50], Class Loss: 0.2596, Discrepancy Loss: 0.1113\n",
      "Epoch [13/50], Class Loss: 0.2322, Discrepancy Loss: 0.1079\n",
      "Epoch [14/50], Class Loss: 0.2066, Discrepancy Loss: 0.1117\n",
      "Epoch [15/50], Class Loss: 0.2210, Discrepancy Loss: 0.1036\n",
      "Epoch [16/50], Class Loss: 0.1713, Discrepancy Loss: 0.1130\n",
      "Epoch [17/50], Class Loss: 0.1515, Discrepancy Loss: 0.1115\n",
      "Epoch [18/50], Class Loss: 0.1566, Discrepancy Loss: 0.1135\n",
      "Epoch [19/50], Class Loss: 0.1415, Discrepancy Loss: 0.1096\n",
      "Epoch [20/50], Class Loss: 0.1465, Discrepancy Loss: 0.1008\n",
      "Epoch [21/50], Class Loss: 0.1396, Discrepancy Loss: 0.0906\n",
      "Epoch [22/50], Class Loss: 0.1357, Discrepancy Loss: 0.0934\n",
      "Epoch [23/50], Class Loss: 0.1362, Discrepancy Loss: 0.0950\n",
      "Epoch [24/50], Class Loss: 0.1198, Discrepancy Loss: 0.1017\n",
      "Epoch [25/50], Class Loss: 0.1329, Discrepancy Loss: 0.1015\n",
      "Epoch [26/50], Class Loss: 0.1300, Discrepancy Loss: 0.0940\n",
      "Epoch [27/50], Class Loss: 0.1275, Discrepancy Loss: 0.1032\n",
      "Epoch [28/50], Class Loss: 0.1367, Discrepancy Loss: 0.1108\n",
      "Epoch [29/50], Class Loss: 0.1216, Discrepancy Loss: 0.1120\n",
      "Epoch [30/50], Class Loss: 0.1206, Discrepancy Loss: 0.1134\n",
      "Epoch [31/50], Class Loss: 0.1283, Discrepancy Loss: 0.1187\n",
      "Epoch [32/50], Class Loss: 0.1151, Discrepancy Loss: 0.1079\n",
      "Epoch [33/50], Class Loss: 0.1201, Discrepancy Loss: 0.1103\n",
      "Epoch [34/50], Class Loss: 0.1155, Discrepancy Loss: 0.1098\n",
      "Epoch [35/50], Class Loss: 0.1178, Discrepancy Loss: 0.1129\n",
      "Epoch [36/50], Class Loss: 0.1191, Discrepancy Loss: 0.1097\n",
      "Epoch [37/50], Class Loss: 0.1158, Discrepancy Loss: 0.1077\n",
      "Epoch [38/50], Class Loss: 0.1191, Discrepancy Loss: 0.1190\n",
      "Epoch [39/50], Class Loss: 0.1241, Discrepancy Loss: 0.1169\n",
      "Epoch [40/50], Class Loss: 0.1211, Discrepancy Loss: 0.1100\n",
      "Epoch [41/50], Class Loss: 0.1183, Discrepancy Loss: 0.1154\n",
      "Epoch [42/50], Class Loss: 0.1293, Discrepancy Loss: 0.1111\n",
      "Epoch [43/50], Class Loss: 0.1248, Discrepancy Loss: 0.1158\n",
      "Epoch [44/50], Class Loss: 0.1147, Discrepancy Loss: 0.1185\n",
      "Epoch [45/50], Class Loss: 0.1064, Discrepancy Loss: 0.1069\n",
      "Epoch [46/50], Class Loss: 0.1176, Discrepancy Loss: 0.1034\n",
      "Epoch [47/50], Class Loss: 0.1262, Discrepancy Loss: 0.1145\n",
      "Epoch [48/50], Class Loss: 0.1231, Discrepancy Loss: 0.1106\n",
      "Epoch [49/50], Class Loss: 0.1079, Discrepancy Loss: 0.1111\n",
      "Epoch [50/50], Class Loss: 0.1180, Discrepancy Loss: 0.1141\n",
      "Source Domain Performance - Accuracy: 87.11%, Precision: 90.69%, Recall: 87.29%, F1 Score: 86.81%\n",
      "Target Domain Performance - Accuracy: 63.79%, Precision: 67.36%, Recall: 64.34%, F1 Score: 64.02%\n",
      "\n",
      "Run 9/10\n",
      "Epoch [1/50], Class Loss: 2.4175, Discrepancy Loss: 0.1647\n",
      "Epoch [2/50], Class Loss: 1.6789, Discrepancy Loss: 0.1634\n",
      "Epoch [3/50], Class Loss: 1.3478, Discrepancy Loss: 0.1534\n",
      "Epoch [4/50], Class Loss: 1.2951, Discrepancy Loss: 0.1568\n",
      "Epoch [5/50], Class Loss: 1.2618, Discrepancy Loss: 0.1685\n",
      "Epoch [6/50], Class Loss: 0.7435, Discrepancy Loss: 0.1422\n",
      "Epoch [7/50], Class Loss: 0.4998, Discrepancy Loss: 0.1034\n",
      "Epoch [8/50], Class Loss: 0.4514, Discrepancy Loss: 0.0894\n",
      "Epoch [9/50], Class Loss: 0.3628, Discrepancy Loss: 0.0876\n",
      "Epoch [10/50], Class Loss: 0.3532, Discrepancy Loss: 0.0725\n",
      "Epoch [11/50], Class Loss: 0.3613, Discrepancy Loss: 0.0710\n",
      "Epoch [12/50], Class Loss: 0.3283, Discrepancy Loss: 0.0650\n",
      "Epoch [13/50], Class Loss: 0.2779, Discrepancy Loss: 0.0587\n",
      "Epoch [14/50], Class Loss: 0.2590, Discrepancy Loss: 0.0637\n",
      "Epoch [15/50], Class Loss: 0.2172, Discrepancy Loss: 0.0579\n",
      "Epoch [16/50], Class Loss: 0.1839, Discrepancy Loss: 0.0547\n",
      "Epoch [17/50], Class Loss: 0.1704, Discrepancy Loss: 0.0602\n",
      "Epoch [18/50], Class Loss: 0.1477, Discrepancy Loss: 0.0611\n",
      "Epoch [19/50], Class Loss: 0.1554, Discrepancy Loss: 0.0651\n",
      "Epoch [20/50], Class Loss: 0.1380, Discrepancy Loss: 0.0667\n",
      "Epoch [21/50], Class Loss: 0.1092, Discrepancy Loss: 0.0652\n",
      "Epoch [22/50], Class Loss: 0.1119, Discrepancy Loss: 0.0690\n",
      "Epoch [23/50], Class Loss: 0.1001, Discrepancy Loss: 0.0715\n",
      "Epoch [24/50], Class Loss: 0.1009, Discrepancy Loss: 0.0715\n",
      "Epoch [25/50], Class Loss: 0.1009, Discrepancy Loss: 0.0688\n",
      "Epoch [26/50], Class Loss: 0.1041, Discrepancy Loss: 0.0714\n",
      "Epoch [27/50], Class Loss: 0.0986, Discrepancy Loss: 0.0734\n",
      "Epoch [28/50], Class Loss: 0.0920, Discrepancy Loss: 0.0779\n",
      "Epoch [29/50], Class Loss: 0.0932, Discrepancy Loss: 0.0831\n",
      "Epoch [30/50], Class Loss: 0.0904, Discrepancy Loss: 0.0807\n",
      "Epoch [31/50], Class Loss: 0.0905, Discrepancy Loss: 0.0780\n",
      "Epoch [32/50], Class Loss: 0.0878, Discrepancy Loss: 0.0830\n",
      "Epoch [33/50], Class Loss: 0.0947, Discrepancy Loss: 0.0813\n",
      "Epoch [34/50], Class Loss: 0.0928, Discrepancy Loss: 0.0819\n",
      "Epoch [35/50], Class Loss: 0.0956, Discrepancy Loss: 0.0821\n",
      "Epoch [36/50], Class Loss: 0.0838, Discrepancy Loss: 0.0813\n",
      "Epoch [37/50], Class Loss: 0.0868, Discrepancy Loss: 0.0832\n",
      "Epoch [38/50], Class Loss: 0.0961, Discrepancy Loss: 0.0830\n",
      "Epoch [39/50], Class Loss: 0.1010, Discrepancy Loss: 0.0794\n",
      "Epoch [40/50], Class Loss: 0.0972, Discrepancy Loss: 0.0857\n",
      "Epoch [41/50], Class Loss: 0.0909, Discrepancy Loss: 0.0830\n",
      "Epoch [42/50], Class Loss: 0.0853, Discrepancy Loss: 0.0755\n",
      "Epoch [43/50], Class Loss: 0.0935, Discrepancy Loss: 0.0817\n",
      "Epoch [44/50], Class Loss: 0.1168, Discrepancy Loss: 0.0787\n",
      "Epoch [45/50], Class Loss: 0.1183, Discrepancy Loss: 0.0841\n",
      "Epoch [46/50], Class Loss: 0.0844, Discrepancy Loss: 0.0800\n",
      "Epoch [47/50], Class Loss: 0.0818, Discrepancy Loss: 0.0802\n",
      "Epoch [48/50], Class Loss: 0.0859, Discrepancy Loss: 0.0785\n",
      "Epoch [49/50], Class Loss: 0.0946, Discrepancy Loss: 0.0833\n",
      "Epoch [50/50], Class Loss: 0.0852, Discrepancy Loss: 0.0878\n",
      "Source Domain Performance - Accuracy: 88.49%, Precision: 89.73%, Recall: 88.74%, F1 Score: 88.57%\n",
      "Target Domain Performance - Accuracy: 69.18%, Precision: 71.90%, Recall: 69.72%, F1 Score: 70.30%\n",
      "\n",
      "Run 10/10\n",
      "Epoch [1/50], Class Loss: 2.6259, Discrepancy Loss: 0.1466\n",
      "Epoch [2/50], Class Loss: 1.5552, Discrepancy Loss: 0.1604\n",
      "Epoch [3/50], Class Loss: 1.3910, Discrepancy Loss: 0.1608\n",
      "Epoch [4/50], Class Loss: 1.3230, Discrepancy Loss: 0.1646\n",
      "Epoch [5/50], Class Loss: 1.3512, Discrepancy Loss: 0.1418\n",
      "Epoch [6/50], Class Loss: 1.1537, Discrepancy Loss: 0.1418\n",
      "Epoch [7/50], Class Loss: 0.6534, Discrepancy Loss: 0.1234\n",
      "Epoch [8/50], Class Loss: 0.4111, Discrepancy Loss: 0.1002\n",
      "Epoch [9/50], Class Loss: 0.4002, Discrepancy Loss: 0.0724\n",
      "Epoch [10/50], Class Loss: 1.3881, Discrepancy Loss: 0.1296\n",
      "Epoch [11/50], Class Loss: 1.1372, Discrepancy Loss: 0.1308\n",
      "Epoch [12/50], Class Loss: 1.2167, Discrepancy Loss: 0.1260\n",
      "Epoch [13/50], Class Loss: 1.1300, Discrepancy Loss: 0.1352\n",
      "Epoch [14/50], Class Loss: 1.1163, Discrepancy Loss: 0.1372\n",
      "Epoch [15/50], Class Loss: 1.0830, Discrepancy Loss: 0.1436\n",
      "Epoch [16/50], Class Loss: 1.0855, Discrepancy Loss: 0.1334\n",
      "Epoch [17/50], Class Loss: 1.1001, Discrepancy Loss: 0.1266\n",
      "Epoch [18/50], Class Loss: 1.0353, Discrepancy Loss: 0.1367\n",
      "Epoch [19/50], Class Loss: 0.8445, Discrepancy Loss: 0.1535\n",
      "Epoch [20/50], Class Loss: 0.6666, Discrepancy Loss: 0.1430\n",
      "Epoch [21/50], Class Loss: 0.6290, Discrepancy Loss: 0.1435\n",
      "Epoch [22/50], Class Loss: 0.6181, Discrepancy Loss: 0.1521\n",
      "Epoch [23/50], Class Loss: 0.6952, Discrepancy Loss: 0.1468\n",
      "Epoch [24/50], Class Loss: 0.6514, Discrepancy Loss: 0.1509\n",
      "Epoch [25/50], Class Loss: 0.6414, Discrepancy Loss: 0.1494\n",
      "Epoch [26/50], Class Loss: 0.6570, Discrepancy Loss: 0.1516\n",
      "Epoch [27/50], Class Loss: 0.5803, Discrepancy Loss: 0.1453\n",
      "Epoch [28/50], Class Loss: 0.5885, Discrepancy Loss: 0.1500\n",
      "Epoch [29/50], Class Loss: 0.5885, Discrepancy Loss: 0.1499\n",
      "Epoch [30/50], Class Loss: 0.5718, Discrepancy Loss: 0.1601\n",
      "Epoch [31/50], Class Loss: 0.5439, Discrepancy Loss: 0.1392\n",
      "Epoch [32/50], Class Loss: 0.5415, Discrepancy Loss: 0.1442\n",
      "Epoch [33/50], Class Loss: 0.5395, Discrepancy Loss: 0.1510\n",
      "Epoch [34/50], Class Loss: 0.5720, Discrepancy Loss: 0.1510\n",
      "Epoch [35/50], Class Loss: 0.5705, Discrepancy Loss: 0.1421\n",
      "Epoch [36/50], Class Loss: 0.5357, Discrepancy Loss: 0.1531\n",
      "Epoch [37/50], Class Loss: 0.5335, Discrepancy Loss: 0.1443\n",
      "Epoch [38/50], Class Loss: 0.5332, Discrepancy Loss: 0.1440\n",
      "Epoch [39/50], Class Loss: 0.5414, Discrepancy Loss: 0.1542\n",
      "Epoch [40/50], Class Loss: 0.5599, Discrepancy Loss: 0.1455\n",
      "Epoch [41/50], Class Loss: 0.5624, Discrepancy Loss: 0.1585\n",
      "Epoch [42/50], Class Loss: 0.5238, Discrepancy Loss: 0.1558\n",
      "Epoch [43/50], Class Loss: 0.5381, Discrepancy Loss: 0.1440\n",
      "Epoch [44/50], Class Loss: 0.5311, Discrepancy Loss: 0.1547\n",
      "Epoch [45/50], Class Loss: 0.5498, Discrepancy Loss: 0.1441\n",
      "Epoch [46/50], Class Loss: 0.5399, Discrepancy Loss: 0.1498\n",
      "Epoch [47/50], Class Loss: 0.5466, Discrepancy Loss: 0.1510\n",
      "Epoch [48/50], Class Loss: 0.5421, Discrepancy Loss: 0.1357\n",
      "Epoch [49/50], Class Loss: 0.5270, Discrepancy Loss: 0.1411\n",
      "Epoch [50/50], Class Loss: 0.5313, Discrepancy Loss: 0.1462\n",
      "Source Domain Performance - Accuracy: 56.59%, Precision: 62.55%, Recall: 57.76%, F1 Score: 49.87%\n",
      "Target Domain Performance - Accuracy: 49.82%, Precision: 58.96%, Recall: 50.13%, F1 Score: 44.54%\n",
      "\n",
      "Source performance: 85.89% 88.29% 86.17% 85.17%\n",
      "Target performance: 64.72% 68.42% 65.28% 64.87%\n",
      "\n",
      "Per-Class Accuracy on Target Domain:\n",
      "bpsk: 99.85%\n",
      "qpsk: 57.50%\n",
      "16qam: 62.33%\n",
      "16apsk: 41.44%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load testbed data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "file_path = \"/home/ash/ic3/testbed_da/data\"\n",
    "\n",
    "# Classes in loaded npy files\n",
    "class_subset = [\"bpsk\", \"qpsk\", \"16qam\", \"16apsk\"]\n",
    "\n",
    "# simulated data\n",
    "X_sim = np.load(file_path + \"/sim_X.npy\")\n",
    "Y_sim = np.load(file_path + \"/sim_Y.npy\")\n",
    "\n",
    "# over the air data\n",
    "X_ota = np.load(file_path + \"/ota_X.npy\")\n",
    "Y_ota = np.load(file_path + \"/ota_Y.npy\")\n",
    "\n",
    "z_val = 10\n",
    "n_epochs = 50\n",
    "lr = 0.001\n",
    "n_runs = 10\n",
    "n_snr = 4\n",
    "\n",
    "t_base_acc = []\n",
    "t_dann_acc = []\n",
    "t_star_acc = []\n",
    "t_mcd_acc = []\n",
    "t_coral_acc = []\n",
    "t_jan_acc = []\n",
    "\n",
    "s_base_acc = []\n",
    "s_dann_acc = []\n",
    "s_star_acc = []\n",
    "s_mcd_acc = []\n",
    "s_coral_acc = []\n",
    "s_jan_acc = []\n",
    "\n",
    "for i in range(n_snr):\n",
    "    print(f'SNR level: {z_val}')\n",
    "    # Filter for SNR level\n",
    "    source_mask = (Y_sim[:, 1] == z_val)\n",
    "    X_s = X_sim[source_mask]\n",
    "    Y_s = Y_sim[source_mask]\n",
    "    Y_s = Y_s[:,0]\n",
    "\n",
    "    source_mask = (Y_ota[:, 1] == z_val+4)\n",
    "    X_t = X_ota[source_mask]\n",
    "    Y_t = Y_ota[source_mask]\n",
    "    Y_t = Y_t[:,0]\n",
    "    \n",
    "    S_train_loader, S_val_loader = funcs.create_loader(X_s, Y_s, permute=False)\n",
    "    T_train_loader, T_val_loader = funcs.create_loader(X_t, Y_t, permute=False)\n",
    "\n",
    "    print(f'SNR level: {z_val}')\n",
    "    print('CORAL')\n",
    "    s_coral, t_coral = coral.Coral(G=CORAL_G, C=CORAL_C, device=device, S_train_loader=S_train_loader,\n",
    "                           S_val_loader=S_val_loader, T_train_loader=T_train_loader, T_val_loader=T_val_loader,\n",
    "                           class_subset=class_subset, n_classes=len(class_subset), lr=lr, n_epochs=n_epochs, n_runs=n_runs,\n",
    "                           patience=5, lambda_coral=0.5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_coral_acc.append(s_coral)\n",
    "    t_coral_acc.append(t_coral)\n",
    "\n",
    "    print(f'SNR level: {z_val}')\n",
    "    print('JAN')\n",
    "    s_jan, t_jan = jan.Jan(num_classes=len(class_subset), device=device, S_train_loader=S_train_loader,\n",
    "                     T_train_loader=T_train_loader, S_val_loader=S_val_loader, T_val_loader=T_val_loader,\n",
    "                     n_epochs=n_epochs, lr=lr, lambda_jmmd=0.1, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_jan_acc.append(s_jan)\n",
    "    t_jan_acc.append(t_jan)\n",
    "\n",
    "    print(f'SNR level: {z_val}')\n",
    "    print('BASE')\n",
    "    s_base, t_base = base.Base(model_cls=CLDNN, device=device, S_train_loader=S_train_loader, \n",
    "                    S_val_loader=S_val_loader, T_val_loader=T_val_loader, class_subset=class_subset, \n",
    "                    n_classes=len(class_subset), lr=lr, n_epochs=n_epochs, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_base_acc.append(s_base)\n",
    "    t_base_acc.append(t_base)\n",
    "\n",
    "    print(f'SNR level: {z_val}')\n",
    "    print('DANN')\n",
    "    s_dann, t_dann = dann.DAN(dann.DANN, FA=CLDNN_FA, LP=CLDNN_LP, DC=CLDNN_DC,\n",
    "                      device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,\n",
    "                      T_train_loader=T_train_loader, T_val_loader=T_val_loader,\n",
    "                      class_subset=class_subset, n_classes=len(class_subset), lr=lr,\n",
    "                      n_epochs=n_epochs, n_runs=n_runs).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_dann_acc.append(s_dann)\n",
    "    t_dann_acc.append(t_dann)\n",
    "\n",
    "    s_mcd, t_mcd = mcd.Mcd(G=MCD_G, C=MCD_C, device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,  \n",
    "               T_train_loader=T_train_loader, T_val_loader=T_val_loader, class_subset=class_subset,\n",
    "               n_classes=len(class_subset), lr=lr, n_epochs=50, n_runs=n_runs, patience=5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_mcd_acc.append(s_mcd)\n",
    "    t_mcd_acc.append(t_mcd)\n",
    "\n",
    "    print(f'SNR level: {z_val}')\n",
    "    print('STAR')\n",
    "    s_star, t_star = star.Star(G=STAR_G, C=STAR_C, device=device, S_train_loader=S_train_loader, S_val_loader=S_val_loader,  \n",
    "                   T_train_loader=T_train_loader, T_val_loader=T_val_loader, class_subset=class_subset,\n",
    "                   n_classes=len(class_subset), lr=lr, n_epochs=n_epochs, n_runs=n_runs, patience=5).run()\n",
    "    torch.cuda.empty_cache()\n",
    "    s_star_acc.append(s_star)\n",
    "    t_star_acc.append(t_star)\n",
    "\n",
    "    z_val += 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129ad27a-d1f2-4acb-8563-e586c61cc2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(1, n_snr+1)\n",
    "print(len(t_base_acc))\n",
    "print(len(x))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, t_base_acc, marker='o', linestyle='-', label='Base')\n",
    "plt.plot(x, t_dann_acc, marker='s', linestyle='--', label='Dann')\n",
    "plt.plot(x, t_star_acc, marker='^', linestyle='--', label='Star')\n",
    "plt.plot(x, t_mcd_acc, marker='D', linestyle='--', label='MCD')\n",
    "plt.plot(x, t_coral_acc, marker='v', linestyle='--', label='CORAL')\n",
    "plt.plot(x, t_jan_acc, marker='x', linestyle='--', label='JANN')\n",
    "\n",
    "\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Acc (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce363d8-84a5-4974-9f76-a0bad753fa24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
